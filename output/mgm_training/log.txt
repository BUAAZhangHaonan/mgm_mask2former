[08/30 15:01:15] detectron2 INFO: Rank of current process: 0. World size: 1
[08/30 15:01:16] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:43:55) [GCC 13.3.0]
numpy                            2.2.6
detectron2                       0.6 @/home/fuyx/hch/detectron2/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6, 8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   575.64.03
CUDA_HOME                        /home/fuyx/anaconda3/envs/m2f
Pillow                           11.3.0
torchvision                      0.20.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[08/30 15:01:16] detectron2 INFO: Command line arguments: Namespace(config_file='MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=['OUTPUT_DIR', './output/mgm_training'])
[08/30 15:01:16] detectron2 INFO: Contents of args.config_file=MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml:
MODEL:
  META_ARCHITECTURE: "MGMMaskFormer"

  # RGB Backbone: Swin Transformer Tiny
  RGB_BACKBONE:
    NAME: "D2SwinTransformer"
    WEIGHTS: ""
    SWIN:
      EMBED_DIM: 96
      DEPTHS: [2, 2, 6, 2]
      NUM_HEADS: [3, 6, 12, 24]
      WINDOW_SIZE: 7
      APE: False
      DROP_PATH_RATE: 0.3
      PATCH_NORM: True
      OUT_FEATURES: ["res2", "res3", "res4", "res5"]

  # Depth Backbone: ConvNeXt Tiny
  DEPTH_BACKBONE:
    NAME: "ConvNeXtDepthBackbone"
    WEIGHTS: ""
    CONVNEXT:
      DEPTHS: [3, 3, 9, 3]
      DIMS: [96, 192, 384, 768]
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1e-6

  # MGM Fusion Configuration
  MGM:
    ENABLED: True
    SHARED: True
    RESIDUAL_ALPHA: 0.05
    POST_FUSE_NORM: True              # 新增：融合后GN
    LOSS_ENTROPY_W: 0.01
    TEMP_INIT: 1.5
    TEMP_FINAL: 1.0
    TEMP_STEPS: 3000                  # 建议略短，收敛更快
    CLAMP_MIN: 0.05
    CLAMP_MAX: 0.95
    NOISE_MASK_WEIGHT: 0.0            # 前期建议关；有噪声掩码再开到0.05~0.1
    HIDDEN_DIM: 256
    FEATURE_DIMS: [96, 192, 384, 768]
    SCALE_KEYS: ["res2", "res3", "res4", "res5"]

    PRIOR:
      ENABLED: False                   # 总开关
      USE_GRADIENT: True              # 先验逐项开关
      USE_VARIANCE: True
      USE_VALID_HOLE: True
      USE_RGB_EDGE: False             # 前期建议关（最耗时）
      VAR_KERNEL: 5
      Z_MIN: 0.0
      Z_MAX: 1.0
      COMPUTE_ON: "res3"              # "full"|"res2"|"res3"|"res4"|"res5"；前期建议用res3提速

    ROBUST_NORM:
      ENABLED: False                  # 前期建议关；要稳健再开
      METHOD: "minmax"                # "minmax"|"quantile"


  # DPE Configuration
  DPE:
    ENABLED: True

  # Boundary Configuration
  BOUNDARY:
    ENABLED: False

  # RGB Input Pixel Mean/Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]

  # Semantic Segmentation Head
  SEM_SEG_HEAD:
    NAME: "MGMHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 1
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MGMMSDeformAttnPixelDecoder"
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6

  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MGMMultiScaleMaskedTransformerDecoder"
    TRANSFORMER_IN_FEATURE: "multi_scale_pixel_decoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 2.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 100
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    DEC_LAYERS: 10
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.8

# 数据集配置
DATASETS:
  TRAIN: ("coco_instance_train_rgbd",)
  TEST: ("coco_instance_val_rgbd",)

# 数据加载器配置
DATALOADER:
  NUM_WORKERS: 4
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  REPEAT_THRESHOLD: 0.0

# RGB-D Input Configuration
INPUT:
  DATASET_ROOT: "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input"
  IMAGE_SIZE: 1024
  MIN_SCALE: 0.1
  MAX_SCALE: 2.0
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "coco_instance_lsj_rgbd"
  RANDOM_FLIP: "horizontal"
  SIZE_DIVISIBILITY: 32

  # RGB光度增强
  RGB_PHOTO_AUG:
    ENABLED: False
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    SATURATION: 0.1
    HUE: 0.0

  # 深度数据配置
  DEPTH_FORMAT: "I"
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_CLIP_MAX: 1.0
  DEPTH_NORM: "minmax"
  DEPTH_NOISE:
    ENABLED: False
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
    DROP_PROB: 0.0
    DROP_VAL: 0.0

# 求解器配置
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (327778, 355092)
  MAX_ITER: 368750
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: "linear"
  GAMMA: 0.1
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_EMBED: 0.0
  CLIP_GRADIENTS:
    ENABLED: False
  AMP:
    ENABLED: True

# 测试配置
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False

# 输出配置
OUTPUT_DIR: "./output"

# 版本号
VERSION: 2.0

[08/30 15:01:16] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  LOAD_PROPOSALS: false
  NUM_WORKERS: 4
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_instance_val_rgbd
  TRAIN:
  - coco_instance_train_rgbd
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj_rgbd
  DATASET_ROOT: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
  DEPTH_CLIP_MAX: 1.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_FORMAT: I
  DEPTH_NOISE:
    DROP_PROB: 0.0
    DROP_VAL: 0.0
    ENABLED: false
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
  DEPTH_NORM: minmax
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  RGB_PHOTO_AUG:
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    ENABLED: false
    HUE: 0.0
    SATURATION: 0.1
  SIZE_DIVISIBILITY: 32
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BOUNDARY:
    ENABLED: false
  DEPTH_BACKBONE:
    CONVNEXT:
      DEPTHS:
      - 3
      - 3
      - 9
      - 3
      DIMS:
      - 96
      - 192
      - 384
      - 768
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1.0e-06
    NAME: ConvNeXtDepthBackbone
    WEIGHTS: ''
  DEVICE: cuda
  DPE:
    ENABLED: true
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MGMMultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MGMMaskFormer
  MGM:
    CLAMP_MAX: 0.95
    CLAMP_MIN: 0.05
    ENABLED: true
    FEATURE_DIMS:
    - 96
    - 192
    - 384
    - 768
    HIDDEN_DIM: 256
    LOSS_ENTROPY_W: 0.01
    NOISE_MASK_WEIGHT: 0.0
    POST_FUSE_NORM: true
    PRIOR:
      COMPUTE_ON: res3
      ENABLED: false
      USE_GRADIENT: true
      USE_RGB_EDGE: false
      USE_VALID_HOLE: true
      USE_VARIANCE: true
      VAR_KERNEL: 5
      Z_MAX: 1.0
      Z_MIN: 0.0
    RESIDUAL_ALPHA: 0.05
    ROBUST_NORM:
      ENABLED: false
      METHOD: minmax
    SCALE_KEYS:
    - res2
    - res3
    - res4
    - res5
    SHARED: true
    TEMP_FINAL: 1.0
    TEMP_INIT: 1.5
    TEMP_STEPS: 3000
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  RGB_BACKBONE:
    NAME: D2SwinTransformer
    SWIN:
      APE: false
      ATTN_DROP_RATE: 0.0
      DEPTHS:
      - 2
      - 2
      - 6
      - 2
      DROP_PATH_RATE: 0.3
      DROP_RATE: 0.0
      EMBED_DIM: 96
      MLP_RATIO: 4.0
      NUM_HEADS:
      - 3
      - 6
      - 12
      - 24
      OUT_FEATURES:
      - res2
      - res3
      - res4
      - res5
      PATCH_NORM: true
      PATCH_SIZE: 4
      PRETRAIN_IMG_SIZE: 224
      QKV_BIAS: true
      QK_SCALE: null
      USE_CHECKPOINT: false
      WINDOW_SIZE: 7
    WEIGHTS: ''
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MGMHead
    NORM: GN
    NUM_CLASSES: 1
    PIXEL_DECODER_NAME: MGMMSDeformAttnPixelDecoder
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: ''
OUTPUT_DIR: ./output/mgm_training
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 368750
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 327778
  - 355092
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2.0
VIS_PERIOD: 0

[08/30 15:01:16] detectron2 INFO: Full config saved to ./output/mgm_training/config.yaml
[08/30 15:01:16] d2.utils.env INFO: Using a generated random seed 17793223
[08/30 15:02:10] detectron2 INFO: Rank of current process: 0. World size: 1
[08/30 15:02:10] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:43:55) [GCC 13.3.0]
numpy                            2.2.6
detectron2                       0.6 @/home/fuyx/hch/detectron2/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6, 8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   575.64.03
CUDA_HOME                        /home/fuyx/anaconda3/envs/m2f
Pillow                           11.3.0
torchvision                      0.20.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[08/30 15:02:10] detectron2 INFO: Command line arguments: Namespace(config_file='MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=['OUTPUT_DIR', './output/mgm_training'])
[08/30 15:02:10] detectron2 INFO: Contents of args.config_file=MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml:
MODEL:
  META_ARCHITECTURE: "MGMMaskFormer"

  # RGB Backbone: Swin Transformer Tiny
  RGB_BACKBONE:
    NAME: "D2SwinTransformer"
    WEIGHTS: ""
    SWIN:
      EMBED_DIM: 96
      DEPTHS: [2, 2, 6, 2]
      NUM_HEADS: [3, 6, 12, 24]
      WINDOW_SIZE: 7
      APE: False
      DROP_PATH_RATE: 0.3
      PATCH_NORM: True
      OUT_FEATURES: ["res2", "res3", "res4", "res5"]

  # Depth Backbone: ConvNeXt Tiny
  DEPTH_BACKBONE:
    NAME: "ConvNeXtDepthBackbone"
    WEIGHTS: ""
    CONVNEXT:
      DEPTHS: [3, 3, 9, 3]
      DIMS: [96, 192, 384, 768]
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1e-6

  # MGM Fusion Configuration
  MGM:
    ENABLED: True
    SHARED: True
    RESIDUAL_ALPHA: 0.05
    POST_FUSE_NORM: True              # 新增：融合后GN
    LOSS_ENTROPY_W: 0.01
    TEMP_INIT: 1.5
    TEMP_FINAL: 1.0
    TEMP_STEPS: 3000                  # 建议略短，收敛更快
    CLAMP_MIN: 0.05
    CLAMP_MAX: 0.95
    NOISE_MASK_WEIGHT: 0.0            # 前期建议关；有噪声掩码再开到0.05~0.1
    HIDDEN_DIM: 256
    FEATURE_DIMS: [96, 192, 384, 768]
    SCALE_KEYS: ["res2", "res3", "res4", "res5"]

    PRIOR:
      ENABLED: False                   # 总开关
      USE_GRADIENT: True              # 先验逐项开关
      USE_VARIANCE: True
      USE_VALID_HOLE: True
      USE_RGB_EDGE: False             # 前期建议关（最耗时）
      VAR_KERNEL: 5
      Z_MIN: 0.0
      Z_MAX: 1.0
      COMPUTE_ON: "res3"              # "full"|"res2"|"res3"|"res4"|"res5"；前期建议用res3提速

    ROBUST_NORM:
      ENABLED: False                  # 前期建议关；要稳健再开
      METHOD: "minmax"                # "minmax"|"quantile"


  # DPE Configuration
  DPE:
    ENABLED: True

  # Boundary Configuration
  BOUNDARY:
    ENABLED: False

  # RGB Input Pixel Mean/Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]

  # Semantic Segmentation Head
  SEM_SEG_HEAD:
    NAME: "MGMHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 1
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MGMMSDeformAttnPixelDecoder"
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6

  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MGMMultiScaleMaskedTransformerDecoder"
    TRANSFORMER_IN_FEATURE: "multi_scale_pixel_decoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 2.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 100
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    DEC_LAYERS: 10
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.8

# 数据集配置
DATASETS:
  TRAIN: ("coco_instance_train_rgbd",)
  TEST: ("coco_instance_val_rgbd",)

# 数据加载器配置
DATALOADER:
  NUM_WORKERS: 4
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  REPEAT_THRESHOLD: 0.0

# RGB-D Input Configuration
INPUT:
  DATASET_ROOT: "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input"
  IMAGE_SIZE: 1024
  MIN_SCALE: 0.1
  MAX_SCALE: 2.0
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "coco_instance_lsj_rgbd"
  RANDOM_FLIP: "horizontal"
  SIZE_DIVISIBILITY: 32

  # RGB光度增强
  RGB_PHOTO_AUG:
    ENABLED: False
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    SATURATION: 0.1
    HUE: 0.0

  # 深度数据配置
  DEPTH_FORMAT: "I"
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_CLIP_MAX: 1.0
  DEPTH_NORM: "minmax"
  DEPTH_NOISE:
    ENABLED: False
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
    DROP_PROB: 0.0
    DROP_VAL: 0.0

# 求解器配置
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (327778, 355092)
  MAX_ITER: 368750
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: "linear"
  GAMMA: 0.1
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_EMBED: 0.0
  CLIP_GRADIENTS:
    ENABLED: False
  AMP:
    ENABLED: True

# 测试配置
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False

# 输出配置
OUTPUT_DIR: "./output"

# 版本号
VERSION: 2.0

[08/30 15:02:10] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  LOAD_PROPOSALS: false
  NUM_WORKERS: 4
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_instance_val_rgbd
  TRAIN:
  - coco_instance_train_rgbd
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj_rgbd
  DATASET_ROOT: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
  DEPTH_CLIP_MAX: 1.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_FORMAT: I
  DEPTH_NOISE:
    DROP_PROB: 0.0
    DROP_VAL: 0.0
    ENABLED: false
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
  DEPTH_NORM: minmax
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  RGB_PHOTO_AUG:
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    ENABLED: false
    HUE: 0.0
    SATURATION: 0.1
  SIZE_DIVISIBILITY: 32
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BOUNDARY:
    ENABLED: false
  DEPTH_BACKBONE:
    CONVNEXT:
      DEPTHS:
      - 3
      - 3
      - 9
      - 3
      DIMS:
      - 96
      - 192
      - 384
      - 768
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1.0e-06
    NAME: ConvNeXtDepthBackbone
    WEIGHTS: ''
  DEVICE: cuda
  DPE:
    ENABLED: true
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MGMMultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MGMMaskFormer
  MGM:
    CLAMP_MAX: 0.95
    CLAMP_MIN: 0.05
    ENABLED: true
    FEATURE_DIMS:
    - 96
    - 192
    - 384
    - 768
    HIDDEN_DIM: 256
    LOSS_ENTROPY_W: 0.01
    NOISE_MASK_WEIGHT: 0.0
    POST_FUSE_NORM: true
    PRIOR:
      COMPUTE_ON: res3
      ENABLED: false
      USE_GRADIENT: true
      USE_RGB_EDGE: false
      USE_VALID_HOLE: true
      USE_VARIANCE: true
      VAR_KERNEL: 5
      Z_MAX: 1.0
      Z_MIN: 0.0
    RESIDUAL_ALPHA: 0.05
    ROBUST_NORM:
      ENABLED: false
      METHOD: minmax
    SCALE_KEYS:
    - res2
    - res3
    - res4
    - res5
    SHARED: true
    TEMP_FINAL: 1.0
    TEMP_INIT: 1.5
    TEMP_STEPS: 3000
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  RGB_BACKBONE:
    NAME: D2SwinTransformer
    SWIN:
      APE: false
      ATTN_DROP_RATE: 0.0
      DEPTHS:
      - 2
      - 2
      - 6
      - 2
      DROP_PATH_RATE: 0.3
      DROP_RATE: 0.0
      EMBED_DIM: 96
      MLP_RATIO: 4.0
      NUM_HEADS:
      - 3
      - 6
      - 12
      - 24
      OUT_FEATURES:
      - res2
      - res3
      - res4
      - res5
      PATCH_NORM: true
      PATCH_SIZE: 4
      PRETRAIN_IMG_SIZE: 224
      QKV_BIAS: true
      QK_SCALE: null
      USE_CHECKPOINT: false
      WINDOW_SIZE: 7
    WEIGHTS: ''
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MGMHead
    NORM: GN
    NUM_CLASSES: 1
    PIXEL_DECODER_NAME: MGMMSDeformAttnPixelDecoder
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: ''
OUTPUT_DIR: ./output/mgm_training
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 368750
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 327778
  - 355092
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2.0
VIS_PERIOD: 0

[08/30 15:02:10] detectron2 INFO: Full config saved to ./output/mgm_training/config.yaml
[08/30 15:02:10] d2.utils.env INFO: Using a generated random seed 11995680
[08/30 15:02:34] detectron2 INFO: Rank of current process: 0. World size: 1
[08/30 15:02:34] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:43:55) [GCC 13.3.0]
numpy                            2.2.6
detectron2                       0.6 @/home/fuyx/hch/detectron2/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6, 8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   575.64.03
CUDA_HOME                        /home/fuyx/anaconda3/envs/m2f
Pillow                           11.3.0
torchvision                      0.20.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[08/30 15:02:34] detectron2 INFO: Command line arguments: Namespace(config_file='MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=['OUTPUT_DIR', './output/mgm_training'])
[08/30 15:02:34] detectron2 INFO: Contents of args.config_file=MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml:
MODEL:
  META_ARCHITECTURE: "MGMMaskFormer"

  # RGB Backbone: Swin Transformer Tiny
  RGB_BACKBONE:
    NAME: "D2SwinTransformer"
    WEIGHTS: ""
    SWIN:
      EMBED_DIM: 96
      DEPTHS: [2, 2, 6, 2]
      NUM_HEADS: [3, 6, 12, 24]
      WINDOW_SIZE: 7
      APE: False
      DROP_PATH_RATE: 0.3
      PATCH_NORM: True
      OUT_FEATURES: ["res2", "res3", "res4", "res5"]

  # Depth Backbone: ConvNeXt Tiny
  DEPTH_BACKBONE:
    NAME: "ConvNeXtDepthBackbone"
    WEIGHTS: ""
    CONVNEXT:
      DEPTHS: [3, 3, 9, 3]
      DIMS: [96, 192, 384, 768]
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1e-6

  # MGM Fusion Configuration
  MGM:
    ENABLED: True
    SHARED: True
    RESIDUAL_ALPHA: 0.05
    POST_FUSE_NORM: True              # 新增：融合后GN
    LOSS_ENTROPY_W: 0.01
    TEMP_INIT: 1.5
    TEMP_FINAL: 1.0
    TEMP_STEPS: 3000                  # 建议略短，收敛更快
    CLAMP_MIN: 0.05
    CLAMP_MAX: 0.95
    NOISE_MASK_WEIGHT: 0.0            # 前期建议关；有噪声掩码再开到0.05~0.1
    HIDDEN_DIM: 256
    FEATURE_DIMS: [96, 192, 384, 768]
    SCALE_KEYS: ["res2", "res3", "res4", "res5"]

    PRIOR:
      ENABLED: False                   # 总开关
      USE_GRADIENT: True              # 先验逐项开关
      USE_VARIANCE: True
      USE_VALID_HOLE: True
      USE_RGB_EDGE: False             # 前期建议关（最耗时）
      VAR_KERNEL: 5
      Z_MIN: 0.0
      Z_MAX: 1.0
      COMPUTE_ON: "res3"              # "full"|"res2"|"res3"|"res4"|"res5"；前期建议用res3提速

    ROBUST_NORM:
      ENABLED: False                  # 前期建议关；要稳健再开
      METHOD: "minmax"                # "minmax"|"quantile"


  # DPE Configuration
  DPE:
    ENABLED: True

  # Boundary Configuration
  BOUNDARY:
    ENABLED: False

  # RGB Input Pixel Mean/Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]

  # Semantic Segmentation Head
  SEM_SEG_HEAD:
    NAME: "MGMHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 1
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MGMMSDeformAttnPixelDecoder"
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6

  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MGMMultiScaleMaskedTransformerDecoder"
    TRANSFORMER_IN_FEATURE: "multi_scale_pixel_decoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 2.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 100
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    DEC_LAYERS: 10
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.8

# 数据集配置
DATASETS:
  TRAIN: ("coco_instance_train_rgbd",)
  TEST: ("coco_instance_val_rgbd",)

# 数据加载器配置
DATALOADER:
  NUM_WORKERS: 4
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  REPEAT_THRESHOLD: 0.0

# RGB-D Input Configuration
INPUT:
  DATASET_ROOT: "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input"
  IMAGE_SIZE: 1024
  MIN_SCALE: 0.1
  MAX_SCALE: 2.0
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "coco_instance_lsj_rgbd"
  RANDOM_FLIP: "horizontal"
  SIZE_DIVISIBILITY: 32

  # RGB光度增强
  RGB_PHOTO_AUG:
    ENABLED: False
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    SATURATION: 0.1
    HUE: 0.0

  # 深度数据配置
  DEPTH_FORMAT: "I"
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_CLIP_MAX: 1.0
  DEPTH_NORM: "minmax"
  DEPTH_NOISE:
    ENABLED: False
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
    DROP_PROB: 0.0
    DROP_VAL: 0.0

# 求解器配置
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (327778, 355092)
  MAX_ITER: 368750
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: "linear"
  GAMMA: 0.1
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_EMBED: 0.0
  CLIP_GRADIENTS:
    ENABLED: False
  AMP:
    ENABLED: True

# 测试配置
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False

# 输出配置
OUTPUT_DIR: "./output"

# 版本号
VERSION: 2.0

[08/30 15:02:34] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  LOAD_PROPOSALS: false
  NUM_WORKERS: 4
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_instance_val_rgbd
  TRAIN:
  - coco_instance_train_rgbd
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj_rgbd
  DATASET_ROOT: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
  DEPTH_CLIP_MAX: 1.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_FORMAT: I
  DEPTH_NOISE:
    DROP_PROB: 0.0
    DROP_VAL: 0.0
    ENABLED: false
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
  DEPTH_NORM: minmax
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  RGB_PHOTO_AUG:
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    ENABLED: false
    HUE: 0.0
    SATURATION: 0.1
  SIZE_DIVISIBILITY: 32
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BOUNDARY:
    ENABLED: false
  DEPTH_BACKBONE:
    CONVNEXT:
      DEPTHS:
      - 3
      - 3
      - 9
      - 3
      DIMS:
      - 96
      - 192
      - 384
      - 768
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1.0e-06
    NAME: ConvNeXtDepthBackbone
    WEIGHTS: ''
  DEVICE: cuda
  DPE:
    ENABLED: true
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MGMMultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MGMMaskFormer
  MGM:
    CLAMP_MAX: 0.95
    CLAMP_MIN: 0.05
    ENABLED: true
    FEATURE_DIMS:
    - 96
    - 192
    - 384
    - 768
    HIDDEN_DIM: 256
    LOSS_ENTROPY_W: 0.01
    NOISE_MASK_WEIGHT: 0.0
    POST_FUSE_NORM: true
    PRIOR:
      COMPUTE_ON: res3
      ENABLED: false
      USE_GRADIENT: true
      USE_RGB_EDGE: false
      USE_VALID_HOLE: true
      USE_VARIANCE: true
      VAR_KERNEL: 5
      Z_MAX: 1.0
      Z_MIN: 0.0
    RESIDUAL_ALPHA: 0.05
    ROBUST_NORM:
      ENABLED: false
      METHOD: minmax
    SCALE_KEYS:
    - res2
    - res3
    - res4
    - res5
    SHARED: true
    TEMP_FINAL: 1.0
    TEMP_INIT: 1.5
    TEMP_STEPS: 3000
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  RGB_BACKBONE:
    NAME: D2SwinTransformer
    SWIN:
      APE: false
      ATTN_DROP_RATE: 0.0
      DEPTHS:
      - 2
      - 2
      - 6
      - 2
      DROP_PATH_RATE: 0.3
      DROP_RATE: 0.0
      EMBED_DIM: 96
      MLP_RATIO: 4.0
      NUM_HEADS:
      - 3
      - 6
      - 12
      - 24
      OUT_FEATURES:
      - res2
      - res3
      - res4
      - res5
      PATCH_NORM: true
      PATCH_SIZE: 4
      PRETRAIN_IMG_SIZE: 224
      QKV_BIAS: true
      QK_SCALE: null
      USE_CHECKPOINT: false
      WINDOW_SIZE: 7
    WEIGHTS: ''
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MGMHead
    NORM: GN
    NUM_CLASSES: 1
    PIXEL_DECODER_NAME: MGMMSDeformAttnPixelDecoder
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: ''
OUTPUT_DIR: ./output/mgm_training
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 368750
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 327778
  - 355092
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2.0
VIS_PERIOD: 0

[08/30 15:02:34] detectron2 INFO: Full config saved to ./output/mgm_training/config.yaml
[08/30 15:02:34] d2.utils.env INFO: Using a generated random seed 36195246
[08/30 15:02:35] d2.engine.defaults INFO: Model:
MGMMaskFormer(
  (rgb_backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.055)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.109)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.136)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.164)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.191)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.218)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.245)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.273)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.300)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (depth_backbone): ConvNeXtDepthBackbone(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
  )
  (mgm): MultiModalGatedFusion(
    (prior_extractor): DepthPriorExtractor()
    (conf_pred): ConfidencePredictor(
      (proj_image): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_depth): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (head): Sequential(
        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): GroupNorm(8, 128, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (align_image): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (align_depth): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (post_norm): ModuleList(
      (0): GroupNorm(8, 96, eps=1e-05, affine=True)
      (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      (2): GroupNorm(8, 384, eps=1e-05, affine=True)
      (3): GroupNorm(8, 768, eps=1e-05, affine=True)
    )
  )
  (sem_seg_head): MGMHead(
    (pixel_decoder): MGMMSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (depth_pe): DepthPosEncoding(
        (mlp): Sequential(
          (0): Conv2d(1, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MGMMultiScaleMaskedTransformerDecoder(
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x MGMCrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=2, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 1
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/30 15:02:35] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [Mapper] Noise-mask dir not found, will skip masks: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/depth/depth_noise_mask
[08/30 15:02:35] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [COCOInstanceRGBDDatasetMapper] Augs: [RandomFlip(), ResizeScale(min_scale=0.1, max_scale=2.0, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=(1024, 1024))] | RGB: RGB | DATASET_ROOT=/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
[08/30 15:02:35] d2.data.build WARNING: The following dataset names are not registered in the DatasetCatalog: {'coco_instance_train_rgbd'}. Available datasets are KeysView(DatasetCatalog(registered datasets: coco_2014_train, coco_2014_val, coco_2014_minival, coco_2014_valminusminival, coco_2017_train, coco_2017_val, coco_2017_test, coco_2017_test-dev, coco_2017_val_100, keypoints_coco_2014_train, keypoints_coco_2014_val, keypoints_coco_2014_minival, keypoints_coco_2014_valminusminival, keypoints_coco_2017_train, keypoints_coco_2017_val, keypoints_coco_2017_val_100, coco_2017_train_panoptic_separated, coco_2017_train_panoptic_stuffonly, coco_2017_train_panoptic, coco_2017_val_panoptic_separated, coco_2017_val_panoptic_stuffonly, coco_2017_val_panoptic, coco_2017_val_100_panoptic_separated, coco_2017_val_100_panoptic_stuffonly, coco_2017_val_100_panoptic, lvis_v1_train, lvis_v1_val, lvis_v1_test_dev, lvis_v1_test_challenge, lvis_v0.5_train, lvis_v0.5_val, lvis_v0.5_val_rand_100, lvis_v0.5_test, lvis_v0.5_train_cocofied, lvis_v0.5_val_cocofied, cityscapes_fine_instance_seg_train, cityscapes_fine_sem_seg_train, cityscapes_fine_instance_seg_val, cityscapes_fine_sem_seg_val, cityscapes_fine_instance_seg_test, cityscapes_fine_sem_seg_test, cityscapes_fine_panoptic_train, cityscapes_fine_panoptic_val, voc_2007_trainval, voc_2007_train, voc_2007_val, voc_2007_test, voc_2012_trainval, voc_2012_train, voc_2012_val, ade20k_sem_seg_train, ade20k_sem_seg_val, coco_instance_rgbd_train, coco_instance_rgbd_val, coco_instance_rgbd_test))
[08/30 15:11:19] detectron2 INFO: Rank of current process: 0. World size: 1
[08/30 15:11:19] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:43:55) [GCC 13.3.0]
numpy                            2.2.6
detectron2                       0.6 @/home/fuyx/hch/detectron2/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6, 8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   575.64.03
CUDA_HOME                        /home/fuyx/anaconda3/envs/m2f
Pillow                           11.3.0
torchvision                      0.20.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[08/30 15:11:19] detectron2 INFO: Command line arguments: Namespace(config_file='MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=['OUTPUT_DIR', './output/mgm_training'])
[08/30 15:11:19] detectron2 INFO: Contents of args.config_file=MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml:
MODEL:
  META_ARCHITECTURE: "MGMMaskFormer"

  # RGB Backbone: Swin Transformer Tiny
  RGB_BACKBONE:
    NAME: "D2SwinTransformer"
    WEIGHTS: ""
    SWIN:
      EMBED_DIM: 96
      DEPTHS: [2, 2, 6, 2]
      NUM_HEADS: [3, 6, 12, 24]
      WINDOW_SIZE: 7
      APE: False
      DROP_PATH_RATE: 0.3
      PATCH_NORM: True
      OUT_FEATURES: ["res2", "res3", "res4", "res5"]

  # Depth Backbone: ConvNeXt Tiny
  DEPTH_BACKBONE:
    NAME: "ConvNeXtDepthBackbone"
    WEIGHTS: ""
    CONVNEXT:
      DEPTHS: [3, 3, 9, 3]
      DIMS: [96, 192, 384, 768]
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1e-6

  # MGM Fusion Configuration
  MGM:
    ENABLED: True
    SHARED: True
    RESIDUAL_ALPHA: 0.05
    POST_FUSE_NORM: True              # 新增：融合后GN
    LOSS_ENTROPY_W: 0.01
    TEMP_INIT: 1.5
    TEMP_FINAL: 1.0
    TEMP_STEPS: 3000                  # 建议略短，收敛更快
    CLAMP_MIN: 0.05
    CLAMP_MAX: 0.95
    NOISE_MASK_WEIGHT: 0.0            # 前期建议关；有噪声掩码再开到0.05~0.1
    HIDDEN_DIM: 256
    FEATURE_DIMS: [96, 192, 384, 768]
    SCALE_KEYS: ["res2", "res3", "res4", "res5"]

    PRIOR:
      ENABLED: False                   # 总开关
      USE_GRADIENT: True              # 先验逐项开关
      USE_VARIANCE: True
      USE_VALID_HOLE: True
      USE_RGB_EDGE: False             # 前期建议关（最耗时）
      VAR_KERNEL: 5
      Z_MIN: 0.0
      Z_MAX: 1.0
      COMPUTE_ON: "res3"              # "full"|"res2"|"res3"|"res4"|"res5"；前期建议用res3提速

    ROBUST_NORM:
      ENABLED: False                  # 前期建议关；要稳健再开
      METHOD: "minmax"                # "minmax"|"quantile"


  # DPE Configuration
  DPE:
    ENABLED: True

  # Boundary Configuration
  BOUNDARY:
    ENABLED: False

  # RGB Input Pixel Mean/Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]

  # Semantic Segmentation Head
  SEM_SEG_HEAD:
    NAME: "MGMHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 1
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MGMMSDeformAttnPixelDecoder"
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6

  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MGMMultiScaleMaskedTransformerDecoder"
    TRANSFORMER_IN_FEATURE: "multi_scale_pixel_decoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 2.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 100
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    DEC_LAYERS: 10
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.8

# 数据集配置
DATASETS:
  TRAIN: ("coco_instance_rgbd_train",)
  TEST: ("coco_instance_rgbd_val",)

# 数据加载器配置
DATALOADER:
  NUM_WORKERS: 4
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  REPEAT_THRESHOLD: 0.0

# RGB-D Input Configuration
INPUT:
  DATASET_ROOT: "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input"
  IMAGE_SIZE: 1024
  MIN_SCALE: 0.1
  MAX_SCALE: 2.0
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "coco_instance_lsj_rgbd"
  RANDOM_FLIP: "horizontal"
  SIZE_DIVISIBILITY: 32

  # RGB光度增强
  RGB_PHOTO_AUG:
    ENABLED: False
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    SATURATION: 0.1
    HUE: 0.0

  # 深度数据配置
  DEPTH_FORMAT: "I"
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_CLIP_MAX: 1.0
  DEPTH_NORM: "minmax"
  DEPTH_NOISE:
    ENABLED: False
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
    DROP_PROB: 0.0
    DROP_VAL: 0.0

# 求解器配置
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (327778, 355092)
  MAX_ITER: 368750
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: "linear"
  GAMMA: 0.1
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_EMBED: 0.0
  CLIP_GRADIENTS:
    ENABLED: False
  AMP:
    ENABLED: True

# 测试配置
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False

# 输出配置
OUTPUT_DIR: "./output"

# 版本号
VERSION: 2.0

[08/30 15:11:19] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  LOAD_PROPOSALS: false
  NUM_WORKERS: 4
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_instance_rgbd_val
  TRAIN:
  - coco_instance_rgbd_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj_rgbd
  DATASET_ROOT: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
  DEPTH_CLIP_MAX: 1.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_FORMAT: I
  DEPTH_NOISE:
    DROP_PROB: 0.0
    DROP_VAL: 0.0
    ENABLED: false
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
  DEPTH_NORM: minmax
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  RGB_PHOTO_AUG:
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    ENABLED: false
    HUE: 0.0
    SATURATION: 0.1
  SIZE_DIVISIBILITY: 32
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BOUNDARY:
    ENABLED: false
  DEPTH_BACKBONE:
    CONVNEXT:
      DEPTHS:
      - 3
      - 3
      - 9
      - 3
      DIMS:
      - 96
      - 192
      - 384
      - 768
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1.0e-06
    NAME: ConvNeXtDepthBackbone
    WEIGHTS: ''
  DEVICE: cuda
  DPE:
    ENABLED: true
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MGMMultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MGMMaskFormer
  MGM:
    CLAMP_MAX: 0.95
    CLAMP_MIN: 0.05
    ENABLED: true
    FEATURE_DIMS:
    - 96
    - 192
    - 384
    - 768
    HIDDEN_DIM: 256
    LOSS_ENTROPY_W: 0.01
    NOISE_MASK_WEIGHT: 0.0
    POST_FUSE_NORM: true
    PRIOR:
      COMPUTE_ON: res3
      ENABLED: false
      USE_GRADIENT: true
      USE_RGB_EDGE: false
      USE_VALID_HOLE: true
      USE_VARIANCE: true
      VAR_KERNEL: 5
      Z_MAX: 1.0
      Z_MIN: 0.0
    RESIDUAL_ALPHA: 0.05
    ROBUST_NORM:
      ENABLED: false
      METHOD: minmax
    SCALE_KEYS:
    - res2
    - res3
    - res4
    - res5
    SHARED: true
    TEMP_FINAL: 1.0
    TEMP_INIT: 1.5
    TEMP_STEPS: 3000
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  RGB_BACKBONE:
    NAME: D2SwinTransformer
    SWIN:
      APE: false
      ATTN_DROP_RATE: 0.0
      DEPTHS:
      - 2
      - 2
      - 6
      - 2
      DROP_PATH_RATE: 0.3
      DROP_RATE: 0.0
      EMBED_DIM: 96
      MLP_RATIO: 4.0
      NUM_HEADS:
      - 3
      - 6
      - 12
      - 24
      OUT_FEATURES:
      - res2
      - res3
      - res4
      - res5
      PATCH_NORM: true
      PATCH_SIZE: 4
      PRETRAIN_IMG_SIZE: 224
      QKV_BIAS: true
      QK_SCALE: null
      USE_CHECKPOINT: false
      WINDOW_SIZE: 7
    WEIGHTS: ''
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MGMHead
    NORM: GN
    NUM_CLASSES: 1
    PIXEL_DECODER_NAME: MGMMSDeformAttnPixelDecoder
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: ''
OUTPUT_DIR: ./output/mgm_training
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 368750
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 327778
  - 355092
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2.0
VIS_PERIOD: 0

[08/30 15:11:19] detectron2 INFO: Full config saved to ./output/mgm_training/config.yaml
[08/30 15:11:19] d2.utils.env INFO: Using a generated random seed 21306994
[08/30 15:11:40] d2.engine.defaults INFO: Model:
MGMMaskFormer(
  (rgb_backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.055)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.109)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.136)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.164)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.191)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.218)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.245)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.273)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.300)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (depth_backbone): ConvNeXtDepthBackbone(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
  )
  (mgm): MultiModalGatedFusion(
    (prior_extractor): DepthPriorExtractor()
    (conf_pred): ConfidencePredictor(
      (proj_image): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_depth): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (head): Sequential(
        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): GroupNorm(8, 128, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (align_image): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (align_depth): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (post_norm): ModuleList(
      (0): GroupNorm(8, 96, eps=1e-05, affine=True)
      (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      (2): GroupNorm(8, 384, eps=1e-05, affine=True)
      (3): GroupNorm(8, 768, eps=1e-05, affine=True)
    )
  )
  (sem_seg_head): MGMHead(
    (pixel_decoder): MGMMSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (depth_pe): DepthPosEncoding(
        (mlp): Sequential(
          (0): Conv2d(1, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MGMMultiScaleMaskedTransformerDecoder(
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x MGMCrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=2, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 1
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/30 15:11:40] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [Mapper] Noise-mask dir not found, will skip masks: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/depth/depth_noise_mask
[08/30 15:11:40] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [COCOInstanceRGBDDatasetMapper] Augs: [RandomFlip(), ResizeScale(min_scale=0.1, max_scale=2.0, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=(1024, 1024))] | RGB: RGB | DATASET_ROOT=/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
[08/30 15:11:40] d2.data.datasets.coco INFO: Loaded 0 images in COCO format from /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/annotations/instances_train.json
[08/30 15:22:24] detectron2 INFO: Rank of current process: 0. World size: 1
[08/30 15:22:25] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:43:55) [GCC 13.3.0]
numpy                            2.2.6
detectron2                       0.6 @/home/fuyx/hch/detectron2/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6, 8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   575.64.03
CUDA_HOME                        /home/fuyx/anaconda3/envs/m2f
Pillow                           11.3.0
torchvision                      0.20.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[08/30 15:22:25] detectron2 INFO: Command line arguments: Namespace(config_file='MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=['OUTPUT_DIR', './output/mgm_training'])
[08/30 15:22:25] detectron2 INFO: Contents of args.config_file=MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml:
MODEL:
  META_ARCHITECTURE: "MGMMaskFormer"

  # RGB Backbone: Swin Transformer Tiny
  RGB_BACKBONE:
    NAME: "D2SwinTransformer"
    WEIGHTS: ""
    SWIN:
      EMBED_DIM: 96
      DEPTHS: [2, 2, 6, 2]
      NUM_HEADS: [3, 6, 12, 24]
      WINDOW_SIZE: 7
      APE: False
      DROP_PATH_RATE: 0.3
      PATCH_NORM: True
      OUT_FEATURES: ["res2", "res3", "res4", "res5"]

  # Depth Backbone: ConvNeXt Tiny
  DEPTH_BACKBONE:
    NAME: "ConvNeXtDepthBackbone"
    WEIGHTS: ""
    CONVNEXT:
      DEPTHS: [3, 3, 9, 3]
      DIMS: [96, 192, 384, 768]
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1e-6

  # MGM Fusion Configuration
  MGM:
    ENABLED: True
    SHARED: True
    RESIDUAL_ALPHA: 0.05
    POST_FUSE_NORM: True # 新增：融合后GN
    LOSS_ENTROPY_W: 0.01
    TEMP_INIT: 1.5
    TEMP_FINAL: 1.0
    TEMP_STEPS: 3000 # 建议略短，收敛更快
    CLAMP_MIN: 0.05
    CLAMP_MAX: 0.95
    NOISE_MASK_WEIGHT: 0.0 # 前期建议关；有噪声掩码再开到0.05~0.1
    HIDDEN_DIM: 256
    FEATURE_DIMS: [96, 192, 384, 768]
    SCALE_KEYS: ["res2", "res3", "res4", "res5"]

    PRIOR:
      ENABLED: False # 总开关
      USE_GRADIENT: True # 先验逐项开关
      USE_VARIANCE: True
      USE_VALID_HOLE: True
      USE_RGB_EDGE: False # 前期建议关（最耗时）
      VAR_KERNEL: 5
      Z_MIN: 0.0
      Z_MAX: 1.0
      COMPUTE_ON: "res3" # "full"|"res2"|"res3"|"res4"|"res5"；前期建议用res3提速

    ROBUST_NORM:
      ENABLED: False # 前期建议关；要稳健再开
      METHOD: "minmax" # "minmax"|"quantile"

  # DPE Configuration
  DPE:
    ENABLED: True

  # Boundary Configuration
  BOUNDARY:
    ENABLED: False

  # RGB Input Pixel Mean/Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]

  # Semantic Segmentation Head
  SEM_SEG_HEAD:
    NAME: "MGMHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 1
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MGMMSDeformAttnPixelDecoder"
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6

  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MGMMultiScaleMaskedTransformerDecoder"
    TRANSFORMER_IN_FEATURE: "multi_scale_pixel_decoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 2.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 100
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    DEC_LAYERS: 10
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.8

# 数据集配置
DATASETS:
  TRAIN: ("coco_instance_rgbd_train",)
  TEST: ("coco_instance_rgbd_val",)

# 数据加载器配置
DATALOADER:
  NUM_WORKERS: 4
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  REPEAT_THRESHOLD: 0.0

# RGB-D Input Configuration
INPUT:
  DATASET_ROOT: "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input"
  IMAGE_SIZE: 1024
  MIN_SCALE: 0.1
  MAX_SCALE: 2.0
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "coco_instance_lsj_rgbd"
  RANDOM_FLIP: "horizontal"
  SIZE_DIVISIBILITY: 32

  # RGB光度增强
  RGB_PHOTO_AUG:
    ENABLED: False
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    SATURATION: 0.1
    HUE: 0.0

  # 深度数据配置
  DEPTH_FORMAT: "I"
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_CLIP_MAX: 1.0
  DEPTH_NORM: "minmax"
  DEPTH_NOISE:
    ENABLED: False
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
    DROP_PROB: 0.0
    DROP_VAL: 0.0

# 求解器配置
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (327778, 355092)
  MAX_ITER: 368750
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: "linear"
  GAMMA: 0.1
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_EMBED: 0.0
  CLIP_GRADIENTS:
    ENABLED: False
  AMP:
    ENABLED: True

# 测试配置
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False

# 输出配置
OUTPUT_DIR: "./output"

# 版本号
VERSION: 2.0

[08/30 15:22:25] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  LOAD_PROPOSALS: false
  NUM_WORKERS: 4
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_instance_rgbd_val
  TRAIN:
  - coco_instance_rgbd_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj_rgbd
  DATASET_ROOT: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
  DEPTH_CLIP_MAX: 1.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_FORMAT: I
  DEPTH_NOISE:
    DROP_PROB: 0.0
    DROP_VAL: 0.0
    ENABLED: false
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
  DEPTH_NORM: minmax
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  RGB_PHOTO_AUG:
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    ENABLED: false
    HUE: 0.0
    SATURATION: 0.1
  SIZE_DIVISIBILITY: 32
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BOUNDARY:
    ENABLED: false
  DEPTH_BACKBONE:
    CONVNEXT:
      DEPTHS:
      - 3
      - 3
      - 9
      - 3
      DIMS:
      - 96
      - 192
      - 384
      - 768
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1.0e-06
    NAME: ConvNeXtDepthBackbone
    WEIGHTS: ''
  DEVICE: cuda
  DPE:
    ENABLED: true
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MGMMultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MGMMaskFormer
  MGM:
    CLAMP_MAX: 0.95
    CLAMP_MIN: 0.05
    ENABLED: true
    FEATURE_DIMS:
    - 96
    - 192
    - 384
    - 768
    HIDDEN_DIM: 256
    LOSS_ENTROPY_W: 0.01
    NOISE_MASK_WEIGHT: 0.0
    POST_FUSE_NORM: true
    PRIOR:
      COMPUTE_ON: res3
      ENABLED: false
      USE_GRADIENT: true
      USE_RGB_EDGE: false
      USE_VALID_HOLE: true
      USE_VARIANCE: true
      VAR_KERNEL: 5
      Z_MAX: 1.0
      Z_MIN: 0.0
    RESIDUAL_ALPHA: 0.05
    ROBUST_NORM:
      ENABLED: false
      METHOD: minmax
    SCALE_KEYS:
    - res2
    - res3
    - res4
    - res5
    SHARED: true
    TEMP_FINAL: 1.0
    TEMP_INIT: 1.5
    TEMP_STEPS: 3000
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  RGB_BACKBONE:
    NAME: D2SwinTransformer
    SWIN:
      APE: false
      ATTN_DROP_RATE: 0.0
      DEPTHS:
      - 2
      - 2
      - 6
      - 2
      DROP_PATH_RATE: 0.3
      DROP_RATE: 0.0
      EMBED_DIM: 96
      MLP_RATIO: 4.0
      NUM_HEADS:
      - 3
      - 6
      - 12
      - 24
      OUT_FEATURES:
      - res2
      - res3
      - res4
      - res5
      PATCH_NORM: true
      PATCH_SIZE: 4
      PRETRAIN_IMG_SIZE: 224
      QKV_BIAS: true
      QK_SCALE: null
      USE_CHECKPOINT: false
      WINDOW_SIZE: 7
    WEIGHTS: ''
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MGMHead
    NORM: GN
    NUM_CLASSES: 1
    PIXEL_DECODER_NAME: MGMMSDeformAttnPixelDecoder
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: ''
OUTPUT_DIR: ./output/mgm_training
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 368750
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 327778
  - 355092
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2.0
VIS_PERIOD: 0

[08/30 15:22:25] detectron2 INFO: Full config saved to ./output/mgm_training/config.yaml
[08/30 15:22:25] d2.utils.env INFO: Using a generated random seed 26998051
[08/30 15:22:46] d2.engine.defaults INFO: Model:
MGMMaskFormer(
  (rgb_backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.055)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.109)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.136)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.164)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.191)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.218)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.245)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.273)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.300)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (depth_backbone): ConvNeXtDepthBackbone(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
  )
  (mgm): MultiModalGatedFusion(
    (prior_extractor): DepthPriorExtractor()
    (conf_pred): ConfidencePredictor(
      (proj_image): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_depth): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (head): Sequential(
        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): GroupNorm(8, 128, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (align_image): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (align_depth): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (post_norm): ModuleList(
      (0): GroupNorm(8, 96, eps=1e-05, affine=True)
      (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      (2): GroupNorm(8, 384, eps=1e-05, affine=True)
      (3): GroupNorm(8, 768, eps=1e-05, affine=True)
    )
  )
  (sem_seg_head): MGMHead(
    (pixel_decoder): MGMMSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (depth_pe): DepthPosEncoding(
        (mlp): Sequential(
          (0): Conv2d(1, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MGMMultiScaleMaskedTransformerDecoder(
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x MGMCrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=2, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 1
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/30 15:22:46] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [Mapper] Noise-mask dir not found, will skip masks: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/depth/depth_noise_mask
[08/30 15:22:46] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [COCOInstanceRGBDDatasetMapper] Augs: [RandomFlip(), ResizeScale(min_scale=0.1, max_scale=2.0, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=(1024, 1024))] | RGB: RGB | DATASET_ROOT=/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
[08/30 15:22:46] d2.data.datasets.coco INFO: Loaded 6 images in COCO format from /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/annotations/instances_train.json
[08/30 15:22:46] d2.data.build INFO: Removed 0 images with no usable annotations. 6 images left.
[08/30 15:22:46] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| component  | 147          |
|            |              |[0m
[08/30 15:22:46] d2.data.build INFO: Using training sampler TrainingSampler
[08/30 15:22:46] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[08/30 15:22:46] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[08/30 15:22:46] d2.data.common INFO: Serialized dataset takes 0.16 MiB
[08/30 15:22:46] d2.data.build INFO: Making batched data loader with batch_size=16
[08/30 15:22:46] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[08/30 15:22:46] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[08/30 15:22:46] d2.engine.train_loop INFO: Starting training from iteration 0
[08/30 15:22:46] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/fuyx/hch/detectron2/detectron2/engine/train_loop.py", line 155, in train
    self.run_step()
  File "/home/fuyx/hch/detectron2/detectron2/engine/defaults.py", line 530, in run_step
    self._trainer.run_step()
  File "/home/fuyx/hch/detectron2/detectron2/engine/train_loop.py", line 488, in run_step
    data = next(self._data_loader_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/data/common.py", line 329, in __iter__
    for d in self.dataset:
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1465, in _next_data
    return self._process_data(data)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1491, in _process_data
    data.reraise()
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/_utils.py", line 715, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 33, in fetch
    data.append(next(self.dataset_iter))
                ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/data/common.py", line 296, in __iter__
    yield self.dataset[idx]
          ~~~~~~~~~~~~^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/data/common.py", line 125, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/utils/serialize.py", line 26, in __call__
    return self._obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/data/dataset_mappers/coco_instance_rgbd_dataset_mapper.py", line 367, in __call__
    instances.gt_boxes = Boxes(instances.gt_masks.get_bounding_boxes())
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/structures/boxes.py", line 148, in __init__
    tensor = torch.as_tensor(tensor, dtype=torch.float32, device=torch.device("cpu"))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: too many dimensions 'Boxes'

[08/30 15:22:46] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[08/30 15:22:46] d2.utils.events INFO:  iter: 0       lr: N/A  max_mem: 303M
[08/30 15:29:41] detectron2 INFO: Rank of current process: 0. World size: 1
[08/30 15:29:42] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:43:55) [GCC 13.3.0]
numpy                            2.2.6
detectron2                       0.6 @/home/fuyx/hch/detectron2/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6, 8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   575.64.03
CUDA_HOME                        /home/fuyx/anaconda3/envs/m2f
Pillow                           11.3.0
torchvision                      0.20.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[08/30 15:29:42] detectron2 INFO: Command line arguments: Namespace(config_file='MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=['OUTPUT_DIR', './output/mgm_training'])
[08/30 15:29:42] detectron2 INFO: Contents of args.config_file=MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml:
MODEL:
  META_ARCHITECTURE: "MGMMaskFormer"

  # RGB Backbone: Swin Transformer Tiny
  RGB_BACKBONE:
    NAME: "D2SwinTransformer"
    WEIGHTS: ""
    SWIN:
      EMBED_DIM: 96
      DEPTHS: [2, 2, 6, 2]
      NUM_HEADS: [3, 6, 12, 24]
      WINDOW_SIZE: 7
      APE: False
      DROP_PATH_RATE: 0.3
      PATCH_NORM: True
      OUT_FEATURES: ["res2", "res3", "res4", "res5"]

  # Depth Backbone: ConvNeXt Tiny
  DEPTH_BACKBONE:
    NAME: "ConvNeXtDepthBackbone"
    WEIGHTS: ""
    CONVNEXT:
      DEPTHS: [3, 3, 9, 3]
      DIMS: [96, 192, 384, 768]
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1e-6

  # MGM Fusion Configuration
  MGM:
    ENABLED: True
    SHARED: True
    RESIDUAL_ALPHA: 0.05
    POST_FUSE_NORM: True # 新增：融合后GN
    LOSS_ENTROPY_W: 0.01
    TEMP_INIT: 1.5
    TEMP_FINAL: 1.0
    TEMP_STEPS: 3000 # 建议略短，收敛更快
    CLAMP_MIN: 0.05
    CLAMP_MAX: 0.95
    NOISE_MASK_WEIGHT: 0.0 # 前期建议关；有噪声掩码再开到0.05~0.1
    HIDDEN_DIM: 256
    FEATURE_DIMS: [96, 192, 384, 768]
    SCALE_KEYS: ["res2", "res3", "res4", "res5"]

    PRIOR:
      ENABLED: False # 总开关
      USE_GRADIENT: True # 先验逐项开关
      USE_VARIANCE: True
      USE_VALID_HOLE: True
      USE_RGB_EDGE: False # 前期建议关（最耗时）
      VAR_KERNEL: 5
      Z_MIN: 0.0
      Z_MAX: 1.0
      COMPUTE_ON: "res3" # "full"|"res2"|"res3"|"res4"|"res5"；前期建议用res3提速

    ROBUST_NORM:
      ENABLED: False # 前期建议关；要稳健再开
      METHOD: "minmax" # "minmax"|"quantile"

  # DPE Configuration
  DPE:
    ENABLED: True

  # Boundary Configuration
  BOUNDARY:
    ENABLED: False

  # RGB Input Pixel Mean/Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]

  # Semantic Segmentation Head
  SEM_SEG_HEAD:
    NAME: "MGMHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 1
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MGMMSDeformAttnPixelDecoder"
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6

  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MGMMultiScaleMaskedTransformerDecoder"
    TRANSFORMER_IN_FEATURE: "multi_scale_pixel_decoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 2.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 100
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    DEC_LAYERS: 10
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.8

# 数据集配置
DATASETS:
  TRAIN: ("coco_instance_rgbd_train",)
  TEST: ("coco_instance_rgbd_val",)

# 数据加载器配置
DATALOADER:
  NUM_WORKERS: 4
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  REPEAT_THRESHOLD: 0.0

# RGB-D Input Configuration
INPUT:
  DATASET_ROOT: "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input"
  IMAGE_SIZE: 1024
  MIN_SCALE: 0.1
  MAX_SCALE: 2.0
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "coco_instance_lsj_rgbd"
  RANDOM_FLIP: "horizontal"
  SIZE_DIVISIBILITY: 32

  # RGB光度增强
  RGB_PHOTO_AUG:
    ENABLED: False
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    SATURATION: 0.1
    HUE: 0.0

  # 深度数据配置
  DEPTH_FORMAT: "I"
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_CLIP_MAX: 1.0
  DEPTH_NORM: "minmax"
  DEPTH_NOISE:
    ENABLED: False
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
    DROP_PROB: 0.0
    DROP_VAL: 0.0

# 求解器配置
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (327778, 355092)
  MAX_ITER: 368750
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: "linear"
  GAMMA: 0.1
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_EMBED: 0.0
  CLIP_GRADIENTS:
    ENABLED: False
  AMP:
    ENABLED: True

# 测试配置
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False

# 输出配置
OUTPUT_DIR: "./output"

# 版本号
VERSION: 2.0

[08/30 15:29:42] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  LOAD_PROPOSALS: false
  NUM_WORKERS: 4
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_instance_rgbd_val
  TRAIN:
  - coco_instance_rgbd_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj_rgbd
  DATASET_ROOT: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
  DEPTH_CLIP_MAX: 1.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_FORMAT: I
  DEPTH_NOISE:
    DROP_PROB: 0.0
    DROP_VAL: 0.0
    ENABLED: false
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
  DEPTH_NORM: minmax
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  RGB_PHOTO_AUG:
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    ENABLED: false
    HUE: 0.0
    SATURATION: 0.1
  SIZE_DIVISIBILITY: 32
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BOUNDARY:
    ENABLED: false
  DEPTH_BACKBONE:
    CONVNEXT:
      DEPTHS:
      - 3
      - 3
      - 9
      - 3
      DIMS:
      - 96
      - 192
      - 384
      - 768
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1.0e-06
    NAME: ConvNeXtDepthBackbone
    WEIGHTS: ''
  DEVICE: cuda
  DPE:
    ENABLED: true
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MGMMultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MGMMaskFormer
  MGM:
    CLAMP_MAX: 0.95
    CLAMP_MIN: 0.05
    ENABLED: true
    FEATURE_DIMS:
    - 96
    - 192
    - 384
    - 768
    HIDDEN_DIM: 256
    LOSS_ENTROPY_W: 0.01
    NOISE_MASK_WEIGHT: 0.0
    POST_FUSE_NORM: true
    PRIOR:
      COMPUTE_ON: res3
      ENABLED: false
      USE_GRADIENT: true
      USE_RGB_EDGE: false
      USE_VALID_HOLE: true
      USE_VARIANCE: true
      VAR_KERNEL: 5
      Z_MAX: 1.0
      Z_MIN: 0.0
    RESIDUAL_ALPHA: 0.05
    ROBUST_NORM:
      ENABLED: false
      METHOD: minmax
    SCALE_KEYS:
    - res2
    - res3
    - res4
    - res5
    SHARED: true
    TEMP_FINAL: 1.0
    TEMP_INIT: 1.5
    TEMP_STEPS: 3000
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  RGB_BACKBONE:
    NAME: D2SwinTransformer
    SWIN:
      APE: false
      ATTN_DROP_RATE: 0.0
      DEPTHS:
      - 2
      - 2
      - 6
      - 2
      DROP_PATH_RATE: 0.3
      DROP_RATE: 0.0
      EMBED_DIM: 96
      MLP_RATIO: 4.0
      NUM_HEADS:
      - 3
      - 6
      - 12
      - 24
      OUT_FEATURES:
      - res2
      - res3
      - res4
      - res5
      PATCH_NORM: true
      PATCH_SIZE: 4
      PRETRAIN_IMG_SIZE: 224
      QKV_BIAS: true
      QK_SCALE: null
      USE_CHECKPOINT: false
      WINDOW_SIZE: 7
    WEIGHTS: ''
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MGMHead
    NORM: GN
    NUM_CLASSES: 1
    PIXEL_DECODER_NAME: MGMMSDeformAttnPixelDecoder
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: ''
OUTPUT_DIR: ./output/mgm_training
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 368750
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 327778
  - 355092
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2.0
VIS_PERIOD: 0

[08/30 15:29:42] detectron2 INFO: Full config saved to ./output/mgm_training/config.yaml
[08/30 15:29:42] d2.utils.env INFO: Using a generated random seed 43835501
[08/30 15:30:02] d2.engine.defaults INFO: Model:
MGMMaskFormer(
  (rgb_backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.055)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.109)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.136)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.164)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.191)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.218)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.245)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.273)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.300)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (depth_backbone): ConvNeXtDepthBackbone(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
  )
  (mgm): MultiModalGatedFusion(
    (prior_extractor): DepthPriorExtractor()
    (conf_pred): ConfidencePredictor(
      (proj_image): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_depth): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (head): Sequential(
        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): GroupNorm(8, 128, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (align_image): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (align_depth): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (post_norm): ModuleList(
      (0): GroupNorm(8, 96, eps=1e-05, affine=True)
      (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      (2): GroupNorm(8, 384, eps=1e-05, affine=True)
      (3): GroupNorm(8, 768, eps=1e-05, affine=True)
    )
  )
  (sem_seg_head): MGMHead(
    (pixel_decoder): MGMMSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (depth_pe): DepthPosEncoding(
        (mlp): Sequential(
          (0): Conv2d(1, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MGMMultiScaleMaskedTransformerDecoder(
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x MGMCrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=2, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 1
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/30 15:30:02] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [Mapper] Noise-mask dir not found, will skip masks: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/depth/depth_noise_mask
[08/30 15:30:02] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [COCOInstanceRGBDDatasetMapper] Augs: [RandomFlip(), ResizeScale(min_scale=0.1, max_scale=2.0, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=(1024, 1024))] | RGB: RGB | DATASET_ROOT=/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
[08/30 15:30:02] d2.data.datasets.coco INFO: Loaded 6 images in COCO format from /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/annotations/instances_train.json
[08/30 15:30:02] d2.data.build INFO: Removed 0 images with no usable annotations. 6 images left.
[08/30 15:30:02] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| component  | 147          |
|            |              |[0m
[08/30 15:30:02] d2.data.build INFO: Using training sampler TrainingSampler
[08/30 15:30:02] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[08/30 15:30:02] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[08/30 15:30:02] d2.data.common INFO: Serialized dataset takes 0.16 MiB
[08/30 15:30:02] d2.data.build INFO: Making batched data loader with batch_size=16
[08/30 15:30:02] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[08/30 15:30:02] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[08/30 15:30:02] d2.engine.train_loop INFO: Starting training from iteration 0
[08/30 15:30:03] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/fuyx/hch/detectron2/detectron2/engine/train_loop.py", line 155, in train
    self.run_step()
  File "/home/fuyx/hch/detectron2/detectron2/engine/defaults.py", line 530, in run_step
    self._trainer.run_step()
  File "/home/fuyx/hch/detectron2/detectron2/engine/train_loop.py", line 488, in run_step
    data = next(self._data_loader_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/data/common.py", line 329, in __iter__
    for d in self.dataset:
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1465, in _next_data
    return self._process_data(data)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1491, in _process_data
    data.reraise()
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/_utils.py", line 715, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 33, in fetch
    data.append(next(self.dataset_iter))
                ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/data/common.py", line 296, in __iter__
    yield self.dataset[idx]
          ~~~~~~~~~~~~^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/data/common.py", line 125, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/utils/serialize.py", line 26, in __call__
    return self._obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/data/dataset_mappers/coco_instance_rgbd_dataset_mapper.py", line 367, in __call__
    instances.gt_boxes = Boxes(instances.gt_masks.get_bounding_boxes())
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/structures/boxes.py", line 148, in __init__
    tensor = torch.as_tensor(tensor, dtype=torch.float32, device=torch.device("cpu"))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: too many dimensions 'Boxes'

[08/30 15:30:03] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[08/30 15:30:03] d2.utils.events INFO:  iter: 0       lr: N/A  max_mem: 303M
[08/30 15:31:31] detectron2 INFO: Rank of current process: 0. World size: 1
[08/30 15:31:31] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:43:55) [GCC 13.3.0]
numpy                            2.2.6
detectron2                       0.6 @/home/fuyx/hch/detectron2/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6, 8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   575.64.03
CUDA_HOME                        /home/fuyx/anaconda3/envs/m2f
Pillow                           11.3.0
torchvision                      0.20.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[08/30 15:31:31] detectron2 INFO: Command line arguments: Namespace(config_file='MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=['OUTPUT_DIR', './output/mgm_training'])
[08/30 15:31:31] detectron2 INFO: Contents of args.config_file=MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml:
MODEL:
  META_ARCHITECTURE: "MGMMaskFormer"

  # RGB Backbone: Swin Transformer Tiny
  RGB_BACKBONE:
    NAME: "D2SwinTransformer"
    WEIGHTS: ""
    SWIN:
      EMBED_DIM: 96
      DEPTHS: [2, 2, 6, 2]
      NUM_HEADS: [3, 6, 12, 24]
      WINDOW_SIZE: 7
      APE: False
      DROP_PATH_RATE: 0.3
      PATCH_NORM: True
      OUT_FEATURES: ["res2", "res3", "res4", "res5"]

  # Depth Backbone: ConvNeXt Tiny
  DEPTH_BACKBONE:
    NAME: "ConvNeXtDepthBackbone"
    WEIGHTS: ""
    CONVNEXT:
      DEPTHS: [3, 3, 9, 3]
      DIMS: [96, 192, 384, 768]
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1e-6

  # MGM Fusion Configuration
  MGM:
    ENABLED: True
    SHARED: True
    RESIDUAL_ALPHA: 0.05
    POST_FUSE_NORM: True # 新增：融合后GN
    LOSS_ENTROPY_W: 0.01
    TEMP_INIT: 1.5
    TEMP_FINAL: 1.0
    TEMP_STEPS: 3000 # 建议略短，收敛更快
    CLAMP_MIN: 0.05
    CLAMP_MAX: 0.95
    NOISE_MASK_WEIGHT: 0.0 # 前期建议关；有噪声掩码再开到0.05~0.1
    HIDDEN_DIM: 256
    FEATURE_DIMS: [96, 192, 384, 768]
    SCALE_KEYS: ["res2", "res3", "res4", "res5"]

    PRIOR:
      ENABLED: False # 总开关
      USE_GRADIENT: True # 先验逐项开关
      USE_VARIANCE: True
      USE_VALID_HOLE: True
      USE_RGB_EDGE: False # 前期建议关（最耗时）
      VAR_KERNEL: 5
      Z_MIN: 0.0
      Z_MAX: 1.0
      COMPUTE_ON: "res3" # "full"|"res2"|"res3"|"res4"|"res5"；前期建议用res3提速

    ROBUST_NORM:
      ENABLED: False # 前期建议关；要稳健再开
      METHOD: "minmax" # "minmax"|"quantile"

  # DPE Configuration
  DPE:
    ENABLED: True

  # Boundary Configuration
  BOUNDARY:
    ENABLED: False

  # RGB Input Pixel Mean/Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]

  # Semantic Segmentation Head
  SEM_SEG_HEAD:
    NAME: "MGMHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 1
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MGMMSDeformAttnPixelDecoder"
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6

  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MGMMultiScaleMaskedTransformerDecoder"
    TRANSFORMER_IN_FEATURE: "multi_scale_pixel_decoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 2.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 100
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    DEC_LAYERS: 10
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.8

# 数据集配置
DATASETS:
  TRAIN: ("coco_instance_rgbd_train",)
  TEST: ("coco_instance_rgbd_val",)

# 数据加载器配置
DATALOADER:
  NUM_WORKERS: 4
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  REPEAT_THRESHOLD: 0.0

# RGB-D Input Configuration
INPUT:
  DATASET_ROOT: "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input"
  IMAGE_SIZE: 1024
  MIN_SCALE: 0.1
  MAX_SCALE: 2.0
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "coco_instance_lsj_rgbd"
  RANDOM_FLIP: "horizontal"
  SIZE_DIVISIBILITY: 32

  # RGB光度增强
  RGB_PHOTO_AUG:
    ENABLED: False
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    SATURATION: 0.1
    HUE: 0.0

  # 深度数据配置
  DEPTH_FORMAT: "I"
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_CLIP_MAX: 1.0
  DEPTH_NORM: "minmax"
  DEPTH_NOISE:
    ENABLED: False
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
    DROP_PROB: 0.0
    DROP_VAL: 0.0

# 求解器配置
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (327778, 355092)
  MAX_ITER: 368750
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: "linear"
  GAMMA: 0.1
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_EMBED: 0.0
  CLIP_GRADIENTS:
    ENABLED: False
  AMP:
    ENABLED: True

# 测试配置
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False

# 输出配置
OUTPUT_DIR: "./output"

# 版本号
VERSION: 2.0

[08/30 15:31:31] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  LOAD_PROPOSALS: false
  NUM_WORKERS: 4
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_instance_rgbd_val
  TRAIN:
  - coco_instance_rgbd_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj_rgbd
  DATASET_ROOT: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
  DEPTH_CLIP_MAX: 1.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_FORMAT: I
  DEPTH_NOISE:
    DROP_PROB: 0.0
    DROP_VAL: 0.0
    ENABLED: false
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
  DEPTH_NORM: minmax
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  RGB_PHOTO_AUG:
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    ENABLED: false
    HUE: 0.0
    SATURATION: 0.1
  SIZE_DIVISIBILITY: 32
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BOUNDARY:
    ENABLED: false
  DEPTH_BACKBONE:
    CONVNEXT:
      DEPTHS:
      - 3
      - 3
      - 9
      - 3
      DIMS:
      - 96
      - 192
      - 384
      - 768
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1.0e-06
    NAME: ConvNeXtDepthBackbone
    WEIGHTS: ''
  DEVICE: cuda
  DPE:
    ENABLED: true
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MGMMultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MGMMaskFormer
  MGM:
    CLAMP_MAX: 0.95
    CLAMP_MIN: 0.05
    ENABLED: true
    FEATURE_DIMS:
    - 96
    - 192
    - 384
    - 768
    HIDDEN_DIM: 256
    LOSS_ENTROPY_W: 0.01
    NOISE_MASK_WEIGHT: 0.0
    POST_FUSE_NORM: true
    PRIOR:
      COMPUTE_ON: res3
      ENABLED: false
      USE_GRADIENT: true
      USE_RGB_EDGE: false
      USE_VALID_HOLE: true
      USE_VARIANCE: true
      VAR_KERNEL: 5
      Z_MAX: 1.0
      Z_MIN: 0.0
    RESIDUAL_ALPHA: 0.05
    ROBUST_NORM:
      ENABLED: false
      METHOD: minmax
    SCALE_KEYS:
    - res2
    - res3
    - res4
    - res5
    SHARED: true
    TEMP_FINAL: 1.0
    TEMP_INIT: 1.5
    TEMP_STEPS: 3000
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  RGB_BACKBONE:
    NAME: D2SwinTransformer
    SWIN:
      APE: false
      ATTN_DROP_RATE: 0.0
      DEPTHS:
      - 2
      - 2
      - 6
      - 2
      DROP_PATH_RATE: 0.3
      DROP_RATE: 0.0
      EMBED_DIM: 96
      MLP_RATIO: 4.0
      NUM_HEADS:
      - 3
      - 6
      - 12
      - 24
      OUT_FEATURES:
      - res2
      - res3
      - res4
      - res5
      PATCH_NORM: true
      PATCH_SIZE: 4
      PRETRAIN_IMG_SIZE: 224
      QKV_BIAS: true
      QK_SCALE: null
      USE_CHECKPOINT: false
      WINDOW_SIZE: 7
    WEIGHTS: ''
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MGMHead
    NORM: GN
    NUM_CLASSES: 1
    PIXEL_DECODER_NAME: MGMMSDeformAttnPixelDecoder
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: ''
OUTPUT_DIR: ./output/mgm_training
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 368750
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 327778
  - 355092
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2.0
VIS_PERIOD: 0

[08/30 15:31:31] detectron2 INFO: Full config saved to ./output/mgm_training/config.yaml
[08/30 15:31:31] d2.utils.env INFO: Using a generated random seed 33271875
[08/30 15:31:52] d2.engine.defaults INFO: Model:
MGMMaskFormer(
  (rgb_backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.055)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.109)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.136)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.164)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.191)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.218)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.245)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.273)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.300)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (depth_backbone): ConvNeXtDepthBackbone(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
  )
  (mgm): MultiModalGatedFusion(
    (prior_extractor): DepthPriorExtractor()
    (conf_pred): ConfidencePredictor(
      (proj_image): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_depth): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (head): Sequential(
        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): GroupNorm(8, 128, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (align_image): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (align_depth): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (post_norm): ModuleList(
      (0): GroupNorm(8, 96, eps=1e-05, affine=True)
      (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      (2): GroupNorm(8, 384, eps=1e-05, affine=True)
      (3): GroupNorm(8, 768, eps=1e-05, affine=True)
    )
  )
  (sem_seg_head): MGMHead(
    (pixel_decoder): MGMMSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (depth_pe): DepthPosEncoding(
        (mlp): Sequential(
          (0): Conv2d(1, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MGMMultiScaleMaskedTransformerDecoder(
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x MGMCrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=2, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 1
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/30 15:31:52] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [Mapper] Noise-mask dir not found, will skip masks: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/depth/depth_noise_mask
[08/30 15:31:52] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [COCOInstanceRGBDDatasetMapper] Augs: [RandomFlip(), ResizeScale(min_scale=0.1, max_scale=2.0, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=(1024, 1024))] | RGB: RGB | DATASET_ROOT=/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
[08/30 15:31:52] d2.data.datasets.coco INFO: Loaded 6 images in COCO format from /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/annotations/instances_train.json
[08/30 15:31:52] d2.data.build INFO: Removed 0 images with no usable annotations. 6 images left.
[08/30 15:31:52] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| component  | 147          |
|            |              |[0m
[08/30 15:31:52] d2.data.build INFO: Using training sampler TrainingSampler
[08/30 15:31:52] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[08/30 15:31:52] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[08/30 15:31:52] d2.data.common INFO: Serialized dataset takes 0.16 MiB
[08/30 15:31:52] d2.data.build INFO: Making batched data loader with batch_size=16
[08/30 15:31:52] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[08/30 15:31:52] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[08/30 15:31:52] d2.engine.train_loop INFO: Starting training from iteration 0
[08/30 15:31:52] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/fuyx/hch/detectron2/detectron2/engine/train_loop.py", line 155, in train
    self.run_step()
  File "/home/fuyx/hch/detectron2/detectron2/engine/defaults.py", line 530, in run_step
    self._trainer.run_step()
  File "/home/fuyx/hch/detectron2/detectron2/engine/train_loop.py", line 488, in run_step
    data = next(self._data_loader_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/data/common.py", line 329, in __iter__
    for d in self.dataset:
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1465, in _next_data
    return self._process_data(data)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1491, in _process_data
    data.reraise()
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/_utils.py", line 715, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 33, in fetch
    data.append(next(self.dataset_iter))
                ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/data/common.py", line 296, in __iter__
    yield self.dataset[idx]
          ~~~~~~~~~~~~^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/data/common.py", line 125, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/utils/serialize.py", line 26, in __call__
    return self._obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/data/dataset_mappers/coco_instance_rgbd_dataset_mapper.py", line 367, in __call__
    instances.gt_boxes = Boxes(instances.gt_masks.get_bounding_boxes())
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/structures/boxes.py", line 148, in __init__
    tensor = torch.as_tensor(tensor, dtype=torch.float32, device=torch.device("cpu"))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: too many dimensions 'Boxes'

[08/30 15:31:52] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[08/30 15:31:52] d2.utils.events INFO:  iter: 0       lr: N/A  max_mem: 303M
[08/30 15:32:46] detectron2 INFO: Rank of current process: 0. World size: 1
[08/30 15:32:46] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:43:55) [GCC 13.3.0]
numpy                            2.2.6
detectron2                       0.6 @/home/fuyx/hch/detectron2/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6, 8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   575.64.03
CUDA_HOME                        /home/fuyx/anaconda3/envs/m2f
Pillow                           11.3.0
torchvision                      0.20.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[08/30 15:32:46] detectron2 INFO: Command line arguments: Namespace(config_file='MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=['OUTPUT_DIR', './output/mgm_training'])
[08/30 15:32:46] detectron2 INFO: Contents of args.config_file=MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml:
MODEL:
  META_ARCHITECTURE: "MGMMaskFormer"

  # RGB Backbone: Swin Transformer Tiny
  RGB_BACKBONE:
    NAME: "D2SwinTransformer"
    WEIGHTS: ""
    SWIN:
      EMBED_DIM: 96
      DEPTHS: [2, 2, 6, 2]
      NUM_HEADS: [3, 6, 12, 24]
      WINDOW_SIZE: 7
      APE: False
      DROP_PATH_RATE: 0.3
      PATCH_NORM: True
      OUT_FEATURES: ["res2", "res3", "res4", "res5"]

  # Depth Backbone: ConvNeXt Tiny
  DEPTH_BACKBONE:
    NAME: "ConvNeXtDepthBackbone"
    WEIGHTS: ""
    CONVNEXT:
      DEPTHS: [3, 3, 9, 3]
      DIMS: [96, 192, 384, 768]
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1e-6

  # MGM Fusion Configuration
  MGM:
    ENABLED: True
    SHARED: True
    RESIDUAL_ALPHA: 0.05
    POST_FUSE_NORM: True # 新增：融合后GN
    LOSS_ENTROPY_W: 0.01
    TEMP_INIT: 1.5
    TEMP_FINAL: 1.0
    TEMP_STEPS: 3000 # 建议略短，收敛更快
    CLAMP_MIN: 0.05
    CLAMP_MAX: 0.95
    NOISE_MASK_WEIGHT: 0.0 # 前期建议关；有噪声掩码再开到0.05~0.1
    HIDDEN_DIM: 256
    FEATURE_DIMS: [96, 192, 384, 768]
    SCALE_KEYS: ["res2", "res3", "res4", "res5"]

    PRIOR:
      ENABLED: False # 总开关
      USE_GRADIENT: True # 先验逐项开关
      USE_VARIANCE: True
      USE_VALID_HOLE: True
      USE_RGB_EDGE: False # 前期建议关（最耗时）
      VAR_KERNEL: 5
      Z_MIN: 0.0
      Z_MAX: 1.0
      COMPUTE_ON: "res3" # "full"|"res2"|"res3"|"res4"|"res5"；前期建议用res3提速

    ROBUST_NORM:
      ENABLED: False # 前期建议关；要稳健再开
      METHOD: "minmax" # "minmax"|"quantile"

  # DPE Configuration
  DPE:
    ENABLED: True

  # Boundary Configuration
  BOUNDARY:
    ENABLED: False

  # RGB Input Pixel Mean/Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]

  # Semantic Segmentation Head
  SEM_SEG_HEAD:
    NAME: "MGMHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 1
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MGMMSDeformAttnPixelDecoder"
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6

  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MGMMultiScaleMaskedTransformerDecoder"
    TRANSFORMER_IN_FEATURE: "multi_scale_pixel_decoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 2.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 100
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    DEC_LAYERS: 10
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.8

# 数据集配置
DATASETS:
  TRAIN: ("coco_instance_rgbd_train",)
  TEST: ("coco_instance_rgbd_val",)

# 数据加载器配置
DATALOADER:
  NUM_WORKERS: 4
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  REPEAT_THRESHOLD: 0.0

# RGB-D Input Configuration
INPUT:
  DATASET_ROOT: "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input"
  IMAGE_SIZE: 1024
  MIN_SCALE: 0.1
  MAX_SCALE: 2.0
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "coco_instance_lsj_rgbd"
  RANDOM_FLIP: "horizontal"
  SIZE_DIVISIBILITY: 32

  # RGB光度增强
  RGB_PHOTO_AUG:
    ENABLED: False
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    SATURATION: 0.1
    HUE: 0.0

  # 深度数据配置
  DEPTH_FORMAT: "I"
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_CLIP_MAX: 1.0
  DEPTH_NORM: "minmax"
  DEPTH_NOISE:
    ENABLED: False
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
    DROP_PROB: 0.0
    DROP_VAL: 0.0

# 求解器配置
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (327778, 355092)
  MAX_ITER: 368750
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: "linear"
  GAMMA: 0.1
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_EMBED: 0.0
  CLIP_GRADIENTS:
    ENABLED: False
  AMP:
    ENABLED: True

# 测试配置
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False

# 输出配置
OUTPUT_DIR: "./output"

# 版本号
VERSION: 2.0

[08/30 15:32:46] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  LOAD_PROPOSALS: false
  NUM_WORKERS: 4
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_instance_rgbd_val
  TRAIN:
  - coco_instance_rgbd_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj_rgbd
  DATASET_ROOT: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
  DEPTH_CLIP_MAX: 1.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_FORMAT: I
  DEPTH_NOISE:
    DROP_PROB: 0.0
    DROP_VAL: 0.0
    ENABLED: false
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
  DEPTH_NORM: minmax
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  RGB_PHOTO_AUG:
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    ENABLED: false
    HUE: 0.0
    SATURATION: 0.1
  SIZE_DIVISIBILITY: 32
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BOUNDARY:
    ENABLED: false
  DEPTH_BACKBONE:
    CONVNEXT:
      DEPTHS:
      - 3
      - 3
      - 9
      - 3
      DIMS:
      - 96
      - 192
      - 384
      - 768
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1.0e-06
    NAME: ConvNeXtDepthBackbone
    WEIGHTS: ''
  DEVICE: cuda
  DPE:
    ENABLED: true
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MGMMultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MGMMaskFormer
  MGM:
    CLAMP_MAX: 0.95
    CLAMP_MIN: 0.05
    ENABLED: true
    FEATURE_DIMS:
    - 96
    - 192
    - 384
    - 768
    HIDDEN_DIM: 256
    LOSS_ENTROPY_W: 0.01
    NOISE_MASK_WEIGHT: 0.0
    POST_FUSE_NORM: true
    PRIOR:
      COMPUTE_ON: res3
      ENABLED: false
      USE_GRADIENT: true
      USE_RGB_EDGE: false
      USE_VALID_HOLE: true
      USE_VARIANCE: true
      VAR_KERNEL: 5
      Z_MAX: 1.0
      Z_MIN: 0.0
    RESIDUAL_ALPHA: 0.05
    ROBUST_NORM:
      ENABLED: false
      METHOD: minmax
    SCALE_KEYS:
    - res2
    - res3
    - res4
    - res5
    SHARED: true
    TEMP_FINAL: 1.0
    TEMP_INIT: 1.5
    TEMP_STEPS: 3000
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  RGB_BACKBONE:
    NAME: D2SwinTransformer
    SWIN:
      APE: false
      ATTN_DROP_RATE: 0.0
      DEPTHS:
      - 2
      - 2
      - 6
      - 2
      DROP_PATH_RATE: 0.3
      DROP_RATE: 0.0
      EMBED_DIM: 96
      MLP_RATIO: 4.0
      NUM_HEADS:
      - 3
      - 6
      - 12
      - 24
      OUT_FEATURES:
      - res2
      - res3
      - res4
      - res5
      PATCH_NORM: true
      PATCH_SIZE: 4
      PRETRAIN_IMG_SIZE: 224
      QKV_BIAS: true
      QK_SCALE: null
      USE_CHECKPOINT: false
      WINDOW_SIZE: 7
    WEIGHTS: ''
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MGMHead
    NORM: GN
    NUM_CLASSES: 1
    PIXEL_DECODER_NAME: MGMMSDeformAttnPixelDecoder
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: ''
OUTPUT_DIR: ./output/mgm_training
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 368750
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 327778
  - 355092
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2.0
VIS_PERIOD: 0

[08/30 15:32:46] detectron2 INFO: Full config saved to ./output/mgm_training/config.yaml
[08/30 15:32:46] d2.utils.env INFO: Using a generated random seed 48527415
[08/30 15:33:07] d2.engine.defaults INFO: Model:
MGMMaskFormer(
  (rgb_backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.055)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.109)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.136)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.164)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.191)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.218)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.245)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.273)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.300)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (depth_backbone): ConvNeXtDepthBackbone(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
  )
  (mgm): MultiModalGatedFusion(
    (prior_extractor): DepthPriorExtractor()
    (conf_pred): ConfidencePredictor(
      (proj_image): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_depth): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (head): Sequential(
        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): GroupNorm(8, 128, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (align_image): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (align_depth): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (post_norm): ModuleList(
      (0): GroupNorm(8, 96, eps=1e-05, affine=True)
      (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      (2): GroupNorm(8, 384, eps=1e-05, affine=True)
      (3): GroupNorm(8, 768, eps=1e-05, affine=True)
    )
  )
  (sem_seg_head): MGMHead(
    (pixel_decoder): MGMMSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (depth_pe): DepthPosEncoding(
        (mlp): Sequential(
          (0): Conv2d(1, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MGMMultiScaleMaskedTransformerDecoder(
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x MGMCrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=2, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 1
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/30 15:33:07] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [Mapper] Noise-mask dir not found, will skip masks: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/depth/depth_noise_mask
[08/30 15:33:07] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [COCOInstanceRGBDDatasetMapper] Augs: [RandomFlip(), ResizeScale(min_scale=0.1, max_scale=2.0, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=(1024, 1024))] | RGB: RGB | DATASET_ROOT=/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
[08/30 15:33:07] d2.data.datasets.coco INFO: Loaded 6 images in COCO format from /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/annotations/instances_train.json
[08/30 15:33:07] d2.data.build INFO: Removed 0 images with no usable annotations. 6 images left.
[08/30 15:33:07] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| component  | 147          |
|            |              |[0m
[08/30 15:33:07] d2.data.build INFO: Using training sampler TrainingSampler
[08/30 15:33:07] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[08/30 15:33:07] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[08/30 15:33:07] d2.data.common INFO: Serialized dataset takes 0.16 MiB
[08/30 15:33:07] d2.data.build INFO: Making batched data loader with batch_size=16
[08/30 15:33:07] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[08/30 15:33:07] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[08/30 15:33:07] d2.engine.train_loop INFO: Starting training from iteration 0
[08/30 15:33:07] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/fuyx/hch/detectron2/detectron2/engine/train_loop.py", line 155, in train
    self.run_step()
  File "/home/fuyx/hch/detectron2/detectron2/engine/defaults.py", line 530, in run_step
    self._trainer.run_step()
  File "/home/fuyx/hch/detectron2/detectron2/engine/train_loop.py", line 488, in run_step
    data = next(self._data_loader_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/data/common.py", line 329, in __iter__
    for d in self.dataset:
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1465, in _next_data
    return self._process_data(data)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1491, in _process_data
    data.reraise()
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/_utils.py", line 715, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 33, in fetch
    data.append(next(self.dataset_iter))
                ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/data/common.py", line 296, in __iter__
    yield self.dataset[idx]
          ~~~~~~~~~~~~^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/data/common.py", line 125, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/utils/serialize.py", line 26, in __call__
    return self._obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/data/dataset_mappers/coco_instance_rgbd_dataset_mapper.py", line 391, in __call__
    instances.gt_boxes = Boxes(bounding_boxes)
                         ^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/structures/boxes.py", line 148, in __init__
    tensor = torch.as_tensor(tensor, dtype=torch.float32, device=torch.device("cpu"))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: too many dimensions 'Boxes'

[08/30 15:33:07] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[08/30 15:33:07] d2.utils.events INFO:  iter: 0       lr: N/A  max_mem: 303M
[08/30 15:34:31] detectron2 INFO: Rank of current process: 0. World size: 1
[08/30 15:34:31] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:43:55) [GCC 13.3.0]
numpy                            2.2.6
detectron2                       0.6 @/home/fuyx/hch/detectron2/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6, 8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   575.64.03
CUDA_HOME                        /home/fuyx/anaconda3/envs/m2f
Pillow                           11.3.0
torchvision                      0.20.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[08/30 15:34:31] detectron2 INFO: Command line arguments: Namespace(config_file='MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=['OUTPUT_DIR', './output/mgm_training'])
[08/30 15:34:31] detectron2 INFO: Contents of args.config_file=MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml:
MODEL:
  META_ARCHITECTURE: "MGMMaskFormer"

  # RGB Backbone: Swin Transformer Tiny
  RGB_BACKBONE:
    NAME: "D2SwinTransformer"
    WEIGHTS: ""
    SWIN:
      EMBED_DIM: 96
      DEPTHS: [2, 2, 6, 2]
      NUM_HEADS: [3, 6, 12, 24]
      WINDOW_SIZE: 7
      APE: False
      DROP_PATH_RATE: 0.3
      PATCH_NORM: True
      OUT_FEATURES: ["res2", "res3", "res4", "res5"]

  # Depth Backbone: ConvNeXt Tiny
  DEPTH_BACKBONE:
    NAME: "ConvNeXtDepthBackbone"
    WEIGHTS: ""
    CONVNEXT:
      DEPTHS: [3, 3, 9, 3]
      DIMS: [96, 192, 384, 768]
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1e-6

  # MGM Fusion Configuration
  MGM:
    ENABLED: True
    SHARED: True
    RESIDUAL_ALPHA: 0.05
    POST_FUSE_NORM: True # 新增：融合后GN
    LOSS_ENTROPY_W: 0.01
    TEMP_INIT: 1.5
    TEMP_FINAL: 1.0
    TEMP_STEPS: 3000 # 建议略短，收敛更快
    CLAMP_MIN: 0.05
    CLAMP_MAX: 0.95
    NOISE_MASK_WEIGHT: 0.0 # 前期建议关；有噪声掩码再开到0.05~0.1
    HIDDEN_DIM: 256
    FEATURE_DIMS: [96, 192, 384, 768]
    SCALE_KEYS: ["res2", "res3", "res4", "res5"]

    PRIOR:
      ENABLED: False # 总开关
      USE_GRADIENT: True # 先验逐项开关
      USE_VARIANCE: True
      USE_VALID_HOLE: True
      USE_RGB_EDGE: False # 前期建议关（最耗时）
      VAR_KERNEL: 5
      Z_MIN: 0.0
      Z_MAX: 1.0
      COMPUTE_ON: "res3" # "full"|"res2"|"res3"|"res4"|"res5"；前期建议用res3提速

    ROBUST_NORM:
      ENABLED: False # 前期建议关；要稳健再开
      METHOD: "minmax" # "minmax"|"quantile"

  # DPE Configuration
  DPE:
    ENABLED: True

  # Boundary Configuration
  BOUNDARY:
    ENABLED: False

  # RGB Input Pixel Mean/Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]

  # Semantic Segmentation Head
  SEM_SEG_HEAD:
    NAME: "MGMHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 1
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MGMMSDeformAttnPixelDecoder"
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6

  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MGMMultiScaleMaskedTransformerDecoder"
    TRANSFORMER_IN_FEATURE: "multi_scale_pixel_decoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 2.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 100
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    DEC_LAYERS: 10
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.8

# 数据集配置
DATASETS:
  TRAIN: ("coco_instance_rgbd_train",)
  TEST: ("coco_instance_rgbd_val",)

# 数据加载器配置
DATALOADER:
  NUM_WORKERS: 4
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  REPEAT_THRESHOLD: 0.0

# RGB-D Input Configuration
INPUT:
  DATASET_ROOT: "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input"
  IMAGE_SIZE: 1024
  MIN_SCALE: 0.1
  MAX_SCALE: 2.0
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "coco_instance_lsj_rgbd"
  RANDOM_FLIP: "horizontal"
  SIZE_DIVISIBILITY: 32

  # RGB光度增强
  RGB_PHOTO_AUG:
    ENABLED: False
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    SATURATION: 0.1
    HUE: 0.0

  # 深度数据配置
  DEPTH_FORMAT: "I"
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_CLIP_MAX: 1.0
  DEPTH_NORM: "minmax"
  DEPTH_NOISE:
    ENABLED: False
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
    DROP_PROB: 0.0
    DROP_VAL: 0.0

# 求解器配置
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (327778, 355092)
  MAX_ITER: 368750
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: "linear"
  GAMMA: 0.1
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_EMBED: 0.0
  CLIP_GRADIENTS:
    ENABLED: False
  AMP:
    ENABLED: True

# 测试配置
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False

# 输出配置
OUTPUT_DIR: "./output"

# 版本号
VERSION: 2.0

[08/30 15:34:31] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  LOAD_PROPOSALS: false
  NUM_WORKERS: 4
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_instance_rgbd_val
  TRAIN:
  - coco_instance_rgbd_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj_rgbd
  DATASET_ROOT: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
  DEPTH_CLIP_MAX: 1.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_FORMAT: I
  DEPTH_NOISE:
    DROP_PROB: 0.0
    DROP_VAL: 0.0
    ENABLED: false
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
  DEPTH_NORM: minmax
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  RGB_PHOTO_AUG:
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    ENABLED: false
    HUE: 0.0
    SATURATION: 0.1
  SIZE_DIVISIBILITY: 32
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BOUNDARY:
    ENABLED: false
  DEPTH_BACKBONE:
    CONVNEXT:
      DEPTHS:
      - 3
      - 3
      - 9
      - 3
      DIMS:
      - 96
      - 192
      - 384
      - 768
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1.0e-06
    NAME: ConvNeXtDepthBackbone
    WEIGHTS: ''
  DEVICE: cuda
  DPE:
    ENABLED: true
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MGMMultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MGMMaskFormer
  MGM:
    CLAMP_MAX: 0.95
    CLAMP_MIN: 0.05
    ENABLED: true
    FEATURE_DIMS:
    - 96
    - 192
    - 384
    - 768
    HIDDEN_DIM: 256
    LOSS_ENTROPY_W: 0.01
    NOISE_MASK_WEIGHT: 0.0
    POST_FUSE_NORM: true
    PRIOR:
      COMPUTE_ON: res3
      ENABLED: false
      USE_GRADIENT: true
      USE_RGB_EDGE: false
      USE_VALID_HOLE: true
      USE_VARIANCE: true
      VAR_KERNEL: 5
      Z_MAX: 1.0
      Z_MIN: 0.0
    RESIDUAL_ALPHA: 0.05
    ROBUST_NORM:
      ENABLED: false
      METHOD: minmax
    SCALE_KEYS:
    - res2
    - res3
    - res4
    - res5
    SHARED: true
    TEMP_FINAL: 1.0
    TEMP_INIT: 1.5
    TEMP_STEPS: 3000
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  RGB_BACKBONE:
    NAME: D2SwinTransformer
    SWIN:
      APE: false
      ATTN_DROP_RATE: 0.0
      DEPTHS:
      - 2
      - 2
      - 6
      - 2
      DROP_PATH_RATE: 0.3
      DROP_RATE: 0.0
      EMBED_DIM: 96
      MLP_RATIO: 4.0
      NUM_HEADS:
      - 3
      - 6
      - 12
      - 24
      OUT_FEATURES:
      - res2
      - res3
      - res4
      - res5
      PATCH_NORM: true
      PATCH_SIZE: 4
      PRETRAIN_IMG_SIZE: 224
      QKV_BIAS: true
      QK_SCALE: null
      USE_CHECKPOINT: false
      WINDOW_SIZE: 7
    WEIGHTS: ''
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MGMHead
    NORM: GN
    NUM_CLASSES: 1
    PIXEL_DECODER_NAME: MGMMSDeformAttnPixelDecoder
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: ''
OUTPUT_DIR: ./output/mgm_training
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 368750
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 327778
  - 355092
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2.0
VIS_PERIOD: 0

[08/30 15:34:31] detectron2 INFO: Full config saved to ./output/mgm_training/config.yaml
[08/30 15:34:31] d2.utils.env INFO: Using a generated random seed 33309710
[08/30 15:34:52] d2.engine.defaults INFO: Model:
MGMMaskFormer(
  (rgb_backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.055)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.109)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.136)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.164)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.191)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.218)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.245)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.273)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.300)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (depth_backbone): ConvNeXtDepthBackbone(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
  )
  (mgm): MultiModalGatedFusion(
    (prior_extractor): DepthPriorExtractor()
    (conf_pred): ConfidencePredictor(
      (proj_image): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_depth): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (head): Sequential(
        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): GroupNorm(8, 128, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (align_image): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (align_depth): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (post_norm): ModuleList(
      (0): GroupNorm(8, 96, eps=1e-05, affine=True)
      (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      (2): GroupNorm(8, 384, eps=1e-05, affine=True)
      (3): GroupNorm(8, 768, eps=1e-05, affine=True)
    )
  )
  (sem_seg_head): MGMHead(
    (pixel_decoder): MGMMSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (depth_pe): DepthPosEncoding(
        (mlp): Sequential(
          (0): Conv2d(1, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MGMMultiScaleMaskedTransformerDecoder(
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x MGMCrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=2, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 1
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/30 15:34:52] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [Mapper] Noise-mask dir not found, will skip masks: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/depth/depth_noise_mask
[08/30 15:34:52] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [COCOInstanceRGBDDatasetMapper] Augs: [RandomFlip(), ResizeScale(min_scale=0.1, max_scale=2.0, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=(1024, 1024))] | RGB: RGB | DATASET_ROOT=/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
[08/30 15:34:52] d2.data.datasets.coco INFO: Loaded 6 images in COCO format from /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/annotations/instances_train.json
[08/30 15:34:52] d2.data.build INFO: Removed 0 images with no usable annotations. 6 images left.
[08/30 15:34:52] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| component  | 147          |
|            |              |[0m
[08/30 15:34:52] d2.data.build INFO: Using training sampler TrainingSampler
[08/30 15:34:52] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[08/30 15:34:52] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[08/30 15:34:52] d2.data.common INFO: Serialized dataset takes 0.16 MiB
[08/30 15:34:52] d2.data.build INFO: Making batched data loader with batch_size=16
[08/30 15:34:52] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[08/30 15:34:52] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[08/30 15:34:52] d2.engine.train_loop INFO: Starting training from iteration 0
[08/30 15:34:53] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/fuyx/hch/detectron2/detectron2/engine/train_loop.py", line 155, in train
    self.run_step()
  File "/home/fuyx/hch/detectron2/detectron2/engine/defaults.py", line 530, in run_step
    self._trainer.run_step()
  File "/home/fuyx/hch/detectron2/detectron2/engine/train_loop.py", line 494, in run_step
    loss_dict = self.model(data)
                ^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/modeling/meta_arch/mgm_model.py", line 180, in forward
    rgb_features = self.rgb_backbone(images.tensor)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/modeling/backbone/swin.py", line 792, in forward
    y = super().forward(x)
        ^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/modeling/backbone/swin.py", line 703, in forward
    x_out, H, W, x, Wh, Ww = layer(x, Wh, Ww)
                             ^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/modeling/backbone/swin.py", line 479, in forward
    x = blk(x, attn_mask)
        ^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/modeling/backbone/swin.py", line 323, in forward
    x = x + self.drop_path(self.mlp(self.norm2(x)))
                           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/modeling/backbone/swin.py", line 42, in forward
    x = self.act(x)
        ^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 734, in forward
    return F.gelu(input, approximate=self.approximate)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 137.31 MiB is free. Including non-PyTorch memory, this process has 22.03 GiB memory in use. Of the allocated memory 21.08 GiB is allocated by PyTorch, and 659.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[08/30 15:34:53] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[08/30 15:34:53] d2.utils.events INFO:  iter: 0       lr: N/A  max_mem: 21583M
[08/30 15:37:07] detectron2 INFO: Rank of current process: 0. World size: 1
[08/30 15:37:07] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:43:55) [GCC 13.3.0]
numpy                            2.2.6
detectron2                       0.6 @/home/fuyx/hch/detectron2/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6, 8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   575.64.03
CUDA_HOME                        /home/fuyx/anaconda3/envs/m2f
Pillow                           11.3.0
torchvision                      0.20.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[08/30 15:37:07] detectron2 INFO: Command line arguments: Namespace(config_file='MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=['OUTPUT_DIR', './output/mgm_training'])
[08/30 15:37:07] detectron2 INFO: Contents of args.config_file=MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml:
MODEL:
  META_ARCHITECTURE: "MGMMaskFormer"

  # RGB Backbone: Swin Transformer Tiny
  RGB_BACKBONE:
    NAME: "D2SwinTransformer"
    WEIGHTS: ""
    SWIN:
      EMBED_DIM: 96
      DEPTHS: [2, 2, 6, 2]
      NUM_HEADS: [3, 6, 12, 24]
      WINDOW_SIZE: 7
      APE: False
      DROP_PATH_RATE: 0.3
      PATCH_NORM: True
      OUT_FEATURES: ["res2", "res3", "res4", "res5"]

  # Depth Backbone: ConvNeXt Tiny
  DEPTH_BACKBONE:
    NAME: "ConvNeXtDepthBackbone"
    WEIGHTS: ""
    CONVNEXT:
      DEPTHS: [3, 3, 9, 3]
      DIMS: [96, 192, 384, 768]
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1e-6

  # MGM Fusion Configuration
  MGM:
    ENABLED: True
    SHARED: True
    RESIDUAL_ALPHA: 0.05
    POST_FUSE_NORM: True # 新增：融合后GN
    LOSS_ENTROPY_W: 0.01
    TEMP_INIT: 1.5
    TEMP_FINAL: 1.0
    TEMP_STEPS: 3000 # 建议略短，收敛更快
    CLAMP_MIN: 0.05
    CLAMP_MAX: 0.95
    NOISE_MASK_WEIGHT: 0.0 # 前期建议关；有噪声掩码再开到0.05~0.1
    HIDDEN_DIM: 256
    FEATURE_DIMS: [96, 192, 384, 768]
    SCALE_KEYS: ["res2", "res3", "res4", "res5"]

    PRIOR:
      ENABLED: False # 总开关
      USE_GRADIENT: True # 先验逐项开关
      USE_VARIANCE: True
      USE_VALID_HOLE: True
      USE_RGB_EDGE: False # 前期建议关（最耗时）
      VAR_KERNEL: 5
      Z_MIN: 0.0
      Z_MAX: 1.0
      COMPUTE_ON: "res3" # "full"|"res2"|"res3"|"res4"|"res5"；前期建议用res3提速

    ROBUST_NORM:
      ENABLED: False # 前期建议关；要稳健再开
      METHOD: "minmax" # "minmax"|"quantile"

  # DPE Configuration
  DPE:
    ENABLED: True

  # Boundary Configuration
  BOUNDARY:
    ENABLED: False

  # RGB Input Pixel Mean/Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]

  # Semantic Segmentation Head
  SEM_SEG_HEAD:
    NAME: "MGMHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 1
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MGMMSDeformAttnPixelDecoder"
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6

  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MGMMultiScaleMaskedTransformerDecoder"
    TRANSFORMER_IN_FEATURE: "multi_scale_pixel_decoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 2.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 100
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    DEC_LAYERS: 10
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.8

# 数据集配置
DATASETS:
  TRAIN: ("coco_instance_rgbd_train",)
  TEST: ("coco_instance_rgbd_val",)

# 数据加载器配置
DATALOADER:
  NUM_WORKERS: 4
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  REPEAT_THRESHOLD: 0.0

# RGB-D Input Configuration
INPUT:
  DATASET_ROOT: "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input"
  IMAGE_SIZE: 1024
  MIN_SCALE: 0.1
  MAX_SCALE: 2.0
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "coco_instance_lsj_rgbd"
  RANDOM_FLIP: "horizontal"
  SIZE_DIVISIBILITY: 32

  # RGB光度增强
  RGB_PHOTO_AUG:
    ENABLED: False
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    SATURATION: 0.1
    HUE: 0.0

  # 深度数据配置
  DEPTH_FORMAT: "I"
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_CLIP_MAX: 1.0
  DEPTH_NORM: "minmax"
  DEPTH_NOISE:
    ENABLED: False
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
    DROP_PROB: 0.0
    DROP_VAL: 0.0

# 求解器配置
SOLVER:
  IMS_PER_BATCH: 4
  BASE_LR: 0.0001
  STEPS: (327778, 355092)
  MAX_ITER: 368750
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: "linear"
  GAMMA: 0.1
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_EMBED: 0.0
  CLIP_GRADIENTS:
    ENABLED: False
  AMP:
    ENABLED: True

# 测试配置
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False

# 输出配置
OUTPUT_DIR: "./output"

# 版本号
VERSION: 2.0

[08/30 15:37:07] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  LOAD_PROPOSALS: false
  NUM_WORKERS: 4
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_instance_rgbd_val
  TRAIN:
  - coco_instance_rgbd_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj_rgbd
  DATASET_ROOT: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
  DEPTH_CLIP_MAX: 1.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_FORMAT: I
  DEPTH_NOISE:
    DROP_PROB: 0.0
    DROP_VAL: 0.0
    ENABLED: false
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
  DEPTH_NORM: minmax
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  RGB_PHOTO_AUG:
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    ENABLED: false
    HUE: 0.0
    SATURATION: 0.1
  SIZE_DIVISIBILITY: 32
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BOUNDARY:
    ENABLED: false
  DEPTH_BACKBONE:
    CONVNEXT:
      DEPTHS:
      - 3
      - 3
      - 9
      - 3
      DIMS:
      - 96
      - 192
      - 384
      - 768
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1.0e-06
    NAME: ConvNeXtDepthBackbone
    WEIGHTS: ''
  DEVICE: cuda
  DPE:
    ENABLED: true
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MGMMultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MGMMaskFormer
  MGM:
    CLAMP_MAX: 0.95
    CLAMP_MIN: 0.05
    ENABLED: true
    FEATURE_DIMS:
    - 96
    - 192
    - 384
    - 768
    HIDDEN_DIM: 256
    LOSS_ENTROPY_W: 0.01
    NOISE_MASK_WEIGHT: 0.0
    POST_FUSE_NORM: true
    PRIOR:
      COMPUTE_ON: res3
      ENABLED: false
      USE_GRADIENT: true
      USE_RGB_EDGE: false
      USE_VALID_HOLE: true
      USE_VARIANCE: true
      VAR_KERNEL: 5
      Z_MAX: 1.0
      Z_MIN: 0.0
    RESIDUAL_ALPHA: 0.05
    ROBUST_NORM:
      ENABLED: false
      METHOD: minmax
    SCALE_KEYS:
    - res2
    - res3
    - res4
    - res5
    SHARED: true
    TEMP_FINAL: 1.0
    TEMP_INIT: 1.5
    TEMP_STEPS: 3000
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  RGB_BACKBONE:
    NAME: D2SwinTransformer
    SWIN:
      APE: false
      ATTN_DROP_RATE: 0.0
      DEPTHS:
      - 2
      - 2
      - 6
      - 2
      DROP_PATH_RATE: 0.3
      DROP_RATE: 0.0
      EMBED_DIM: 96
      MLP_RATIO: 4.0
      NUM_HEADS:
      - 3
      - 6
      - 12
      - 24
      OUT_FEATURES:
      - res2
      - res3
      - res4
      - res5
      PATCH_NORM: true
      PATCH_SIZE: 4
      PRETRAIN_IMG_SIZE: 224
      QKV_BIAS: true
      QK_SCALE: null
      USE_CHECKPOINT: false
      WINDOW_SIZE: 7
    WEIGHTS: ''
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MGMHead
    NORM: GN
    NUM_CLASSES: 1
    PIXEL_DECODER_NAME: MGMMSDeformAttnPixelDecoder
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: ''
OUTPUT_DIR: ./output/mgm_training
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 368750
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 327778
  - 355092
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2.0
VIS_PERIOD: 0

[08/30 15:37:07] detectron2 INFO: Full config saved to ./output/mgm_training/config.yaml
[08/30 15:37:07] d2.utils.env INFO: Using a generated random seed 9136265
[08/30 15:37:28] d2.engine.defaults INFO: Model:
MGMMaskFormer(
  (rgb_backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.055)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.109)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.136)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.164)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.191)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.218)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.245)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.273)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.300)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (depth_backbone): ConvNeXtDepthBackbone(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
  )
  (mgm): MultiModalGatedFusion(
    (prior_extractor): DepthPriorExtractor()
    (conf_pred): ConfidencePredictor(
      (proj_image): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_depth): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (head): Sequential(
        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): GroupNorm(8, 128, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (align_image): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (align_depth): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (post_norm): ModuleList(
      (0): GroupNorm(8, 96, eps=1e-05, affine=True)
      (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      (2): GroupNorm(8, 384, eps=1e-05, affine=True)
      (3): GroupNorm(8, 768, eps=1e-05, affine=True)
    )
  )
  (sem_seg_head): MGMHead(
    (pixel_decoder): MGMMSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (depth_pe): DepthPosEncoding(
        (mlp): Sequential(
          (0): Conv2d(1, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MGMMultiScaleMaskedTransformerDecoder(
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x MGMCrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=2, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 1
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/30 15:37:28] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [Mapper] Noise-mask dir not found, will skip masks: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/depth/depth_noise_mask
[08/30 15:37:28] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [COCOInstanceRGBDDatasetMapper] Augs: [RandomFlip(), ResizeScale(min_scale=0.1, max_scale=2.0, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=(1024, 1024))] | RGB: RGB | DATASET_ROOT=/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
[08/30 15:37:28] d2.data.datasets.coco INFO: Loaded 6 images in COCO format from /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/annotations/instances_train.json
[08/30 15:37:28] d2.data.build INFO: Removed 0 images with no usable annotations. 6 images left.
[08/30 15:37:28] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| component  | 147          |
|            |              |[0m
[08/30 15:37:28] d2.data.build INFO: Using training sampler TrainingSampler
[08/30 15:37:28] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[08/30 15:37:28] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[08/30 15:37:28] d2.data.common INFO: Serialized dataset takes 0.16 MiB
[08/30 15:37:28] d2.data.build INFO: Making batched data loader with batch_size=4
[08/30 15:37:28] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[08/30 15:37:28] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[08/30 15:37:28] d2.engine.train_loop INFO: Starting training from iteration 0
[08/30 15:37:29] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/fuyx/hch/detectron2/detectron2/engine/train_loop.py", line 155, in train
    self.run_step()
  File "/home/fuyx/hch/detectron2/detectron2/engine/defaults.py", line 530, in run_step
    self._trainer.run_step()
  File "/home/fuyx/hch/detectron2/detectron2/engine/train_loop.py", line 494, in run_step
    loss_dict = self.model(data)
                ^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/modeling/meta_arch/mgm_model.py", line 192, in forward
    outputs = self.sem_seg_head(
              ^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/modeling/head/mgm_head.py", line 96, in forward
    return self.layers(features, confidence_maps, depth_raw, padding_mask, mask)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/modeling/head/mgm_head.py", line 109, in layers
    self.pixel_decoder.forward_features(
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/modeling/pixel_decoder/mgm_msdeformattn.py", line 385, in forward_features
    y, spatial_shapes, level_start_index = self.transformer(srcs, pos)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/modeling/pixel_decoder/mgm_msdeformattn.py", line 98, in forward
    memory = self.encoder(
             ^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/modeling/pixel_decoder/mgm_msdeformattn.py", line 216, in forward
    output = layer(
             ^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/modeling/pixel_decoder/mgm_msdeformattn.py", line 160, in forward
    src = self.forward_ffn(src)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/modeling/pixel_decoder/mgm_msdeformattn.py", line 136, in forward_ffn
    src2 = self.linear2(self.dropout2(self.activation(self.linear1(src))))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/functional.py", line 1704, in relu
    result = torch.relu(input)
             ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 336.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 205.31 MiB is free. Including non-PyTorch memory, this process has 21.96 GiB memory in use. Of the allocated memory 21.52 GiB is allocated by PyTorch, and 128.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[08/30 15:37:29] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[08/30 15:37:29] d2.utils.events INFO:  iter: 0       lr: N/A  max_mem: 22043M
[08/30 15:39:26] detectron2 INFO: Rank of current process: 0. World size: 1
[08/30 15:39:26] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:43:55) [GCC 13.3.0]
numpy                            2.2.6
detectron2                       0.6 @/home/fuyx/hch/detectron2/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6, 8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   575.64.03
CUDA_HOME                        /home/fuyx/anaconda3/envs/m2f
Pillow                           11.3.0
torchvision                      0.20.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[08/30 15:39:26] detectron2 INFO: Command line arguments: Namespace(config_file='MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=['OUTPUT_DIR', './output/mgm_training'])
[08/30 15:39:26] detectron2 INFO: Contents of args.config_file=MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml:
MODEL:
  META_ARCHITECTURE: "MGMMaskFormer"

  # RGB Backbone: Swin Transformer Tiny
  RGB_BACKBONE:
    NAME: "D2SwinTransformer"
    WEIGHTS: ""
    SWIN:
      EMBED_DIM: 96
      DEPTHS: [2, 2, 6, 2]
      NUM_HEADS: [3, 6, 12, 24]
      WINDOW_SIZE: 7
      APE: False
      DROP_PATH_RATE: 0.3
      PATCH_NORM: True
      OUT_FEATURES: ["res2", "res3", "res4", "res5"]

  # Depth Backbone: ConvNeXt Tiny
  DEPTH_BACKBONE:
    NAME: "ConvNeXtDepthBackbone"
    WEIGHTS: ""
    CONVNEXT:
      DEPTHS: [3, 3, 9, 3]
      DIMS: [96, 192, 384, 768]
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1e-6

  # MGM Fusion Configuration
  MGM:
    ENABLED: True
    SHARED: True
    RESIDUAL_ALPHA: 0.05
    POST_FUSE_NORM: True # 新增：融合后GN
    LOSS_ENTROPY_W: 0.01
    TEMP_INIT: 1.5
    TEMP_FINAL: 1.0
    TEMP_STEPS: 3000 # 建议略短，收敛更快
    CLAMP_MIN: 0.05
    CLAMP_MAX: 0.95
    NOISE_MASK_WEIGHT: 0.0 # 前期建议关；有噪声掩码再开到0.05~0.1
    HIDDEN_DIM: 256
    FEATURE_DIMS: [96, 192, 384, 768]
    SCALE_KEYS: ["res2", "res3", "res4", "res5"]

    PRIOR:
      ENABLED: False # 总开关
      USE_GRADIENT: True # 先验逐项开关
      USE_VARIANCE: True
      USE_VALID_HOLE: True
      USE_RGB_EDGE: False # 前期建议关（最耗时）
      VAR_KERNEL: 5
      Z_MIN: 0.0
      Z_MAX: 1.0
      COMPUTE_ON: "res3" # "full"|"res2"|"res3"|"res4"|"res5"；前期建议用res3提速

    ROBUST_NORM:
      ENABLED: False # 前期建议关；要稳健再开
      METHOD: "minmax" # "minmax"|"quantile"

  # DPE Configuration
  DPE:
    ENABLED: True

  # Boundary Configuration
  BOUNDARY:
    ENABLED: False

  # RGB Input Pixel Mean/Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]

  # Semantic Segmentation Head
  SEM_SEG_HEAD:
    NAME: "MGMHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 1
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MGMMSDeformAttnPixelDecoder"
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6

  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MGMMultiScaleMaskedTransformerDecoder"
    TRANSFORMER_IN_FEATURE: "multi_scale_pixel_decoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 2.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 100
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    DEC_LAYERS: 10
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.8

# 数据集配置
DATASETS:
  TRAIN: ("coco_instance_rgbd_train",)
  TEST: ("coco_instance_rgbd_val",)

# 数据加载器配置
DATALOADER:
  NUM_WORKERS: 4
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  REPEAT_THRESHOLD: 0.0

# RGB-D Input Configuration
INPUT:
  DATASET_ROOT: "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input"
  IMAGE_SIZE: 1024
  MIN_SCALE: 0.1
  MAX_SCALE: 2.0
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "coco_instance_lsj_rgbd"
  RANDOM_FLIP: "horizontal"
  SIZE_DIVISIBILITY: 32

  # RGB光度增强
  RGB_PHOTO_AUG:
    ENABLED: False
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    SATURATION: 0.1
    HUE: 0.0

  # 深度数据配置
  DEPTH_FORMAT: "I"
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_CLIP_MAX: 1.0
  DEPTH_NORM: "minmax"
  DEPTH_NOISE:
    ENABLED: False
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
    DROP_PROB: 0.0
    DROP_VAL: 0.0

# 求解器配置
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (327778, 355092)
  MAX_ITER: 368750
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  GAMMA: 0.1
  OPTIMIZER: ADAMW
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_EMBED: 0.0
  CLIP_GRADIENTS:
    ENABLED: False
  AMP:
    ENABLED: True

# 测试配置
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False

# 输出配置
OUTPUT_DIR: "./output"

# 版本号
VERSION: 2.0

[08/30 15:39:26] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  LOAD_PROPOSALS: false
  NUM_WORKERS: 4
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_instance_rgbd_val
  TRAIN:
  - coco_instance_rgbd_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj_rgbd
  DATASET_ROOT: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
  DEPTH_CLIP_MAX: 1.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_FORMAT: I
  DEPTH_NOISE:
    DROP_PROB: 0.0
    DROP_VAL: 0.0
    ENABLED: false
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
  DEPTH_NORM: minmax
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  RGB_PHOTO_AUG:
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    ENABLED: false
    HUE: 0.0
    SATURATION: 0.1
  SIZE_DIVISIBILITY: 32
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BOUNDARY:
    ENABLED: false
  DEPTH_BACKBONE:
    CONVNEXT:
      DEPTHS:
      - 3
      - 3
      - 9
      - 3
      DIMS:
      - 96
      - 192
      - 384
      - 768
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1.0e-06
    NAME: ConvNeXtDepthBackbone
    WEIGHTS: ''
  DEVICE: cuda
  DPE:
    ENABLED: true
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MGMMultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MGMMaskFormer
  MGM:
    CLAMP_MAX: 0.95
    CLAMP_MIN: 0.05
    ENABLED: true
    FEATURE_DIMS:
    - 96
    - 192
    - 384
    - 768
    HIDDEN_DIM: 256
    LOSS_ENTROPY_W: 0.01
    NOISE_MASK_WEIGHT: 0.0
    POST_FUSE_NORM: true
    PRIOR:
      COMPUTE_ON: res3
      ENABLED: false
      USE_GRADIENT: true
      USE_RGB_EDGE: false
      USE_VALID_HOLE: true
      USE_VARIANCE: true
      VAR_KERNEL: 5
      Z_MAX: 1.0
      Z_MIN: 0.0
    RESIDUAL_ALPHA: 0.05
    ROBUST_NORM:
      ENABLED: false
      METHOD: minmax
    SCALE_KEYS:
    - res2
    - res3
    - res4
    - res5
    SHARED: true
    TEMP_FINAL: 1.0
    TEMP_INIT: 1.5
    TEMP_STEPS: 3000
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  RGB_BACKBONE:
    NAME: D2SwinTransformer
    SWIN:
      APE: false
      ATTN_DROP_RATE: 0.0
      DEPTHS:
      - 2
      - 2
      - 6
      - 2
      DROP_PATH_RATE: 0.3
      DROP_RATE: 0.0
      EMBED_DIM: 96
      MLP_RATIO: 4.0
      NUM_HEADS:
      - 3
      - 6
      - 12
      - 24
      OUT_FEATURES:
      - res2
      - res3
      - res4
      - res5
      PATCH_NORM: true
      PATCH_SIZE: 4
      PRETRAIN_IMG_SIZE: 224
      QKV_BIAS: true
      QK_SCALE: null
      USE_CHECKPOINT: false
      WINDOW_SIZE: 7
    WEIGHTS: ''
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MGMHead
    NORM: GN
    NUM_CLASSES: 1
    PIXEL_DECODER_NAME: MGMMSDeformAttnPixelDecoder
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: ''
OUTPUT_DIR: ./output/mgm_training
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 368750
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 327778
  - 355092
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2.0
VIS_PERIOD: 0

[08/30 15:39:26] detectron2 INFO: Full config saved to ./output/mgm_training/config.yaml
[08/30 15:39:26] d2.utils.env INFO: Using a generated random seed 28284608
[08/30 15:39:47] d2.engine.defaults INFO: Model:
MGMMaskFormer(
  (rgb_backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.055)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.109)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.136)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.164)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.191)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.218)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.245)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.273)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.300)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (depth_backbone): ConvNeXtDepthBackbone(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
  )
  (mgm): MultiModalGatedFusion(
    (prior_extractor): DepthPriorExtractor()
    (conf_pred): ConfidencePredictor(
      (proj_image): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_depth): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (head): Sequential(
        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): GroupNorm(8, 128, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (align_image): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (align_depth): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (post_norm): ModuleList(
      (0): GroupNorm(8, 96, eps=1e-05, affine=True)
      (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      (2): GroupNorm(8, 384, eps=1e-05, affine=True)
      (3): GroupNorm(8, 768, eps=1e-05, affine=True)
    )
  )
  (sem_seg_head): MGMHead(
    (pixel_decoder): MGMMSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (depth_pe): DepthPosEncoding(
        (mlp): Sequential(
          (0): Conv2d(1, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MGMMultiScaleMaskedTransformerDecoder(
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x MGMCrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=2, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 1
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/30 15:39:47] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [Mapper] Noise-mask dir not found, will skip masks: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/depth/depth_noise_mask
[08/30 15:39:47] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [COCOInstanceRGBDDatasetMapper] Augs: [RandomFlip(), ResizeScale(min_scale=0.1, max_scale=2.0, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=(1024, 1024))] | RGB: RGB | DATASET_ROOT=/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
[08/30 15:39:47] d2.data.datasets.coco INFO: Loaded 6 images in COCO format from /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/annotations/instances_train.json
[08/30 15:39:47] d2.data.build INFO: Removed 0 images with no usable annotations. 6 images left.
[08/30 15:39:47] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| component  | 147          |
|            |              |[0m
[08/30 15:39:47] d2.data.build INFO: Using training sampler TrainingSampler
[08/30 15:39:47] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[08/30 15:39:47] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[08/30 15:39:47] d2.data.common INFO: Serialized dataset takes 0.16 MiB
[08/30 15:39:47] d2.data.build INFO: Making batched data loader with batch_size=1
[08/30 15:39:47] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[08/30 15:39:47] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[08/30 15:40:10] detectron2 INFO: Rank of current process: 0. World size: 1
[08/30 15:40:11] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:43:55) [GCC 13.3.0]
numpy                            2.2.6
detectron2                       0.6 @/home/fuyx/hch/detectron2/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6, 8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   575.64.03
CUDA_HOME                        /home/fuyx/anaconda3/envs/m2f
Pillow                           11.3.0
torchvision                      0.20.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[08/30 15:40:11] detectron2 INFO: Command line arguments: Namespace(config_file='MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=['OUTPUT_DIR', './output/mgm_training'])
[08/30 15:40:11] detectron2 INFO: Contents of args.config_file=MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml:
MODEL:
  META_ARCHITECTURE: "MGMMaskFormer"

  # RGB Backbone: Swin Transformer Tiny
  RGB_BACKBONE:
    NAME: "D2SwinTransformer"
    WEIGHTS: ""
    SWIN:
      EMBED_DIM: 96
      DEPTHS: [2, 2, 6, 2]
      NUM_HEADS: [3, 6, 12, 24]
      WINDOW_SIZE: 7
      APE: False
      DROP_PATH_RATE: 0.3
      PATCH_NORM: True
      OUT_FEATURES: ["res2", "res3", "res4", "res5"]

  # Depth Backbone: ConvNeXt Tiny
  DEPTH_BACKBONE:
    NAME: "ConvNeXtDepthBackbone"
    WEIGHTS: ""
    CONVNEXT:
      DEPTHS: [3, 3, 9, 3]
      DIMS: [96, 192, 384, 768]
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1e-6

  # MGM Fusion Configuration
  MGM:
    ENABLED: True
    SHARED: True
    RESIDUAL_ALPHA: 0.05
    POST_FUSE_NORM: True # 新增：融合后GN
    LOSS_ENTROPY_W: 0.01
    TEMP_INIT: 1.5
    TEMP_FINAL: 1.0
    TEMP_STEPS: 3000 # 建议略短，收敛更快
    CLAMP_MIN: 0.05
    CLAMP_MAX: 0.95
    NOISE_MASK_WEIGHT: 0.0 # 前期建议关；有噪声掩码再开到0.05~0.1
    HIDDEN_DIM: 256
    FEATURE_DIMS: [96, 192, 384, 768]
    SCALE_KEYS: ["res2", "res3", "res4", "res5"]

    PRIOR:
      ENABLED: False # 总开关
      USE_GRADIENT: True # 先验逐项开关
      USE_VARIANCE: True
      USE_VALID_HOLE: True
      USE_RGB_EDGE: False # 前期建议关（最耗时）
      VAR_KERNEL: 5
      Z_MIN: 0.0
      Z_MAX: 1.0
      COMPUTE_ON: "res3" # "full"|"res2"|"res3"|"res4"|"res5"；前期建议用res3提速

    ROBUST_NORM:
      ENABLED: False # 前期建议关；要稳健再开
      METHOD: "minmax" # "minmax"|"quantile"

  # DPE Configuration
  DPE:
    ENABLED: True

  # Boundary Configuration
  BOUNDARY:
    ENABLED: False

  # RGB Input Pixel Mean/Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]

  # Semantic Segmentation Head
  SEM_SEG_HEAD:
    NAME: "MGMHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 1
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MGMMSDeformAttnPixelDecoder"
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6

  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MGMMultiScaleMaskedTransformerDecoder"
    TRANSFORMER_IN_FEATURE: "multi_scale_pixel_decoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 2.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 100
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    DEC_LAYERS: 10
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.8

# 数据集配置
DATASETS:
  TRAIN: ("coco_instance_rgbd_train",)
  TEST: ("coco_instance_rgbd_val",)

# 数据加载器配置
DATALOADER:
  NUM_WORKERS: 4
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  REPEAT_THRESHOLD: 0.0

# RGB-D Input Configuration
INPUT:
  DATASET_ROOT: "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input"
  IMAGE_SIZE: 1024
  MIN_SCALE: 0.1
  MAX_SCALE: 2.0
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "coco_instance_lsj_rgbd"
  RANDOM_FLIP: "horizontal"
  SIZE_DIVISIBILITY: 32

  # RGB光度增强
  RGB_PHOTO_AUG:
    ENABLED: False
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    SATURATION: 0.1
    HUE: 0.0

  # 深度数据配置
  DEPTH_FORMAT: "I"
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_CLIP_MAX: 1.0
  DEPTH_NORM: "minmax"
  DEPTH_NOISE:
    ENABLED: False
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
    DROP_PROB: 0.0
    DROP_VAL: 0.0

# 求解器配置
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (327778, 355092)
  MAX_ITER: 368750
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  GAMMA: 0.1
  OPTIMIZER: ADAMW
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_EMBED: 0.0
  CLIP_GRADIENTS:
    ENABLED: False
  AMP:
    ENABLED: True

# 测试配置
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False

# 输出配置
OUTPUT_DIR: "./output"

# 版本号
VERSION: 2.0

[08/30 15:40:11] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  LOAD_PROPOSALS: false
  NUM_WORKERS: 4
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_instance_rgbd_val
  TRAIN:
  - coco_instance_rgbd_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj_rgbd
  DATASET_ROOT: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
  DEPTH_CLIP_MAX: 1.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_FORMAT: I
  DEPTH_NOISE:
    DROP_PROB: 0.0
    DROP_VAL: 0.0
    ENABLED: false
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
  DEPTH_NORM: minmax
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  RGB_PHOTO_AUG:
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    ENABLED: false
    HUE: 0.0
    SATURATION: 0.1
  SIZE_DIVISIBILITY: 32
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BOUNDARY:
    ENABLED: false
  DEPTH_BACKBONE:
    CONVNEXT:
      DEPTHS:
      - 3
      - 3
      - 9
      - 3
      DIMS:
      - 96
      - 192
      - 384
      - 768
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1.0e-06
    NAME: ConvNeXtDepthBackbone
    WEIGHTS: ''
  DEVICE: cuda
  DPE:
    ENABLED: true
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MGMMultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MGMMaskFormer
  MGM:
    CLAMP_MAX: 0.95
    CLAMP_MIN: 0.05
    ENABLED: true
    FEATURE_DIMS:
    - 96
    - 192
    - 384
    - 768
    HIDDEN_DIM: 256
    LOSS_ENTROPY_W: 0.01
    NOISE_MASK_WEIGHT: 0.0
    POST_FUSE_NORM: true
    PRIOR:
      COMPUTE_ON: res3
      ENABLED: false
      USE_GRADIENT: true
      USE_RGB_EDGE: false
      USE_VALID_HOLE: true
      USE_VARIANCE: true
      VAR_KERNEL: 5
      Z_MAX: 1.0
      Z_MIN: 0.0
    RESIDUAL_ALPHA: 0.05
    ROBUST_NORM:
      ENABLED: false
      METHOD: minmax
    SCALE_KEYS:
    - res2
    - res3
    - res4
    - res5
    SHARED: true
    TEMP_FINAL: 1.0
    TEMP_INIT: 1.5
    TEMP_STEPS: 3000
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  RGB_BACKBONE:
    NAME: D2SwinTransformer
    SWIN:
      APE: false
      ATTN_DROP_RATE: 0.0
      DEPTHS:
      - 2
      - 2
      - 6
      - 2
      DROP_PATH_RATE: 0.3
      DROP_RATE: 0.0
      EMBED_DIM: 96
      MLP_RATIO: 4.0
      NUM_HEADS:
      - 3
      - 6
      - 12
      - 24
      OUT_FEATURES:
      - res2
      - res3
      - res4
      - res5
      PATCH_NORM: true
      PATCH_SIZE: 4
      PRETRAIN_IMG_SIZE: 224
      QKV_BIAS: true
      QK_SCALE: null
      USE_CHECKPOINT: false
      WINDOW_SIZE: 7
    WEIGHTS: ''
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MGMHead
    NORM: GN
    NUM_CLASSES: 1
    PIXEL_DECODER_NAME: MGMMSDeformAttnPixelDecoder
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: ''
OUTPUT_DIR: ./output/mgm_training
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 368750
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 327778
  - 355092
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2.0
VIS_PERIOD: 0

[08/30 15:40:11] detectron2 INFO: Full config saved to ./output/mgm_training/config.yaml
[08/30 15:40:11] d2.utils.env INFO: Using a generated random seed 12609172
[08/30 15:40:31] d2.engine.defaults INFO: Model:
MGMMaskFormer(
  (rgb_backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.055)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.109)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.136)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.164)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.191)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.218)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.245)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.273)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.300)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (depth_backbone): ConvNeXtDepthBackbone(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
  )
  (mgm): MultiModalGatedFusion(
    (prior_extractor): DepthPriorExtractor()
    (conf_pred): ConfidencePredictor(
      (proj_image): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_depth): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (head): Sequential(
        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): GroupNorm(8, 128, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (align_image): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (align_depth): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (post_norm): ModuleList(
      (0): GroupNorm(8, 96, eps=1e-05, affine=True)
      (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      (2): GroupNorm(8, 384, eps=1e-05, affine=True)
      (3): GroupNorm(8, 768, eps=1e-05, affine=True)
    )
  )
  (sem_seg_head): MGMHead(
    (pixel_decoder): MGMMSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (depth_pe): DepthPosEncoding(
        (mlp): Sequential(
          (0): Conv2d(1, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MGMMultiScaleMaskedTransformerDecoder(
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x MGMCrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=2, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 1
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/30 15:40:31] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [Mapper] Noise-mask dir not found, will skip masks: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/depth/depth_noise_mask
[08/30 15:40:31] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [COCOInstanceRGBDDatasetMapper] Augs: [RandomFlip(), ResizeScale(min_scale=0.1, max_scale=2.0, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=(1024, 1024))] | RGB: RGB | DATASET_ROOT=/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
[08/30 15:40:31] d2.data.datasets.coco INFO: Loaded 6 images in COCO format from /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/annotations/instances_train.json
[08/30 15:40:31] d2.data.build INFO: Removed 0 images with no usable annotations. 6 images left.
[08/30 15:40:31] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| component  | 147          |
|            |              |[0m
[08/30 15:40:31] d2.data.build INFO: Using training sampler TrainingSampler
[08/30 15:40:31] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[08/30 15:40:31] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[08/30 15:40:31] d2.data.common INFO: Serialized dataset takes 0.16 MiB
[08/30 15:40:31] d2.data.build INFO: Making batched data loader with batch_size=1
[08/30 15:40:31] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[08/30 15:40:31] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[08/30 15:40:31] d2.engine.train_loop INFO: Starting training from iteration 0
[08/30 15:40:41] d2.utils.events INFO:  eta: 1 day, 16:43:35  iter: 19  total_loss: 96.92  loss_ce: 3.072  loss_mask: 3.856  loss_dice: 4.946  loss_ce_0: 1.122  loss_mask_0: 1.872  loss_dice_0: 4.879  loss_ce_1: 1.167  loss_mask_1: 3.084  loss_dice_1: 4.885  loss_ce_2: 1.125  loss_mask_2: 1.794  loss_dice_2: 4.903  loss_ce_3: 1.305  loss_mask_3: 3.002  loss_dice_3: 4.922  loss_ce_4: 1.168  loss_mask_4: 5.091  loss_dice_4: 4.906  loss_ce_5: 1.197  loss_mask_5: 3.439  loss_dice_5: 4.94  loss_ce_6: 1.711  loss_mask_6: 2.726  loss_dice_6: 4.961  loss_ce_7: 1.175  loss_mask_7: 3.047  loss_dice_7: 4.953  loss_ce_8: 1.29  loss_mask_8: 3.594  loss_dice_8: 4.957  loss_mgm_entropy: 0.006891    time: 0.4178  last_time: 0.4343  data_time: 0.0161  last_data_time: 0.0031   lr: 0.0001  max_mem: 15311M
[08/30 15:40:49] d2.utils.events INFO:  eta: 1 day, 19:26:26  iter: 39  total_loss: 64.76  loss_ce: 1.125  loss_mask: 0.7245  loss_dice: 4.757  loss_ce_0: 0.7553  loss_mask_0: 0.7534  loss_dice_0: 4.715  loss_ce_1: 0.688  loss_mask_1: 0.7262  loss_dice_1: 4.706  loss_ce_2: 0.7841  loss_mask_2: 0.7478  loss_dice_2: 4.708  loss_ce_3: 0.8831  loss_mask_3: 0.7347  loss_dice_3: 4.726  loss_ce_4: 1.022  loss_mask_4: 0.7034  loss_dice_4: 4.721  loss_ce_5: 1.098  loss_mask_5: 0.7406  loss_dice_5: 4.735  loss_ce_6: 1.158  loss_mask_6: 0.725  loss_dice_6: 4.75  loss_ce_7: 1.123  loss_mask_7: 0.7368  loss_dice_7: 4.737  loss_ce_8: 1.157  loss_mask_8: 0.7297  loss_dice_8: 4.753  loss_mgm_entropy: 0.006393    time: 0.4220  last_time: 0.4235  data_time: 0.0028  last_data_time: 0.0025   lr: 0.0001  max_mem: 15314M
[08/30 15:40:58] d2.utils.events INFO:  eta: 1 day, 19:37:33  iter: 59  total_loss: 59.07  loss_ce: 1.098  loss_mask: 0.5541  loss_dice: 4.722  loss_ce_0: 0.7292  loss_mask_0: 0.5628  loss_dice_0: 4.712  loss_ce_1: 0.3566  loss_mask_1: 0.5577  loss_dice_1: 4.701  loss_ce_2: 0.232  loss_mask_2: 0.5699  loss_dice_2: 4.688  loss_ce_3: 0.2655  loss_mask_3: 0.5487  loss_dice_3: 4.708  loss_ce_4: 0.4236  loss_mask_4: 0.5608  loss_dice_4: 4.712  loss_ce_5: 0.648  loss_mask_5: 0.5625  loss_dice_5: 4.722  loss_ce_6: 0.8555  loss_mask_6: 0.5988  loss_dice_6: 4.713  loss_ce_7: 1.022  loss_mask_7: 0.5653  loss_dice_7: 4.711  loss_ce_8: 1.075  loss_mask_8: 0.5763  loss_dice_8: 4.72  loss_mgm_entropy: 0.006348    time: 0.4252  last_time: 0.4258  data_time: 0.0028  last_data_time: 0.0030   lr: 0.0001  max_mem: 15316M
[08/30 15:41:06] d2.utils.events INFO:  eta: 1 day, 19:36:49  iter: 79  total_loss: 54  loss_ce: 0.4969  loss_mask: 0.4568  loss_dice: 4.704  loss_ce_0: 0.7043  loss_mask_0: 0.4217  loss_dice_0: 4.695  loss_ce_1: 0.1651  loss_mask_1: 0.4274  loss_dice_1: 4.681  loss_ce_2: 0.07717  loss_mask_2: 0.4169  loss_dice_2: 4.682  loss_ce_3: 0.06935  loss_mask_3: 0.4208  loss_dice_3: 4.698  loss_ce_4: 0.0702  loss_mask_4: 0.4324  loss_dice_4: 4.674  loss_ce_5: 0.07121  loss_mask_5: 0.4231  loss_dice_5: 4.693  loss_ce_6: 0.06161  loss_mask_6: 0.446  loss_dice_6: 4.673  loss_ce_7: 0.1073  loss_mask_7: 0.4287  loss_dice_7: 4.703  loss_ce_8: 0.2063  loss_mask_8: 0.4547  loss_dice_8: 4.711  loss_mgm_entropy: 0.006314    time: 0.4252  last_time: 0.4231  data_time: 0.0028  last_data_time: 0.0034   lr: 0.0001  max_mem: 15317M
[08/30 15:41:15] d2.utils.events INFO:  eta: 1 day, 19:35:55  iter: 99  total_loss: 55.76  loss_ce: 0.0874  loss_mask: 0.7238  loss_dice: 4.723  loss_ce_0: 0.6876  loss_mask_0: 0.6723  loss_dice_0: 4.737  loss_ce_1: 0.1136  loss_mask_1: 0.703  loss_dice_1: 4.705  loss_ce_2: 0.05213  loss_mask_2: 0.7116  loss_dice_2: 4.715  loss_ce_3: 0.05427  loss_mask_3: 0.7199  loss_dice_3: 4.711  loss_ce_4: 0.05544  loss_mask_4: 0.7167  loss_dice_4: 4.715  loss_ce_5: 0.055  loss_mask_5: 0.708  loss_dice_5: 4.722  loss_ce_6: 0.0494  loss_mask_6: 0.7189  loss_dice_6: 4.721  loss_ce_7: 0.05059  loss_mask_7: 0.7207  loss_dice_7: 4.734  loss_ce_8: 0.06726  loss_mask_8: 0.722  loss_dice_8: 4.737  loss_mgm_entropy: 0.006282    time: 0.4254  last_time: 0.4243  data_time: 0.0028  last_data_time: 0.0026   lr: 0.0001  max_mem: 15317M
[08/30 15:41:23] d2.utils.events INFO:  eta: 1 day, 19:37:17  iter: 119  total_loss: 51.34  loss_ce: 0.02929  loss_mask: 0.3169  loss_dice: 4.734  loss_ce_0: 0.6705  loss_mask_0: 0.3033  loss_dice_0: 4.686  loss_ce_1: 0.06877  loss_mask_1: 0.3129  loss_dice_1: 4.673  loss_ce_2: 0.02356  loss_mask_2: 0.2986  loss_dice_2: 4.692  loss_ce_3: 0.02089  loss_mask_3: 0.3105  loss_dice_3: 4.687  loss_ce_4: 0.0204  loss_mask_4: 0.3204  loss_dice_4: 4.702  loss_ce_5: 0.01979  loss_mask_5: 0.3129  loss_dice_5: 4.712  loss_ce_6: 0.02081  loss_mask_6: 0.3187  loss_dice_6: 4.728  loss_ce_7: 0.02198  loss_mask_7: 0.3131  loss_dice_7: 4.714  loss_ce_8: 0.02398  loss_mask_8: 0.3317  loss_dice_8: 4.711  loss_mgm_entropy: 0.006229    time: 0.4258  last_time: 0.4272  data_time: 0.0029  last_data_time: 0.0027   lr: 0.0001  max_mem: 15317M
[08/30 15:41:32] d2.utils.events INFO:  eta: 1 day, 19:37:09  iter: 139  total_loss: 54.83  loss_ce: 0.04077  loss_mask: 0.6524  loss_dice: 4.726  loss_ce_0: 0.6534  loss_mask_0: 0.6501  loss_dice_0: 4.685  loss_ce_1: 0.06102  loss_mask_1: 0.6417  loss_dice_1: 4.681  loss_ce_2: 0.02898  loss_mask_2: 0.6497  loss_dice_2: 4.675  loss_ce_3: 0.03842  loss_mask_3: 0.6585  loss_dice_3: 4.679  loss_ce_4: 0.04092  loss_mask_4: 0.6579  loss_dice_4: 4.691  loss_ce_5: 0.03483  loss_mask_5: 0.6638  loss_dice_5: 4.7  loss_ce_6: 0.03512  loss_mask_6: 0.6665  loss_dice_6: 4.717  loss_ce_7: 0.03783  loss_mask_7: 0.6542  loss_dice_7: 4.719  loss_ce_8: 0.03663  loss_mask_8: 0.639  loss_dice_8: 4.725  loss_mgm_entropy: 0.006125    time: 0.4259  last_time: 0.4249  data_time: 0.0029  last_data_time: 0.0030   lr: 0.0001  max_mem: 15317M
[08/30 15:41:40] d2.utils.events INFO:  eta: 1 day, 19:37:15  iter: 159  total_loss: 52.16  loss_ce: 0.0484  loss_mask: 0.4458  loss_dice: 4.695  loss_ce_0: 0.6428  loss_mask_0: 0.3998  loss_dice_0: 4.629  loss_ce_1: 0.06769  loss_mask_1: 0.3942  loss_dice_1: 4.605  loss_ce_2: 0.04478  loss_mask_2: 0.3968  loss_dice_2: 4.602  loss_ce_3: 0.04557  loss_mask_3: 0.4028  loss_dice_3: 4.625  loss_ce_4: 0.04797  loss_mask_4: 0.4083  loss_dice_4: 4.643  loss_ce_5: 0.05248  loss_mask_5: 0.4084  loss_dice_5: 4.679  loss_ce_6: 0.05288  loss_mask_6: 0.4234  loss_dice_6: 4.687  loss_ce_7: 0.0557  loss_mask_7: 0.4257  loss_dice_7: 4.685  loss_ce_8: 0.04946  loss_mask_8: 0.4327  loss_dice_8: 4.697  loss_mgm_entropy: 0.0061    time: 0.4258  last_time: 0.4230  data_time: 0.0029  last_data_time: 0.0033   lr: 0.0001  max_mem: 15318M
[08/30 15:41:49] d2.utils.events INFO:  eta: 1 day, 19:37:35  iter: 179  total_loss: 53.95  loss_ce: 0.07191  loss_mask: 0.7403  loss_dice: 4.642  loss_ce_0: 0.6263  loss_mask_0: 0.7214  loss_dice_0: 4.512  loss_ce_1: 0.07823  loss_mask_1: 0.7168  loss_dice_1: 4.415  loss_ce_2: 0.06812  loss_mask_2: 0.7565  loss_dice_2: 4.408  loss_ce_3: 0.0686  loss_mask_3: 0.768  loss_dice_3: 4.423  loss_ce_4: 0.05833  loss_mask_4: 0.7717  loss_dice_4: 4.46  loss_ce_5: 0.05443  loss_mask_5: 0.7587  loss_dice_5: 4.521  loss_ce_6: 0.05673  loss_mask_6: 0.7678  loss_dice_6: 4.568  loss_ce_7: 0.05817  loss_mask_7: 0.7494  loss_dice_7: 4.623  loss_ce_8: 0.05569  loss_mask_8: 0.7428  loss_dice_8: 4.644  loss_mgm_entropy: 0.005963    time: 0.4259  last_time: 0.4280  data_time: 0.0029  last_data_time: 0.0030   lr: 0.0001  max_mem: 15318M
[08/30 15:41:55] d2.engine.hooks INFO: Overall training speed: 191 iterations in 0:01:21 (0.4280 s / it)
[08/30 15:41:55] d2.engine.hooks INFO: Total training time: 0:01:21 (0:00:00 on hooks)
[08/30 15:41:55] d2.utils.events INFO:  eta: 1 day, 19:38:19  iter: 193  total_loss: 52.47  loss_ce: 0.04012  loss_mask: 0.658  loss_dice: 4.557  loss_ce_0: 0.6202  loss_mask_0: 0.6345  loss_dice_0: 4.447  loss_ce_1: 0.06057  loss_mask_1: 0.6505  loss_dice_1: 4.338  loss_ce_2: 0.06074  loss_mask_2: 0.6728  loss_dice_2: 4.328  loss_ce_3: 0.06252  loss_mask_3: 0.6644  loss_dice_3: 4.336  loss_ce_4: 0.05991  loss_mask_4: 0.6537  loss_dice_4: 4.354  loss_ce_5: 0.05242  loss_mask_5: 0.6653  loss_dice_5: 4.404  loss_ce_6: 0.06027  loss_mask_6: 0.6693  loss_dice_6: 4.439  loss_ce_7: 0.05223  loss_mask_7: 0.6664  loss_dice_7: 4.47  loss_ce_8: 0.04891  loss_mask_8: 0.672  loss_dice_8: 4.51  loss_mgm_entropy: 0.005895    time: 0.4260  last_time: 0.4286  data_time: 0.0030  last_data_time: 0.0032   lr: 0.0001  max_mem: 15318M
[08/30 15:43:50] detectron2 INFO: Rank of current process: 0. World size: 1
[08/30 15:43:51] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:43:55) [GCC 13.3.0]
numpy                            2.2.6
detectron2                       0.6 @/home/fuyx/hch/detectron2/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6, 8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   575.64.03
CUDA_HOME                        /home/fuyx/anaconda3/envs/m2f
Pillow                           11.3.0
torchvision                      0.20.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[08/30 15:43:51] detectron2 INFO: Command line arguments: Namespace(config_file='MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=['OUTPUT_DIR', './output/mgm_training'])
[08/30 15:43:51] detectron2 INFO: Contents of args.config_file=MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml:
MODEL:
  META_ARCHITECTURE: "MGMMaskFormer"

  # RGB Backbone: Swin Transformer Tiny
  RGB_BACKBONE:
    NAME: "D2SwinTransformer"
    WEIGHTS: ""
    SWIN:
      EMBED_DIM: 96
      DEPTHS: [2, 2, 6, 2]
      NUM_HEADS: [3, 6, 12, 24]
      WINDOW_SIZE: 7
      APE: False
      DROP_PATH_RATE: 0.3
      PATCH_NORM: True
      OUT_FEATURES: ["res2", "res3", "res4", "res5"]

  # Depth Backbone: ConvNeXt Tiny
  DEPTH_BACKBONE:
    NAME: "ConvNeXtDepthBackbone"
    WEIGHTS: ""
    CONVNEXT:
      DEPTHS: [3, 3, 9, 3]
      DIMS: [96, 192, 384, 768]
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1e-6

  # MGM Fusion Configuration
  MGM:
    ENABLED: True
    SHARED: True
    RESIDUAL_ALPHA: 0.05
    POST_FUSE_NORM: True # 新增：融合后GN
    LOSS_ENTROPY_W: 0.01
    TEMP_INIT: 1.5
    TEMP_FINAL: 1.0
    TEMP_STEPS: 3000 # 建议略短，收敛更快
    CLAMP_MIN: 0.05
    CLAMP_MAX: 0.95
    NOISE_MASK_WEIGHT: 0.0 # 前期建议关；有噪声掩码再开到0.05~0.1
    HIDDEN_DIM: 256
    FEATURE_DIMS: [96, 192, 384, 768]
    SCALE_KEYS: ["res2", "res3", "res4", "res5"]

    PRIOR:
      ENABLED: False # 总开关
      USE_GRADIENT: True # 先验逐项开关
      USE_VARIANCE: True
      USE_VALID_HOLE: True
      USE_RGB_EDGE: False # 前期建议关（最耗时）
      VAR_KERNEL: 5
      Z_MIN: 0.0
      Z_MAX: 1.0
      COMPUTE_ON: "res3" # "full"|"res2"|"res3"|"res4"|"res5"；前期建议用res3提速

    ROBUST_NORM:
      ENABLED: False # 前期建议关；要稳健再开
      METHOD: "minmax" # "minmax"|"quantile"

  # DPE Configuration
  DPE:
    ENABLED: True

  # Boundary Configuration
  BOUNDARY:
    ENABLED: False

  # RGB Input Pixel Mean/Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]

  # Semantic Segmentation Head
  SEM_SEG_HEAD:
    NAME: "MGMHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 1
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MGMMSDeformAttnPixelDecoder"
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6

  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MGMMultiScaleMaskedTransformerDecoder"
    TRANSFORMER_IN_FEATURE: "multi_scale_pixel_decoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 2.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 100
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    DEC_LAYERS: 10
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.8

# 数据集配置
DATASETS:
  TRAIN: ("coco_instance_rgbd_train",)
  TEST: ("coco_instance_rgbd_val",)

# 数据加载器配置
DATALOADER:
  NUM_WORKERS: 4
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  REPEAT_THRESHOLD: 0.0

# RGB-D Input Configuration
INPUT:
  DATASET_ROOT: "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input"
  IMAGE_SIZE: 1024
  MIN_SCALE: 0.1
  MAX_SCALE: 2.0
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "coco_instance_lsj_rgbd"
  RANDOM_FLIP: "horizontal"
  SIZE_DIVISIBILITY: 32

  # RGB光度增强
  RGB_PHOTO_AUG:
    ENABLED: False
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    SATURATION: 0.1
    HUE: 0.0

  # 深度数据配置
  DEPTH_FORMAT: "I"
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_CLIP_MAX: 1.0
  DEPTH_NORM: "minmax"
  DEPTH_NOISE:
    ENABLED: False
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
    DROP_PROB: 0.0
    DROP_VAL: 0.0

# 求解器配置
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (327778, 355092)
  MAX_ITER: 368750
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  GAMMA: 0.1
  OPTIMIZER: ADAMW
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_EMBED: 0.0
  CLIP_GRADIENTS:
    ENABLED: False
  AMP:
    ENABLED: True

# 测试配置
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False

# 输出配置
OUTPUT_DIR: "./output"

# 版本号
VERSION: 2.0

[08/30 15:43:51] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  LOAD_PROPOSALS: false
  NUM_WORKERS: 4
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_instance_rgbd_val
  TRAIN:
  - coco_instance_rgbd_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj_rgbd
  DATASET_ROOT: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
  DEPTH_CLIP_MAX: 1.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_FORMAT: I
  DEPTH_NOISE:
    DROP_PROB: 0.0
    DROP_VAL: 0.0
    ENABLED: false
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
  DEPTH_NORM: minmax
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  RGB_PHOTO_AUG:
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    ENABLED: false
    HUE: 0.0
    SATURATION: 0.1
  SIZE_DIVISIBILITY: 32
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BOUNDARY:
    ENABLED: false
  DEPTH_BACKBONE:
    CONVNEXT:
      DEPTHS:
      - 3
      - 3
      - 9
      - 3
      DIMS:
      - 96
      - 192
      - 384
      - 768
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1.0e-06
    NAME: ConvNeXtDepthBackbone
    WEIGHTS: ''
  DEVICE: cuda
  DPE:
    ENABLED: true
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MGMMultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MGMMaskFormer
  MGM:
    CLAMP_MAX: 0.95
    CLAMP_MIN: 0.05
    ENABLED: true
    FEATURE_DIMS:
    - 96
    - 192
    - 384
    - 768
    HIDDEN_DIM: 256
    LOSS_ENTROPY_W: 0.01
    NOISE_MASK_WEIGHT: 0.0
    POST_FUSE_NORM: true
    PRIOR:
      COMPUTE_ON: res3
      ENABLED: false
      USE_GRADIENT: true
      USE_RGB_EDGE: false
      USE_VALID_HOLE: true
      USE_VARIANCE: true
      VAR_KERNEL: 5
      Z_MAX: 1.0
      Z_MIN: 0.0
    RESIDUAL_ALPHA: 0.05
    ROBUST_NORM:
      ENABLED: false
      METHOD: minmax
    SCALE_KEYS:
    - res2
    - res3
    - res4
    - res5
    SHARED: true
    TEMP_FINAL: 1.0
    TEMP_INIT: 1.5
    TEMP_STEPS: 3000
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  RGB_BACKBONE:
    NAME: D2SwinTransformer
    SWIN:
      APE: false
      ATTN_DROP_RATE: 0.0
      DEPTHS:
      - 2
      - 2
      - 6
      - 2
      DROP_PATH_RATE: 0.3
      DROP_RATE: 0.0
      EMBED_DIM: 96
      MLP_RATIO: 4.0
      NUM_HEADS:
      - 3
      - 6
      - 12
      - 24
      OUT_FEATURES:
      - res2
      - res3
      - res4
      - res5
      PATCH_NORM: true
      PATCH_SIZE: 4
      PRETRAIN_IMG_SIZE: 224
      QKV_BIAS: true
      QK_SCALE: null
      USE_CHECKPOINT: false
      WINDOW_SIZE: 7
    WEIGHTS: ''
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MGMHead
    NORM: GN
    NUM_CLASSES: 1
    PIXEL_DECODER_NAME: MGMMSDeformAttnPixelDecoder
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: ''
OUTPUT_DIR: ./output/mgm_training
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 368750
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 327778
  - 355092
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2.0
VIS_PERIOD: 0

[08/30 15:43:51] detectron2 INFO: Full config saved to ./output/mgm_training/config.yaml
[08/30 15:43:51] d2.utils.env INFO: Using a generated random seed 53034487
[08/30 15:44:11] d2.engine.defaults INFO: Model:
MGMMaskFormer(
  (rgb_backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.055)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.109)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.136)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.164)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.191)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.218)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.245)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.273)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.300)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (depth_backbone): ConvNeXtDepthBackbone(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
  )
  (mgm): MultiModalGatedFusion(
    (prior_extractor): DepthPriorExtractor()
    (conf_pred): ConfidencePredictor(
      (proj_image): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_depth): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (head): Sequential(
        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): GroupNorm(8, 128, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (align_image): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (align_depth): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (post_norm): ModuleList(
      (0): GroupNorm(8, 96, eps=1e-05, affine=True)
      (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      (2): GroupNorm(8, 384, eps=1e-05, affine=True)
      (3): GroupNorm(8, 768, eps=1e-05, affine=True)
    )
  )
  (sem_seg_head): MGMHead(
    (pixel_decoder): MGMMSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (depth_pe): DepthPosEncoding(
        (mlp): Sequential(
          (0): Conv2d(1, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MGMMultiScaleMaskedTransformerDecoder(
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x MGMCrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=2, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 1
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/30 15:44:12] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [Mapper] Noise-mask dir not found, will skip masks: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/depth/depth_noise_mask
[08/30 15:44:12] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [COCOInstanceRGBDDatasetMapper] Augs: [RandomFlip(), ResizeScale(min_scale=0.1, max_scale=2.0, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=(1024, 1024))] | RGB: RGB | DATASET_ROOT=/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
[08/30 15:44:12] d2.data.datasets.coco INFO: Loaded 6 images in COCO format from /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/annotations/instances_train.json
[08/30 15:44:12] d2.data.build INFO: Removed 0 images with no usable annotations. 6 images left.
[08/30 15:44:12] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| component  | 147          |
|            |              |[0m
[08/30 15:44:12] d2.data.build INFO: Using training sampler TrainingSampler
[08/30 15:44:12] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[08/30 15:44:12] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[08/30 15:44:12] d2.data.common INFO: Serialized dataset takes 0.16 MiB
[08/30 15:44:12] d2.data.build INFO: Making batched data loader with batch_size=1
[08/30 15:44:12] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[08/30 15:44:12] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[08/30 15:44:12] d2.engine.train_loop INFO: Starting training from iteration 0
[08/30 15:44:21] d2.utils.events INFO:  eta: 1 day, 16:32:44  iter: 19  total_loss: 102.5  loss_ce: 1.158  loss_mask: 3.544  loss_dice: 4.916  loss_ce_0: 1.4  loss_mask_0: 2.974  loss_dice_0: 4.853  loss_ce_1: 1.33  loss_mask_1: 3.578  loss_dice_1: 4.919  loss_ce_2: 1.44  loss_mask_2: 3.821  loss_dice_2: 4.914  loss_ce_3: 1.37  loss_mask_3: 3.546  loss_dice_3: 4.923  loss_ce_4: 2.982  loss_mask_4: 4.211  loss_dice_4: 4.946  loss_ce_5: 1.912  loss_mask_5: 3.322  loss_dice_5: 4.916  loss_ce_6: 2.411  loss_mask_6: 3.576  loss_dice_6: 4.936  loss_ce_7: 1.5  loss_mask_7: 3.598  loss_dice_7: 4.906  loss_ce_8: 1.589  loss_mask_8: 4.461  loss_dice_8: 4.946  loss_mgm_entropy: 0.006661    time: 0.4090  last_time: 0.4469  data_time: 0.0142  last_data_time: 0.0030   lr: 0.0001  max_mem: 14683M
[08/30 15:44:29] d2.utils.events INFO:  eta: 1 day, 19:19:34  iter: 39  total_loss: 63.27  loss_ce: 1.178  loss_mask: 0.5006  loss_dice: 4.829  loss_ce_0: 0.7533  loss_mask_0: 0.3887  loss_dice_0: 4.76  loss_ce_1: 0.8089  loss_mask_1: 0.4684  loss_dice_1: 4.722  loss_ce_2: 0.9455  loss_mask_2: 0.4931  loss_dice_2: 4.735  loss_ce_3: 1.153  loss_mask_3: 0.5574  loss_dice_3: 4.749  loss_ce_4: 1.123  loss_mask_4: 0.5239  loss_dice_4: 4.759  loss_ce_5: 1.206  loss_mask_5: 0.5237  loss_dice_5: 4.801  loss_ce_6: 1.194  loss_mask_6: 0.4996  loss_dice_6: 4.761  loss_ce_7: 1.165  loss_mask_7: 0.4519  loss_dice_7: 4.779  loss_ce_8: 1.158  loss_mask_8: 0.4061  loss_dice_8: 4.799  loss_mgm_entropy: 0.005343    time: 0.4179  last_time: 0.4279  data_time: 0.0027  last_data_time: 0.0031   lr: 0.0001  max_mem: 15315M
[08/30 15:44:38] d2.utils.events INFO:  eta: 1 day, 19:30:52  iter: 59  total_loss: 65.14  loss_ce: 1.173  loss_mask: 0.7329  loss_dice: 4.782  loss_ce_0: 0.7398  loss_mask_0: 0.7276  loss_dice_0: 4.76  loss_ce_1: 0.5841  loss_mask_1: 0.7605  loss_dice_1: 4.783  loss_ce_2: 0.6819  loss_mask_2: 0.7263  loss_dice_2: 4.782  loss_ce_3: 0.9087  loss_mask_3: 0.798  loss_dice_3: 4.812  loss_ce_4: 1.055  loss_mask_4: 0.8251  loss_dice_4: 4.823  loss_ce_5: 1.109  loss_mask_5: 0.8251  loss_dice_5: 4.846  loss_ce_6: 1.125  loss_mask_6: 0.7484  loss_dice_6: 4.828  loss_ce_7: 1.137  loss_mask_7: 0.7567  loss_dice_7: 4.8  loss_ce_8: 1.157  loss_mask_8: 0.7353  loss_dice_8: 4.797  loss_mgm_entropy: 0.004871    time: 0.4222  last_time: 0.4271  data_time: 0.0027  last_data_time: 0.0029   lr: 0.0001  max_mem: 15315M
[08/30 15:44:44] d2.engine.hooks INFO: Overall training speed: 73 iterations in 0:00:30 (0.4238 s / it)
[08/30 15:44:44] d2.engine.hooks INFO: Total training time: 0:00:30 (0:00:00 on hooks)
[08/30 15:44:44] d2.utils.events INFO:  eta: 1 day, 19:31:07  iter: 75  total_loss: 62.37  loss_ce: 1.13  loss_mask: 0.6317  loss_dice: 4.748  loss_ce_0: 0.7203  loss_mask_0: 0.647  loss_dice_0: 4.739  loss_ce_1: 0.3724  loss_mask_1: 0.6694  loss_dice_1: 4.731  loss_ce_2: 0.4216  loss_mask_2: 0.6324  loss_dice_2: 4.744  loss_ce_3: 0.6561  loss_mask_3: 0.6321  loss_dice_3: 4.76  loss_ce_4: 0.9219  loss_mask_4: 0.6506  loss_dice_4: 4.749  loss_ce_5: 1.051  loss_mask_5: 0.6429  loss_dice_5: 4.751  loss_ce_6: 1.101  loss_mask_6: 0.6222  loss_dice_6: 4.769  loss_ce_7: 1.113  loss_mask_7: 0.6366  loss_dice_7: 4.748  loss_ce_8: 1.122  loss_mask_8: 0.631  loss_dice_8: 4.757  loss_mgm_entropy: 0.004834    time: 0.4227  last_time: 0.4265  data_time: 0.0027  last_data_time: 0.0027   lr: 0.0001  max_mem: 15315M
[08/30 15:47:50] detectron2 INFO: Rank of current process: 0. World size: 1
[08/30 15:47:51] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:43:55) [GCC 13.3.0]
numpy                            2.2.6
detectron2                       0.6 @/home/fuyx/hch/detectron2/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6, 8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   575.64.03
CUDA_HOME                        /home/fuyx/anaconda3/envs/m2f
Pillow                           11.3.0
torchvision                      0.20.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[08/30 15:47:51] detectron2 INFO: Command line arguments: Namespace(config_file='MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=['OUTPUT_DIR', './output/mgm_training'])
[08/30 15:47:51] detectron2 INFO: Contents of args.config_file=MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml:
MODEL:
  META_ARCHITECTURE: "MGMMaskFormer"

  # RGB Backbone: Swin Transformer Tiny
  RGB_BACKBONE:
    NAME: "D2SwinTransformer"
    WEIGHTS: ""
    SWIN:
      EMBED_DIM: 96
      DEPTHS: [2, 2, 6, 2]
      NUM_HEADS: [3, 6, 12, 24]
      WINDOW_SIZE: 7
      APE: False
      DROP_PATH_RATE: 0.3
      PATCH_NORM: True
      OUT_FEATURES: ["res2", "res3", "res4", "res5"]

  # Depth Backbone: ConvNeXt Tiny
  DEPTH_BACKBONE:
    NAME: "ConvNeXtDepthBackbone"
    WEIGHTS: ""
    CONVNEXT:
      DEPTHS: [3, 3, 9, 3]
      DIMS: [96, 192, 384, 768]
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1e-6

  # MGM Fusion Configuration
  MGM:
    ENABLED: True
    SHARED: True
    RESIDUAL_ALPHA: 0.05
    POST_FUSE_NORM: True # 新增：融合后GN
    LOSS_ENTROPY_W: 0.01
    TEMP_INIT: 1.5
    TEMP_FINAL: 1.0
    TEMP_STEPS: 3000 # 建议略短，收敛更快
    CLAMP_MIN: 0.05
    CLAMP_MAX: 0.95
    NOISE_MASK_WEIGHT: 0.0 # 前期建议关；有噪声掩码再开到0.05~0.1
    HIDDEN_DIM: 256
    FEATURE_DIMS: [96, 192, 384, 768]
    SCALE_KEYS: ["res2", "res3", "res4", "res5"]

    PRIOR:
      ENABLED: False # 总开关
      USE_GRADIENT: True # 先验逐项开关
      USE_VARIANCE: True
      USE_VALID_HOLE: True
      USE_RGB_EDGE: False # 前期建议关（最耗时）
      VAR_KERNEL: 5
      Z_MIN: 0.0
      Z_MAX: 1.0
      COMPUTE_ON: "res3" # "full"|"res2"|"res3"|"res4"|"res5"；前期建议用res3提速

    ROBUST_NORM:
      ENABLED: False # 前期建议关；要稳健再开
      METHOD: "minmax" # "minmax"|"quantile"

  # DPE Configuration
  DPE:
    ENABLED: True

  # Boundary Configuration
  BOUNDARY:
    ENABLED: False

  # RGB Input Pixel Mean/Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]

  # Semantic Segmentation Head
  SEM_SEG_HEAD:
    NAME: "MGMHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 1
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MGMMSDeformAttnPixelDecoder"
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6

  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MGMMultiScaleMaskedTransformerDecoder"
    TRANSFORMER_IN_FEATURE: "multi_scale_pixel_decoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 2.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 100
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    DEC_LAYERS: 10
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.8

# 数据集配置
DATASETS:
  TRAIN: ("coco_instance_rgbd_train",)
  TEST: ("coco_instance_rgbd_val",)

# 数据加载器配置
DATALOADER:
  NUM_WORKERS: 4
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  REPEAT_THRESHOLD: 0.0

# RGB-D Input Configuration
INPUT:
  DATASET_ROOT: "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input"
  IMAGE_SIZE: 1024
  MIN_SCALE: 0.1
  MAX_SCALE: 2.0
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "coco_instance_lsj_rgbd"
  RANDOM_FLIP: "horizontal"
  SIZE_DIVISIBILITY: 32

  # RGB光度增强
  RGB_PHOTO_AUG:
    ENABLED: False
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    SATURATION: 0.1
    HUE: 0.0

  # 深度数据配置
  DEPTH_FORMAT: "I"
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_CLIP_MAX: 1.0
  DEPTH_NORM: "minmax"
  DEPTH_NOISE:
    ENABLED: False
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
    DROP_PROB: 0.0
    DROP_VAL: 0.0

# 求解器配置
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (327778, 355092)
  MAX_ITER: 368750
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  GAMMA: 0.1
  OPTIMIZER: ADAMW
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_EMBED: 0.0
  CLIP_GRADIENTS:
    ENABLED: False
  AMP:
    ENABLED: True

# 测试配置
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False

# 输出配置
OUTPUT_DIR: "./output"

# 版本号
VERSION: 2.0

[08/30 15:47:51] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  LOAD_PROPOSALS: false
  NUM_WORKERS: 4
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_instance_rgbd_val
  TRAIN:
  - coco_instance_rgbd_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj_rgbd
  DATASET_ROOT: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
  DEPTH_CLIP_MAX: 1.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_FORMAT: I
  DEPTH_NOISE:
    DROP_PROB: 0.0
    DROP_VAL: 0.0
    ENABLED: false
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
  DEPTH_NORM: minmax
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  RGB_PHOTO_AUG:
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    ENABLED: false
    HUE: 0.0
    SATURATION: 0.1
  SIZE_DIVISIBILITY: 32
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BOUNDARY:
    ENABLED: false
  DEPTH_BACKBONE:
    CONVNEXT:
      DEPTHS:
      - 3
      - 3
      - 9
      - 3
      DIMS:
      - 96
      - 192
      - 384
      - 768
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1.0e-06
    NAME: ConvNeXtDepthBackbone
    WEIGHTS: ''
  DEVICE: cuda
  DPE:
    ENABLED: true
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MGMMultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MGMMaskFormer
  MGM:
    CLAMP_MAX: 0.95
    CLAMP_MIN: 0.05
    ENABLED: true
    FEATURE_DIMS:
    - 96
    - 192
    - 384
    - 768
    HIDDEN_DIM: 256
    LOSS_ENTROPY_W: 0.01
    NOISE_MASK_WEIGHT: 0.0
    POST_FUSE_NORM: true
    PRIOR:
      COMPUTE_ON: res3
      ENABLED: false
      USE_GRADIENT: true
      USE_RGB_EDGE: false
      USE_VALID_HOLE: true
      USE_VARIANCE: true
      VAR_KERNEL: 5
      Z_MAX: 1.0
      Z_MIN: 0.0
    RESIDUAL_ALPHA: 0.05
    ROBUST_NORM:
      ENABLED: false
      METHOD: minmax
    SCALE_KEYS:
    - res2
    - res3
    - res4
    - res5
    SHARED: true
    TEMP_FINAL: 1.0
    TEMP_INIT: 1.5
    TEMP_STEPS: 3000
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  RGB_BACKBONE:
    NAME: D2SwinTransformer
    SWIN:
      APE: false
      ATTN_DROP_RATE: 0.0
      DEPTHS:
      - 2
      - 2
      - 6
      - 2
      DROP_PATH_RATE: 0.3
      DROP_RATE: 0.0
      EMBED_DIM: 96
      MLP_RATIO: 4.0
      NUM_HEADS:
      - 3
      - 6
      - 12
      - 24
      OUT_FEATURES:
      - res2
      - res3
      - res4
      - res5
      PATCH_NORM: true
      PATCH_SIZE: 4
      PRETRAIN_IMG_SIZE: 224
      QKV_BIAS: true
      QK_SCALE: null
      USE_CHECKPOINT: false
      WINDOW_SIZE: 7
    WEIGHTS: ''
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MGMHead
    NORM: GN
    NUM_CLASSES: 1
    PIXEL_DECODER_NAME: MGMMSDeformAttnPixelDecoder
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: ''
OUTPUT_DIR: ./output/mgm_training
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 368750
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 327778
  - 355092
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2.0
VIS_PERIOD: 0

[08/30 15:47:51] detectron2 INFO: Full config saved to ./output/mgm_training/config.yaml
[08/30 15:47:51] d2.utils.env INFO: Using a generated random seed 52819554
[08/30 15:48:11] d2.engine.defaults INFO: Model:
MGMMaskFormer(
  (rgb_backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.055)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.109)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.136)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.164)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.191)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.218)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.245)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.273)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.300)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (depth_backbone): ConvNeXtDepthBackbone(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
  )
  (mgm): MultiModalGatedFusion(
    (prior_extractor): DepthPriorExtractor()
    (conf_pred): ConfidencePredictor(
      (proj_image): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_depth): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (head): Sequential(
        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): GroupNorm(8, 128, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (align_image): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (align_depth): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (post_norm): ModuleList(
      (0): GroupNorm(8, 96, eps=1e-05, affine=True)
      (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      (2): GroupNorm(8, 384, eps=1e-05, affine=True)
      (3): GroupNorm(8, 768, eps=1e-05, affine=True)
    )
  )
  (sem_seg_head): MGMHead(
    (pixel_decoder): MGMMSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (depth_pe): DepthPosEncoding(
        (mlp): Sequential(
          (0): Conv2d(1, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MGMMultiScaleMaskedTransformerDecoder(
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x MGMCrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=2, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 1
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/30 15:48:11] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [Mapper] Noise-mask dir not found, will skip masks: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/depth/depth_noise_mask
[08/30 15:48:11] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [COCOInstanceRGBDDatasetMapper] Augs: [RandomFlip(), ResizeScale(min_scale=0.1, max_scale=2.0, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=(1024, 1024))] | RGB: RGB | DATASET_ROOT=/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
[08/30 15:48:11] d2.data.datasets.coco INFO: Loaded 6 images in COCO format from /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/annotations/instances_train.json
[08/30 15:48:11] d2.data.build INFO: Removed 0 images with no usable annotations. 6 images left.
[08/30 15:48:11] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| component  | 147          |
|            |              |[0m
[08/30 15:48:11] d2.data.build INFO: Using training sampler TrainingSampler
[08/30 15:48:11] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[08/30 15:48:11] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[08/30 15:48:11] d2.data.common INFO: Serialized dataset takes 0.16 MiB
[08/30 15:48:11] d2.data.build INFO: Making batched data loader with batch_size=1
[08/30 15:48:11] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[08/30 15:48:11] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[08/30 15:48:11] d2.engine.train_loop INFO: Starting training from iteration 0
[08/30 15:48:20] d2.utils.events INFO:  eta: 1 day, 16:23:55  iter: 19  total_loss: 109.7  loss_ce: 2.094  loss_mask: 4.974  loss_dice: 4.951  loss_ce_0: 1.44  loss_mask_0: 3.293  loss_dice_0: 4.933  loss_ce_1: 1.16  loss_mask_1: 3.343  loss_dice_1: 4.931  loss_ce_2: 1.183  loss_mask_2: 4.368  loss_dice_2: 4.95  loss_ce_3: 1.203  loss_mask_3: 5.753  loss_dice_3: 4.95  loss_ce_4: 1.453  loss_mask_4: 4.226  loss_dice_4: 4.96  loss_ce_5: 1.311  loss_mask_5: 3.291  loss_dice_5: 4.942  loss_ce_6: 1.231  loss_mask_6: 4.103  loss_dice_6: 4.96  loss_ce_7: 1.111  loss_mask_7: 6.266  loss_dice_7: 4.965  loss_ce_8: 1.269  loss_mask_8: 6.209  loss_dice_8: 4.958  loss_mgm_entropy: 0.006898    time: 0.4118  last_time: 0.4254  data_time: 0.0131  last_data_time: 0.0027   lr: 0.0001  max_mem: 15304M
[08/30 15:48:29] d2.utils.events INFO:  eta: 1 day, 19:18:19  iter: 39  total_loss: 62.11  loss_ce: 1.11  loss_mask: 0.4548  loss_dice: 4.756  loss_ce_0: 0.7343  loss_mask_0: 0.4455  loss_dice_0: 4.761  loss_ce_1: 0.7639  loss_mask_1: 0.4401  loss_dice_1: 4.751  loss_ce_2: 0.8945  loss_mask_2: 0.4637  loss_dice_2: 4.732  loss_ce_3: 0.9792  loss_mask_3: 0.4984  loss_dice_3: 4.743  loss_ce_4: 1.051  loss_mask_4: 0.4379  loss_dice_4: 4.762  loss_ce_5: 1.087  loss_mask_5: 0.4687  loss_dice_5: 4.751  loss_ce_6: 1.105  loss_mask_6: 0.4415  loss_dice_6: 4.763  loss_ce_7: 1.132  loss_mask_7: 0.4943  loss_dice_7: 4.752  loss_ce_8: 1.114  loss_mask_8: 0.4884  loss_dice_8: 4.763  loss_mgm_entropy: 0.006046    time: 0.4188  last_time: 0.4282  data_time: 0.0028  last_data_time: 0.0026   lr: 0.0001  max_mem: 15312M
[08/30 15:48:38] d2.utils.events INFO:  eta: 1 day, 19:26:53  iter: 59  total_loss: 59.24  loss_ce: 1.104  loss_mask: 0.4539  loss_dice: 4.755  loss_ce_0: 0.6997  loss_mask_0: 0.4467  loss_dice_0: 4.723  loss_ce_1: 0.4104  loss_mask_1: 0.4916  loss_dice_1: 4.725  loss_ce_2: 0.4139  loss_mask_2: 0.489  loss_dice_2: 4.75  loss_ce_3: 0.5591  loss_mask_3: 0.4884  loss_dice_3: 4.749  loss_ce_4: 0.7669  loss_mask_4: 0.4933  loss_dice_4: 4.751  loss_ce_5: 0.9652  loss_mask_5: 0.4613  loss_dice_5: 4.742  loss_ce_6: 1.046  loss_mask_6: 0.4944  loss_dice_6: 4.753  loss_ce_7: 1.079  loss_mask_7: 0.4723  loss_dice_7: 4.748  loss_ce_8: 1.098  loss_mask_8: 0.4529  loss_dice_8: 4.746  loss_mgm_entropy: 0.005905    time: 0.4230  last_time: 0.4260  data_time: 0.0029  last_data_time: 0.0032   lr: 0.0001  max_mem: 15314M
[08/30 15:48:46] d2.utils.events INFO:  eta: 1 day, 19:32:16  iter: 79  total_loss: 56.73  loss_ce: 0.8637  loss_mask: 0.5731  loss_dice: 4.723  loss_ce_0: 0.6696  loss_mask_0: 0.5542  loss_dice_0: 4.703  loss_ce_1: 0.1674  loss_mask_1: 0.558  loss_dice_1: 4.699  loss_ce_2: 0.07309  loss_mask_2: 0.5462  loss_dice_2: 4.696  loss_ce_3: 0.04677  loss_mask_3: 0.54  loss_dice_3: 4.701  loss_ce_4: 0.04832  loss_mask_4: 0.5309  loss_dice_4: 4.704  loss_ce_5: 0.07384  loss_mask_5: 0.5412  loss_dice_5: 4.698  loss_ce_6: 0.21  loss_mask_6: 0.5493  loss_dice_6: 4.713  loss_ce_7: 0.3432  loss_mask_7: 0.5506  loss_dice_7: 4.719  loss_ce_8: 0.5877  loss_mask_8: 0.5507  loss_dice_8: 4.717  loss_mgm_entropy: 0.005796    time: 0.4240  last_time: 0.4252  data_time: 0.0028  last_data_time: 0.0024   lr: 0.0001  max_mem: 15314M
[08/30 15:48:55] d2.utils.events INFO:  eta: 1 day, 19:29:46  iter: 99  total_loss: 56.44  loss_ce: 0.2664  loss_mask: 0.7461  loss_dice: 4.785  loss_ce_0: 0.6425  loss_mask_0: 0.7217  loss_dice_0: 4.734  loss_ce_1: 0.1073  loss_mask_1: 0.7441  loss_dice_1: 4.726  loss_ce_2: 0.04457  loss_mask_2: 0.7602  loss_dice_2: 4.713  loss_ce_3: 0.04377  loss_mask_3: 0.7529  loss_dice_3: 4.726  loss_ce_4: 0.03611  loss_mask_4: 0.7525  loss_dice_4: 4.763  loss_ce_5: 0.03787  loss_mask_5: 0.7577  loss_dice_5: 4.737  loss_ce_6: 0.0424  loss_mask_6: 0.7647  loss_dice_6: 4.741  loss_ce_7: 0.05835  loss_mask_7: 0.7579  loss_dice_7: 4.774  loss_ce_8: 0.1199  loss_mask_8: 0.7647  loss_dice_8: 4.763  loss_mgm_entropy: 0.005174    time: 0.4240  last_time: 0.4247  data_time: 0.0029  last_data_time: 0.0020   lr: 0.0001  max_mem: 15314M
[08/30 15:49:01] d2.engine.hooks INFO: Overall training speed: 113 iterations in 0:00:48 (0.4249 s / it)
[08/30 15:49:01] d2.engine.hooks INFO: Total training time: 0:00:48 (0:00:00 on hooks)
[08/30 15:49:01] d2.utils.events INFO:  eta: 1 day, 19:29:29  iter: 115  total_loss: 54.23  loss_ce: 0.07924  loss_mask: 0.6551  loss_dice: 4.74  loss_ce_0: 0.63  loss_mask_0: 0.61  loss_dice_0: 4.707  loss_ce_1: 0.07582  loss_mask_1: 0.6387  loss_dice_1: 4.697  loss_ce_2: 0.03799  loss_mask_2: 0.6384  loss_dice_2: 4.71  loss_ce_3: 0.05422  loss_mask_3: 0.6141  loss_dice_3: 4.704  loss_ce_4: 0.05559  loss_mask_4: 0.5999  loss_dice_4: 4.717  loss_ce_5: 0.05094  loss_mask_5: 0.6421  loss_dice_5: 4.729  loss_ce_6: 0.04951  loss_mask_6: 0.6544  loss_dice_6: 4.723  loss_ce_7: 0.05496  loss_mask_7: 0.6288  loss_dice_7: 4.73  loss_ce_8: 0.06116  loss_mask_8: 0.6252  loss_dice_8: 4.733  loss_mgm_entropy: 0.005322    time: 0.4242  last_time: 0.4295  data_time: 0.0029  last_data_time: 0.0031   lr: 0.0001  max_mem: 15314M
[08/30 15:53:39] detectron2 INFO: Rank of current process: 0. World size: 1
[08/30 15:53:39] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:43:55) [GCC 13.3.0]
numpy                            2.2.6
detectron2                       0.6 @/home/fuyx/hch/detectron2/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6, 8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   575.64.03
CUDA_HOME                        /home/fuyx/anaconda3/envs/m2f
Pillow                           11.3.0
torchvision                      0.20.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[08/30 15:53:39] detectron2 INFO: Command line arguments: Namespace(config_file='MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=['OUTPUT_DIR', './output/mgm_training'])
[08/30 15:53:39] detectron2 INFO: Contents of args.config_file=MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml:
MODEL:
  META_ARCHITECTURE: "MGMMaskFormer"

  # RGB Backbone: Swin Transformer Tiny
  RGB_BACKBONE:
    NAME: "D2SwinTransformer"
    WEIGHTS: ""
    SWIN:
      EMBED_DIM: 96
      DEPTHS: [2, 2, 6, 2]
      NUM_HEADS: [3, 6, 12, 24]
      WINDOW_SIZE: 7
      APE: False
      DROP_PATH_RATE: 0.3
      PATCH_NORM: True
      OUT_FEATURES: ["res2", "res3", "res4", "res5"]

  # Depth Backbone: ConvNeXt Tiny
  DEPTH_BACKBONE:
    NAME: "ConvNeXtDepthBackbone"
    WEIGHTS: ""
    CONVNEXT:
      DEPTHS: [3, 3, 9, 3]
      DIMS: [96, 192, 384, 768]
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1e-6

  # MGM Fusion Configuration
  MGM:
    ENABLED: True
    SHARED: True
    RESIDUAL_ALPHA: 0.05
    POST_FUSE_NORM: True # 新增：融合后GN
    LOSS_ENTROPY_W: 0.01
    TEMP_INIT: 1.5
    TEMP_FINAL: 1.0
    TEMP_STEPS: 3000 # 建议略短，收敛更快
    CLAMP_MIN: 0.05
    CLAMP_MAX: 0.95
    NOISE_MASK_WEIGHT: 0.0 # 前期建议关；有噪声掩码再开到0.05~0.1
    HIDDEN_DIM: 256
    FEATURE_DIMS: [96, 192, 384, 768]
    SCALE_KEYS: ["res2", "res3", "res4", "res5"]

    PRIOR:
      ENABLED: False # 总开关
      USE_GRADIENT: True # 先验逐项开关
      USE_VARIANCE: True
      USE_VALID_HOLE: True
      USE_RGB_EDGE: False # 前期建议关（最耗时）
      VAR_KERNEL: 5
      Z_MIN: 0.0
      Z_MAX: 1.0
      COMPUTE_ON: "res3" # "full"|"res2"|"res3"|"res4"|"res5"；前期建议用res3提速

    ROBUST_NORM:
      ENABLED: False # 前期建议关；要稳健再开
      METHOD: "minmax" # "minmax"|"quantile"

  # DPE Configuration
  DPE:
    ENABLED: True

  # Boundary Configuration
  BOUNDARY:
    ENABLED: False

  # RGB Input Pixel Mean/Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]

  # Semantic Segmentation Head
  SEM_SEG_HEAD:
    NAME: "MGMHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 1
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MGMMSDeformAttnPixelDecoder"
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6

  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MGMMultiScaleMaskedTransformerDecoder"
    TRANSFORMER_IN_FEATURE: "multi_scale_pixel_decoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 2.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 100
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    DEC_LAYERS: 10
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.8

# 数据集配置
DATASETS:
  TRAIN: ("coco_instance_rgbd_train",)
  TEST: ("coco_instance_rgbd_val",)

# 数据加载器配置
DATALOADER:
  NUM_WORKERS: 4
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  REPEAT_THRESHOLD: 0.0

  # RGB-D Input Configuration - 快速训练模式
INPUT:
  DATASET_ROOT: "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input"
  IMAGE_SIZE: 512
  MIN_SCALE: 0.8
  MAX_SCALE: 1.2
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "coco_instance_lsj_rgbd"
  RANDOM_FLIP: "horizontal"
  SIZE_DIVISIBILITY: 32

  # RGB光度增强
  RGB_PHOTO_AUG:
    ENABLED: False
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    SATURATION: 0.1
    HUE: 0.0

  # 深度数据配置
  DEPTH_FORMAT: "I"
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_CLIP_MAX: 1.0
  DEPTH_NORM: "minmax"
  DEPTH_NOISE:
    ENABLED: False
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
    DROP_PROB: 0.0
    DROP_VAL: 0.0

# 求解器配置 - 快速训练模式 (2小时)
SOLVER:
  IMS_PER_BATCH: 4
  BASE_LR: 0.0002
  STEPS: (4000, 6000)
  MAX_ITER: 8000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  GAMMA: 0.1
  OPTIMIZER: ADAMW
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_EMBED: 0.0
  CLIP_GRADIENTS:
    ENABLED: False
  AMP:
    ENABLED: True

# 测试配置
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False

# 输出配置
OUTPUT_DIR: "./output"

# 版本号
VERSION: 2.0

[08/30 15:53:39] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  LOAD_PROPOSALS: false
  NUM_WORKERS: 4
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_instance_rgbd_val
  TRAIN:
  - coco_instance_rgbd_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj_rgbd
  DATASET_ROOT: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
  DEPTH_CLIP_MAX: 1.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_FORMAT: I
  DEPTH_NOISE:
    DROP_PROB: 0.0
    DROP_VAL: 0.0
    ENABLED: false
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
  DEPTH_NORM: minmax
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  FORMAT: RGB
  IMAGE_SIZE: 512
  MASK_FORMAT: polygon
  MAX_SCALE: 1.2
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.8
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  RGB_PHOTO_AUG:
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    ENABLED: false
    HUE: 0.0
    SATURATION: 0.1
  SIZE_DIVISIBILITY: 32
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BOUNDARY:
    ENABLED: false
  DEPTH_BACKBONE:
    CONVNEXT:
      DEPTHS:
      - 3
      - 3
      - 9
      - 3
      DIMS:
      - 96
      - 192
      - 384
      - 768
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1.0e-06
    NAME: ConvNeXtDepthBackbone
    WEIGHTS: ''
  DEVICE: cuda
  DPE:
    ENABLED: true
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MGMMultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MGMMaskFormer
  MGM:
    CLAMP_MAX: 0.95
    CLAMP_MIN: 0.05
    ENABLED: true
    FEATURE_DIMS:
    - 96
    - 192
    - 384
    - 768
    HIDDEN_DIM: 256
    LOSS_ENTROPY_W: 0.01
    NOISE_MASK_WEIGHT: 0.0
    POST_FUSE_NORM: true
    PRIOR:
      COMPUTE_ON: res3
      ENABLED: false
      USE_GRADIENT: true
      USE_RGB_EDGE: false
      USE_VALID_HOLE: true
      USE_VARIANCE: true
      VAR_KERNEL: 5
      Z_MAX: 1.0
      Z_MIN: 0.0
    RESIDUAL_ALPHA: 0.05
    ROBUST_NORM:
      ENABLED: false
      METHOD: minmax
    SCALE_KEYS:
    - res2
    - res3
    - res4
    - res5
    SHARED: true
    TEMP_FINAL: 1.0
    TEMP_INIT: 1.5
    TEMP_STEPS: 3000
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  RGB_BACKBONE:
    NAME: D2SwinTransformer
    SWIN:
      APE: false
      ATTN_DROP_RATE: 0.0
      DEPTHS:
      - 2
      - 2
      - 6
      - 2
      DROP_PATH_RATE: 0.3
      DROP_RATE: 0.0
      EMBED_DIM: 96
      MLP_RATIO: 4.0
      NUM_HEADS:
      - 3
      - 6
      - 12
      - 24
      OUT_FEATURES:
      - res2
      - res3
      - res4
      - res5
      PATCH_NORM: true
      PATCH_SIZE: 4
      PRETRAIN_IMG_SIZE: 224
      QKV_BIAS: true
      QK_SCALE: null
      USE_CHECKPOINT: false
      WINDOW_SIZE: 7
    WEIGHTS: ''
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MGMHead
    NORM: GN
    NUM_CLASSES: 1
    PIXEL_DECODER_NAME: MGMMSDeformAttnPixelDecoder
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: ''
OUTPUT_DIR: ./output/mgm_training
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 8000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 4000
  - 6000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2.0
VIS_PERIOD: 0

[08/30 15:53:39] detectron2 INFO: Full config saved to ./output/mgm_training/config.yaml
[08/30 15:53:39] d2.utils.env INFO: Using a generated random seed 41392581
[08/30 15:54:00] d2.engine.defaults INFO: Model:
MGMMaskFormer(
  (rgb_backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.055)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.109)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.136)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.164)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.191)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.218)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.245)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.273)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.300)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (depth_backbone): ConvNeXtDepthBackbone(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
  )
  (mgm): MultiModalGatedFusion(
    (prior_extractor): DepthPriorExtractor()
    (conf_pred): ConfidencePredictor(
      (proj_image): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_depth): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (head): Sequential(
        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): GroupNorm(8, 128, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (align_image): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (align_depth): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (post_norm): ModuleList(
      (0): GroupNorm(8, 96, eps=1e-05, affine=True)
      (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      (2): GroupNorm(8, 384, eps=1e-05, affine=True)
      (3): GroupNorm(8, 768, eps=1e-05, affine=True)
    )
  )
  (sem_seg_head): MGMHead(
    (pixel_decoder): MGMMSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (depth_pe): DepthPosEncoding(
        (mlp): Sequential(
          (0): Conv2d(1, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MGMMultiScaleMaskedTransformerDecoder(
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x MGMCrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=2, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 1
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/30 15:54:00] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [Mapper] Noise-mask dir not found, will skip masks: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/depth/depth_noise_mask
[08/30 15:54:00] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [COCOInstanceRGBDDatasetMapper] Augs: [RandomFlip(), ResizeScale(min_scale=0.8, max_scale=1.2, target_height=512, target_width=512), FixedSizeCrop(crop_size=(512, 512))] | RGB: RGB | DATASET_ROOT=/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
[08/30 15:54:00] d2.data.datasets.coco INFO: Loaded 6 images in COCO format from /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/annotations/instances_train.json
[08/30 15:54:00] d2.data.build INFO: Removed 0 images with no usable annotations. 6 images left.
[08/30 15:54:00] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| component  | 147          |
|            |              |[0m
[08/30 15:54:00] d2.data.build INFO: Using training sampler TrainingSampler
[08/30 15:54:00] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[08/30 15:54:00] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[08/30 15:54:00] d2.data.common INFO: Serialized dataset takes 0.16 MiB
[08/30 15:54:00] d2.data.build INFO: Making batched data loader with batch_size=4
[08/30 15:54:00] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[08/30 15:54:00] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[08/30 15:54:00] d2.engine.train_loop INFO: Starting training from iteration 0
[08/30 15:54:00] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/fuyx/hch/detectron2/detectron2/engine/train_loop.py", line 155, in train
    self.run_step()
  File "/home/fuyx/hch/detectron2/detectron2/engine/defaults.py", line 530, in run_step
    self._trainer.run_step()
  File "/home/fuyx/hch/detectron2/detectron2/engine/train_loop.py", line 488, in run_step
    data = next(self._data_loader_iter)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/data/common.py", line 329, in __iter__
    for d in self.dataset:
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1465, in _next_data
    return self._process_data(data)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1491, in _process_data
    data.reraise()
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/_utils.py", line 715, in reraise
    raise exception
AssertionError: Caught AssertionError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 33, in fetch
    data.append(next(self.dataset_iter))
                ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/data/common.py", line 296, in __iter__
    yield self.dataset[idx]
          ~~~~~~~~~~~~^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/data/common.py", line 125, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/utils/serialize.py", line 26, in __call__
    return self._obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/data/dataset_mappers/coco_instance_rgbd_dataset_mapper.py", line 345, in __call__
    content_mask = transforms.apply_segmentation(np.ones(image.shape[:2], dtype=np.uint8)).astype(bool)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/fvcore/transforms/transform.py", line 297, in <lambda>
    return lambda x: self._apply(x, name)
                     ^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/fvcore/transforms/transform.py", line 291, in _apply
    x = getattr(t, meth)(x)
        ^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/data/transforms/transform.py", line 155, in apply_segmentation
    segmentation = self.apply_image(segmentation, interp=Image.NEAREST)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/data/transforms/transform.py", line 113, in apply_image
    assert img.shape[:2] == (self.h, self.w)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError

[08/30 15:54:00] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[08/30 15:54:00] d2.utils.events INFO:  iter: 0       lr: N/A  max_mem: 303M
[08/30 15:54:27] detectron2 INFO: Rank of current process: 0. World size: 1
[08/30 15:54:27] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:43:55) [GCC 13.3.0]
numpy                            2.2.6
detectron2                       0.6 @/home/fuyx/hch/detectron2/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6, 8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   575.64.03
CUDA_HOME                        /home/fuyx/anaconda3/envs/m2f
Pillow                           11.3.0
torchvision                      0.20.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[08/30 15:54:27] detectron2 INFO: Command line arguments: Namespace(config_file='MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=['OUTPUT_DIR', './output/mgm_training'])
[08/30 15:54:27] detectron2 INFO: Contents of args.config_file=MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml:
MODEL:
  META_ARCHITECTURE: "MGMMaskFormer"

  # RGB Backbone: Swin Transformer Tiny
  RGB_BACKBONE:
    NAME: "D2SwinTransformer"
    WEIGHTS: ""
    SWIN:
      EMBED_DIM: 96
      DEPTHS: [2, 2, 6, 2]
      NUM_HEADS: [3, 6, 12, 24]
      WINDOW_SIZE: 7
      APE: False
      DROP_PATH_RATE: 0.3
      PATCH_NORM: True
      OUT_FEATURES: ["res2", "res3", "res4", "res5"]

  # Depth Backbone: ConvNeXt Tiny
  DEPTH_BACKBONE:
    NAME: "ConvNeXtDepthBackbone"
    WEIGHTS: ""
    CONVNEXT:
      DEPTHS: [3, 3, 9, 3]
      DIMS: [96, 192, 384, 768]
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1e-6

  # MGM Fusion Configuration
  MGM:
    ENABLED: True
    SHARED: True
    RESIDUAL_ALPHA: 0.05
    POST_FUSE_NORM: True # 新增：融合后GN
    LOSS_ENTROPY_W: 0.01
    TEMP_INIT: 1.5
    TEMP_FINAL: 1.0
    TEMP_STEPS: 3000 # 建议略短，收敛更快
    CLAMP_MIN: 0.05
    CLAMP_MAX: 0.95
    NOISE_MASK_WEIGHT: 0.0 # 前期建议关；有噪声掩码再开到0.05~0.1
    HIDDEN_DIM: 256
    FEATURE_DIMS: [96, 192, 384, 768]
    SCALE_KEYS: ["res2", "res3", "res4", "res5"]

    PRIOR:
      ENABLED: False # 总开关
      USE_GRADIENT: True # 先验逐项开关
      USE_VARIANCE: True
      USE_VALID_HOLE: True
      USE_RGB_EDGE: False # 前期建议关（最耗时）
      VAR_KERNEL: 5
      Z_MIN: 0.0
      Z_MAX: 1.0
      COMPUTE_ON: "res3" # "full"|"res2"|"res3"|"res4"|"res5"；前期建议用res3提速

    ROBUST_NORM:
      ENABLED: False # 前期建议关；要稳健再开
      METHOD: "minmax" # "minmax"|"quantile"

  # DPE Configuration
  DPE:
    ENABLED: True

  # Boundary Configuration
  BOUNDARY:
    ENABLED: False

  # RGB Input Pixel Mean/Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]

  # Semantic Segmentation Head
  SEM_SEG_HEAD:
    NAME: "MGMHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 1
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MGMMSDeformAttnPixelDecoder"
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6

  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MGMMultiScaleMaskedTransformerDecoder"
    TRANSFORMER_IN_FEATURE: "multi_scale_pixel_decoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 2.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 100
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    DEC_LAYERS: 10
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.8

# 数据集配置
DATASETS:
  TRAIN: ("coco_instance_rgbd_train",)
  TEST: ("coco_instance_rgbd_val",)

# 数据加载器配置
DATALOADER:
  NUM_WORKERS: 4
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  REPEAT_THRESHOLD: 0.0

  # RGB-D Input Configuration - 快速训练模式
INPUT:
  DATASET_ROOT: "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input"
  IMAGE_SIZE: 1024
  MIN_SCALE: 0.8
  MAX_SCALE: 1.2
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "coco_instance_lsj_rgbd"
  RANDOM_FLIP: "horizontal"
  SIZE_DIVISIBILITY: 32

  # RGB光度增强
  RGB_PHOTO_AUG:
    ENABLED: False
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    SATURATION: 0.1
    HUE: 0.0

  # 深度数据配置
  DEPTH_FORMAT: "I"
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_CLIP_MAX: 1.0
  DEPTH_NORM: "minmax"
  DEPTH_NOISE:
    ENABLED: False
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
    DROP_PROB: 0.0
    DROP_VAL: 0.0

# 求解器配置 - 快速训练模式 (2小时)
SOLVER:
  IMS_PER_BATCH: 4
  BASE_LR: 0.0002
  STEPS: (4000, 6000)
  MAX_ITER: 8000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  GAMMA: 0.1
  OPTIMIZER: ADAMW
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_EMBED: 0.0
  CLIP_GRADIENTS:
    ENABLED: False
  AMP:
    ENABLED: True

# 测试配置
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False

# 输出配置
OUTPUT_DIR: "./output"

# 版本号
VERSION: 2.0

[08/30 15:54:27] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  LOAD_PROPOSALS: false
  NUM_WORKERS: 4
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_instance_rgbd_val
  TRAIN:
  - coco_instance_rgbd_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj_rgbd
  DATASET_ROOT: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
  DEPTH_CLIP_MAX: 1.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_FORMAT: I
  DEPTH_NOISE:
    DROP_PROB: 0.0
    DROP_VAL: 0.0
    ENABLED: false
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
  DEPTH_NORM: minmax
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 1.2
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.8
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  RGB_PHOTO_AUG:
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    ENABLED: false
    HUE: 0.0
    SATURATION: 0.1
  SIZE_DIVISIBILITY: 32
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BOUNDARY:
    ENABLED: false
  DEPTH_BACKBONE:
    CONVNEXT:
      DEPTHS:
      - 3
      - 3
      - 9
      - 3
      DIMS:
      - 96
      - 192
      - 384
      - 768
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1.0e-06
    NAME: ConvNeXtDepthBackbone
    WEIGHTS: ''
  DEVICE: cuda
  DPE:
    ENABLED: true
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MGMMultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MGMMaskFormer
  MGM:
    CLAMP_MAX: 0.95
    CLAMP_MIN: 0.05
    ENABLED: true
    FEATURE_DIMS:
    - 96
    - 192
    - 384
    - 768
    HIDDEN_DIM: 256
    LOSS_ENTROPY_W: 0.01
    NOISE_MASK_WEIGHT: 0.0
    POST_FUSE_NORM: true
    PRIOR:
      COMPUTE_ON: res3
      ENABLED: false
      USE_GRADIENT: true
      USE_RGB_EDGE: false
      USE_VALID_HOLE: true
      USE_VARIANCE: true
      VAR_KERNEL: 5
      Z_MAX: 1.0
      Z_MIN: 0.0
    RESIDUAL_ALPHA: 0.05
    ROBUST_NORM:
      ENABLED: false
      METHOD: minmax
    SCALE_KEYS:
    - res2
    - res3
    - res4
    - res5
    SHARED: true
    TEMP_FINAL: 1.0
    TEMP_INIT: 1.5
    TEMP_STEPS: 3000
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  RGB_BACKBONE:
    NAME: D2SwinTransformer
    SWIN:
      APE: false
      ATTN_DROP_RATE: 0.0
      DEPTHS:
      - 2
      - 2
      - 6
      - 2
      DROP_PATH_RATE: 0.3
      DROP_RATE: 0.0
      EMBED_DIM: 96
      MLP_RATIO: 4.0
      NUM_HEADS:
      - 3
      - 6
      - 12
      - 24
      OUT_FEATURES:
      - res2
      - res3
      - res4
      - res5
      PATCH_NORM: true
      PATCH_SIZE: 4
      PRETRAIN_IMG_SIZE: 224
      QKV_BIAS: true
      QK_SCALE: null
      USE_CHECKPOINT: false
      WINDOW_SIZE: 7
    WEIGHTS: ''
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MGMHead
    NORM: GN
    NUM_CLASSES: 1
    PIXEL_DECODER_NAME: MGMMSDeformAttnPixelDecoder
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: ''
OUTPUT_DIR: ./output/mgm_training
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 8000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 4000
  - 6000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2.0
VIS_PERIOD: 0

[08/30 15:54:27] detectron2 INFO: Full config saved to ./output/mgm_training/config.yaml
[08/30 15:54:27] d2.utils.env INFO: Using a generated random seed 29423118
[08/30 15:54:48] d2.engine.defaults INFO: Model:
MGMMaskFormer(
  (rgb_backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.055)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.109)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.136)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.164)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.191)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.218)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.245)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.273)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.300)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (depth_backbone): ConvNeXtDepthBackbone(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
  )
  (mgm): MultiModalGatedFusion(
    (prior_extractor): DepthPriorExtractor()
    (conf_pred): ConfidencePredictor(
      (proj_image): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_depth): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (head): Sequential(
        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): GroupNorm(8, 128, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (align_image): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (align_depth): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (post_norm): ModuleList(
      (0): GroupNorm(8, 96, eps=1e-05, affine=True)
      (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      (2): GroupNorm(8, 384, eps=1e-05, affine=True)
      (3): GroupNorm(8, 768, eps=1e-05, affine=True)
    )
  )
  (sem_seg_head): MGMHead(
    (pixel_decoder): MGMMSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (depth_pe): DepthPosEncoding(
        (mlp): Sequential(
          (0): Conv2d(1, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MGMMultiScaleMaskedTransformerDecoder(
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x MGMCrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=2, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 1
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/30 15:54:48] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [Mapper] Noise-mask dir not found, will skip masks: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/depth/depth_noise_mask
[08/30 15:54:48] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [COCOInstanceRGBDDatasetMapper] Augs: [RandomFlip(), ResizeScale(min_scale=0.8, max_scale=1.2, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=(1024, 1024))] | RGB: RGB | DATASET_ROOT=/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
[08/30 15:54:48] d2.data.datasets.coco INFO: Loaded 6 images in COCO format from /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/annotations/instances_train.json
[08/30 15:54:48] d2.data.build INFO: Removed 0 images with no usable annotations. 6 images left.
[08/30 15:54:48] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| component  | 147          |
|            |              |[0m
[08/30 15:54:48] d2.data.build INFO: Using training sampler TrainingSampler
[08/30 15:54:48] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[08/30 15:54:48] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[08/30 15:54:48] d2.data.common INFO: Serialized dataset takes 0.16 MiB
[08/30 15:54:48] d2.data.build INFO: Making batched data loader with batch_size=4
[08/30 15:54:48] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[08/30 15:54:48] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[08/30 15:54:48] d2.engine.train_loop INFO: Starting training from iteration 0
[08/30 15:54:49] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/fuyx/hch/detectron2/detectron2/engine/train_loop.py", line 155, in train
    self.run_step()
  File "/home/fuyx/hch/detectron2/detectron2/engine/defaults.py", line 530, in run_step
    self._trainer.run_step()
  File "/home/fuyx/hch/detectron2/detectron2/engine/train_loop.py", line 494, in run_step
    loss_dict = self.model(data)
                ^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/modeling/meta_arch/mgm_model.py", line 192, in forward
    outputs = self.sem_seg_head(
              ^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/modeling/head/mgm_head.py", line 96, in forward
    return self.layers(features, confidence_maps, depth_raw, padding_mask, mask)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/modeling/head/mgm_head.py", line 109, in layers
    self.pixel_decoder.forward_features(
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/modeling/pixel_decoder/mgm_msdeformattn.py", line 385, in forward_features
    y, spatial_shapes, level_start_index = self.transformer(srcs, pos)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/modeling/pixel_decoder/mgm_msdeformattn.py", line 98, in forward
    memory = self.encoder(
             ^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/modeling/pixel_decoder/mgm_msdeformattn.py", line 216, in forward
    output = layer(
             ^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/modeling/pixel_decoder/mgm_msdeformattn.py", line 160, in forward
    src = self.forward_ffn(src)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mask2former/modeling/pixel_decoder/mgm_msdeformattn.py", line 136, in forward_ffn
    src2 = self.linear2(self.dropout2(self.activation(self.linear1(src))))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch/nn/functional.py", line 1704, in relu
    result = torch.relu(input)
             ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 336.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 205.31 MiB is free. Including non-PyTorch memory, this process has 21.96 GiB memory in use. Of the allocated memory 21.52 GiB is allocated by PyTorch, and 128.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[08/30 15:54:49] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[08/30 15:54:49] d2.utils.events INFO:  iter: 0       lr: N/A  max_mem: 22043M
[08/30 15:55:52] detectron2 INFO: Rank of current process: 0. World size: 1
[08/30 15:55:52] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:43:55) [GCC 13.3.0]
numpy                            2.2.6
detectron2                       0.6 @/home/fuyx/hch/detectron2/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6, 8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   575.64.03
CUDA_HOME                        /home/fuyx/anaconda3/envs/m2f
Pillow                           11.3.0
torchvision                      0.20.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[08/30 15:55:52] detectron2 INFO: Command line arguments: Namespace(config_file='MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=['OUTPUT_DIR', './output/mgm_training'])
[08/30 15:55:52] detectron2 INFO: Contents of args.config_file=MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml:
MODEL:
  META_ARCHITECTURE: "MGMMaskFormer"

  # RGB Backbone: Swin Transformer Tiny
  RGB_BACKBONE:
    NAME: "D2SwinTransformer"
    WEIGHTS: ""
    SWIN:
      EMBED_DIM: 96
      DEPTHS: [2, 2, 6, 2]
      NUM_HEADS: [3, 6, 12, 24]
      WINDOW_SIZE: 7
      APE: False
      DROP_PATH_RATE: 0.3
      PATCH_NORM: True
      OUT_FEATURES: ["res2", "res3", "res4", "res5"]

  # Depth Backbone: ConvNeXt Tiny
  DEPTH_BACKBONE:
    NAME: "ConvNeXtDepthBackbone"
    WEIGHTS: ""
    CONVNEXT:
      DEPTHS: [3, 3, 9, 3]
      DIMS: [96, 192, 384, 768]
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1e-6

  # MGM Fusion Configuration
  MGM:
    ENABLED: True
    SHARED: True
    RESIDUAL_ALPHA: 0.05
    POST_FUSE_NORM: True # 新增：融合后GN
    LOSS_ENTROPY_W: 0.01
    TEMP_INIT: 1.5
    TEMP_FINAL: 1.0
    TEMP_STEPS: 3000 # 建议略短，收敛更快
    CLAMP_MIN: 0.05
    CLAMP_MAX: 0.95
    NOISE_MASK_WEIGHT: 0.0 # 前期建议关；有噪声掩码再开到0.05~0.1
    HIDDEN_DIM: 256
    FEATURE_DIMS: [96, 192, 384, 768]
    SCALE_KEYS: ["res2", "res3", "res4", "res5"]

    PRIOR:
      ENABLED: False # 总开关
      USE_GRADIENT: True # 先验逐项开关
      USE_VARIANCE: True
      USE_VALID_HOLE: True
      USE_RGB_EDGE: False # 前期建议关（最耗时）
      VAR_KERNEL: 5
      Z_MIN: 0.0
      Z_MAX: 1.0
      COMPUTE_ON: "res3" # "full"|"res2"|"res3"|"res4"|"res5"；前期建议用res3提速

    ROBUST_NORM:
      ENABLED: False # 前期建议关；要稳健再开
      METHOD: "minmax" # "minmax"|"quantile"

  # DPE Configuration
  DPE:
    ENABLED: True

  # Boundary Configuration
  BOUNDARY:
    ENABLED: False

  # RGB Input Pixel Mean/Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]

  # Semantic Segmentation Head
  SEM_SEG_HEAD:
    NAME: "MGMHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 1
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MGMMSDeformAttnPixelDecoder"
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6

  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MGMMultiScaleMaskedTransformerDecoder"
    TRANSFORMER_IN_FEATURE: "multi_scale_pixel_decoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 2.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 100
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    DEC_LAYERS: 10
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.8

# 数据集配置
DATASETS:
  TRAIN: ("coco_instance_rgbd_train",)
  TEST: ("coco_instance_rgbd_val",)

# 数据加载器配置
DATALOADER:
  NUM_WORKERS: 4
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  REPEAT_THRESHOLD: 0.0

  # RGB-D Input Configuration - 快速训练模式
INPUT:
  DATASET_ROOT: "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input"
  IMAGE_SIZE: 1024
  MIN_SCALE: 0.8
  MAX_SCALE: 1.2
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "coco_instance_lsj_rgbd"
  RANDOM_FLIP: "horizontal"
  SIZE_DIVISIBILITY: 32

  # RGB光度增强
  RGB_PHOTO_AUG:
    ENABLED: False
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    SATURATION: 0.1
    HUE: 0.0

  # 深度数据配置
  DEPTH_FORMAT: "I"
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_CLIP_MAX: 1.0
  DEPTH_NORM: "minmax"
  DEPTH_NOISE:
    ENABLED: False
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
    DROP_PROB: 0.0
    DROP_VAL: 0.0

# 求解器配置 - 快速训练模式 (2小时) - 解决OOM
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0002
  STEPS: (4000, 6000)
  MAX_ITER: 8000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  GAMMA: 0.1
  OPTIMIZER: ADAMW
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_EMBED: 0.0
  CLIP_GRADIENTS:
    ENABLED: False
  AMP:
    ENABLED: True

# 测试配置
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False

# 输出配置
OUTPUT_DIR: "./output"

# 版本号
VERSION: 2.0

[08/30 15:55:52] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  LOAD_PROPOSALS: false
  NUM_WORKERS: 4
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_instance_rgbd_val
  TRAIN:
  - coco_instance_rgbd_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj_rgbd
  DATASET_ROOT: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
  DEPTH_CLIP_MAX: 1.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_FORMAT: I
  DEPTH_NOISE:
    DROP_PROB: 0.0
    DROP_VAL: 0.0
    ENABLED: false
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
  DEPTH_NORM: minmax
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 1.2
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.8
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  RGB_PHOTO_AUG:
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    ENABLED: false
    HUE: 0.0
    SATURATION: 0.1
  SIZE_DIVISIBILITY: 32
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BOUNDARY:
    ENABLED: false
  DEPTH_BACKBONE:
    CONVNEXT:
      DEPTHS:
      - 3
      - 3
      - 9
      - 3
      DIMS:
      - 96
      - 192
      - 384
      - 768
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1.0e-06
    NAME: ConvNeXtDepthBackbone
    WEIGHTS: ''
  DEVICE: cuda
  DPE:
    ENABLED: true
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MGMMultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MGMMaskFormer
  MGM:
    CLAMP_MAX: 0.95
    CLAMP_MIN: 0.05
    ENABLED: true
    FEATURE_DIMS:
    - 96
    - 192
    - 384
    - 768
    HIDDEN_DIM: 256
    LOSS_ENTROPY_W: 0.01
    NOISE_MASK_WEIGHT: 0.0
    POST_FUSE_NORM: true
    PRIOR:
      COMPUTE_ON: res3
      ENABLED: false
      USE_GRADIENT: true
      USE_RGB_EDGE: false
      USE_VALID_HOLE: true
      USE_VARIANCE: true
      VAR_KERNEL: 5
      Z_MAX: 1.0
      Z_MIN: 0.0
    RESIDUAL_ALPHA: 0.05
    ROBUST_NORM:
      ENABLED: false
      METHOD: minmax
    SCALE_KEYS:
    - res2
    - res3
    - res4
    - res5
    SHARED: true
    TEMP_FINAL: 1.0
    TEMP_INIT: 1.5
    TEMP_STEPS: 3000
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  RGB_BACKBONE:
    NAME: D2SwinTransformer
    SWIN:
      APE: false
      ATTN_DROP_RATE: 0.0
      DEPTHS:
      - 2
      - 2
      - 6
      - 2
      DROP_PATH_RATE: 0.3
      DROP_RATE: 0.0
      EMBED_DIM: 96
      MLP_RATIO: 4.0
      NUM_HEADS:
      - 3
      - 6
      - 12
      - 24
      OUT_FEATURES:
      - res2
      - res3
      - res4
      - res5
      PATCH_NORM: true
      PATCH_SIZE: 4
      PRETRAIN_IMG_SIZE: 224
      QKV_BIAS: true
      QK_SCALE: null
      USE_CHECKPOINT: false
      WINDOW_SIZE: 7
    WEIGHTS: ''
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MGMHead
    NORM: GN
    NUM_CLASSES: 1
    PIXEL_DECODER_NAME: MGMMSDeformAttnPixelDecoder
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: ''
OUTPUT_DIR: ./output/mgm_training
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 8000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 4000
  - 6000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2.0
VIS_PERIOD: 0

[08/30 15:55:52] detectron2 INFO: Full config saved to ./output/mgm_training/config.yaml
[08/30 15:55:52] d2.utils.env INFO: Using a generated random seed 54618244
[08/30 15:56:13] d2.engine.defaults INFO: Model:
MGMMaskFormer(
  (rgb_backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.055)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.109)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.136)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.164)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.191)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.218)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.245)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.273)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.300)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (depth_backbone): ConvNeXtDepthBackbone(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
  )
  (mgm): MultiModalGatedFusion(
    (prior_extractor): DepthPriorExtractor()
    (conf_pred): ConfidencePredictor(
      (proj_image): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_depth): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (head): Sequential(
        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): GroupNorm(8, 128, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (align_image): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (align_depth): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (post_norm): ModuleList(
      (0): GroupNorm(8, 96, eps=1e-05, affine=True)
      (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      (2): GroupNorm(8, 384, eps=1e-05, affine=True)
      (3): GroupNorm(8, 768, eps=1e-05, affine=True)
    )
  )
  (sem_seg_head): MGMHead(
    (pixel_decoder): MGMMSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (depth_pe): DepthPosEncoding(
        (mlp): Sequential(
          (0): Conv2d(1, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MGMMultiScaleMaskedTransformerDecoder(
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x MGMCrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=2, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 1
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/30 15:56:13] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [Mapper] Noise-mask dir not found, will skip masks: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/depth/depth_noise_mask
[08/30 15:56:13] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [COCOInstanceRGBDDatasetMapper] Augs: [RandomFlip(), ResizeScale(min_scale=0.8, max_scale=1.2, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=(1024, 1024))] | RGB: RGB | DATASET_ROOT=/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
[08/30 15:56:13] d2.data.datasets.coco INFO: Loaded 6 images in COCO format from /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/annotations/instances_train.json
[08/30 15:56:13] d2.data.build INFO: Removed 0 images with no usable annotations. 6 images left.
[08/30 15:56:13] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| component  | 147          |
|            |              |[0m
[08/30 15:56:13] d2.data.build INFO: Using training sampler TrainingSampler
[08/30 15:56:13] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[08/30 15:56:13] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[08/30 15:56:13] d2.data.common INFO: Serialized dataset takes 0.16 MiB
[08/30 15:56:13] d2.data.build INFO: Making batched data loader with batch_size=1
[08/30 15:56:13] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[08/30 15:56:13] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[08/30 15:56:13] d2.engine.train_loop INFO: Starting training from iteration 0
[08/30 15:56:22] d2.utils.events INFO:  eta: 0:52:55  iter: 19  total_loss: 105.7  loss_ce: 2.128  loss_mask: 6.652  loss_dice: 4.942  loss_ce_0: 1.116  loss_mask_0: 2.686  loss_dice_0: 4.773  loss_ce_1: 1.046  loss_mask_1: 3.045  loss_dice_1: 4.822  loss_ce_2: 1.021  loss_mask_2: 2.718  loss_dice_2: 4.779  loss_ce_3: 1.089  loss_mask_3: 4.798  loss_dice_3: 4.958  loss_ce_4: 1.281  loss_mask_4: 4.7  loss_dice_4: 4.91  loss_ce_5: 1.254  loss_mask_5: 5.034  loss_dice_5: 4.959  loss_ce_6: 1.335  loss_mask_6: 3.562  loss_dice_6: 4.905  loss_ce_7: 2.505  loss_mask_7: 3.371  loss_dice_7: 4.944  loss_ce_8: 2.276  loss_mask_8: 3.722  loss_dice_8: 4.954  loss_mgm_entropy: 0.006892    time: 0.4199  last_time: 0.4250  data_time: 0.0142  last_data_time: 0.0031   lr: 0.0002  max_mem: 15310M
[08/30 15:56:31] d2.utils.events INFO:  eta: 0:56:12  iter: 39  total_loss: 62.48  loss_ce: 1.102  loss_mask: 0.5411  loss_dice: 4.78  loss_ce_0: 0.6628  loss_mask_0: 0.5372  loss_dice_0: 4.779  loss_ce_1: 0.5131  loss_mask_1: 0.5425  loss_dice_1: 4.762  loss_ce_2: 0.6937  loss_mask_2: 0.5455  loss_dice_2: 4.765  loss_ce_3: 0.864  loss_mask_3: 0.5565  loss_dice_3: 4.776  loss_ce_4: 0.9946  loss_mask_4: 0.553  loss_dice_4: 4.778  loss_ce_5: 1.078  loss_mask_5: 0.5572  loss_dice_5: 4.77  loss_ce_6: 1.081  loss_mask_6: 0.5591  loss_dice_6: 4.77  loss_ce_7: 1.105  loss_mask_7: 0.5462  loss_dice_7: 4.778  loss_ce_8: 1.102  loss_mask_8: 0.5484  loss_dice_8: 4.782  loss_mgm_entropy: 0.005322    time: 0.4228  last_time: 0.4325  data_time: 0.0027  last_data_time: 0.0024   lr: 0.0002  max_mem: 15310M
[08/30 15:56:40] d2.utils.events INFO:  eta: 0:56:07  iter: 59  total_loss: 56.38  loss_ce: 0.9309  loss_mask: 0.5827  loss_dice: 4.769  loss_ce_0: 0.6132  loss_mask_0: 0.5829  loss_dice_0: 4.734  loss_ce_1: 0.1198  loss_mask_1: 0.573  loss_dice_1: 4.742  loss_ce_2: 0.06087  loss_mask_2: 0.5807  loss_dice_2: 4.74  loss_ce_3: 0.05497  loss_mask_3: 0.6011  loss_dice_3: 4.749  loss_ce_4: 0.04143  loss_mask_4: 0.5823  loss_dice_4: 4.773  loss_ce_5: 0.0592  loss_mask_5: 0.599  loss_dice_5: 4.769  loss_ce_6: 0.06303  loss_mask_6: 0.5783  loss_dice_6: 4.769  loss_ce_7: 0.1614  loss_mask_7: 0.5885  loss_dice_7: 4.759  loss_ce_8: 0.6087  loss_mask_8: 0.5862  loss_dice_8: 4.761  loss_mgm_entropy: 0.005111    time: 0.4260  last_time: 0.4248  data_time: 0.0027  last_data_time: 0.0026   lr: 0.0002  max_mem: 15314M
[08/30 15:56:48] d2.utils.events INFO:  eta: 0:56:04  iter: 79  total_loss: 54.65  loss_ce: 0.04153  loss_mask: 0.6295  loss_dice: 4.764  loss_ce_0: 0.5752  loss_mask_0: 0.6098  loss_dice_0: 4.718  loss_ce_1: 0.04411  loss_mask_1: 0.5967  loss_dice_1: 4.715  loss_ce_2: 0.03709  loss_mask_2: 0.6091  loss_dice_2: 4.719  loss_ce_3: 0.05178  loss_mask_3: 0.618  loss_dice_3: 4.73  loss_ce_4: 0.05182  loss_mask_4: 0.6119  loss_dice_4: 4.742  loss_ce_5: 0.04922  loss_mask_5: 0.6158  loss_dice_5: 4.751  loss_ce_6: 0.04689  loss_mask_6: 0.63  loss_dice_6: 4.766  loss_ce_7: 0.04501  loss_mask_7: 0.6247  loss_dice_7: 4.759  loss_ce_8: 0.043  loss_mask_8: 0.631  loss_dice_8: 4.754  loss_mgm_entropy: 0.00459    time: 0.4262  last_time: 0.4265  data_time: 0.0027  last_data_time: 0.0033   lr: 0.0002  max_mem: 15317M
[08/30 15:56:57] d2.utils.events INFO:  eta: 0:55:56  iter: 99  total_loss: 53.32  loss_ce: 0.008658  loss_mask: 0.5747  loss_dice: 4.746  loss_ce_0: 0.543  loss_mask_0: 0.5506  loss_dice_0: 4.712  loss_ce_1: 0.03603  loss_mask_1: 0.5568  loss_dice_1: 4.692  loss_ce_2: 0.001973  loss_mask_2: 0.5585  loss_dice_2: 4.685  loss_ce_3: 0.00412  loss_mask_3: 0.5581  loss_dice_3: 4.7  loss_ce_4: 0.002712  loss_mask_4: 0.5626  loss_dice_4: 4.715  loss_ce_5: 0.003551  loss_mask_5: 0.5713  loss_dice_5: 4.715  loss_ce_6: 0.002731  loss_mask_6: 0.5639  loss_dice_6: 4.744  loss_ce_7: 0.005532  loss_mask_7: 0.5598  loss_dice_7: 4.724  loss_ce_8: 0.009318  loss_mask_8: 0.5728  loss_dice_8: 4.725  loss_mgm_entropy: 0.004718    time: 0.4264  last_time: 0.4237  data_time: 0.0028  last_data_time: 0.0028   lr: 0.0002  max_mem: 15317M
[08/30 15:57:05] d2.utils.events INFO:  eta: 0:55:48  iter: 119  total_loss: 53.42  loss_ce: 0.03183  loss_mask: 0.5718  loss_dice: 4.616  loss_ce_0: 0.5148  loss_mask_0: 0.5206  loss_dice_0: 4.665  loss_ce_1: 0.02182  loss_mask_1: 0.5309  loss_dice_1: 4.614  loss_ce_2: 0.01142  loss_mask_2: 0.5659  loss_dice_2: 4.588  loss_ce_3: 0.008736  loss_mask_3: 0.585  loss_dice_3: 4.595  loss_ce_4: 0.00754  loss_mask_4: 0.5849  loss_dice_4: 4.602  loss_ce_5: 0.01925  loss_mask_5: 0.5648  loss_dice_5: 4.616  loss_ce_6: 0.03213  loss_mask_6: 0.541  loss_dice_6: 4.642  loss_ce_7: 0.03066  loss_mask_7: 0.5618  loss_dice_7: 4.637  loss_ce_8: 0.02173  loss_mask_8: 0.5826  loss_dice_8: 4.618  loss_mgm_entropy: 0.004911    time: 0.4263  last_time: 0.4240  data_time: 0.0029  last_data_time: 0.0028   lr: 0.0002  max_mem: 15317M
[08/30 15:57:14] d2.utils.events INFO:  eta: 0:55:39  iter: 139  total_loss: 52.46  loss_ce: 0.0256  loss_mask: 0.5898  loss_dice: 4.556  loss_ce_0: 0.4894  loss_mask_0: 0.5548  loss_dice_0: 4.63  loss_ce_1: 0.02861  loss_mask_1: 0.5713  loss_dice_1: 4.551  loss_ce_2: 0.0152  loss_mask_2: 0.5734  loss_dice_2: 4.545  loss_ce_3: 0.0229  loss_mask_3: 0.5789  loss_dice_3: 4.555  loss_ce_4: 0.02771  loss_mask_4: 0.5885  loss_dice_4: 4.566  loss_ce_5: 0.04926  loss_mask_5: 0.5991  loss_dice_5: 4.556  loss_ce_6: 0.0426  loss_mask_6: 0.5834  loss_dice_6: 4.569  loss_ce_7: 0.02168  loss_mask_7: 0.5996  loss_dice_7: 4.558  loss_ce_8: 0.03037  loss_mask_8: 0.5808  loss_dice_8: 4.556  loss_mgm_entropy: 0.005481    time: 0.4261  last_time: 0.4236  data_time: 0.0029  last_data_time: 0.0031   lr: 0.0002  max_mem: 15317M
[08/30 15:57:22] d2.utils.events INFO:  eta: 0:55:33  iter: 159  total_loss: 52.04  loss_ce: 0.02912  loss_mask: 0.5817  loss_dice: 4.546  loss_ce_0: 0.4669  loss_mask_0: 0.5706  loss_dice_0: 4.596  loss_ce_1: 0.04016  loss_mask_1: 0.6003  loss_dice_1: 4.498  loss_ce_2: 0.05242  loss_mask_2: 0.595  loss_dice_2: 4.501  loss_ce_3: 0.04663  loss_mask_3: 0.5966  loss_dice_3: 4.518  loss_ce_4: 0.0514  loss_mask_4: 0.5917  loss_dice_4: 4.522  loss_ce_5: 0.04731  loss_mask_5: 0.5964  loss_dice_5: 4.538  loss_ce_6: 0.04702  loss_mask_6: 0.5881  loss_dice_6: 4.552  loss_ce_7: 0.03721  loss_mask_7: 0.5894  loss_dice_7: 4.549  loss_ce_8: 0.03589  loss_mask_8: 0.5878  loss_dice_8: 4.537  loss_mgm_entropy: 0.005339    time: 0.4262  last_time: 0.4257  data_time: 0.0029  last_data_time: 0.0030   lr: 0.0002  max_mem: 15318M
[08/30 15:57:31] d2.utils.events INFO:  eta: 0:55:26  iter: 179  total_loss: 52.11  loss_ce: 0.01789  loss_mask: 0.625  loss_dice: 4.519  loss_ce_0: 0.4443  loss_mask_0: 0.5941  loss_dice_0: 4.568  loss_ce_1: 0.0222  loss_mask_1: 0.5983  loss_dice_1: 4.505  loss_ce_2: 0.01707  loss_mask_2: 0.6098  loss_dice_2: 4.505  loss_ce_3: 0.02116  loss_mask_3: 0.6059  loss_dice_3: 4.503  loss_ce_4: 0.0238  loss_mask_4: 0.5963  loss_dice_4: 4.513  loss_ce_5: 0.03238  loss_mask_5: 0.6116  loss_dice_5: 4.518  loss_ce_6: 0.03172  loss_mask_6: 0.6082  loss_dice_6: 4.516  loss_ce_7: 0.03009  loss_mask_7: 0.6082  loss_dice_7: 4.52  loss_ce_8: 0.01908  loss_mask_8: 0.6201  loss_dice_8: 4.52  loss_mgm_entropy: 0.00503    time: 0.4263  last_time: 0.4262  data_time: 0.0030  last_data_time: 0.0038   lr: 0.0002  max_mem: 15318M
[08/30 15:57:39] d2.utils.events INFO:  eta: 0:55:19  iter: 199  total_loss: 51.68  loss_ce: 0.01847  loss_mask: 0.6369  loss_dice: 4.511  loss_ce_0: 0.4196  loss_mask_0: 0.6242  loss_dice_0: 4.585  loss_ce_1: 0.02878  loss_mask_1: 0.6338  loss_dice_1: 4.472  loss_ce_2: 0.01834  loss_mask_2: 0.6241  loss_dice_2: 4.468  loss_ce_3: 0.0207  loss_mask_3: 0.6355  loss_dice_3: 4.481  loss_ce_4: 0.02069  loss_mask_4: 0.6414  loss_dice_4: 4.499  loss_ce_5: 0.02297  loss_mask_5: 0.6441  loss_dice_5: 4.491  loss_ce_6: 0.02186  loss_mask_6: 0.6293  loss_dice_6: 4.519  loss_ce_7: 0.0233  loss_mask_7: 0.6325  loss_dice_7: 4.536  loss_ce_8: 0.02064  loss_mask_8: 0.6272  loss_dice_8: 4.524  loss_mgm_entropy: 0.004713    time: 0.4266  last_time: 0.4270  data_time: 0.0030  last_data_time: 0.0027   lr: 0.0002  max_mem: 15320M
[08/30 15:57:49] d2.utils.events INFO:  eta: 0:55:13  iter: 219  total_loss: 48.46  loss_ce: 0.02413  loss_mask: 0.672  loss_dice: 4.15  loss_ce_0: 0.3996  loss_mask_0: 0.5838  loss_dice_0: 4.362  loss_ce_1: 0.03559  loss_mask_1: 0.6377  loss_dice_1: 4.118  loss_ce_2: 0.03158  loss_mask_2: 0.6661  loss_dice_2: 4.114  loss_ce_3: 0.02215  loss_mask_3: 0.665  loss_dice_3: 4.105  loss_ce_4: 0.02506  loss_mask_4: 0.6554  loss_dice_4: 4.121  loss_ce_5: 0.02145  loss_mask_5: 0.6765  loss_dice_5: 4.128  loss_ce_6: 0.02207  loss_mask_6: 0.67  loss_dice_6: 4.155  loss_ce_7: 0.02122  loss_mask_7: 0.6487  loss_dice_7: 4.155  loss_ce_8: 0.02224  loss_mask_8: 0.6706  loss_dice_8: 4.136  loss_mgm_entropy: 0.004786    time: 0.4269  last_time: 0.4281  data_time: 0.0029  last_data_time: 0.0030   lr: 0.0002  max_mem: 15320M
[08/30 15:57:57] d2.utils.events INFO:  eta: 0:55:05  iter: 239  total_loss: 46.69  loss_ce: 0.03317  loss_mask: 0.5797  loss_dice: 3.999  loss_ce_0: 0.38  loss_mask_0: 0.5302  loss_dice_0: 4.173  loss_ce_1: 0.03277  loss_mask_1: 0.5675  loss_dice_1: 3.897  loss_ce_2: 0.0314  loss_mask_2: 0.5874  loss_dice_2: 3.904  loss_ce_3: 0.02783  loss_mask_3: 0.6118  loss_dice_3: 3.922  loss_ce_4: 0.0347  loss_mask_4: 0.5947  loss_dice_4: 3.97  loss_ce_5: 0.02535  loss_mask_5: 0.5872  loss_dice_5: 4.024  loss_ce_6: 0.02987  loss_mask_6: 0.6334  loss_dice_6: 4.074  loss_ce_7: 0.02994  loss_mask_7: 0.6165  loss_dice_7: 4.035  loss_ce_8: 0.03289  loss_mask_8: 0.5794  loss_dice_8: 3.972  loss_mgm_entropy: 0.005014    time: 0.4270  last_time: 0.4251  data_time: 0.0031  last_data_time: 0.0040   lr: 0.0002  max_mem: 15320M
[08/30 15:58:06] d2.utils.events INFO:  eta: 0:54:59  iter: 259  total_loss: 41  loss_ce: 0.03181  loss_mask: 0.5477  loss_dice: 3.61  loss_ce_0: 0.3608  loss_mask_0: 0.443  loss_dice_0: 3.811  loss_ce_1: 0.03552  loss_mask_1: 0.52  loss_dice_1: 3.416  loss_ce_2: 0.03921  loss_mask_2: 0.5471  loss_dice_2: 3.434  loss_ce_3: 0.03085  loss_mask_3: 0.5465  loss_dice_3: 3.491  loss_ce_4: 0.03922  loss_mask_4: 0.5396  loss_dice_4: 3.52  loss_ce_5: 0.03344  loss_mask_5: 0.5533  loss_dice_5: 3.534  loss_ce_6: 0.03312  loss_mask_6: 0.5256  loss_dice_6: 3.548  loss_ce_7: 0.03262  loss_mask_7: 0.552  loss_dice_7: 3.617  loss_ce_8: 0.03762  loss_mask_8: 0.5551  loss_dice_8: 3.645  loss_mgm_entropy: 0.004986    time: 0.4270  last_time: 0.4284  data_time: 0.0031  last_data_time: 0.0028   lr: 0.0002  max_mem: 15320M
[08/30 15:58:14] d2.utils.events INFO:  eta: 0:54:51  iter: 279  total_loss: 38.79  loss_ce: 0.03436  loss_mask: 0.596  loss_dice: 3.255  loss_ce_0: 0.343  loss_mask_0: 0.4725  loss_dice_0: 3.461  loss_ce_1: 0.03553  loss_mask_1: 0.5708  loss_dice_1: 3.081  loss_ce_2: 0.03643  loss_mask_2: 0.5831  loss_dice_2: 3.045  loss_ce_3: 0.03403  loss_mask_3: 0.6124  loss_dice_3: 3.167  loss_ce_4: 0.04411  loss_mask_4: 0.6128  loss_dice_4: 3.181  loss_ce_5: 0.04093  loss_mask_5: 0.6256  loss_dice_5: 3.215  loss_ce_6: 0.034  loss_mask_6: 0.6127  loss_dice_6: 3.291  loss_ce_7: 0.03362  loss_mask_7: 0.6071  loss_dice_7: 3.301  loss_ce_8: 0.03376  loss_mask_8: 0.593  loss_dice_8: 3.32  loss_mgm_entropy: 0.004939    time: 0.4271  last_time: 0.4277  data_time: 0.0028  last_data_time: 0.0028   lr: 0.0002  max_mem: 15320M
[08/30 15:58:23] d2.utils.events INFO:  eta: 0:54:44  iter: 299  total_loss: 35.13  loss_ce: 0.04718  loss_mask: 0.4504  loss_dice: 3.047  loss_ce_0: 0.3264  loss_mask_0: 0.3695  loss_dice_0: 3.225  loss_ce_1: 0.02656  loss_mask_1: 0.4357  loss_dice_1: 2.967  loss_ce_2: 0.03485  loss_mask_2: 0.4322  loss_dice_2: 2.892  loss_ce_3: 0.04286  loss_mask_3: 0.4495  loss_dice_3: 2.985  loss_ce_4: 0.03575  loss_mask_4: 0.463  loss_dice_4: 3.037  loss_ce_5: 0.03632  loss_mask_5: 0.481  loss_dice_5: 3.092  loss_ce_6: 0.03574  loss_mask_6: 0.4564  loss_dice_6: 3.055  loss_ce_7: 0.04047  loss_mask_7: 0.4641  loss_dice_7: 3.073  loss_ce_8: 0.03924  loss_mask_8: 0.4595  loss_dice_8: 3.039  loss_mgm_entropy: 0.004913    time: 0.4272  last_time: 0.4271  data_time: 0.0030  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 15:58:32] d2.utils.events INFO:  eta: 0:54:36  iter: 319  total_loss: 33.09  loss_ce: 0.1535  loss_mask: 0.4159  loss_dice: 2.708  loss_ce_0: 0.316  loss_mask_0: 0.3607  loss_dice_0: 2.989  loss_ce_1: 0.08072  loss_mask_1: 0.3836  loss_dice_1: 2.594  loss_ce_2: 0.1072  loss_mask_2: 0.4227  loss_dice_2: 2.578  loss_ce_3: 0.1167  loss_mask_3: 0.4425  loss_dice_3: 2.666  loss_ce_4: 0.127  loss_mask_4: 0.4423  loss_dice_4: 2.739  loss_ce_5: 0.1215  loss_mask_5: 0.4505  loss_dice_5: 2.781  loss_ce_6: 0.1194  loss_mask_6: 0.4368  loss_dice_6: 2.718  loss_ce_7: 0.1304  loss_mask_7: 0.4416  loss_dice_7: 2.76  loss_ce_8: 0.1456  loss_mask_8: 0.4796  loss_dice_8: 2.85  loss_mgm_entropy: 0.004991    time: 0.4273  last_time: 0.4275  data_time: 0.0031  last_data_time: 0.0030   lr: 0.0002  max_mem: 15320M
[08/30 15:58:40] d2.utils.events INFO:  eta: 0:54:29  iter: 339  total_loss: 31.07  loss_ce: 0.3227  loss_mask: 0.4139  loss_dice: 2.438  loss_ce_0: 0.3141  loss_mask_0: 0.3378  loss_dice_0: 2.765  loss_ce_1: 0.1113  loss_mask_1: 0.39  loss_dice_1: 2.326  loss_ce_2: 0.1243  loss_mask_2: 0.4151  loss_dice_2: 2.308  loss_ce_3: 0.122  loss_mask_3: 0.4037  loss_dice_3: 2.423  loss_ce_4: 0.1254  loss_mask_4: 0.4346  loss_dice_4: 2.54  loss_ce_5: 0.1175  loss_mask_5: 0.4608  loss_dice_5: 2.533  loss_ce_6: 0.1267  loss_mask_6: 0.4103  loss_dice_6: 2.485  loss_ce_7: 0.1313  loss_mask_7: 0.4127  loss_dice_7: 2.558  loss_ce_8: 0.2324  loss_mask_8: 0.4481  loss_dice_8: 2.509  loss_mgm_entropy: 0.004892    time: 0.4274  last_time: 0.4395  data_time: 0.0030  last_data_time: 0.0029   lr: 0.0002  max_mem: 15320M
[08/30 15:58:49] d2.utils.events INFO:  eta: 0:54:22  iter: 359  total_loss: 27.33  loss_ce: 0.4133  loss_mask: 0.3458  loss_dice: 2.126  loss_ce_0: 0.3128  loss_mask_0: 0.2846  loss_dice_0: 2.492  loss_ce_1: 0.1133  loss_mask_1: 0.3446  loss_dice_1: 2.105  loss_ce_2: 0.1466  loss_mask_2: 0.3685  loss_dice_2: 2.039  loss_ce_3: 0.1651  loss_mask_3: 0.3738  loss_dice_3: 2.088  loss_ce_4: 0.1829  loss_mask_4: 0.3455  loss_dice_4: 2.125  loss_ce_5: 0.1952  loss_mask_5: 0.3708  loss_dice_5: 2.237  loss_ce_6: 0.2373  loss_mask_6: 0.3451  loss_dice_6: 2.183  loss_ce_7: 0.2552  loss_mask_7: 0.357  loss_dice_7: 2.228  loss_ce_8: 0.3676  loss_mask_8: 0.3324  loss_dice_8: 2.225  loss_mgm_entropy: 0.004671    time: 0.4275  last_time: 0.4276  data_time: 0.0030  last_data_time: 0.0036   lr: 0.0002  max_mem: 15320M
[08/30 15:58:57] d2.utils.events INFO:  eta: 0:54:14  iter: 379  total_loss: 26.67  loss_ce: 0.3249  loss_mask: 0.3451  loss_dice: 1.981  loss_ce_0: 0.3208  loss_mask_0: 0.2975  loss_dice_0: 2.27  loss_ce_1: 0.1314  loss_mask_1: 0.3336  loss_dice_1: 1.94  loss_ce_2: 0.1773  loss_mask_2: 0.3657  loss_dice_2: 1.87  loss_ce_3: 0.2056  loss_mask_3: 0.3507  loss_dice_3: 1.942  loss_ce_4: 0.2344  loss_mask_4: 0.3533  loss_dice_4: 2.08  loss_ce_5: 0.2089  loss_mask_5: 0.3632  loss_dice_5: 2.047  loss_ce_6: 0.2569  loss_mask_6: 0.3544  loss_dice_6: 1.97  loss_ce_7: 0.277  loss_mask_7: 0.3344  loss_dice_7: 2.066  loss_ce_8: 0.3522  loss_mask_8: 0.378  loss_dice_8: 2.065  loss_mgm_entropy: 0.004724    time: 0.4275  last_time: 0.4290  data_time: 0.0029  last_data_time: 0.0030   lr: 0.0002  max_mem: 15320M
[08/30 15:59:06] d2.utils.events INFO:  eta: 0:54:07  iter: 399  total_loss: 23.52  loss_ce: 0.3556  loss_mask: 0.2799  loss_dice: 1.816  loss_ce_0: 0.3378  loss_mask_0: 0.2273  loss_dice_0: 2.119  loss_ce_1: 0.1681  loss_mask_1: 0.2828  loss_dice_1: 1.75  loss_ce_2: 0.1728  loss_mask_2: 0.26  loss_dice_2: 1.654  loss_ce_3: 0.1934  loss_mask_3: 0.2718  loss_dice_3: 1.716  loss_ce_4: 0.2314  loss_mask_4: 0.2771  loss_dice_4: 1.818  loss_ce_5: 0.2084  loss_mask_5: 0.3095  loss_dice_5: 1.809  loss_ce_6: 0.2821  loss_mask_6: 0.3054  loss_dice_6: 1.791  loss_ce_7: 0.2615  loss_mask_7: 0.2741  loss_dice_7: 1.768  loss_ce_8: 0.3285  loss_mask_8: 0.2662  loss_dice_8: 1.802  loss_mgm_entropy: 0.005083    time: 0.4277  last_time: 0.4286  data_time: 0.0032  last_data_time: 0.0037   lr: 0.0002  max_mem: 15320M
[08/30 15:59:15] d2.utils.events INFO:  eta: 0:53:59  iter: 419  total_loss: 22.28  loss_ce: 0.3873  loss_mask: 0.2892  loss_dice: 1.578  loss_ce_0: 0.3216  loss_mask_0: 0.2612  loss_dice_0: 1.955  loss_ce_1: 0.1464  loss_mask_1: 0.3145  loss_dice_1: 1.645  loss_ce_2: 0.1575  loss_mask_2: 0.293  loss_dice_2: 1.548  loss_ce_3: 0.2192  loss_mask_3: 0.2825  loss_dice_3: 1.544  loss_ce_4: 0.2607  loss_mask_4: 0.3087  loss_dice_4: 1.739  loss_ce_5: 0.2702  loss_mask_5: 0.2925  loss_dice_5: 1.607  loss_ce_6: 0.3186  loss_mask_6: 0.3037  loss_dice_6: 1.626  loss_ce_7: 0.3295  loss_mask_7: 0.301  loss_dice_7: 1.694  loss_ce_8: 0.439  loss_mask_8: 0.2945  loss_dice_8: 1.625  loss_mgm_entropy: 0.004993    time: 0.4278  last_time: 0.4261  data_time: 0.0029  last_data_time: 0.0029   lr: 0.0002  max_mem: 15320M
[08/30 15:59:23] d2.utils.events INFO:  eta: 0:53:51  iter: 439  total_loss: 20.13  loss_ce: 0.4232  loss_mask: 0.2205  loss_dice: 1.43  loss_ce_0: 0.3359  loss_mask_0: 0.1919  loss_dice_0: 1.774  loss_ce_1: 0.1446  loss_mask_1: 0.2346  loss_dice_1: 1.396  loss_ce_2: 0.1851  loss_mask_2: 0.2264  loss_dice_2: 1.298  loss_ce_3: 0.2091  loss_mask_3: 0.2043  loss_dice_3: 1.358  loss_ce_4: 0.2594  loss_mask_4: 0.2381  loss_dice_4: 1.514  loss_ce_5: 0.2579  loss_mask_5: 0.242  loss_dice_5: 1.526  loss_ce_6: 0.2754  loss_mask_6: 0.2452  loss_dice_6: 1.503  loss_ce_7: 0.3142  loss_mask_7: 0.2178  loss_dice_7: 1.547  loss_ce_8: 0.4485  loss_mask_8: 0.2207  loss_dice_8: 1.487  loss_mgm_entropy: 0.004889    time: 0.4279  last_time: 0.4275  data_time: 0.0030  last_data_time: 0.0028   lr: 0.0002  max_mem: 15320M
[08/30 15:59:32] d2.utils.events INFO:  eta: 0:53:43  iter: 459  total_loss: 19.82  loss_ce: 0.379  loss_mask: 0.2379  loss_dice: 1.403  loss_ce_0: 0.3306  loss_mask_0: 0.2129  loss_dice_0: 1.733  loss_ce_1: 0.1526  loss_mask_1: 0.2318  loss_dice_1: 1.387  loss_ce_2: 0.2131  loss_mask_2: 0.2388  loss_dice_2: 1.308  loss_ce_3: 0.2297  loss_mask_3: 0.2566  loss_dice_3: 1.323  loss_ce_4: 0.2733  loss_mask_4: 0.2461  loss_dice_4: 1.426  loss_ce_5: 0.2649  loss_mask_5: 0.2701  loss_dice_5: 1.468  loss_ce_6: 0.3067  loss_mask_6: 0.2656  loss_dice_6: 1.47  loss_ce_7: 0.3151  loss_mask_7: 0.2508  loss_dice_7: 1.401  loss_ce_8: 0.4443  loss_mask_8: 0.247  loss_dice_8: 1.429  loss_mgm_entropy: 0.004952    time: 0.4279  last_time: 0.4415  data_time: 0.0030  last_data_time: 0.0038   lr: 0.0002  max_mem: 15320M
[08/30 15:59:40] d2.utils.events INFO:  eta: 0:53:35  iter: 479  total_loss: 17.25  loss_ce: 0.4042  loss_mask: 0.1884  loss_dice: 1.105  loss_ce_0: 0.3152  loss_mask_0: 0.1714  loss_dice_0: 1.491  loss_ce_1: 0.1738  loss_mask_1: 0.2003  loss_dice_1: 1.155  loss_ce_2: 0.1905  loss_mask_2: 0.2058  loss_dice_2: 1.096  loss_ce_3: 0.2166  loss_mask_3: 0.2059  loss_dice_3: 1.087  loss_ce_4: 0.2515  loss_mask_4: 0.2031  loss_dice_4: 1.201  loss_ce_5: 0.243  loss_mask_5: 0.2122  loss_dice_5: 1.236  loss_ce_6: 0.2825  loss_mask_6: 0.2511  loss_dice_6: 1.274  loss_ce_7: 0.3169  loss_mask_7: 0.1961  loss_dice_7: 1.19  loss_ce_8: 0.3288  loss_mask_8: 0.2015  loss_dice_8: 1.212  loss_mgm_entropy: 0.005049    time: 0.4280  last_time: 0.4279  data_time: 0.0032  last_data_time: 0.0037   lr: 0.0002  max_mem: 15320M
[08/30 15:59:49] d2.utils.events INFO:  eta: 0:53:26  iter: 499  total_loss: 18.9  loss_ce: 0.4251  loss_mask: 0.2554  loss_dice: 1.239  loss_ce_0: 0.3088  loss_mask_0: 0.2217  loss_dice_0: 1.601  loss_ce_1: 0.1988  loss_mask_1: 0.2301  loss_dice_1: 1.249  loss_ce_2: 0.1904  loss_mask_2: 0.2447  loss_dice_2: 1.189  loss_ce_3: 0.2353  loss_mask_3: 0.2588  loss_dice_3: 1.155  loss_ce_4: 0.2595  loss_mask_4: 0.2408  loss_dice_4: 1.254  loss_ce_5: 0.2648  loss_mask_5: 0.28  loss_dice_5: 1.367  loss_ce_6: 0.2732  loss_mask_6: 0.2847  loss_dice_6: 1.354  loss_ce_7: 0.2876  loss_mask_7: 0.2468  loss_dice_7: 1.314  loss_ce_8: 0.3136  loss_mask_8: 0.2405  loss_dice_8: 1.3  loss_mgm_entropy: 0.005037    time: 0.4281  last_time: 0.4286  data_time: 0.0031  last_data_time: 0.0036   lr: 0.0002  max_mem: 15320M
[08/30 15:59:58] d2.utils.events INFO:  eta: 0:53:18  iter: 519  total_loss: 15.74  loss_ce: 0.3604  loss_mask: 0.2051  loss_dice: 0.9917  loss_ce_0: 0.2979  loss_mask_0: 0.1794  loss_dice_0: 1.354  loss_ce_1: 0.1754  loss_mask_1: 0.1741  loss_dice_1: 1.002  loss_ce_2: 0.1791  loss_mask_2: 0.1944  loss_dice_2: 0.999  loss_ce_3: 0.2263  loss_mask_3: 0.1884  loss_dice_3: 1.009  loss_ce_4: 0.2564  loss_mask_4: 0.1757  loss_dice_4: 1.083  loss_ce_5: 0.258  loss_mask_5: 0.2152  loss_dice_5: 1.202  loss_ce_6: 0.2971  loss_mask_6: 0.2028  loss_dice_6: 1.143  loss_ce_7: 0.3186  loss_mask_7: 0.2049  loss_dice_7: 1.127  loss_ce_8: 0.322  loss_mask_8: 0.1837  loss_dice_8: 1.03  loss_mgm_entropy: 0.005037    time: 0.4281  last_time: 0.4304  data_time: 0.0030  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:00:06] d2.utils.events INFO:  eta: 0:53:10  iter: 539  total_loss: 15.63  loss_ce: 0.3498  loss_mask: 0.1997  loss_dice: 0.952  loss_ce_0: 0.2983  loss_mask_0: 0.1689  loss_dice_0: 1.319  loss_ce_1: 0.1912  loss_mask_1: 0.2018  loss_dice_1: 1.024  loss_ce_2: 0.179  loss_mask_2: 0.1912  loss_dice_2: 0.9555  loss_ce_3: 0.2011  loss_mask_3: 0.2106  loss_dice_3: 0.973  loss_ce_4: 0.2414  loss_mask_4: 0.2164  loss_dice_4: 1.048  loss_ce_5: 0.2534  loss_mask_5: 0.1992  loss_dice_5: 1.088  loss_ce_6: 0.2708  loss_mask_6: 0.2033  loss_dice_6: 1.119  loss_ce_7: 0.2859  loss_mask_7: 0.214  loss_dice_7: 1.069  loss_ce_8: 0.3009  loss_mask_8: 0.1821  loss_dice_8: 1.054  loss_mgm_entropy: 0.004978    time: 0.4282  last_time: 0.4282  data_time: 0.0031  last_data_time: 0.0037   lr: 0.0002  max_mem: 15320M
[08/30 16:00:15] d2.utils.events INFO:  eta: 0:53:02  iter: 559  total_loss: 13.57  loss_ce: 0.3161  loss_mask: 0.1651  loss_dice: 0.8658  loss_ce_0: 0.2923  loss_mask_0: 0.1674  loss_dice_0: 1.268  loss_ce_1: 0.1855  loss_mask_1: 0.1278  loss_dice_1: 0.8836  loss_ce_2: 0.18  loss_mask_2: 0.152  loss_dice_2: 0.9054  loss_ce_3: 0.1963  loss_mask_3: 0.1582  loss_dice_3: 0.9083  loss_ce_4: 0.2115  loss_mask_4: 0.1912  loss_dice_4: 0.9577  loss_ce_5: 0.2461  loss_mask_5: 0.1553  loss_dice_5: 1.009  loss_ce_6: 0.2528  loss_mask_6: 0.171  loss_dice_6: 1.121  loss_ce_7: 0.2732  loss_mask_7: 0.147  loss_dice_7: 0.904  loss_ce_8: 0.3031  loss_mask_8: 0.1687  loss_dice_8: 0.9463  loss_mgm_entropy: 0.005098    time: 0.4282  last_time: 0.4289  data_time: 0.0030  last_data_time: 0.0037   lr: 0.0002  max_mem: 15320M
[08/30 16:00:23] d2.utils.events INFO:  eta: 0:52:53  iter: 579  total_loss: 12.71  loss_ce: 0.3015  loss_mask: 0.1482  loss_dice: 0.8151  loss_ce_0: 0.2821  loss_mask_0: 0.1298  loss_dice_0: 1.081  loss_ce_1: 0.1721  loss_mask_1: 0.1364  loss_dice_1: 0.8195  loss_ce_2: 0.1559  loss_mask_2: 0.1412  loss_dice_2: 0.7837  loss_ce_3: 0.1709  loss_mask_3: 0.1392  loss_dice_3: 0.7745  loss_ce_4: 0.2391  loss_mask_4: 0.1404  loss_dice_4: 0.844  loss_ce_5: 0.2473  loss_mask_5: 0.1373  loss_dice_5: 0.8729  loss_ce_6: 0.2962  loss_mask_6: 0.1559  loss_dice_6: 0.9044  loss_ce_7: 0.2698  loss_mask_7: 0.1437  loss_dice_7: 0.8404  loss_ce_8: 0.3069  loss_mask_8: 0.1444  loss_dice_8: 0.8203  loss_mgm_entropy: 0.005235    time: 0.4283  last_time: 0.4274  data_time: 0.0032  last_data_time: 0.0036   lr: 0.0002  max_mem: 15320M
[08/30 16:00:32] d2.utils.events INFO:  eta: 0:52:45  iter: 599  total_loss: 11.95  loss_ce: 0.2976  loss_mask: 0.1425  loss_dice: 0.7795  loss_ce_0: 0.2704  loss_mask_0: 0.1561  loss_dice_0: 1.048  loss_ce_1: 0.1813  loss_mask_1: 0.1347  loss_dice_1: 0.7635  loss_ce_2: 0.1745  loss_mask_2: 0.137  loss_dice_2: 0.7291  loss_ce_3: 0.1819  loss_mask_3: 0.1326  loss_dice_3: 0.7217  loss_ce_4: 0.2171  loss_mask_4: 0.1447  loss_dice_4: 0.7745  loss_ce_5: 0.2435  loss_mask_5: 0.1613  loss_dice_5: 0.8179  loss_ce_6: 0.2635  loss_mask_6: 0.1332  loss_dice_6: 0.7768  loss_ce_7: 0.2645  loss_mask_7: 0.1543  loss_dice_7: 0.7987  loss_ce_8: 0.2806  loss_mask_8: 0.1524  loss_dice_8: 0.8154  loss_mgm_entropy: 0.005095    time: 0.4283  last_time: 0.4397  data_time: 0.0030  last_data_time: 0.0031   lr: 0.0002  max_mem: 15320M
[08/30 16:00:41] d2.utils.events INFO:  eta: 0:52:36  iter: 619  total_loss: 11.11  loss_ce: 0.2738  loss_mask: 0.1399  loss_dice: 0.6746  loss_ce_0: 0.2629  loss_mask_0: 0.1259  loss_dice_0: 0.9881  loss_ce_1: 0.1567  loss_mask_1: 0.139  loss_dice_1: 0.7091  loss_ce_2: 0.1555  loss_mask_2: 0.1355  loss_dice_2: 0.6523  loss_ce_3: 0.1743  loss_mask_3: 0.1478  loss_dice_3: 0.6625  loss_ce_4: 0.2045  loss_mask_4: 0.1689  loss_dice_4: 0.7494  loss_ce_5: 0.2328  loss_mask_5: 0.1277  loss_dice_5: 0.7266  loss_ce_6: 0.2284  loss_mask_6: 0.1423  loss_dice_6: 0.7093  loss_ce_7: 0.2662  loss_mask_7: 0.1518  loss_dice_7: 0.767  loss_ce_8: 0.2465  loss_mask_8: 0.1474  loss_dice_8: 0.7762  loss_mgm_entropy: 0.005135    time: 0.4284  last_time: 0.4289  data_time: 0.0030  last_data_time: 0.0030   lr: 0.0002  max_mem: 15320M
[08/30 16:00:49] d2.utils.events INFO:  eta: 0:52:28  iter: 639  total_loss: 11.94  loss_ce: 0.253  loss_mask: 0.1445  loss_dice: 0.7872  loss_ce_0: 0.2573  loss_mask_0: 0.1458  loss_dice_0: 1.036  loss_ce_1: 0.1661  loss_mask_1: 0.1389  loss_dice_1: 0.7295  loss_ce_2: 0.1603  loss_mask_2: 0.14  loss_dice_2: 0.6876  loss_ce_3: 0.1758  loss_mask_3: 0.1553  loss_dice_3: 0.7319  loss_ce_4: 0.2164  loss_mask_4: 0.1506  loss_dice_4: 0.7721  loss_ce_5: 0.2048  loss_mask_5: 0.1373  loss_dice_5: 0.8033  loss_ce_6: 0.2382  loss_mask_6: 0.1485  loss_dice_6: 0.8415  loss_ce_7: 0.2591  loss_mask_7: 0.146  loss_dice_7: 0.8313  loss_ce_8: 0.2435  loss_mask_8: 0.1576  loss_dice_8: 0.827  loss_mgm_entropy: 0.005049    time: 0.4284  last_time: 0.4280  data_time: 0.0030  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:00:58] d2.utils.events INFO:  eta: 0:52:20  iter: 659  total_loss: 9.979  loss_ce: 0.2321  loss_mask: 0.1045  loss_dice: 0.5878  loss_ce_0: 0.2518  loss_mask_0: 0.09394  loss_dice_0: 0.89  loss_ce_1: 0.1593  loss_mask_1: 0.1095  loss_dice_1: 0.6419  loss_ce_2: 0.1617  loss_mask_2: 0.107  loss_dice_2: 0.5944  loss_ce_3: 0.1701  loss_mask_3: 0.1047  loss_dice_3: 0.5924  loss_ce_4: 0.1964  loss_mask_4: 0.1133  loss_dice_4: 0.6511  loss_ce_5: 0.2171  loss_mask_5: 0.1143  loss_dice_5: 0.6491  loss_ce_6: 0.225  loss_mask_6: 0.1064  loss_dice_6: 0.6407  loss_ce_7: 0.2273  loss_mask_7: 0.1084  loss_dice_7: 0.6767  loss_ce_8: 0.2072  loss_mask_8: 0.1132  loss_dice_8: 0.6708  loss_mgm_entropy: 0.005075    time: 0.4286  last_time: 0.4277  data_time: 0.0030  last_data_time: 0.0033   lr: 0.0002  max_mem: 15320M
[08/30 16:01:06] d2.utils.events INFO:  eta: 0:52:11  iter: 679  total_loss: 9.258  loss_ce: 0.2064  loss_mask: 0.1156  loss_dice: 0.5718  loss_ce_0: 0.2434  loss_mask_0: 0.1129  loss_dice_0: 0.8483  loss_ce_1: 0.1444  loss_mask_1: 0.09952  loss_dice_1: 0.576  loss_ce_2: 0.1319  loss_mask_2: 0.09419  loss_dice_2: 0.5041  loss_ce_3: 0.1662  loss_mask_3: 0.09261  loss_dice_3: 0.5207  loss_ce_4: 0.1893  loss_mask_4: 0.1024  loss_dice_4: 0.5757  loss_ce_5: 0.1823  loss_mask_5: 0.112  loss_dice_5: 0.5751  loss_ce_6: 0.2043  loss_mask_6: 0.1181  loss_dice_6: 0.5794  loss_ce_7: 0.2479  loss_mask_7: 0.1245  loss_dice_7: 0.5969  loss_ce_8: 0.2036  loss_mask_8: 0.1083  loss_dice_8: 0.5815  loss_mgm_entropy: 0.004943    time: 0.4286  last_time: 0.4282  data_time: 0.0031  last_data_time: 0.0031   lr: 0.0002  max_mem: 15320M
[08/30 16:01:15] d2.utils.events INFO:  eta: 0:52:03  iter: 699  total_loss: 9.699  loss_ce: 0.1927  loss_mask: 0.1044  loss_dice: 0.5872  loss_ce_0: 0.2355  loss_mask_0: 0.09513  loss_dice_0: 0.8327  loss_ce_1: 0.1383  loss_mask_1: 0.1043  loss_dice_1: 0.6376  loss_ce_2: 0.126  loss_mask_2: 0.09626  loss_dice_2: 0.5827  loss_ce_3: 0.1497  loss_mask_3: 0.09689  loss_dice_3: 0.5358  loss_ce_4: 0.168  loss_mask_4: 0.1032  loss_dice_4: 0.6772  loss_ce_5: 0.1714  loss_mask_5: 0.1017  loss_dice_5: 0.6705  loss_ce_6: 0.1856  loss_mask_6: 0.1068  loss_dice_6: 0.6798  loss_ce_7: 0.2027  loss_mask_7: 0.1217  loss_dice_7: 0.6714  loss_ce_8: 0.2139  loss_mask_8: 0.1009  loss_dice_8: 0.6364  loss_mgm_entropy: 0.004898    time: 0.4287  last_time: 0.4266  data_time: 0.0030  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 16:01:24] d2.utils.events INFO:  eta: 0:51:55  iter: 719  total_loss: 7.934  loss_ce: 0.1815  loss_mask: 0.08777  loss_dice: 0.4957  loss_ce_0: 0.2345  loss_mask_0: 0.09295  loss_dice_0: 0.7156  loss_ce_1: 0.1441  loss_mask_1: 0.08975  loss_dice_1: 0.5017  loss_ce_2: 0.136  loss_mask_2: 0.08529  loss_dice_2: 0.5086  loss_ce_3: 0.1435  loss_mask_3: 0.09984  loss_dice_3: 0.5017  loss_ce_4: 0.1409  loss_mask_4: 0.1103  loss_dice_4: 0.5387  loss_ce_5: 0.1574  loss_mask_5: 0.09165  loss_dice_5: 0.5303  loss_ce_6: 0.1862  loss_mask_6: 0.09455  loss_dice_6: 0.4887  loss_ce_7: 0.1925  loss_mask_7: 0.1041  loss_dice_7: 0.5741  loss_ce_8: 0.1744  loss_mask_8: 0.09267  loss_dice_8: 0.5379  loss_mgm_entropy: 0.005051    time: 0.4287  last_time: 0.4276  data_time: 0.0031  last_data_time: 0.0031   lr: 0.0002  max_mem: 15320M
[08/30 16:01:32] d2.utils.events INFO:  eta: 0:51:46  iter: 739  total_loss: 7.094  loss_ce: 0.1755  loss_mask: 0.08086  loss_dice: 0.4439  loss_ce_0: 0.2234  loss_mask_0: 0.0911  loss_dice_0: 0.7128  loss_ce_1: 0.1131  loss_mask_1: 0.08677  loss_dice_1: 0.4242  loss_ce_2: 0.111  loss_mask_2: 0.07498  loss_dice_2: 0.3872  loss_ce_3: 0.118  loss_mask_3: 0.07353  loss_dice_3: 0.3974  loss_ce_4: 0.1244  loss_mask_4: 0.08248  loss_dice_4: 0.4587  loss_ce_5: 0.1378  loss_mask_5: 0.08299  loss_dice_5: 0.4544  loss_ce_6: 0.1656  loss_mask_6: 0.09047  loss_dice_6: 0.4543  loss_ce_7: 0.1768  loss_mask_7: 0.09184  loss_dice_7: 0.4747  loss_ce_8: 0.1697  loss_mask_8: 0.08282  loss_dice_8: 0.442  loss_mgm_entropy: 0.004942    time: 0.4287  last_time: 0.4282  data_time: 0.0030  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 16:01:41] d2.utils.events INFO:  eta: 0:51:38  iter: 759  total_loss: 7.358  loss_ce: 0.1485  loss_mask: 0.1062  loss_dice: 0.4796  loss_ce_0: 0.2248  loss_mask_0: 0.08729  loss_dice_0: 0.6802  loss_ce_1: 0.1209  loss_mask_1: 0.08855  loss_dice_1: 0.4721  loss_ce_2: 0.09943  loss_mask_2: 0.08497  loss_dice_2: 0.4407  loss_ce_3: 0.1153  loss_mask_3: 0.08237  loss_dice_3: 0.4096  loss_ce_4: 0.1368  loss_mask_4: 0.09845  loss_dice_4: 0.4497  loss_ce_5: 0.1535  loss_mask_5: 0.1029  loss_dice_5: 0.4858  loss_ce_6: 0.1562  loss_mask_6: 0.1019  loss_dice_6: 0.4877  loss_ce_7: 0.167  loss_mask_7: 0.1047  loss_dice_7: 0.4959  loss_ce_8: 0.1497  loss_mask_8: 0.102  loss_dice_8: 0.4714  loss_mgm_entropy: 0.00488    time: 0.4287  last_time: 0.4289  data_time: 0.0030  last_data_time: 0.0028   lr: 0.0002  max_mem: 15320M
[08/30 16:01:49] d2.utils.events INFO:  eta: 0:51:29  iter: 779  total_loss: 6.275  loss_ce: 0.1503  loss_mask: 0.06567  loss_dice: 0.3651  loss_ce_0: 0.2139  loss_mask_0: 0.07107  loss_dice_0: 0.5908  loss_ce_1: 0.1276  loss_mask_1: 0.06501  loss_dice_1: 0.3703  loss_ce_2: 0.1175  loss_mask_2: 0.061  loss_dice_2: 0.3548  loss_ce_3: 0.1242  loss_mask_3: 0.06595  loss_dice_3: 0.3626  loss_ce_4: 0.1234  loss_mask_4: 0.06414  loss_dice_4: 0.3993  loss_ce_5: 0.1435  loss_mask_5: 0.07208  loss_dice_5: 0.3945  loss_ce_6: 0.1612  loss_mask_6: 0.06956  loss_dice_6: 0.3956  loss_ce_7: 0.1704  loss_mask_7: 0.07009  loss_dice_7: 0.3904  loss_ce_8: 0.1428  loss_mask_8: 0.06804  loss_dice_8: 0.4094  loss_mgm_entropy: 0.005014    time: 0.4287  last_time: 0.4282  data_time: 0.0030  last_data_time: 0.0031   lr: 0.0002  max_mem: 15320M
[08/30 16:01:58] d2.utils.events INFO:  eta: 0:51:21  iter: 799  total_loss: 5.77  loss_ce: 0.1239  loss_mask: 0.06682  loss_dice: 0.3474  loss_ce_0: 0.2099  loss_mask_0: 0.07492  loss_dice_0: 0.5891  loss_ce_1: 0.1201  loss_mask_1: 0.06776  loss_dice_1: 0.3655  loss_ce_2: 0.09819  loss_mask_2: 0.06864  loss_dice_2: 0.3235  loss_ce_3: 0.1027  loss_mask_3: 0.0679  loss_dice_3: 0.3435  loss_ce_4: 0.1141  loss_mask_4: 0.07094  loss_dice_4: 0.3594  loss_ce_5: 0.1381  loss_mask_5: 0.06895  loss_dice_5: 0.3483  loss_ce_6: 0.1528  loss_mask_6: 0.06971  loss_dice_6: 0.3516  loss_ce_7: 0.1502  loss_mask_7: 0.07073  loss_dice_7: 0.3792  loss_ce_8: 0.1231  loss_mask_8: 0.06846  loss_dice_8: 0.3677  loss_mgm_entropy: 0.004972    time: 0.4287  last_time: 0.4286  data_time: 0.0030  last_data_time: 0.0034   lr: 0.0002  max_mem: 15320M
[08/30 16:02:07] d2.utils.events INFO:  eta: 0:51:12  iter: 819  total_loss: 7.009  loss_ce: 0.1432  loss_mask: 0.08238  loss_dice: 0.425  loss_ce_0: 0.2051  loss_mask_0: 0.07706  loss_dice_0: 0.668  loss_ce_1: 0.1189  loss_mask_1: 0.07886  loss_dice_1: 0.4318  loss_ce_2: 0.1047  loss_mask_2: 0.07655  loss_dice_2: 0.4025  loss_ce_3: 0.104  loss_mask_3: 0.08203  loss_dice_3: 0.3939  loss_ce_4: 0.1202  loss_mask_4: 0.07684  loss_dice_4: 0.4322  loss_ce_5: 0.1354  loss_mask_5: 0.08459  loss_dice_5: 0.4715  loss_ce_6: 0.1439  loss_mask_6: 0.08926  loss_dice_6: 0.4421  loss_ce_7: 0.1454  loss_mask_7: 0.09118  loss_dice_7: 0.4813  loss_ce_8: 0.1194  loss_mask_8: 0.08787  loss_dice_8: 0.4774  loss_mgm_entropy: 0.00506    time: 0.4288  last_time: 0.4276  data_time: 0.0030  last_data_time: 0.0030   lr: 0.0002  max_mem: 15320M
[08/30 16:02:15] d2.utils.events INFO:  eta: 0:51:04  iter: 839  total_loss: 6.381  loss_ce: 0.1494  loss_mask: 0.07219  loss_dice: 0.401  loss_ce_0: 0.201  loss_mask_0: 0.07812  loss_dice_0: 0.6409  loss_ce_1: 0.1354  loss_mask_1: 0.06399  loss_dice_1: 0.4167  loss_ce_2: 0.128  loss_mask_2: 0.06347  loss_dice_2: 0.3723  loss_ce_3: 0.1324  loss_mask_3: 0.06697  loss_dice_3: 0.3708  loss_ce_4: 0.1361  loss_mask_4: 0.06765  loss_dice_4: 0.4109  loss_ce_5: 0.1384  loss_mask_5: 0.06807  loss_dice_5: 0.4036  loss_ce_6: 0.1554  loss_mask_6: 0.07104  loss_dice_6: 0.4002  loss_ce_7: 0.1594  loss_mask_7: 0.08176  loss_dice_7: 0.4272  loss_ce_8: 0.1398  loss_mask_8: 0.07176  loss_dice_8: 0.4143  loss_mgm_entropy: 0.005316    time: 0.4288  last_time: 0.4283  data_time: 0.0029  last_data_time: 0.0025   lr: 0.0002  max_mem: 15320M
[08/30 16:02:24] d2.utils.events INFO:  eta: 0:50:56  iter: 859  total_loss: 6.475  loss_ce: 0.1398  loss_mask: 0.07924  loss_dice: 0.3754  loss_ce_0: 0.1988  loss_mask_0: 0.07186  loss_dice_0: 0.5768  loss_ce_1: 0.1258  loss_mask_1: 0.07164  loss_dice_1: 0.404  loss_ce_2: 0.1049  loss_mask_2: 0.0758  loss_dice_2: 0.3601  loss_ce_3: 0.1034  loss_mask_3: 0.07074  loss_dice_3: 0.363  loss_ce_4: 0.09487  loss_mask_4: 0.07021  loss_dice_4: 0.4369  loss_ce_5: 0.1511  loss_mask_5: 0.08067  loss_dice_5: 0.4321  loss_ce_6: 0.141  loss_mask_6: 0.08047  loss_dice_6: 0.3892  loss_ce_7: 0.1582  loss_mask_7: 0.07259  loss_dice_7: 0.3712  loss_ce_8: 0.1487  loss_mask_8: 0.08155  loss_dice_8: 0.4195  loss_mgm_entropy: 0.005209    time: 0.4288  last_time: 0.4286  data_time: 0.0030  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 16:02:32] d2.utils.events INFO:  eta: 0:50:47  iter: 879  total_loss: 5.155  loss_ce: 0.1209  loss_mask: 0.05406  loss_dice: 0.2745  loss_ce_0: 0.2001  loss_mask_0: 0.06301  loss_dice_0: 0.4705  loss_ce_1: 0.1102  loss_mask_1: 0.05731  loss_dice_1: 0.3  loss_ce_2: 0.07799  loss_mask_2: 0.05466  loss_dice_2: 0.2657  loss_ce_3: 0.09271  loss_mask_3: 0.05357  loss_dice_3: 0.278  loss_ce_4: 0.1117  loss_mask_4: 0.05701  loss_dice_4: 0.294  loss_ce_5: 0.1287  loss_mask_5: 0.05758  loss_dice_5: 0.3012  loss_ce_6: 0.1284  loss_mask_6: 0.06328  loss_dice_6: 0.2956  loss_ce_7: 0.138  loss_mask_7: 0.06306  loss_dice_7: 0.3041  loss_ce_8: 0.1135  loss_mask_8: 0.06107  loss_dice_8: 0.3149  loss_mgm_entropy: 0.005013    time: 0.4288  last_time: 0.4291  data_time: 0.0031  last_data_time: 0.0033   lr: 0.0002  max_mem: 15320M
[08/30 16:02:41] d2.utils.events INFO:  eta: 0:50:39  iter: 899  total_loss: 5.395  loss_ce: 0.1102  loss_mask: 0.07  loss_dice: 0.3353  loss_ce_0: 0.1904  loss_mask_0: 0.06363  loss_dice_0: 0.5659  loss_ce_1: 0.1121  loss_mask_1: 0.06839  loss_dice_1: 0.33  loss_ce_2: 0.1004  loss_mask_2: 0.06669  loss_dice_2: 0.3026  loss_ce_3: 0.09926  loss_mask_3: 0.06322  loss_dice_3: 0.3048  loss_ce_4: 0.129  loss_mask_4: 0.06222  loss_dice_4: 0.342  loss_ce_5: 0.1233  loss_mask_5: 0.06386  loss_dice_5: 0.3494  loss_ce_6: 0.1312  loss_mask_6: 0.07808  loss_dice_6: 0.3433  loss_ce_7: 0.1599  loss_mask_7: 0.06804  loss_dice_7: 0.3542  loss_ce_8: 0.1262  loss_mask_8: 0.07216  loss_dice_8: 0.373  loss_mgm_entropy: 0.005054    time: 0.4289  last_time: 0.4282  data_time: 0.0030  last_data_time: 0.0031   lr: 0.0002  max_mem: 15320M
[08/30 16:02:50] d2.utils.events INFO:  eta: 0:50:30  iter: 919  total_loss: 5.337  loss_ce: 0.0933  loss_mask: 0.06412  loss_dice: 0.3312  loss_ce_0: 0.1914  loss_mask_0: 0.07725  loss_dice_0: 0.5181  loss_ce_1: 0.1058  loss_mask_1: 0.06756  loss_dice_1: 0.3397  loss_ce_2: 0.07491  loss_mask_2: 0.07053  loss_dice_2: 0.3286  loss_ce_3: 0.07596  loss_mask_3: 0.07019  loss_dice_3: 0.3197  loss_ce_4: 0.09002  loss_mask_4: 0.06509  loss_dice_4: 0.3304  loss_ce_5: 0.138  loss_mask_5: 0.06876  loss_dice_5: 0.3287  loss_ce_6: 0.1227  loss_mask_6: 0.07019  loss_dice_6: 0.3504  loss_ce_7: 0.139  loss_mask_7: 0.07423  loss_dice_7: 0.3396  loss_ce_8: 0.117  loss_mask_8: 0.06923  loss_dice_8: 0.3401  loss_mgm_entropy: 0.005034    time: 0.4289  last_time: 0.4274  data_time: 0.0030  last_data_time: 0.0031   lr: 0.0002  max_mem: 15320M
[08/30 16:02:58] d2.utils.events INFO:  eta: 0:50:22  iter: 939  total_loss: 4.385  loss_ce: 0.08695  loss_mask: 0.04929  loss_dice: 0.2784  loss_ce_0: 0.1825  loss_mask_0: 0.05051  loss_dice_0: 0.3886  loss_ce_1: 0.1145  loss_mask_1: 0.04594  loss_dice_1: 0.2579  loss_ce_2: 0.07619  loss_mask_2: 0.0465  loss_dice_2: 0.2337  loss_ce_3: 0.07638  loss_mask_3: 0.04493  loss_dice_3: 0.249  loss_ce_4: 0.09431  loss_mask_4: 0.04575  loss_dice_4: 0.2466  loss_ce_5: 0.1099  loss_mask_5: 0.05096  loss_dice_5: 0.2822  loss_ce_6: 0.1037  loss_mask_6: 0.05068  loss_dice_6: 0.2903  loss_ce_7: 0.1331  loss_mask_7: 0.04795  loss_dice_7: 0.2641  loss_ce_8: 0.1254  loss_mask_8: 0.04837  loss_dice_8: 0.26  loss_mgm_entropy: 0.005039    time: 0.4289  last_time: 0.4285  data_time: 0.0030  last_data_time: 0.0027   lr: 0.0002  max_mem: 15320M
[08/30 16:03:07] d2.utils.events INFO:  eta: 0:50:14  iter: 959  total_loss: 3.998  loss_ce: 0.08146  loss_mask: 0.04449  loss_dice: 0.2263  loss_ce_0: 0.1835  loss_mask_0: 0.04248  loss_dice_0: 0.3557  loss_ce_1: 0.08813  loss_mask_1: 0.04425  loss_dice_1: 0.2311  loss_ce_2: 0.05869  loss_mask_2: 0.04427  loss_dice_2: 0.2226  loss_ce_3: 0.05448  loss_mask_3: 0.04191  loss_dice_3: 0.2208  loss_ce_4: 0.07527  loss_mask_4: 0.04304  loss_dice_4: 0.2382  loss_ce_5: 0.09732  loss_mask_5: 0.04404  loss_dice_5: 0.2396  loss_ce_6: 0.08755  loss_mask_6: 0.04674  loss_dice_6: 0.2454  loss_ce_7: 0.111  loss_mask_7: 0.04763  loss_dice_7: 0.2478  loss_ce_8: 0.09593  loss_mask_8: 0.04578  loss_dice_8: 0.2349  loss_mgm_entropy: 0.004956    time: 0.4290  last_time: 0.4399  data_time: 0.0031  last_data_time: 0.0031   lr: 0.0002  max_mem: 15320M
[08/30 16:03:16] d2.utils.events INFO:  eta: 0:50:05  iter: 979  total_loss: 3.973  loss_ce: 0.07222  loss_mask: 0.0488  loss_dice: 0.2342  loss_ce_0: 0.1765  loss_mask_0: 0.05837  loss_dice_0: 0.3849  loss_ce_1: 0.09115  loss_mask_1: 0.04837  loss_dice_1: 0.2483  loss_ce_2: 0.07269  loss_mask_2: 0.04514  loss_dice_2: 0.2313  loss_ce_3: 0.06797  loss_mask_3: 0.04437  loss_dice_3: 0.2248  loss_ce_4: 0.07674  loss_mask_4: 0.04893  loss_dice_4: 0.2394  loss_ce_5: 0.09946  loss_mask_5: 0.04371  loss_dice_5: 0.2387  loss_ce_6: 0.08239  loss_mask_6: 0.04868  loss_dice_6: 0.246  loss_ce_7: 0.121  loss_mask_7: 0.04923  loss_dice_7: 0.2481  loss_ce_8: 0.1039  loss_mask_8: 0.04812  loss_dice_8: 0.2503  loss_mgm_entropy: 0.005059    time: 0.4290  last_time: 0.4296  data_time: 0.0032  last_data_time: 0.0038   lr: 0.0002  max_mem: 15320M
[08/30 16:03:24] d2.utils.events INFO:  eta: 0:49:57  iter: 999  total_loss: 3.956  loss_ce: 0.07316  loss_mask: 0.0445  loss_dice: 0.2388  loss_ce_0: 0.1752  loss_mask_0: 0.04012  loss_dice_0: 0.3217  loss_ce_1: 0.0878  loss_mask_1: 0.04277  loss_dice_1: 0.237  loss_ce_2: 0.07246  loss_mask_2: 0.04125  loss_dice_2: 0.223  loss_ce_3: 0.06959  loss_mask_3: 0.04407  loss_dice_3: 0.2266  loss_ce_4: 0.07656  loss_mask_4: 0.04427  loss_dice_4: 0.2405  loss_ce_5: 0.08113  loss_mask_5: 0.04465  loss_dice_5: 0.254  loss_ce_6: 0.08827  loss_mask_6: 0.04473  loss_dice_6: 0.2512  loss_ce_7: 0.1038  loss_mask_7: 0.04708  loss_dice_7: 0.2495  loss_ce_8: 0.09179  loss_mask_8: 0.04562  loss_dice_8: 0.2539  loss_mgm_entropy: 0.004953    time: 0.4290  last_time: 0.4292  data_time: 0.0030  last_data_time: 0.0033   lr: 0.0002  max_mem: 15320M
[08/30 16:03:33] d2.utils.events INFO:  eta: 0:49:48  iter: 1019  total_loss: 4.217  loss_ce: 0.06101  loss_mask: 0.05495  loss_dice: 0.2551  loss_ce_0: 0.1738  loss_mask_0: 0.05299  loss_dice_0: 0.3657  loss_ce_1: 0.0736  loss_mask_1: 0.05419  loss_dice_1: 0.268  loss_ce_2: 0.05173  loss_mask_2: 0.05462  loss_dice_2: 0.259  loss_ce_3: 0.05576  loss_mask_3: 0.05284  loss_dice_3: 0.2586  loss_ce_4: 0.06805  loss_mask_4: 0.05385  loss_dice_4: 0.263  loss_ce_5: 0.07793  loss_mask_5: 0.05238  loss_dice_5: 0.2628  loss_ce_6: 0.07727  loss_mask_6: 0.05413  loss_dice_6: 0.2757  loss_ce_7: 0.09382  loss_mask_7: 0.05544  loss_dice_7: 0.2763  loss_ce_8: 0.08125  loss_mask_8: 0.05355  loss_dice_8: 0.261  loss_mgm_entropy: 0.004915    time: 0.4291  last_time: 0.4323  data_time: 0.0030  last_data_time: 0.0030   lr: 0.0002  max_mem: 15320M
[08/30 16:03:41] d2.utils.events INFO:  eta: 0:49:40  iter: 1039  total_loss: 3.536  loss_ce: 0.05784  loss_mask: 0.04331  loss_dice: 0.2109  loss_ce_0: 0.1697  loss_mask_0: 0.03695  loss_dice_0: 0.3156  loss_ce_1: 0.05881  loss_mask_1: 0.04215  loss_dice_1: 0.221  loss_ce_2: 0.0299  loss_mask_2: 0.0413  loss_dice_2: 0.2119  loss_ce_3: 0.03384  loss_mask_3: 0.03943  loss_dice_3: 0.1974  loss_ce_4: 0.04387  loss_mask_4: 0.04098  loss_dice_4: 0.2109  loss_ce_5: 0.069  loss_mask_5: 0.04115  loss_dice_5: 0.2107  loss_ce_6: 0.06119  loss_mask_6: 0.04217  loss_dice_6: 0.2282  loss_ce_7: 0.08583  loss_mask_7: 0.04291  loss_dice_7: 0.225  loss_ce_8: 0.08494  loss_mask_8: 0.04435  loss_dice_8: 0.2153  loss_mgm_entropy: 0.004989    time: 0.4291  last_time: 0.4297  data_time: 0.0031  last_data_time: 0.0034   lr: 0.0002  max_mem: 15320M
[08/30 16:03:50] d2.utils.events INFO:  eta: 0:49:32  iter: 1059  total_loss: 3.192  loss_ce: 0.07861  loss_mask: 0.03227  loss_dice: 0.1932  loss_ce_0: 0.1683  loss_mask_0: 0.03501  loss_dice_0: 0.2685  loss_ce_1: 0.05708  loss_mask_1: 0.03118  loss_dice_1: 0.1908  loss_ce_2: 0.04362  loss_mask_2: 0.03151  loss_dice_2: 0.1848  loss_ce_3: 0.05188  loss_mask_3: 0.02987  loss_dice_3: 0.1742  loss_ce_4: 0.06108  loss_mask_4: 0.03011  loss_dice_4: 0.1839  loss_ce_5: 0.06407  loss_mask_5: 0.03182  loss_dice_5: 0.1899  loss_ce_6: 0.06764  loss_mask_6: 0.03292  loss_dice_6: 0.1976  loss_ce_7: 0.08196  loss_mask_7: 0.0346  loss_dice_7: 0.1906  loss_ce_8: 0.07801  loss_mask_8: 0.03242  loss_dice_8: 0.2011  loss_mgm_entropy: 0.004986    time: 0.4291  last_time: 0.4407  data_time: 0.0032  last_data_time: 0.0039   lr: 0.0002  max_mem: 15320M
[08/30 16:03:59] d2.utils.events INFO:  eta: 0:49:23  iter: 1079  total_loss: 3.096  loss_ce: 0.04908  loss_mask: 0.03422  loss_dice: 0.1754  loss_ce_0: 0.1636  loss_mask_0: 0.02854  loss_dice_0: 0.2367  loss_ce_1: 0.05303  loss_mask_1: 0.03286  loss_dice_1: 0.1719  loss_ce_2: 0.02811  loss_mask_2: 0.03376  loss_dice_2: 0.1719  loss_ce_3: 0.03215  loss_mask_3: 0.03077  loss_dice_3: 0.1706  loss_ce_4: 0.04646  loss_mask_4: 0.03363  loss_dice_4: 0.1817  loss_ce_5: 0.08339  loss_mask_5: 0.03095  loss_dice_5: 0.1745  loss_ce_6: 0.06867  loss_mask_6: 0.03296  loss_dice_6: 0.1825  loss_ce_7: 0.08219  loss_mask_7: 0.03344  loss_dice_7: 0.1811  loss_ce_8: 0.07264  loss_mask_8: 0.03523  loss_dice_8: 0.1823  loss_mgm_entropy: 0.004948    time: 0.4291  last_time: 0.4277  data_time: 0.0031  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 16:04:07] d2.utils.events INFO:  eta: 0:49:15  iter: 1099  total_loss: 2.873  loss_ce: 0.04725  loss_mask: 0.03492  loss_dice: 0.1766  loss_ce_0: 0.1608  loss_mask_0: 0.03388  loss_dice_0: 0.2634  loss_ce_1: 0.04001  loss_mask_1: 0.03391  loss_dice_1: 0.18  loss_ce_2: 0.0192  loss_mask_2: 0.03633  loss_dice_2: 0.1774  loss_ce_3: 0.01967  loss_mask_3: 0.0367  loss_dice_3: 0.1789  loss_ce_4: 0.03044  loss_mask_4: 0.03436  loss_dice_4: 0.1797  loss_ce_5: 0.05252  loss_mask_5: 0.03601  loss_dice_5: 0.1823  loss_ce_6: 0.05322  loss_mask_6: 0.03531  loss_dice_6: 0.1799  loss_ce_7: 0.06619  loss_mask_7: 0.03466  loss_dice_7: 0.1881  loss_ce_8: 0.05662  loss_mask_8: 0.03553  loss_dice_8: 0.181  loss_mgm_entropy: 0.004926    time: 0.4291  last_time: 0.4275  data_time: 0.0030  last_data_time: 0.0031   lr: 0.0002  max_mem: 15320M
[08/30 16:04:16] d2.utils.events INFO:  eta: 0:49:07  iter: 1119  total_loss: 3.473  loss_ce: 0.07932  loss_mask: 0.03728  loss_dice: 0.1994  loss_ce_0: 0.1624  loss_mask_0: 0.03248  loss_dice_0: 0.273  loss_ce_1: 0.05676  loss_mask_1: 0.03606  loss_dice_1: 0.2083  loss_ce_2: 0.03847  loss_mask_2: 0.03612  loss_dice_2: 0.19  loss_ce_3: 0.03666  loss_mask_3: 0.03645  loss_dice_3: 0.1906  loss_ce_4: 0.04998  loss_mask_4: 0.03472  loss_dice_4: 0.2099  loss_ce_5: 0.06845  loss_mask_5: 0.03938  loss_dice_5: 0.2019  loss_ce_6: 0.06375  loss_mask_6: 0.03972  loss_dice_6: 0.2047  loss_ce_7: 0.09608  loss_mask_7: 0.03945  loss_dice_7: 0.2183  loss_ce_8: 0.07928  loss_mask_8: 0.03878  loss_dice_8: 0.2153  loss_mgm_entropy: 0.004988    time: 0.4291  last_time: 0.4301  data_time: 0.0031  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:04:24] d2.utils.events INFO:  eta: 0:48:58  iter: 1139  total_loss: 3.324  loss_ce: 0.05777  loss_mask: 0.03967  loss_dice: 0.1968  loss_ce_0: 0.1562  loss_mask_0: 0.03524  loss_dice_0: 0.2791  loss_ce_1: 0.04694  loss_mask_1: 0.04074  loss_dice_1: 0.2096  loss_ce_2: 0.02603  loss_mask_2: 0.0399  loss_dice_2: 0.2001  loss_ce_3: 0.02166  loss_mask_3: 0.03899  loss_dice_3: 0.1845  loss_ce_4: 0.03765  loss_mask_4: 0.04421  loss_dice_4: 0.1932  loss_ce_5: 0.06445  loss_mask_5: 0.04616  loss_dice_5: 0.2097  loss_ce_6: 0.06032  loss_mask_6: 0.04424  loss_dice_6: 0.2086  loss_ce_7: 0.08281  loss_mask_7: 0.04337  loss_dice_7: 0.205  loss_ce_8: 0.06051  loss_mask_8: 0.04394  loss_dice_8: 0.2061  loss_mgm_entropy: 0.004935    time: 0.4292  last_time: 0.4313  data_time: 0.0030  last_data_time: 0.0030   lr: 0.0002  max_mem: 15320M
[08/30 16:04:33] d2.utils.events INFO:  eta: 0:48:50  iter: 1159  total_loss: 2.856  loss_ce: 0.0458  loss_mask: 0.03303  loss_dice: 0.1826  loss_ce_0: 0.1527  loss_mask_0: 0.03278  loss_dice_0: 0.2513  loss_ce_1: 0.04338  loss_mask_1: 0.03226  loss_dice_1: 0.1872  loss_ce_2: 0.02183  loss_mask_2: 0.03141  loss_dice_2: 0.17  loss_ce_3: 0.0204  loss_mask_3: 0.0314  loss_dice_3: 0.1775  loss_ce_4: 0.03164  loss_mask_4: 0.03054  loss_dice_4: 0.176  loss_ce_5: 0.06384  loss_mask_5: 0.0312  loss_dice_5: 0.1794  loss_ce_6: 0.04726  loss_mask_6: 0.03301  loss_dice_6: 0.1859  loss_ce_7: 0.06375  loss_mask_7: 0.03247  loss_dice_7: 0.1881  loss_ce_8: 0.04971  loss_mask_8: 0.03269  loss_dice_8: 0.1908  loss_mgm_entropy: 0.004984    time: 0.4292  last_time: 0.4298  data_time: 0.0030  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:04:42] d2.utils.events INFO:  eta: 0:48:42  iter: 1179  total_loss: 2.825  loss_ce: 0.02698  loss_mask: 0.03233  loss_dice: 0.1938  loss_ce_0: 0.1499  loss_mask_0: 0.02941  loss_dice_0: 0.2459  loss_ce_1: 0.03665  loss_mask_1: 0.03087  loss_dice_1: 0.1893  loss_ce_2: 0.01268  loss_mask_2: 0.03192  loss_dice_2: 0.1858  loss_ce_3: 0.01626  loss_mask_3: 0.03303  loss_dice_3: 0.1853  loss_ce_4: 0.03089  loss_mask_4: 0.03321  loss_dice_4: 0.1882  loss_ce_5: 0.04094  loss_mask_5: 0.03291  loss_dice_5: 0.1962  loss_ce_6: 0.03381  loss_mask_6: 0.03265  loss_dice_6: 0.1922  loss_ce_7: 0.05515  loss_mask_7: 0.03393  loss_dice_7: 0.2016  loss_ce_8: 0.0349  loss_mask_8: 0.03238  loss_dice_8: 0.1942  loss_mgm_entropy: 0.005008    time: 0.4292  last_time: 0.4295  data_time: 0.0031  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:04:50] d2.utils.events INFO:  eta: 0:48:33  iter: 1199  total_loss: 2.704  loss_ce: 0.0216  loss_mask: 0.03503  loss_dice: 0.1726  loss_ce_0: 0.1519  loss_mask_0: 0.03946  loss_dice_0: 0.2702  loss_ce_1: 0.02787  loss_mask_1: 0.03374  loss_dice_1: 0.1781  loss_ce_2: 0.006619  loss_mask_2: 0.03352  loss_dice_2: 0.169  loss_ce_3: 0.007942  loss_mask_3: 0.03235  loss_dice_3: 0.1634  loss_ce_4: 0.01364  loss_mask_4: 0.03232  loss_dice_4: 0.1666  loss_ce_5: 0.03573  loss_mask_5: 0.03392  loss_dice_5: 0.1826  loss_ce_6: 0.03936  loss_mask_6: 0.03373  loss_dice_6: 0.1739  loss_ce_7: 0.04609  loss_mask_7: 0.03697  loss_dice_7: 0.182  loss_ce_8: 0.03534  loss_mask_8: 0.03642  loss_dice_8: 0.1708  loss_mgm_entropy: 0.004761    time: 0.4292  last_time: 0.4308  data_time: 0.0031  last_data_time: 0.0027   lr: 0.0002  max_mem: 15320M
[08/30 16:04:59] d2.utils.events INFO:  eta: 0:48:25  iter: 1219  total_loss: 3.416  loss_ce: 0.07648  loss_mask: 0.04714  loss_dice: 0.2184  loss_ce_0: 0.1447  loss_mask_0: 0.04186  loss_dice_0: 0.2997  loss_ce_1: 0.03777  loss_mask_1: 0.04386  loss_dice_1: 0.2185  loss_ce_2: 0.02799  loss_mask_2: 0.04498  loss_dice_2: 0.206  loss_ce_3: 0.02794  loss_mask_3: 0.04255  loss_dice_3: 0.1996  loss_ce_4: 0.04144  loss_mask_4: 0.04024  loss_dice_4: 0.2235  loss_ce_5: 0.04825  loss_mask_5: 0.04687  loss_dice_5: 0.2271  loss_ce_6: 0.03672  loss_mask_6: 0.0479  loss_dice_6: 0.2254  loss_ce_7: 0.05299  loss_mask_7: 0.05341  loss_dice_7: 0.2337  loss_ce_8: 0.05023  loss_mask_8: 0.05014  loss_dice_8: 0.2213  loss_mgm_entropy: 0.004878    time: 0.4292  last_time: 0.4312  data_time: 0.0031  last_data_time: 0.0034   lr: 0.0002  max_mem: 15320M
[08/30 16:05:08] d2.utils.events INFO:  eta: 0:48:17  iter: 1239  total_loss: 3.367  loss_ce: 0.05045  loss_mask: 0.04096  loss_dice: 0.2178  loss_ce_0: 0.1433  loss_mask_0: 0.03998  loss_dice_0: 0.3145  loss_ce_1: 0.02283  loss_mask_1: 0.0413  loss_dice_1: 0.2165  loss_ce_2: 0.006981  loss_mask_2: 0.03962  loss_dice_2: 0.199  loss_ce_3: 0.009489  loss_mask_3: 0.03902  loss_dice_3: 0.204  loss_ce_4: 0.02461  loss_mask_4: 0.04103  loss_dice_4: 0.2314  loss_ce_5: 0.05827  loss_mask_5: 0.04313  loss_dice_5: 0.2228  loss_ce_6: 0.05476  loss_mask_6: 0.04435  loss_dice_6: 0.2475  loss_ce_7: 0.07028  loss_mask_7: 0.04789  loss_dice_7: 0.2519  loss_ce_8: 0.06087  loss_mask_8: 0.04081  loss_dice_8: 0.2172  loss_mgm_entropy: 0.004926    time: 0.4293  last_time: 0.4300  data_time: 0.0030  last_data_time: 0.0039   lr: 0.0002  max_mem: 15320M
[08/30 16:05:16] d2.utils.events INFO:  eta: 0:48:08  iter: 1259  total_loss: 3.039  loss_ce: 0.03799  loss_mask: 0.03656  loss_dice: 0.2054  loss_ce_0: 0.1396  loss_mask_0: 0.03489  loss_dice_0: 0.2636  loss_ce_1: 0.04275  loss_mask_1: 0.03588  loss_dice_1: 0.2057  loss_ce_2: 0.03181  loss_mask_2: 0.03762  loss_dice_2: 0.1969  loss_ce_3: 0.02357  loss_mask_3: 0.03523  loss_dice_3: 0.1847  loss_ce_4: 0.0308  loss_mask_4: 0.03785  loss_dice_4: 0.2061  loss_ce_5: 0.04322  loss_mask_5: 0.0369  loss_dice_5: 0.2053  loss_ce_6: 0.03306  loss_mask_6: 0.03741  loss_dice_6: 0.2035  loss_ce_7: 0.04362  loss_mask_7: 0.03783  loss_dice_7: 0.2078  loss_ce_8: 0.04568  loss_mask_8: 0.03668  loss_dice_8: 0.2067  loss_mgm_entropy: 0.004896    time: 0.4293  last_time: 0.4418  data_time: 0.0030  last_data_time: 0.0036   lr: 0.0002  max_mem: 15320M
[08/30 16:05:25] d2.utils.events INFO:  eta: 0:48:00  iter: 1279  total_loss: 2.498  loss_ce: 0.05302  loss_mask: 0.02964  loss_dice: 0.168  loss_ce_0: 0.1327  loss_mask_0: 0.02718  loss_dice_0: 0.214  loss_ce_1: 0.03874  loss_mask_1: 0.02985  loss_dice_1: 0.1682  loss_ce_2: 0.02607  loss_mask_2: 0.02974  loss_dice_2: 0.1564  loss_ce_3: 0.0159  loss_mask_3: 0.03034  loss_dice_3: 0.1604  loss_ce_4: 0.02674  loss_mask_4: 0.02946  loss_dice_4: 0.1602  loss_ce_5: 0.0424  loss_mask_5: 0.02879  loss_dice_5: 0.1694  loss_ce_6: 0.02987  loss_mask_6: 0.02792  loss_dice_6: 0.1697  loss_ce_7: 0.04883  loss_mask_7: 0.03169  loss_dice_7: 0.1775  loss_ce_8: 0.04997  loss_mask_8: 0.03036  loss_dice_8: 0.1692  loss_mgm_entropy: 0.004877    time: 0.4293  last_time: 0.4301  data_time: 0.0030  last_data_time: 0.0028   lr: 0.0002  max_mem: 15320M
[08/30 16:05:33] d2.utils.events INFO:  eta: 0:47:52  iter: 1299  total_loss: 2.264  loss_ce: 0.04197  loss_mask: 0.02946  loss_dice: 0.155  loss_ce_0: 0.1404  loss_mask_0: 0.0273  loss_dice_0: 0.2051  loss_ce_1: 0.01672  loss_mask_1: 0.02975  loss_dice_1: 0.1644  loss_ce_2: 0.004282  loss_mask_2: 0.02944  loss_dice_2: 0.1606  loss_ce_3: 0.005658  loss_mask_3: 0.02901  loss_dice_3: 0.1572  loss_ce_4: 0.01084  loss_mask_4: 0.02863  loss_dice_4: 0.1552  loss_ce_5: 0.04265  loss_mask_5: 0.02901  loss_dice_5: 0.165  loss_ce_6: 0.0269  loss_mask_6: 0.03042  loss_dice_6: 0.1616  loss_ce_7: 0.04021  loss_mask_7: 0.02929  loss_dice_7: 0.1608  loss_ce_8: 0.02319  loss_mask_8: 0.03125  loss_dice_8: 0.1626  loss_mgm_entropy: 0.004799    time: 0.4293  last_time: 0.4271  data_time: 0.0031  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:05:42] d2.utils.events INFO:  eta: 0:47:43  iter: 1319  total_loss: 2.268  loss_ce: 0.02444  loss_mask: 0.02719  loss_dice: 0.1538  loss_ce_0: 0.135  loss_mask_0: 0.02548  loss_dice_0: 0.2057  loss_ce_1: 0.01553  loss_mask_1: 0.02564  loss_dice_1: 0.1629  loss_ce_2: 0.006779  loss_mask_2: 0.02692  loss_dice_2: 0.1601  loss_ce_3: 0.01267  loss_mask_3: 0.02571  loss_dice_3: 0.1515  loss_ce_4: 0.01972  loss_mask_4: 0.02614  loss_dice_4: 0.1538  loss_ce_5: 0.03702  loss_mask_5: 0.02644  loss_dice_5: 0.1602  loss_ce_6: 0.02566  loss_mask_6: 0.02525  loss_dice_6: 0.1553  loss_ce_7: 0.03057  loss_mask_7: 0.02782  loss_dice_7: 0.1593  loss_ce_8: 0.02462  loss_mask_8: 0.02662  loss_dice_8: 0.1542  loss_mgm_entropy: 0.004929    time: 0.4294  last_time: 0.4295  data_time: 0.0031  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:05:51] d2.utils.events INFO:  eta: 0:47:35  iter: 1339  total_loss: 2.572  loss_ce: 0.01962  loss_mask: 0.03299  loss_dice: 0.1782  loss_ce_0: 0.1266  loss_mask_0: 0.02818  loss_dice_0: 0.2193  loss_ce_1: 0.01554  loss_mask_1: 0.03097  loss_dice_1: 0.1794  loss_ce_2: 0.005545  loss_mask_2: 0.03151  loss_dice_2: 0.167  loss_ce_3: 0.004558  loss_mask_3: 0.0327  loss_dice_3: 0.181  loss_ce_4: 0.01759  loss_mask_4: 0.03181  loss_dice_4: 0.1849  loss_ce_5: 0.01976  loss_mask_5: 0.03285  loss_dice_5: 0.1848  loss_ce_6: 0.01464  loss_mask_6: 0.0301  loss_dice_6: 0.1742  loss_ce_7: 0.01923  loss_mask_7: 0.03068  loss_dice_7: 0.1855  loss_ce_8: 0.03008  loss_mask_8: 0.03579  loss_dice_8: 0.1966  loss_mgm_entropy: 0.004944    time: 0.4294  last_time: 0.4296  data_time: 0.0030  last_data_time: 0.0031   lr: 0.0002  max_mem: 15320M
[08/30 16:05:59] d2.utils.events INFO:  eta: 0:47:26  iter: 1359  total_loss: 2.335  loss_ce: 0.03258  loss_mask: 0.0279  loss_dice: 0.1638  loss_ce_0: 0.1252  loss_mask_0: 0.02695  loss_dice_0: 0.2098  loss_ce_1: 0.01821  loss_mask_1: 0.02907  loss_dice_1: 0.1655  loss_ce_2: 0.005586  loss_mask_2: 0.02658  loss_dice_2: 0.1581  loss_ce_3: 0.005302  loss_mask_3: 0.02674  loss_dice_3: 0.156  loss_ce_4: 0.01738  loss_mask_4: 0.02794  loss_dice_4: 0.1635  loss_ce_5: 0.02498  loss_mask_5: 0.02663  loss_dice_5: 0.1609  loss_ce_6: 0.01607  loss_mask_6: 0.02925  loss_dice_6: 0.1685  loss_ce_7: 0.05024  loss_mask_7: 0.0297  loss_dice_7: 0.1712  loss_ce_8: 0.02411  loss_mask_8: 0.03065  loss_dice_8: 0.1717  loss_mgm_entropy: 0.004897    time: 0.4294  last_time: 0.4283  data_time: 0.0031  last_data_time: 0.0034   lr: 0.0002  max_mem: 15320M
[08/30 16:06:08] d2.utils.events INFO:  eta: 0:47:18  iter: 1379  total_loss: 2.199  loss_ce: 0.01646  loss_mask: 0.02864  loss_dice: 0.1573  loss_ce_0: 0.1272  loss_mask_0: 0.02375  loss_dice_0: 0.195  loss_ce_1: 0.0081  loss_mask_1: 0.02796  loss_dice_1: 0.162  loss_ce_2: 0.003914  loss_mask_2: 0.02818  loss_dice_2: 0.1527  loss_ce_3: 0.004422  loss_mask_3: 0.02681  loss_dice_3: 0.1512  loss_ce_4: 0.009402  loss_mask_4: 0.02674  loss_dice_4: 0.1571  loss_ce_5: 0.02317  loss_mask_5: 0.02802  loss_dice_5: 0.1591  loss_ce_6: 0.01291  loss_mask_6: 0.02956  loss_dice_6: 0.1582  loss_ce_7: 0.02445  loss_mask_7: 0.02899  loss_dice_7: 0.1598  loss_ce_8: 0.01773  loss_mask_8: 0.02991  loss_dice_8: 0.1584  loss_mgm_entropy: 0.004752    time: 0.4294  last_time: 0.4295  data_time: 0.0030  last_data_time: 0.0028   lr: 0.0002  max_mem: 15320M
[08/30 16:06:16] d2.utils.events INFO:  eta: 0:47:10  iter: 1399  total_loss: 2.293  loss_ce: 0.01388  loss_mask: 0.02951  loss_dice: 0.1643  loss_ce_0: 0.1219  loss_mask_0: 0.02536  loss_dice_0: 0.2075  loss_ce_1: 0.009105  loss_mask_1: 0.02835  loss_dice_1: 0.1691  loss_ce_2: 0.002441  loss_mask_2: 0.02857  loss_dice_2: 0.1608  loss_ce_3: 0.002405  loss_mask_3: 0.02816  loss_dice_3: 0.1613  loss_ce_4: 0.008909  loss_mask_4: 0.02894  loss_dice_4: 0.1669  loss_ce_5: 0.0312  loss_mask_5: 0.02905  loss_dice_5: 0.1663  loss_ce_6: 0.02316  loss_mask_6: 0.02939  loss_dice_6: 0.1648  loss_ce_7: 0.03486  loss_mask_7: 0.02895  loss_dice_7: 0.1754  loss_ce_8: 0.01711  loss_mask_8: 0.02952  loss_dice_8: 0.1696  loss_mgm_entropy: 0.004852    time: 0.4294  last_time: 0.4274  data_time: 0.0030  last_data_time: 0.0038   lr: 0.0002  max_mem: 15320M
[08/30 16:06:25] d2.utils.events INFO:  eta: 0:47:01  iter: 1419  total_loss: 2.639  loss_ce: 0.01195  loss_mask: 0.02978  loss_dice: 0.1784  loss_ce_0: 0.1275  loss_mask_0: 0.02724  loss_dice_0: 0.2303  loss_ce_1: 0.05477  loss_mask_1: 0.02965  loss_dice_1: 0.1725  loss_ce_2: 0.02102  loss_mask_2: 0.02941  loss_dice_2: 0.1728  loss_ce_3: 0.02335  loss_mask_3: 0.02858  loss_dice_3: 0.1703  loss_ce_4: 0.03259  loss_mask_4: 0.02982  loss_dice_4: 0.1729  loss_ce_5: 0.02659  loss_mask_5: 0.03134  loss_dice_5: 0.1784  loss_ce_6: 0.01987  loss_mask_6: 0.03014  loss_dice_6: 0.1767  loss_ce_7: 0.0327  loss_mask_7: 0.02897  loss_dice_7: 0.1764  loss_ce_8: 0.02398  loss_mask_8: 0.03131  loss_dice_8: 0.1797  loss_mgm_entropy: 0.004817    time: 0.4294  last_time: 0.4277  data_time: 0.0031  last_data_time: 0.0038   lr: 0.0002  max_mem: 15320M
[08/30 16:06:34] d2.utils.events INFO:  eta: 0:46:53  iter: 1439  total_loss: 2.47  loss_ce: 0.009729  loss_mask: 0.02815  loss_dice: 0.1619  loss_ce_0: 0.1254  loss_mask_0: 0.02842  loss_dice_0: 0.2096  loss_ce_1: 0.0791  loss_mask_1: 0.02841  loss_dice_1: 0.1651  loss_ce_2: 0.0366  loss_mask_2: 0.02859  loss_dice_2: 0.154  loss_ce_3: 0.03282  loss_mask_3: 0.02785  loss_dice_3: 0.1561  loss_ce_4: 0.03595  loss_mask_4: 0.02778  loss_dice_4: 0.1694  loss_ce_5: 0.02857  loss_mask_5: 0.02663  loss_dice_5: 0.1656  loss_ce_6: 0.01316  loss_mask_6: 0.02705  loss_dice_6: 0.1633  loss_ce_7: 0.02137  loss_mask_7: 0.02946  loss_dice_7: 0.1607  loss_ce_8: 0.01311  loss_mask_8: 0.02675  loss_dice_8: 0.1623  loss_mgm_entropy: 0.004804    time: 0.4294  last_time: 0.4284  data_time: 0.0031  last_data_time: 0.0034   lr: 0.0002  max_mem: 15320M
[08/30 16:06:42] d2.utils.events INFO:  eta: 0:46:44  iter: 1459  total_loss: 2.344  loss_ce: 0.01606  loss_mask: 0.02941  loss_dice: 0.1506  loss_ce_0: 0.1249  loss_mask_0: 0.02617  loss_dice_0: 0.2133  loss_ce_1: 0.04172  loss_mask_1: 0.02906  loss_dice_1: 0.16  loss_ce_2: 0.008235  loss_mask_2: 0.02849  loss_dice_2: 0.1445  loss_ce_3: 0.01385  loss_mask_3: 0.02918  loss_dice_3: 0.152  loss_ce_4: 0.02866  loss_mask_4: 0.02772  loss_dice_4: 0.1516  loss_ce_5: 0.02037  loss_mask_5: 0.02942  loss_dice_5: 0.1572  loss_ce_6: 0.0174  loss_mask_6: 0.02823  loss_dice_6: 0.1559  loss_ce_7: 0.03896  loss_mask_7: 0.02881  loss_dice_7: 0.1583  loss_ce_8: 0.01885  loss_mask_8: 0.02925  loss_dice_8: 0.163  loss_mgm_entropy: 0.004741    time: 0.4294  last_time: 0.4289  data_time: 0.0031  last_data_time: 0.0029   lr: 0.0002  max_mem: 15320M
[08/30 16:06:51] d2.utils.events INFO:  eta: 0:46:36  iter: 1479  total_loss: 1.931  loss_ce: 0.006961  loss_mask: 0.0267  loss_dice: 0.1386  loss_ce_0: 0.1179  loss_mask_0: 0.0226  loss_dice_0: 0.1729  loss_ce_1: 0.02743  loss_mask_1: 0.0258  loss_dice_1: 0.1498  loss_ce_2: 0.008538  loss_mask_2: 0.02617  loss_dice_2: 0.1473  loss_ce_3: 0.01211  loss_mask_3: 0.02603  loss_dice_3: 0.1388  loss_ce_4: 0.01552  loss_mask_4: 0.02532  loss_dice_4: 0.1409  loss_ce_5: 0.01462  loss_mask_5: 0.0248  loss_dice_5: 0.1454  loss_ce_6: 0.01011  loss_mask_6: 0.02625  loss_dice_6: 0.1464  loss_ce_7: 0.01767  loss_mask_7: 0.02646  loss_dice_7: 0.1438  loss_ce_8: 0.006837  loss_mask_8: 0.02553  loss_dice_8: 0.144  loss_mgm_entropy: 0.004761    time: 0.4294  last_time: 0.4289  data_time: 0.0031  last_data_time: 0.0030   lr: 0.0002  max_mem: 15320M
[08/30 16:07:00] d2.utils.events INFO:  eta: 0:46:27  iter: 1499  total_loss: 1.987  loss_ce: 0.005148  loss_mask: 0.0237  loss_dice: 0.1468  loss_ce_0: 0.1233  loss_mask_0: 0.02089  loss_dice_0: 0.1767  loss_ce_1: 0.009805  loss_mask_1: 0.02332  loss_dice_1: 0.1434  loss_ce_2: 0.004316  loss_mask_2: 0.02459  loss_dice_2: 0.1483  loss_ce_3: 0.008446  loss_mask_3: 0.02482  loss_dice_3: 0.1458  loss_ce_4: 0.01948  loss_mask_4: 0.02324  loss_dice_4: 0.1501  loss_ce_5: 0.0163  loss_mask_5: 0.02393  loss_dice_5: 0.1477  loss_ce_6: 0.01017  loss_mask_6: 0.02407  loss_dice_6: 0.1509  loss_ce_7: 0.009683  loss_mask_7: 0.02364  loss_dice_7: 0.1512  loss_ce_8: 0.005006  loss_mask_8: 0.02437  loss_dice_8: 0.1443  loss_mgm_entropy: 0.004839    time: 0.4295  last_time: 0.4347  data_time: 0.0031  last_data_time: 0.0030   lr: 0.0002  max_mem: 15320M
[08/30 16:07:08] d2.utils.events INFO:  eta: 0:46:19  iter: 1519  total_loss: 2.337  loss_ce: 0.007339  loss_mask: 0.02828  loss_dice: 0.1627  loss_ce_0: 0.1192  loss_mask_0: 0.02797  loss_dice_0: 0.2076  loss_ce_1: 0.01224  loss_mask_1: 0.02855  loss_dice_1: 0.1714  loss_ce_2: 0.008136  loss_mask_2: 0.02737  loss_dice_2: 0.1675  loss_ce_3: 0.01251  loss_mask_3: 0.02665  loss_dice_3: 0.1628  loss_ce_4: 0.02469  loss_mask_4: 0.02726  loss_dice_4: 0.167  loss_ce_5: 0.02168  loss_mask_5: 0.02705  loss_dice_5: 0.1758  loss_ce_6: 0.01228  loss_mask_6: 0.02645  loss_dice_6: 0.167  loss_ce_7: 0.0244  loss_mask_7: 0.03106  loss_dice_7: 0.1751  loss_ce_8: 0.008592  loss_mask_8: 0.03024  loss_dice_8: 0.1763  loss_mgm_entropy: 0.004851    time: 0.4295  last_time: 0.4288  data_time: 0.0030  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 16:07:17] d2.utils.events INFO:  eta: 0:46:10  iter: 1539  total_loss: 2.196  loss_ce: 0.003358  loss_mask: 0.02894  loss_dice: 0.152  loss_ce_0: 0.1141  loss_mask_0: 0.0283  loss_dice_0: 0.1901  loss_ce_1: 0.0108  loss_mask_1: 0.0305  loss_dice_1: 0.1574  loss_ce_2: 0.002697  loss_mask_2: 0.02765  loss_dice_2: 0.1512  loss_ce_3: 0.004226  loss_mask_3: 0.02798  loss_dice_3: 0.1541  loss_ce_4: 0.01606  loss_mask_4: 0.02929  loss_dice_4: 0.1666  loss_ce_5: 0.01671  loss_mask_5: 0.03056  loss_dice_5: 0.1695  loss_ce_6: 0.01078  loss_mask_6: 0.02793  loss_dice_6: 0.1622  loss_ce_7: 0.01837  loss_mask_7: 0.0288  loss_dice_7: 0.1633  loss_ce_8: 0.007503  loss_mask_8: 0.03105  loss_dice_8: 0.1677  loss_mgm_entropy: 0.004798    time: 0.4295  last_time: 0.4298  data_time: 0.0032  last_data_time: 0.0036   lr: 0.0002  max_mem: 15320M
[08/30 16:07:25] d2.utils.events INFO:  eta: 0:46:02  iter: 1559  total_loss: 2.26  loss_ce: 0.003066  loss_mask: 0.02599  loss_dice: 0.1573  loss_ce_0: 0.1191  loss_mask_0: 0.02444  loss_dice_0: 0.2018  loss_ce_1: 0.01206  loss_mask_1: 0.02628  loss_dice_1: 0.1582  loss_ce_2: 0.00367  loss_mask_2: 0.02665  loss_dice_2: 0.1475  loss_ce_3: 0.01273  loss_mask_3: 0.02494  loss_dice_3: 0.1486  loss_ce_4: 0.03802  loss_mask_4: 0.02617  loss_dice_4: 0.1571  loss_ce_5: 0.006635  loss_mask_5: 0.02763  loss_dice_5: 0.1595  loss_ce_6: 0.006872  loss_mask_6: 0.0269  loss_dice_6: 0.1574  loss_ce_7: 0.01532  loss_mask_7: 0.02801  loss_dice_7: 0.1564  loss_ce_8: 0.016  loss_mask_8: 0.02638  loss_dice_8: 0.1534  loss_mgm_entropy: 0.004683    time: 0.4295  last_time: 0.4285  data_time: 0.0030  last_data_time: 0.0030   lr: 0.0002  max_mem: 15320M
[08/30 16:07:34] d2.utils.events INFO:  eta: 0:45:53  iter: 1579  total_loss: 2.107  loss_ce: 0.003757  loss_mask: 0.02615  loss_dice: 0.1507  loss_ce_0: 0.1173  loss_mask_0: 0.02214  loss_dice_0: 0.184  loss_ce_1: 0.00767  loss_mask_1: 0.02761  loss_dice_1: 0.1572  loss_ce_2: 0.002799  loss_mask_2: 0.02638  loss_dice_2: 0.1522  loss_ce_3: 0.005719  loss_mask_3: 0.02561  loss_dice_3: 0.1433  loss_ce_4: 0.02277  loss_mask_4: 0.02546  loss_dice_4: 0.1486  loss_ce_5: 0.01085  loss_mask_5: 0.0267  loss_dice_5: 0.1588  loss_ce_6: 0.005301  loss_mask_6: 0.0258  loss_dice_6: 0.1564  loss_ce_7: 0.01984  loss_mask_7: 0.02599  loss_dice_7: 0.1608  loss_ce_8: 0.006974  loss_mask_8: 0.02549  loss_dice_8: 0.1523  loss_mgm_entropy: 0.004749    time: 0.4295  last_time: 0.4291  data_time: 0.0031  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 16:07:43] d2.utils.events INFO:  eta: 0:45:45  iter: 1599  total_loss: 1.79  loss_ce: 0.005192  loss_mask: 0.02266  loss_dice: 0.1334  loss_ce_0: 0.1176  loss_mask_0: 0.02081  loss_dice_0: 0.1616  loss_ce_1: 0.003241  loss_mask_1: 0.02329  loss_dice_1: 0.1346  loss_ce_2: 0.002262  loss_mask_2: 0.02238  loss_dice_2: 0.1297  loss_ce_3: 0.00337  loss_mask_3: 0.0235  loss_dice_3: 0.1283  loss_ce_4: 0.01602  loss_mask_4: 0.02254  loss_dice_4: 0.1348  loss_ce_5: 0.00494  loss_mask_5: 0.02253  loss_dice_5: 0.1336  loss_ce_6: 0.004056  loss_mask_6: 0.02255  loss_dice_6: 0.1305  loss_ce_7: 0.008668  loss_mask_7: 0.02276  loss_dice_7: 0.1329  loss_ce_8: 0.004594  loss_mask_8: 0.0224  loss_dice_8: 0.131  loss_mgm_entropy: 0.00475    time: 0.4296  last_time: 0.4385  data_time: 0.0031  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 16:07:51] d2.utils.events INFO:  eta: 0:45:36  iter: 1619  total_loss: 1.866  loss_ce: 0.002758  loss_mask: 0.02353  loss_dice: 0.1369  loss_ce_0: 0.116  loss_mask_0: 0.02057  loss_dice_0: 0.1682  loss_ce_1: 0.007998  loss_mask_1: 0.02345  loss_dice_1: 0.1395  loss_ce_2: 0.001707  loss_mask_2: 0.02381  loss_dice_2: 0.1359  loss_ce_3: 0.001785  loss_mask_3: 0.0231  loss_dice_3: 0.1301  loss_ce_4: 0.01053  loss_mask_4: 0.02304  loss_dice_4: 0.1376  loss_ce_5: 0.003868  loss_mask_5: 0.02309  loss_dice_5: 0.1387  loss_ce_6: 0.003298  loss_mask_6: 0.02325  loss_dice_6: 0.1356  loss_ce_7: 0.00914  loss_mask_7: 0.02333  loss_dice_7: 0.1361  loss_ce_8: 0.003115  loss_mask_8: 0.02292  loss_dice_8: 0.137  loss_mgm_entropy: 0.004771    time: 0.4296  last_time: 0.4338  data_time: 0.0031  last_data_time: 0.0027   lr: 0.0002  max_mem: 15320M
[08/30 16:08:00] d2.utils.events INFO:  eta: 0:45:28  iter: 1639  total_loss: 1.92  loss_ce: 0.001333  loss_mask: 0.02366  loss_dice: 0.1477  loss_ce_0: 0.1155  loss_mask_0: 0.01963  loss_dice_0: 0.1723  loss_ce_1: 0.004043  loss_mask_1: 0.02519  loss_dice_1: 0.1568  loss_ce_2: 0.001573  loss_mask_2: 0.02369  loss_dice_2: 0.1459  loss_ce_3: 0.001787  loss_mask_3: 0.02463  loss_dice_3: 0.1361  loss_ce_4: 0.004098  loss_mask_4: 0.02436  loss_dice_4: 0.153  loss_ce_5: 0.002397  loss_mask_5: 0.02253  loss_dice_5: 0.1441  loss_ce_6: 0.002749  loss_mask_6: 0.02412  loss_dice_6: 0.1516  loss_ce_7: 0.004249  loss_mask_7: 0.02454  loss_dice_7: 0.1549  loss_ce_8: 0.003916  loss_mask_8: 0.02497  loss_dice_8: 0.1549  loss_mgm_entropy: 0.00477    time: 0.4296  last_time: 0.4341  data_time: 0.0031  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 16:08:09] d2.utils.events INFO:  eta: 0:45:19  iter: 1659  total_loss: 2.026  loss_ce: 0.001641  loss_mask: 0.02632  loss_dice: 0.1466  loss_ce_0: 0.1148  loss_mask_0: 0.02531  loss_dice_0: 0.1762  loss_ce_1: 0.00384  loss_mask_1: 0.0266  loss_dice_1: 0.1418  loss_ce_2: 0.001223  loss_mask_2: 0.02551  loss_dice_2: 0.1368  loss_ce_3: 0.003233  loss_mask_3: 0.02681  loss_dice_3: 0.1414  loss_ce_4: 0.009698  loss_mask_4: 0.02719  loss_dice_4: 0.1419  loss_ce_5: 0.008275  loss_mask_5: 0.02665  loss_dice_5: 0.1438  loss_ce_6: 0.009918  loss_mask_6: 0.02676  loss_dice_6: 0.1458  loss_ce_7: 0.01593  loss_mask_7: 0.02723  loss_dice_7: 0.1506  loss_ce_8: 0.004009  loss_mask_8: 0.02554  loss_dice_8: 0.1524  loss_mgm_entropy: 0.004676    time: 0.4296  last_time: 0.4304  data_time: 0.0030  last_data_time: 0.0025   lr: 0.0002  max_mem: 15320M
[08/30 16:08:17] d2.utils.events INFO:  eta: 0:45:11  iter: 1679  total_loss: 1.908  loss_ce: 0.002472  loss_mask: 0.02532  loss_dice: 0.1431  loss_ce_0: 0.1144  loss_mask_0: 0.02155  loss_dice_0: 0.1686  loss_ce_1: 0.008812  loss_mask_1: 0.02453  loss_dice_1: 0.1463  loss_ce_2: 0.002933  loss_mask_2: 0.02468  loss_dice_2: 0.1396  loss_ce_3: 0.003212  loss_mask_3: 0.02425  loss_dice_3: 0.1395  loss_ce_4: 0.007154  loss_mask_4: 0.02379  loss_dice_4: 0.1415  loss_ce_5: 0.006668  loss_mask_5: 0.02497  loss_dice_5: 0.1441  loss_ce_6: 0.006847  loss_mask_6: 0.02498  loss_dice_6: 0.1494  loss_ce_7: 0.00668  loss_mask_7: 0.025  loss_dice_7: 0.1432  loss_ce_8: 0.01079  loss_mask_8: 0.0259  loss_dice_8: 0.1378  loss_mgm_entropy: 0.004766    time: 0.4296  last_time: 0.4307  data_time: 0.0031  last_data_time: 0.0033   lr: 0.0002  max_mem: 15320M
[08/30 16:08:26] d2.utils.events INFO:  eta: 0:45:02  iter: 1699  total_loss: 1.706  loss_ce: 0.00232  loss_mask: 0.02365  loss_dice: 0.1267  loss_ce_0: 0.1149  loss_mask_0: 0.02042  loss_dice_0: 0.163  loss_ce_1: 0.002281  loss_mask_1: 0.02289  loss_dice_1: 0.1313  loss_ce_2: 0.0006279  loss_mask_2: 0.02323  loss_dice_2: 0.1234  loss_ce_3: 0.0009122  loss_mask_3: 0.02139  loss_dice_3: 0.1274  loss_ce_4: 0.002444  loss_mask_4: 0.02387  loss_dice_4: 0.128  loss_ce_5: 0.002949  loss_mask_5: 0.0218  loss_dice_5: 0.1327  loss_ce_6: 0.002915  loss_mask_6: 0.02296  loss_dice_6: 0.1325  loss_ce_7: 0.004092  loss_mask_7: 0.02388  loss_dice_7: 0.1284  loss_ce_8: 0.002831  loss_mask_8: 0.02404  loss_dice_8: 0.1309  loss_mgm_entropy: 0.004693    time: 0.4296  last_time: 0.4289  data_time: 0.0031  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 16:08:34] d2.utils.events INFO:  eta: 0:44:54  iter: 1719  total_loss: 1.805  loss_ce: 0.000973  loss_mask: 0.02131  loss_dice: 0.1318  loss_ce_0: 0.1084  loss_mask_0: 0.01918  loss_dice_0: 0.1619  loss_ce_1: 0.003524  loss_mask_1: 0.02103  loss_dice_1: 0.1356  loss_ce_2: 0.0008583  loss_mask_2: 0.0208  loss_dice_2: 0.1341  loss_ce_3: 0.002281  loss_mask_3: 0.02171  loss_dice_3: 0.135  loss_ce_4: 0.006741  loss_mask_4: 0.02051  loss_dice_4: 0.1398  loss_ce_5: 0.003934  loss_mask_5: 0.02182  loss_dice_5: 0.1417  loss_ce_6: 0.003235  loss_mask_6: 0.02136  loss_dice_6: 0.136  loss_ce_7: 0.007809  loss_mask_7: 0.02062  loss_dice_7: 0.1355  loss_ce_8: 0.003672  loss_mask_8: 0.02146  loss_dice_8: 0.134  loss_mgm_entropy: 0.004755    time: 0.4296  last_time: 0.4295  data_time: 0.0031  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:08:43] d2.utils.events INFO:  eta: 0:44:45  iter: 1739  total_loss: 1.817  loss_ce: 0.001297  loss_mask: 0.02378  loss_dice: 0.1318  loss_ce_0: 0.1078  loss_mask_0: 0.02211  loss_dice_0: 0.1669  loss_ce_1: 0.00268  loss_mask_1: 0.02388  loss_dice_1: 0.139  loss_ce_2: 0.0006448  loss_mask_2: 0.0236  loss_dice_2: 0.1333  loss_ce_3: 0.001222  loss_mask_3: 0.02251  loss_dice_3: 0.1273  loss_ce_4: 0.004281  loss_mask_4: 0.02255  loss_dice_4: 0.1358  loss_ce_5: 0.002173  loss_mask_5: 0.02383  loss_dice_5: 0.1363  loss_ce_6: 0.001458  loss_mask_6: 0.02263  loss_dice_6: 0.138  loss_ce_7: 0.003886  loss_mask_7: 0.02437  loss_dice_7: 0.1351  loss_ce_8: 0.002894  loss_mask_8: 0.02436  loss_dice_8: 0.135  loss_mgm_entropy: 0.004746    time: 0.4296  last_time: 0.4279  data_time: 0.0032  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 16:08:52] d2.utils.events INFO:  eta: 0:44:37  iter: 1759  total_loss: 1.831  loss_ce: 0.0009909  loss_mask: 0.02388  loss_dice: 0.135  loss_ce_0: 0.1103  loss_mask_0: 0.02516  loss_dice_0: 0.1732  loss_ce_1: 0.00318  loss_mask_1: 0.02496  loss_dice_1: 0.137  loss_ce_2: 0.0009423  loss_mask_2: 0.02263  loss_dice_2: 0.1327  loss_ce_3: 0.002441  loss_mask_3: 0.02446  loss_dice_3: 0.1314  loss_ce_4: 0.003939  loss_mask_4: 0.02344  loss_dice_4: 0.1374  loss_ce_5: 0.002567  loss_mask_5: 0.02488  loss_dice_5: 0.139  loss_ce_6: 0.002984  loss_mask_6: 0.02369  loss_dice_6: 0.1352  loss_ce_7: 0.005986  loss_mask_7: 0.0255  loss_dice_7: 0.1402  loss_ce_8: 0.002523  loss_mask_8: 0.02581  loss_dice_8: 0.1395  loss_mgm_entropy: 0.004643    time: 0.4296  last_time: 0.4284  data_time: 0.0031  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 16:09:00] d2.utils.events INFO:  eta: 0:44:28  iter: 1779  total_loss: 1.745  loss_ce: 0.0006253  loss_mask: 0.0224  loss_dice: 0.1306  loss_ce_0: 0.1024  loss_mask_0: 0.01967  loss_dice_0: 0.153  loss_ce_1: 0.003004  loss_mask_1: 0.02158  loss_dice_1: 0.1301  loss_ce_2: 0.0009452  loss_mask_2: 0.02223  loss_dice_2: 0.129  loss_ce_3: 0.001774  loss_mask_3: 0.02232  loss_dice_3: 0.1303  loss_ce_4: 0.004135  loss_mask_4: 0.02045  loss_dice_4: 0.1255  loss_ce_5: 0.001845  loss_mask_5: 0.0213  loss_dice_5: 0.13  loss_ce_6: 0.001226  loss_mask_6: 0.0219  loss_dice_6: 0.1309  loss_ce_7: 0.002705  loss_mask_7: 0.02207  loss_dice_7: 0.1349  loss_ce_8: 0.002109  loss_mask_8: 0.02094  loss_dice_8: 0.1273  loss_mgm_entropy: 0.004626    time: 0.4296  last_time: 0.4303  data_time: 0.0031  last_data_time: 0.0034   lr: 0.0002  max_mem: 15320M
[08/30 16:09:09] d2.utils.events INFO:  eta: 0:44:20  iter: 1799  total_loss: 1.698  loss_ce: 0.0007802  loss_mask: 0.02141  loss_dice: 0.1287  loss_ce_0: 0.1014  loss_mask_0: 0.01878  loss_dice_0: 0.1703  loss_ce_1: 0.002365  loss_mask_1: 0.02146  loss_dice_1: 0.1325  loss_ce_2: 0.0005448  loss_mask_2: 0.02117  loss_dice_2: 0.1331  loss_ce_3: 0.0007374  loss_mask_3: 0.02044  loss_dice_3: 0.1288  loss_ce_4: 0.002906  loss_mask_4: 0.02047  loss_dice_4: 0.1272  loss_ce_5: 0.002099  loss_mask_5: 0.02183  loss_dice_5: 0.137  loss_ce_6: 0.001448  loss_mask_6: 0.02255  loss_dice_6: 0.1362  loss_ce_7: 0.002372  loss_mask_7: 0.02201  loss_dice_7: 0.1322  loss_ce_8: 0.001563  loss_mask_8: 0.02166  loss_dice_8: 0.136  loss_mgm_entropy: 0.00469    time: 0.4296  last_time: 0.4277  data_time: 0.0030  last_data_time: 0.0026   lr: 0.0002  max_mem: 15320M
[08/30 16:09:18] d2.utils.events INFO:  eta: 0:44:11  iter: 1819  total_loss: 1.796  loss_ce: 0.0009747  loss_mask: 0.02431  loss_dice: 0.1358  loss_ce_0: 0.1043  loss_mask_0: 0.02257  loss_dice_0: 0.1627  loss_ce_1: 0.002721  loss_mask_1: 0.02374  loss_dice_1: 0.1372  loss_ce_2: 0.00056  loss_mask_2: 0.02494  loss_dice_2: 0.133  loss_ce_3: 0.000705  loss_mask_3: 0.02502  loss_dice_3: 0.1363  loss_ce_4: 0.002459  loss_mask_4: 0.02521  loss_dice_4: 0.14  loss_ce_5: 0.002266  loss_mask_5: 0.02424  loss_dice_5: 0.1443  loss_ce_6: 0.0009348  loss_mask_6: 0.02528  loss_dice_6: 0.1363  loss_ce_7: 0.002359  loss_mask_7: 0.02485  loss_dice_7: 0.139  loss_ce_8: 0.00136  loss_mask_8: 0.02444  loss_dice_8: 0.1414  loss_mgm_entropy: 0.004637    time: 0.4297  last_time: 0.4294  data_time: 0.0031  last_data_time: 0.0034   lr: 0.0002  max_mem: 15320M
[08/30 16:09:26] d2.utils.events INFO:  eta: 0:44:03  iter: 1839  total_loss: 1.934  loss_ce: 0.0009259  loss_mask: 0.02173  loss_dice: 0.1353  loss_ce_0: 0.1065  loss_mask_0: 0.02009  loss_dice_0: 0.1611  loss_ce_1: 0.001922  loss_mask_1: 0.02241  loss_dice_1: 0.1465  loss_ce_2: 0.0004922  loss_mask_2: 0.02271  loss_dice_2: 0.1442  loss_ce_3: 0.0008926  loss_mask_3: 0.02177  loss_dice_3: 0.1348  loss_ce_4: 0.002969  loss_mask_4: 0.02259  loss_dice_4: 0.1397  loss_ce_5: 0.002171  loss_mask_5: 0.02304  loss_dice_5: 0.1392  loss_ce_6: 0.001316  loss_mask_6: 0.02275  loss_dice_6: 0.1376  loss_ce_7: 0.006184  loss_mask_7: 0.02246  loss_dice_7: 0.1461  loss_ce_8: 0.002345  loss_mask_8: 0.02263  loss_dice_8: 0.1439  loss_mgm_entropy: 0.004746    time: 0.4297  last_time: 0.4297  data_time: 0.0031  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 16:09:35] d2.utils.events INFO:  eta: 0:43:54  iter: 1859  total_loss: 1.869  loss_ce: 0.005086  loss_mask: 0.02159  loss_dice: 0.1295  loss_ce_0: 0.1027  loss_mask_0: 0.02219  loss_dice_0: 0.1684  loss_ce_1: 0.004376  loss_mask_1: 0.02201  loss_dice_1: 0.1296  loss_ce_2: 0.0009684  loss_mask_2: 0.02277  loss_dice_2: 0.1277  loss_ce_3: 0.001564  loss_mask_3: 0.02216  loss_dice_3: 0.1246  loss_ce_4: 0.003653  loss_mask_4: 0.02096  loss_dice_4: 0.1318  loss_ce_5: 0.002803  loss_mask_5: 0.02041  loss_dice_5: 0.1347  loss_ce_6: 0.00242  loss_mask_6: 0.02231  loss_dice_6: 0.1322  loss_ce_7: 0.004725  loss_mask_7: 0.02155  loss_dice_7: 0.1367  loss_ce_8: 0.005704  loss_mask_8: 0.02211  loss_dice_8: 0.1453  loss_mgm_entropy: 0.004677    time: 0.4297  last_time: 0.4305  data_time: 0.0030  last_data_time: 0.0027   lr: 0.0002  max_mem: 15320M
[08/30 16:09:43] d2.utils.events INFO:  eta: 0:43:46  iter: 1879  total_loss: 1.787  loss_ce: 0.009615  loss_mask: 0.0232  loss_dice: 0.1264  loss_ce_0: 0.1057  loss_mask_0: 0.01936  loss_dice_0: 0.1469  loss_ce_1: 0.002372  loss_mask_1: 0.02109  loss_dice_1: 0.1245  loss_ce_2: 0.0008781  loss_mask_2: 0.02263  loss_dice_2: 0.1234  loss_ce_3: 0.002041  loss_mask_3: 0.02221  loss_dice_3: 0.1218  loss_ce_4: 0.004586  loss_mask_4: 0.02193  loss_dice_4: 0.1228  loss_ce_5: 0.03717  loss_mask_5: 0.0226  loss_dice_5: 0.1325  loss_ce_6: 0.02926  loss_mask_6: 0.0228  loss_dice_6: 0.1267  loss_ce_7: 0.004943  loss_mask_7: 0.02181  loss_dice_7: 0.128  loss_ce_8: 0.001771  loss_mask_8: 0.02193  loss_dice_8: 0.1285  loss_mgm_entropy: 0.004702    time: 0.4297  last_time: 0.4283  data_time: 0.0030  last_data_time: 0.0030   lr: 0.0002  max_mem: 15320M
[08/30 16:09:52] d2.utils.events INFO:  eta: 0:43:37  iter: 1899  total_loss: 2.019  loss_ce: 0.001822  loss_mask: 0.02262  loss_dice: 0.135  loss_ce_0: 0.1068  loss_mask_0: 0.02117  loss_dice_0: 0.1624  loss_ce_1: 0.002534  loss_mask_1: 0.02198  loss_dice_1: 0.1379  loss_ce_2: 0.000999  loss_mask_2: 0.02237  loss_dice_2: 0.1314  loss_ce_3: 0.007682  loss_mask_3: 0.02272  loss_dice_3: 0.1321  loss_ce_4: 0.01846  loss_mask_4: 0.02284  loss_dice_4: 0.1438  loss_ce_5: 0.06358  loss_mask_5: 0.0233  loss_dice_5: 0.1592  loss_ce_6: 0.0763  loss_mask_6: 0.02411  loss_dice_6: 0.1424  loss_ce_7: 0.01487  loss_mask_7: 0.02323  loss_dice_7: 0.136  loss_ce_8: 0.005388  loss_mask_8: 0.02288  loss_dice_8: 0.1343  loss_mgm_entropy: 0.004722    time: 0.4298  last_time: 0.4317  data_time: 0.0031  last_data_time: 0.0034   lr: 0.0002  max_mem: 15320M
[08/30 16:10:01] d2.utils.events INFO:  eta: 0:43:29  iter: 1919  total_loss: 1.915  loss_ce: 0.005649  loss_mask: 0.02393  loss_dice: 0.1355  loss_ce_0: 0.1033  loss_mask_0: 0.02154  loss_dice_0: 0.1551  loss_ce_1: 0.001904  loss_mask_1: 0.02395  loss_dice_1: 0.1324  loss_ce_2: 0.001225  loss_mask_2: 0.02345  loss_dice_2: 0.1297  loss_ce_3: 0.002624  loss_mask_3: 0.0237  loss_dice_3: 0.1308  loss_ce_4: 0.01523  loss_mask_4: 0.02438  loss_dice_4: 0.1384  loss_ce_5: 0.03194  loss_mask_5: 0.02536  loss_dice_5: 0.1455  loss_ce_6: 0.01514  loss_mask_6: 0.02405  loss_dice_6: 0.1371  loss_ce_7: 0.01936  loss_mask_7: 0.02558  loss_dice_7: 0.1355  loss_ce_8: 0.00151  loss_mask_8: 0.02454  loss_dice_8: 0.1314  loss_mgm_entropy: 0.004598    time: 0.4298  last_time: 0.4290  data_time: 0.0031  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:10:09] d2.utils.events INFO:  eta: 0:43:20  iter: 1939  total_loss: 1.721  loss_ce: 0.003823  loss_mask: 0.02064  loss_dice: 0.1193  loss_ce_0: 0.1034  loss_mask_0: 0.01748  loss_dice_0: 0.1452  loss_ce_1: 0.00287  loss_mask_1: 0.02001  loss_dice_1: 0.1177  loss_ce_2: 0.0004859  loss_mask_2: 0.02037  loss_dice_2: 0.119  loss_ce_3: 0.001074  loss_mask_3: 0.02054  loss_dice_3: 0.1158  loss_ce_4: 0.004546  loss_mask_4: 0.02176  loss_dice_4: 0.127  loss_ce_5: 0.01775  loss_mask_5: 0.02126  loss_dice_5: 0.1239  loss_ce_6: 0.02377  loss_mask_6: 0.02099  loss_dice_6: 0.1266  loss_ce_7: 0.0256  loss_mask_7: 0.01922  loss_dice_7: 0.1185  loss_ce_8: 0.01168  loss_mask_8: 0.02035  loss_dice_8: 0.1229  loss_mgm_entropy: 0.004667    time: 0.4298  last_time: 0.4294  data_time: 0.0031  last_data_time: 0.0033   lr: 0.0002  max_mem: 15320M
[08/30 16:10:18] d2.utils.events INFO:  eta: 0:43:12  iter: 1959  total_loss: 1.766  loss_ce: 0.002639  loss_mask: 0.01984  loss_dice: 0.1253  loss_ce_0: 0.1023  loss_mask_0: 0.0168  loss_dice_0: 0.1438  loss_ce_1: 0.002382  loss_mask_1: 0.01928  loss_dice_1: 0.1199  loss_ce_2: 0.0005194  loss_mask_2: 0.02057  loss_dice_2: 0.123  loss_ce_3: 0.0006518  loss_mask_3: 0.01943  loss_dice_3: 0.1222  loss_ce_4: 0.003695  loss_mask_4: 0.02054  loss_dice_4: 0.1283  loss_ce_5: 0.006118  loss_mask_5: 0.02018  loss_dice_5: 0.1297  loss_ce_6: 0.01053  loss_mask_6: 0.02028  loss_dice_6: 0.1294  loss_ce_7: 0.00748  loss_mask_7: 0.01997  loss_dice_7: 0.1282  loss_ce_8: 0.005867  loss_mask_8: 0.01906  loss_dice_8: 0.1239  loss_mgm_entropy: 0.004681    time: 0.4298  last_time: 0.4309  data_time: 0.0032  last_data_time: 0.0038   lr: 0.0002  max_mem: 15320M
[08/30 16:10:27] d2.utils.events INFO:  eta: 0:43:03  iter: 1979  total_loss: 1.874  loss_ce: 0.006259  loss_mask: 0.02385  loss_dice: 0.1343  loss_ce_0: 0.104  loss_mask_0: 0.02091  loss_dice_0: 0.1614  loss_ce_1: 0.001668  loss_mask_1: 0.02222  loss_dice_1: 0.1368  loss_ce_2: 0.0006776  loss_mask_2: 0.02371  loss_dice_2: 0.1345  loss_ce_3: 0.0008181  loss_mask_3: 0.02558  loss_dice_3: 0.1413  loss_ce_4: 0.003434  loss_mask_4: 0.02336  loss_dice_4: 0.1331  loss_ce_5: 0.005482  loss_mask_5: 0.02425  loss_dice_5: 0.1463  loss_ce_6: 0.003174  loss_mask_6: 0.02575  loss_dice_6: 0.1424  loss_ce_7: 0.006333  loss_mask_7: 0.0261  loss_dice_7: 0.1438  loss_ce_8: 0.004803  loss_mask_8: 0.02542  loss_dice_8: 0.1486  loss_mgm_entropy: 0.004631    time: 0.4298  last_time: 0.4341  data_time: 0.0032  last_data_time: 0.0038   lr: 0.0002  max_mem: 15320M
[08/30 16:10:35] d2.utils.events INFO:  eta: 0:42:55  iter: 1999  total_loss: 2.336  loss_ce: 0.03438  loss_mask: 0.02918  loss_dice: 0.1688  loss_ce_0: 0.1004  loss_mask_0: 0.02459  loss_dice_0: 0.1934  loss_ce_1: 0.002009  loss_mask_1: 0.02937  loss_dice_1: 0.1668  loss_ce_2: 0.001804  loss_mask_2: 0.02793  loss_dice_2: 0.1553  loss_ce_3: 0.00384  loss_mask_3: 0.02628  loss_dice_3: 0.1574  loss_ce_4: 0.004029  loss_mask_4: 0.02885  loss_dice_4: 0.1683  loss_ce_5: 0.01157  loss_mask_5: 0.02935  loss_dice_5: 0.1746  loss_ce_6: 0.01275  loss_mask_6: 0.02931  loss_dice_6: 0.1741  loss_ce_7: 0.01835  loss_mask_7: 0.03187  loss_dice_7: 0.1839  loss_ce_8: 0.03482  loss_mask_8: 0.03152  loss_dice_8: 0.174  loss_mgm_entropy: 0.004589    time: 0.4298  last_time: 0.4331  data_time: 0.0031  last_data_time: 0.0033   lr: 0.0002  max_mem: 15320M
[08/30 16:10:44] d2.utils.events INFO:  eta: 0:42:46  iter: 2019  total_loss: 2.547  loss_ce: 0.02935  loss_mask: 0.03182  loss_dice: 0.1724  loss_ce_0: 0.1008  loss_mask_0: 0.02627  loss_dice_0: 0.2067  loss_ce_1: 0.002848  loss_mask_1: 0.03198  loss_dice_1: 0.1744  loss_ce_2: 0.00102  loss_mask_2: 0.03122  loss_dice_2: 0.1617  loss_ce_3: 0.00412  loss_mask_3: 0.03015  loss_dice_3: 0.1658  loss_ce_4: 0.00427  loss_mask_4: 0.03189  loss_dice_4: 0.1822  loss_ce_5: 0.03244  loss_mask_5: 0.03504  loss_dice_5: 0.1961  loss_ce_6: 0.03394  loss_mask_6: 0.03391  loss_dice_6: 0.1855  loss_ce_7: 0.03756  loss_mask_7: 0.03319  loss_dice_7: 0.2263  loss_ce_8: 0.05518  loss_mask_8: 0.03458  loss_dice_8: 0.2071  loss_mgm_entropy: 0.004602    time: 0.4298  last_time: 0.4333  data_time: 0.0031  last_data_time: 0.0033   lr: 0.0002  max_mem: 15320M
[08/30 16:10:52] d2.utils.events INFO:  eta: 0:42:38  iter: 2039  total_loss: 2.195  loss_ce: 0.0089  loss_mask: 0.02771  loss_dice: 0.1517  loss_ce_0: 0.1012  loss_mask_0: 0.02623  loss_dice_0: 0.1728  loss_ce_1: 0.002327  loss_mask_1: 0.02881  loss_dice_1: 0.1598  loss_ce_2: 0.0004346  loss_mask_2: 0.02882  loss_dice_2: 0.1491  loss_ce_3: 0.005453  loss_mask_3: 0.02944  loss_dice_3: 0.1475  loss_ce_4: 0.006267  loss_mask_4: 0.02625  loss_dice_4: 0.1542  loss_ce_5: 0.02551  loss_mask_5: 0.02941  loss_dice_5: 0.167  loss_ce_6: 0.0456  loss_mask_6: 0.03173  loss_dice_6: 0.167  loss_ce_7: 0.02125  loss_mask_7: 0.03303  loss_dice_7: 0.1695  loss_ce_8: 0.02157  loss_mask_8: 0.02955  loss_dice_8: 0.1558  loss_mgm_entropy: 0.004609    time: 0.4298  last_time: 0.4320  data_time: 0.0032  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 16:11:01] d2.utils.events INFO:  eta: 0:42:29  iter: 2059  total_loss: 2.271  loss_ce: 0.006023  loss_mask: 0.02899  loss_dice: 0.1635  loss_ce_0: 0.1088  loss_mask_0: 0.02719  loss_dice_0: 0.1976  loss_ce_1: 0.002868  loss_mask_1: 0.0301  loss_dice_1: 0.1604  loss_ce_2: 0.0006201  loss_mask_2: 0.02759  loss_dice_2: 0.152  loss_ce_3: 0.002675  loss_mask_3: 0.02946  loss_dice_3: 0.1501  loss_ce_4: 0.006083  loss_mask_4: 0.02784  loss_dice_4: 0.1572  loss_ce_5: 0.008062  loss_mask_5: 0.02793  loss_dice_5: 0.1603  loss_ce_6: 0.026  loss_mask_6: 0.02919  loss_dice_6: 0.1542  loss_ce_7: 0.02528  loss_mask_7: 0.03033  loss_dice_7: 0.1733  loss_ce_8: 0.01047  loss_mask_8: 0.03361  loss_dice_8: 0.1763  loss_mgm_entropy: 0.004532    time: 0.4298  last_time: 0.4297  data_time: 0.0032  last_data_time: 0.0040   lr: 0.0002  max_mem: 15320M
[08/30 16:11:10] d2.utils.events INFO:  eta: 0:42:21  iter: 2079  total_loss: 2.586  loss_ce: 0.01515  loss_mask: 0.0345  loss_dice: 0.1818  loss_ce_0: 0.1011  loss_mask_0: 0.02506  loss_dice_0: 0.2003  loss_ce_1: 0.01032  loss_mask_1: 0.03012  loss_dice_1: 0.168  loss_ce_2: 0.008378  loss_mask_2: 0.03064  loss_dice_2: 0.1714  loss_ce_3: 0.01484  loss_mask_3: 0.03383  loss_dice_3: 0.1691  loss_ce_4: 0.02205  loss_mask_4: 0.03268  loss_dice_4: 0.1798  loss_ce_5: 0.02903  loss_mask_5: 0.03343  loss_dice_5: 0.1843  loss_ce_6: 0.01924  loss_mask_6: 0.03461  loss_dice_6: 0.1804  loss_ce_7: 0.03591  loss_mask_7: 0.03377  loss_dice_7: 0.1824  loss_ce_8: 0.02283  loss_mask_8: 0.03608  loss_dice_8: 0.184  loss_mgm_entropy: 0.004627    time: 0.4298  last_time: 0.4292  data_time: 0.0033  last_data_time: 0.0037   lr: 0.0002  max_mem: 15320M
[08/30 16:11:18] d2.utils.events INFO:  eta: 0:42:12  iter: 2099  total_loss: 1.981  loss_ce: 0.009955  loss_mask: 0.02412  loss_dice: 0.1354  loss_ce_0: 0.1008  loss_mask_0: 0.02096  loss_dice_0: 0.1546  loss_ce_1: 0.01615  loss_mask_1: 0.023  loss_dice_1: 0.1384  loss_ce_2: 0.00673  loss_mask_2: 0.02187  loss_dice_2: 0.1339  loss_ce_3: 0.008206  loss_mask_3: 0.02335  loss_dice_3: 0.1283  loss_ce_4: 0.01481  loss_mask_4: 0.02228  loss_dice_4: 0.1377  loss_ce_5: 0.02955  loss_mask_5: 0.02305  loss_dice_5: 0.1373  loss_ce_6: 0.02806  loss_mask_6: 0.02285  loss_dice_6: 0.136  loss_ce_7: 0.02305  loss_mask_7: 0.02627  loss_dice_7: 0.1486  loss_ce_8: 0.008853  loss_mask_8: 0.0242  loss_dice_8: 0.1371  loss_mgm_entropy: 0.004627    time: 0.4298  last_time: 0.4336  data_time: 0.0032  last_data_time: 0.0031   lr: 0.0002  max_mem: 15320M
[08/30 16:11:27] d2.utils.events INFO:  eta: 0:42:04  iter: 2119  total_loss: 1.733  loss_ce: 0.004843  loss_mask: 0.02086  loss_dice: 0.1249  loss_ce_0: 0.1011  loss_mask_0: 0.01765  loss_dice_0: 0.1461  loss_ce_1: 0.008693  loss_mask_1: 0.02104  loss_dice_1: 0.1261  loss_ce_2: 0.002779  loss_mask_2: 0.0207  loss_dice_2: 0.1192  loss_ce_3: 0.006062  loss_mask_3: 0.02113  loss_dice_3: 0.1225  loss_ce_4: 0.008711  loss_mask_4: 0.01987  loss_dice_4: 0.1229  loss_ce_5: 0.008889  loss_mask_5: 0.0207  loss_dice_5: 0.1242  loss_ce_6: 0.01441  loss_mask_6: 0.01999  loss_dice_6: 0.1269  loss_ce_7: 0.01099  loss_mask_7: 0.02201  loss_dice_7: 0.1296  loss_ce_8: 0.004688  loss_mask_8: 0.02014  loss_dice_8: 0.1247  loss_mgm_entropy: 0.004607    time: 0.4298  last_time: 0.4294  data_time: 0.0032  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 16:11:36] d2.utils.events INFO:  eta: 0:41:55  iter: 2139  total_loss: 1.613  loss_ce: 0.001576  loss_mask: 0.02085  loss_dice: 0.1191  loss_ce_0: 0.09649  loss_mask_0: 0.01797  loss_dice_0: 0.1362  loss_ce_1: 0.003196  loss_mask_1: 0.01994  loss_dice_1: 0.1174  loss_ce_2: 0.002501  loss_mask_2: 0.02066  loss_dice_2: 0.1182  loss_ce_3: 0.00401  loss_mask_3: 0.01956  loss_dice_3: 0.1177  loss_ce_4: 0.004168  loss_mask_4: 0.01894  loss_dice_4: 0.1153  loss_ce_5: 0.003786  loss_mask_5: 0.01962  loss_dice_5: 0.1189  loss_ce_6: 0.007845  loss_mask_6: 0.01869  loss_dice_6: 0.1153  loss_ce_7: 0.00407  loss_mask_7: 0.02225  loss_dice_7: 0.1219  loss_ce_8: 0.003322  loss_mask_8: 0.01999  loss_dice_8: 0.121  loss_mgm_entropy: 0.0046    time: 0.4299  last_time: 0.4285  data_time: 0.0031  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:11:44] d2.utils.events INFO:  eta: 0:41:47  iter: 2159  total_loss: 1.406  loss_ce: 0.00136  loss_mask: 0.01893  loss_dice: 0.105  loss_ce_0: 0.09974  loss_mask_0: 0.01721  loss_dice_0: 0.1218  loss_ce_1: 0.0006682  loss_mask_1: 0.01869  loss_dice_1: 0.1052  loss_ce_2: 0.0006775  loss_mask_2: 0.01896  loss_dice_2: 0.1079  loss_ce_3: 0.001064  loss_mask_3: 0.01858  loss_dice_3: 0.1041  loss_ce_4: 0.001031  loss_mask_4: 0.01872  loss_dice_4: 0.1094  loss_ce_5: 0.002516  loss_mask_5: 0.01891  loss_dice_5: 0.1108  loss_ce_6: 0.003603  loss_mask_6: 0.01922  loss_dice_6: 0.1068  loss_ce_7: 0.002324  loss_mask_7: 0.0198  loss_dice_7: 0.1072  loss_ce_8: 0.00205  loss_mask_8: 0.01925  loss_dice_8: 0.1107  loss_mgm_entropy: 0.00458    time: 0.4299  last_time: 0.4300  data_time: 0.0031  last_data_time: 0.0036   lr: 0.0002  max_mem: 15320M
[08/30 16:11:53] d2.utils.events INFO:  eta: 0:41:38  iter: 2179  total_loss: 1.431  loss_ce: 0.001854  loss_mask: 0.02113  loss_dice: 0.1116  loss_ce_0: 0.09925  loss_mask_0: 0.01754  loss_dice_0: 0.1272  loss_ce_1: 0.0008093  loss_mask_1: 0.01928  loss_dice_1: 0.1082  loss_ce_2: 0.000447  loss_mask_2: 0.01988  loss_dice_2: 0.1083  loss_ce_3: 0.001176  loss_mask_3: 0.01935  loss_dice_3: 0.1077  loss_ce_4: 0.002736  loss_mask_4: 0.01937  loss_dice_4: 0.1058  loss_ce_5: 0.003115  loss_mask_5: 0.01996  loss_dice_5: 0.107  loss_ce_6: 0.004048  loss_mask_6: 0.02017  loss_dice_6: 0.1091  loss_ce_7: 0.004567  loss_mask_7: 0.02015  loss_dice_7: 0.1093  loss_ce_8: 0.002116  loss_mask_8: 0.0208  loss_dice_8: 0.1095  loss_mgm_entropy: 0.004533    time: 0.4299  last_time: 0.4289  data_time: 0.0032  last_data_time: 0.0030   lr: 0.0002  max_mem: 15320M
[08/30 16:12:02] d2.utils.events INFO:  eta: 0:41:30  iter: 2199  total_loss: 1.453  loss_ce: 0.003166  loss_mask: 0.0189  loss_dice: 0.108  loss_ce_0: 0.09881  loss_mask_0: 0.0161  loss_dice_0: 0.1291  loss_ce_1: 0.0009515  loss_mask_1: 0.0186  loss_dice_1: 0.1089  loss_ce_2: 0.0007989  loss_mask_2: 0.0183  loss_dice_2: 0.1089  loss_ce_3: 0.0009125  loss_mask_3: 0.01837  loss_dice_3: 0.1098  loss_ce_4: 0.002126  loss_mask_4: 0.01721  loss_dice_4: 0.1129  loss_ce_5: 0.001478  loss_mask_5: 0.01776  loss_dice_5: 0.1058  loss_ce_6: 0.001146  loss_mask_6: 0.01822  loss_dice_6: 0.1117  loss_ce_7: 0.001949  loss_mask_7: 0.01875  loss_dice_7: 0.1095  loss_ce_8: 0.001643  loss_mask_8: 0.01901  loss_dice_8: 0.1061  loss_mgm_entropy: 0.004608    time: 0.4299  last_time: 0.4300  data_time: 0.0031  last_data_time: 0.0029   lr: 0.0002  max_mem: 15320M
[08/30 16:12:10] d2.utils.events INFO:  eta: 0:41:21  iter: 2219  total_loss: 1.494  loss_ce: 0.001043  loss_mask: 0.01713  loss_dice: 0.1135  loss_ce_0: 0.09777  loss_mask_0: 0.01507  loss_dice_0: 0.1306  loss_ce_1: 0.0009337  loss_mask_1: 0.01817  loss_dice_1: 0.1117  loss_ce_2: 0.001254  loss_mask_2: 0.01797  loss_dice_2: 0.1151  loss_ce_3: 0.001475  loss_mask_3: 0.01813  loss_dice_3: 0.111  loss_ce_4: 0.001323  loss_mask_4: 0.01757  loss_dice_4: 0.1136  loss_ce_5: 0.001852  loss_mask_5: 0.01693  loss_dice_5: 0.1084  loss_ce_6: 0.001261  loss_mask_6: 0.01783  loss_dice_6: 0.1129  loss_ce_7: 0.001783  loss_mask_7: 0.0175  loss_dice_7: 0.1105  loss_ce_8: 0.0007709  loss_mask_8: 0.01763  loss_dice_8: 0.1094  loss_mgm_entropy: 0.00458    time: 0.4299  last_time: 0.4368  data_time: 0.0032  last_data_time: 0.0028   lr: 0.0002  max_mem: 15320M
[08/30 16:12:19] d2.utils.events INFO:  eta: 0:41:13  iter: 2239  total_loss: 1.497  loss_ce: 0.000725  loss_mask: 0.0193  loss_dice: 0.1145  loss_ce_0: 0.09305  loss_mask_0: 0.01674  loss_dice_0: 0.1291  loss_ce_1: 0.0006692  loss_mask_1: 0.01937  loss_dice_1: 0.1142  loss_ce_2: 0.0008459  loss_mask_2: 0.01929  loss_dice_2: 0.111  loss_ce_3: 0.0007821  loss_mask_3: 0.01885  loss_dice_3: 0.117  loss_ce_4: 0.0009623  loss_mask_4: 0.01823  loss_dice_4: 0.1143  loss_ce_5: 0.001092  loss_mask_5: 0.01904  loss_dice_5: 0.1162  loss_ce_6: 0.00103  loss_mask_6: 0.01901  loss_dice_6: 0.1141  loss_ce_7: 0.001423  loss_mask_7: 0.01993  loss_dice_7: 0.1154  loss_ce_8: 0.000977  loss_mask_8: 0.0202  loss_dice_8: 0.1168  loss_mgm_entropy: 0.00454    time: 0.4299  last_time: 0.4282  data_time: 0.0031  last_data_time: 0.0029   lr: 0.0002  max_mem: 15320M
[08/30 16:12:28] d2.utils.events INFO:  eta: 0:41:04  iter: 2259  total_loss: 1.472  loss_ce: 0.0009104  loss_mask: 0.01989  loss_dice: 0.1103  loss_ce_0: 0.09641  loss_mask_0: 0.01716  loss_dice_0: 0.1357  loss_ce_1: 0.001227  loss_mask_1: 0.01857  loss_dice_1: 0.1112  loss_ce_2: 0.001416  loss_mask_2: 0.01918  loss_dice_2: 0.1079  loss_ce_3: 0.005075  loss_mask_3: 0.01958  loss_dice_3: 0.1076  loss_ce_4: 0.003079  loss_mask_4: 0.01883  loss_dice_4: 0.1078  loss_ce_5: 0.001686  loss_mask_5: 0.01928  loss_dice_5: 0.1116  loss_ce_6: 0.001093  loss_mask_6: 0.01971  loss_dice_6: 0.1139  loss_ce_7: 0.001776  loss_mask_7: 0.02086  loss_dice_7: 0.1131  loss_ce_8: 0.0008155  loss_mask_8: 0.01949  loss_dice_8: 0.1114  loss_mgm_entropy: 0.00451    time: 0.4299  last_time: 0.4299  data_time: 0.0032  last_data_time: 0.0034   lr: 0.0002  max_mem: 15320M
[08/30 16:12:36] d2.utils.events INFO:  eta: 0:40:56  iter: 2279  total_loss: 1.451  loss_ce: 0.001741  loss_mask: 0.01836  loss_dice: 0.113  loss_ce_0: 0.09702  loss_mask_0: 0.01507  loss_dice_0: 0.1205  loss_ce_1: 0.001044  loss_mask_1: 0.01797  loss_dice_1: 0.1076  loss_ce_2: 0.0004337  loss_mask_2: 0.01737  loss_dice_2: 0.1114  loss_ce_3: 0.001386  loss_mask_3: 0.01795  loss_dice_3: 0.107  loss_ce_4: 0.001076  loss_mask_4: 0.01658  loss_dice_4: 0.1069  loss_ce_5: 0.001747  loss_mask_5: 0.01813  loss_dice_5: 0.115  loss_ce_6: 0.001281  loss_mask_6: 0.0178  loss_dice_6: 0.1089  loss_ce_7: 0.002036  loss_mask_7: 0.01808  loss_dice_7: 0.1116  loss_ce_8: 0.001193  loss_mask_8: 0.01744  loss_dice_8: 0.1106  loss_mgm_entropy: 0.004543    time: 0.4299  last_time: 0.4296  data_time: 0.0031  last_data_time: 0.0033   lr: 0.0002  max_mem: 15320M
[08/30 16:12:45] d2.utils.events INFO:  eta: 0:40:47  iter: 2299  total_loss: 1.484  loss_ce: 0.0006789  loss_mask: 0.01805  loss_dice: 0.1139  loss_ce_0: 0.09436  loss_mask_0: 0.01506  loss_dice_0: 0.1391  loss_ce_1: 0.0009698  loss_mask_1: 0.01738  loss_dice_1: 0.1157  loss_ce_2: 0.0004335  loss_mask_2: 0.01709  loss_dice_2: 0.1171  loss_ce_3: 0.0007049  loss_mask_3: 0.01628  loss_dice_3: 0.1125  loss_ce_4: 0.001423  loss_mask_4: 0.01708  loss_dice_4: 0.1183  loss_ce_5: 0.001037  loss_mask_5: 0.01727  loss_dice_5: 0.1165  loss_ce_6: 0.00187  loss_mask_6: 0.01764  loss_dice_6: 0.1177  loss_ce_7: 0.001353  loss_mask_7: 0.01814  loss_dice_7: 0.1199  loss_ce_8: 0.001157  loss_mask_8: 0.01698  loss_dice_8: 0.1141  loss_mgm_entropy: 0.004587    time: 0.4299  last_time: 0.4294  data_time: 0.0032  last_data_time: 0.0034   lr: 0.0002  max_mem: 15320M
[08/30 16:12:54] d2.utils.events INFO:  eta: 0:40:39  iter: 2319  total_loss: 1.619  loss_ce: 0.0005743  loss_mask: 0.02323  loss_dice: 0.1201  loss_ce_0: 0.09589  loss_mask_0: 0.02069  loss_dice_0: 0.1455  loss_ce_1: 0.0007328  loss_mask_1: 0.02225  loss_dice_1: 0.1203  loss_ce_2: 0.0003448  loss_mask_2: 0.02339  loss_dice_2: 0.1165  loss_ce_3: 0.0006146  loss_mask_3: 0.0219  loss_dice_3: 0.1146  loss_ce_4: 0.0008896  loss_mask_4: 0.02173  loss_dice_4: 0.1194  loss_ce_5: 0.001116  loss_mask_5: 0.0231  loss_dice_5: 0.1257  loss_ce_6: 0.001049  loss_mask_6: 0.02388  loss_dice_6: 0.1265  loss_ce_7: 0.001286  loss_mask_7: 0.02529  loss_dice_7: 0.1279  loss_ce_8: 0.0009796  loss_mask_8: 0.02441  loss_dice_8: 0.1221  loss_mgm_entropy: 0.004481    time: 0.4299  last_time: 0.4340  data_time: 0.0031  last_data_time: 0.0037   lr: 0.0002  max_mem: 15320M
[08/30 16:13:02] d2.utils.events INFO:  eta: 0:40:30  iter: 2339  total_loss: 1.567  loss_ce: 0.0006475  loss_mask: 0.0197  loss_dice: 0.1177  loss_ce_0: 0.09659  loss_mask_0: 0.01764  loss_dice_0: 0.1302  loss_ce_1: 0.0004592  loss_mask_1: 0.02284  loss_dice_1: 0.123  loss_ce_2: 0.000294  loss_mask_2: 0.02174  loss_dice_2: 0.1168  loss_ce_3: 0.0009194  loss_mask_3: 0.02263  loss_dice_3: 0.1185  loss_ce_4: 0.0006359  loss_mask_4: 0.02218  loss_dice_4: 0.1224  loss_ce_5: 0.000763  loss_mask_5: 0.02113  loss_dice_5: 0.1229  loss_ce_6: 0.001251  loss_mask_6: 0.0214  loss_dice_6: 0.1208  loss_ce_7: 0.0009291  loss_mask_7: 0.02208  loss_dice_7: 0.1195  loss_ce_8: 0.001008  loss_mask_8: 0.02301  loss_dice_8: 0.1231  loss_mgm_entropy: 0.004495    time: 0.4299  last_time: 0.4296  data_time: 0.0031  last_data_time: 0.0030   lr: 0.0002  max_mem: 15320M
[08/30 16:13:11] d2.utils.events INFO:  eta: 0:40:22  iter: 2359  total_loss: 1.463  loss_ce: 0.0003885  loss_mask: 0.01891  loss_dice: 0.1133  loss_ce_0: 0.09481  loss_mask_0: 0.01601  loss_dice_0: 0.1272  loss_ce_1: 0.000529  loss_mask_1: 0.01853  loss_dice_1: 0.1132  loss_ce_2: 0.0003092  loss_mask_2: 0.01806  loss_dice_2: 0.1101  loss_ce_3: 0.00059  loss_mask_3: 0.01846  loss_dice_3: 0.1093  loss_ce_4: 0.0004855  loss_mask_4: 0.01772  loss_dice_4: 0.1116  loss_ce_5: 0.0006567  loss_mask_5: 0.01799  loss_dice_5: 0.1096  loss_ce_6: 0.0008823  loss_mask_6: 0.01858  loss_dice_6: 0.1119  loss_ce_7: 0.001388  loss_mask_7: 0.01817  loss_dice_7: 0.1169  loss_ce_8: 0.001004  loss_mask_8: 0.01825  loss_dice_8: 0.1155  loss_mgm_entropy: 0.004558    time: 0.4299  last_time: 0.4414  data_time: 0.0032  last_data_time: 0.0039   lr: 0.0002  max_mem: 15320M
[08/30 16:13:19] d2.utils.events INFO:  eta: 0:40:13  iter: 2379  total_loss: 1.447  loss_ce: 0.0003108  loss_mask: 0.01802  loss_dice: 0.1113  loss_ce_0: 0.09892  loss_mask_0: 0.01583  loss_dice_0: 0.1293  loss_ce_1: 0.0003348  loss_mask_1: 0.01755  loss_dice_1: 0.1137  loss_ce_2: 0.000191  loss_mask_2: 0.01772  loss_dice_2: 0.108  loss_ce_3: 0.0003181  loss_mask_3: 0.0171  loss_dice_3: 0.1092  loss_ce_4: 0.0006359  loss_mask_4: 0.017  loss_dice_4: 0.1067  loss_ce_5: 0.0006852  loss_mask_5: 0.01773  loss_dice_5: 0.1109  loss_ce_6: 0.0008549  loss_mask_6: 0.01684  loss_dice_6: 0.1128  loss_ce_7: 0.001147  loss_mask_7: 0.01804  loss_dice_7: 0.109  loss_ce_8: 0.0009596  loss_mask_8: 0.01797  loss_dice_8: 0.1142  loss_mgm_entropy: 0.004548    time: 0.4299  last_time: 0.4295  data_time: 0.0032  last_data_time: 0.0034   lr: 0.0002  max_mem: 15320M
[08/30 16:13:28] d2.utils.events INFO:  eta: 0:40:05  iter: 2399  total_loss: 1.4  loss_ce: 0.001139  loss_mask: 0.01766  loss_dice: 0.1099  loss_ce_0: 0.0959  loss_mask_0: 0.01443  loss_dice_0: 0.1235  loss_ce_1: 0.0004827  loss_mask_1: 0.01675  loss_dice_1: 0.1057  loss_ce_2: 0.0002882  loss_mask_2: 0.01812  loss_dice_2: 0.105  loss_ce_3: 0.0004582  loss_mask_3: 0.01733  loss_dice_3: 0.1056  loss_ce_4: 0.0004996  loss_mask_4: 0.0162  loss_dice_4: 0.1075  loss_ce_5: 0.0009496  loss_mask_5: 0.01688  loss_dice_5: 0.1051  loss_ce_6: 0.0006374  loss_mask_6: 0.01693  loss_dice_6: 0.1103  loss_ce_7: 0.001014  loss_mask_7: 0.01737  loss_dice_7: 0.1094  loss_ce_8: 0.002171  loss_mask_8: 0.01806  loss_dice_8: 0.1121  loss_mgm_entropy: 0.004579    time: 0.4300  last_time: 0.4292  data_time: 0.0031  last_data_time: 0.0028   lr: 0.0002  max_mem: 15320M
[08/30 16:13:37] d2.utils.events INFO:  eta: 0:39:56  iter: 2419  total_loss: 1.543  loss_ce: 0.0006107  loss_mask: 0.02085  loss_dice: 0.1146  loss_ce_0: 0.09559  loss_mask_0: 0.01894  loss_dice_0: 0.1333  loss_ce_1: 0.0005157  loss_mask_1: 0.02082  loss_dice_1: 0.1164  loss_ce_2: 0.0002759  loss_mask_2: 0.02184  loss_dice_2: 0.1145  loss_ce_3: 0.0004552  loss_mask_3: 0.02179  loss_dice_3: 0.119  loss_ce_4: 0.000425  loss_mask_4: 0.0222  loss_dice_4: 0.1185  loss_ce_5: 0.0008905  loss_mask_5: 0.02246  loss_dice_5: 0.123  loss_ce_6: 0.000945  loss_mask_6: 0.02159  loss_dice_6: 0.1138  loss_ce_7: 0.0009111  loss_mask_7: 0.02114  loss_dice_7: 0.1133  loss_ce_8: 0.001723  loss_mask_8: 0.02258  loss_dice_8: 0.1163  loss_mgm_entropy: 0.00454    time: 0.4300  last_time: 0.4318  data_time: 0.0031  last_data_time: 0.0036   lr: 0.0002  max_mem: 15320M
[08/30 16:13:45] d2.utils.events INFO:  eta: 0:39:48  iter: 2439  total_loss: 3.604  loss_ce: 0.03928  loss_mask: 0.04047  loss_dice: 0.2402  loss_ce_0: 0.09685  loss_mask_0: 0.03568  loss_dice_0: 0.2604  loss_ce_1: 0.00279  loss_mask_1: 0.04043  loss_dice_1: 0.2549  loss_ce_2: 0.01123  loss_mask_2: 0.04312  loss_dice_2: 0.248  loss_ce_3: 0.007893  loss_mask_3: 0.04344  loss_dice_3: 0.2433  loss_ce_4: 0.007021  loss_mask_4: 0.04164  loss_dice_4: 0.2425  loss_ce_5: 0.006601  loss_mask_5: 0.04507  loss_dice_5: 0.267  loss_ce_6: 0.008724  loss_mask_6: 0.05041  loss_dice_6: 0.2694  loss_ce_7: 0.006391  loss_mask_7: 0.04149  loss_dice_7: 0.2519  loss_ce_8: 0.003314  loss_mask_8: 0.04091  loss_dice_8: 0.2522  loss_mgm_entropy: 0.004551    time: 0.4300  last_time: 0.4384  data_time: 0.0031  last_data_time: 0.0038   lr: 0.0002  max_mem: 15320M
[08/30 16:13:54] d2.utils.events INFO:  eta: 0:39:39  iter: 2459  total_loss: 5.671  loss_ce: 0.1278  loss_mask: 0.06741  loss_dice: 0.3634  loss_ce_0: 0.1021  loss_mask_0: 0.04915  loss_dice_0: 0.3918  loss_ce_1: 0.09401  loss_mask_1: 0.06582  loss_dice_1: 0.3474  loss_ce_2: 0.06343  loss_mask_2: 0.06955  loss_dice_2: 0.3363  loss_ce_3: 0.02493  loss_mask_3: 0.06734  loss_dice_3: 0.3127  loss_ce_4: 0.1044  loss_mask_4: 0.06875  loss_dice_4: 0.3707  loss_ce_5: 0.04789  loss_mask_5: 0.06499  loss_dice_5: 0.3621  loss_ce_6: 0.05617  loss_mask_6: 0.07411  loss_dice_6: 0.3899  loss_ce_7: 0.131  loss_mask_7: 0.09109  loss_dice_7: 0.4376  loss_ce_8: 0.1825  loss_mask_8: 0.07645  loss_dice_8: 0.4364  loss_mgm_entropy: 0.00409    time: 0.4300  last_time: 0.4323  data_time: 0.0030  last_data_time: 0.0028   lr: 0.0002  max_mem: 15320M
[08/30 16:14:03] d2.utils.events INFO:  eta: 0:39:31  iter: 2479  total_loss: 7.166  loss_ce: 0.08271  loss_mask: 0.1173  loss_dice: 0.4932  loss_ce_0: 0.09785  loss_mask_0: 0.07577  loss_dice_0: 0.4846  loss_ce_1: 0.07174  loss_mask_1: 0.1013  loss_dice_1: 0.4124  loss_ce_2: 0.07234  loss_mask_2: 0.09466  loss_dice_2: 0.4616  loss_ce_3: 0.09572  loss_mask_3: 0.1073  loss_dice_3: 0.4976  loss_ce_4: 0.1186  loss_mask_4: 0.1058  loss_dice_4: 0.4758  loss_ce_5: 0.1039  loss_mask_5: 0.1165  loss_dice_5: 0.4599  loss_ce_6: 0.08438  loss_mask_6: 0.1118  loss_dice_6: 0.4733  loss_ce_7: 0.1081  loss_mask_7: 0.1131  loss_dice_7: 0.5243  loss_ce_8: 0.199  loss_mask_8: 0.1053  loss_dice_8: 0.4874  loss_mgm_entropy: 0.004277    time: 0.4300  last_time: 0.4296  data_time: 0.0030  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:14:11] d2.utils.events INFO:  eta: 0:39:22  iter: 2499  total_loss: 5.06  loss_ce: 0.06648  loss_mask: 0.07329  loss_dice: 0.3293  loss_ce_0: 0.0993  loss_mask_0: 0.05348  loss_dice_0: 0.3646  loss_ce_1: 0.1335  loss_mask_1: 0.06364  loss_dice_1: 0.3428  loss_ce_2: 0.04475  loss_mask_2: 0.05727  loss_dice_2: 0.307  loss_ce_3: 0.05025  loss_mask_3: 0.0616  loss_dice_3: 0.3202  loss_ce_4: 0.07655  loss_mask_4: 0.06083  loss_dice_4: 0.3263  loss_ce_5: 0.112  loss_mask_5: 0.06966  loss_dice_5: 0.3738  loss_ce_6: 0.09362  loss_mask_6: 0.06495  loss_dice_6: 0.3491  loss_ce_7: 0.07239  loss_mask_7: 0.07637  loss_dice_7: 0.3657  loss_ce_8: 0.08202  loss_mask_8: 0.06253  loss_dice_8: 0.3091  loss_mgm_entropy: 0.00432    time: 0.4301  last_time: 0.4286  data_time: 0.0031  last_data_time: 0.0031   lr: 0.0002  max_mem: 15320M
[08/30 16:14:20] d2.utils.events INFO:  eta: 0:39:13  iter: 2519  total_loss: 4.579  loss_ce: 0.06625  loss_mask: 0.06946  loss_dice: 0.3239  loss_ce_0: 0.09542  loss_mask_0: 0.05016  loss_dice_0: 0.3151  loss_ce_1: 0.04376  loss_mask_1: 0.06592  loss_dice_1: 0.2846  loss_ce_2: 0.03804  loss_mask_2: 0.06058  loss_dice_2: 0.2631  loss_ce_3: 0.03118  loss_mask_3: 0.05694  loss_dice_3: 0.2689  loss_ce_4: 0.0509  loss_mask_4: 0.05284  loss_dice_4: 0.2696  loss_ce_5: 0.04851  loss_mask_5: 0.06471  loss_dice_5: 0.314  loss_ce_6: 0.05868  loss_mask_6: 0.06778  loss_dice_6: 0.2974  loss_ce_7: 0.07775  loss_mask_7: 0.06154  loss_dice_7: 0.2957  loss_ce_8: 0.06118  loss_mask_8: 0.06905  loss_dice_8: 0.3289  loss_mgm_entropy: 0.004613    time: 0.4301  last_time: 0.4301  data_time: 0.0032  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:14:29] d2.utils.events INFO:  eta: 0:39:05  iter: 2539  total_loss: 3.462  loss_ce: 0.04166  loss_mask: 0.05489  loss_dice: 0.2498  loss_ce_0: 0.09789  loss_mask_0: 0.03726  loss_dice_0: 0.2523  loss_ce_1: 0.02126  loss_mask_1: 0.04555  loss_dice_1: 0.2179  loss_ce_2: 0.0149  loss_mask_2: 0.04729  loss_dice_2: 0.2372  loss_ce_3: 0.01976  loss_mask_3: 0.04683  loss_dice_3: 0.2442  loss_ce_4: 0.04503  loss_mask_4: 0.04734  loss_dice_4: 0.2454  loss_ce_5: 0.02774  loss_mask_5: 0.04864  loss_dice_5: 0.2346  loss_ce_6: 0.04889  loss_mask_6: 0.04526  loss_dice_6: 0.2318  loss_ce_7: 0.04356  loss_mask_7: 0.05375  loss_dice_7: 0.2601  loss_ce_8: 0.03914  loss_mask_8: 0.04883  loss_dice_8: 0.2458  loss_mgm_entropy: 0.004557    time: 0.4301  last_time: 0.4300  data_time: 0.0031  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 16:14:37] d2.utils.events INFO:  eta: 0:38:56  iter: 2559  total_loss: 2.95  loss_ce: 0.04014  loss_mask: 0.03961  loss_dice: 0.1848  loss_ce_0: 0.09443  loss_mask_0: 0.0315  loss_dice_0: 0.2197  loss_ce_1: 0.009814  loss_mask_1: 0.03621  loss_dice_1: 0.1749  loss_ce_2: 0.007978  loss_mask_2: 0.0371  loss_dice_2: 0.1789  loss_ce_3: 0.03446  loss_mask_3: 0.0348  loss_dice_3: 0.1788  loss_ce_4: 0.0309  loss_mask_4: 0.03714  loss_dice_4: 0.1866  loss_ce_5: 0.03653  loss_mask_5: 0.03753  loss_dice_5: 0.2015  loss_ce_6: 0.0194  loss_mask_6: 0.037  loss_dice_6: 0.2052  loss_ce_7: 0.03435  loss_mask_7: 0.04242  loss_dice_7: 0.2057  loss_ce_8: 0.03195  loss_mask_8: 0.03989  loss_dice_8: 0.1871  loss_mgm_entropy: 0.004694    time: 0.4301  last_time: 0.4286  data_time: 0.0031  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 16:14:46] d2.utils.events INFO:  eta: 0:38:48  iter: 2579  total_loss: 2.248  loss_ce: 0.01889  loss_mask: 0.03468  loss_dice: 0.1608  loss_ce_0: 0.09735  loss_mask_0: 0.02714  loss_dice_0: 0.1881  loss_ce_1: 0.01404  loss_mask_1: 0.03417  loss_dice_1: 0.1637  loss_ce_2: 0.001302  loss_mask_2: 0.03153  loss_dice_2: 0.1533  loss_ce_3: 0.006901  loss_mask_3: 0.03184  loss_dice_3: 0.1555  loss_ce_4: 0.01844  loss_mask_4: 0.03421  loss_dice_4: 0.181  loss_ce_5: 0.01074  loss_mask_5: 0.03474  loss_dice_5: 0.1803  loss_ce_6: 0.01411  loss_mask_6: 0.0338  loss_dice_6: 0.1664  loss_ce_7: 0.02539  loss_mask_7: 0.03429  loss_dice_7: 0.1676  loss_ce_8: 0.02013  loss_mask_8: 0.03272  loss_dice_8: 0.1617  loss_mgm_entropy: 0.004682    time: 0.4301  last_time: 0.4284  data_time: 0.0030  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 16:14:54] d2.utils.events INFO:  eta: 0:38:39  iter: 2599  total_loss: 2.027  loss_ce: 0.01168  loss_mask: 0.03066  loss_dice: 0.1531  loss_ce_0: 0.09426  loss_mask_0: 0.02312  loss_dice_0: 0.1635  loss_ce_1: 0.004159  loss_mask_1: 0.02958  loss_dice_1: 0.1523  loss_ce_2: 0.001862  loss_mask_2: 0.02765  loss_dice_2: 0.1465  loss_ce_3: 0.004284  loss_mask_3: 0.02717  loss_dice_3: 0.145  loss_ce_4: 0.0196  loss_mask_4: 0.02879  loss_dice_4: 0.15  loss_ce_5: 0.02357  loss_mask_5: 0.02826  loss_dice_5: 0.148  loss_ce_6: 0.008172  loss_mask_6: 0.02872  loss_dice_6: 0.1507  loss_ce_7: 0.01676  loss_mask_7: 0.02959  loss_dice_7: 0.1531  loss_ce_8: 0.0122  loss_mask_8: 0.03035  loss_dice_8: 0.1487  loss_mgm_entropy: 0.004719    time: 0.4301  last_time: 0.4300  data_time: 0.0031  last_data_time: 0.0033   lr: 0.0002  max_mem: 15320M
[08/30 16:15:03] d2.utils.events INFO:  eta: 0:38:31  iter: 2619  total_loss: 1.646  loss_ce: 0.003543  loss_mask: 0.02243  loss_dice: 0.1239  loss_ce_0: 0.09211  loss_mask_0: 0.01909  loss_dice_0: 0.1375  loss_ce_1: 0.002153  loss_mask_1: 0.02283  loss_dice_1: 0.1257  loss_ce_2: 0.0006194  loss_mask_2: 0.02171  loss_dice_2: 0.1228  loss_ce_3: 0.001364  loss_mask_3: 0.02128  loss_dice_3: 0.1223  loss_ce_4: 0.00608  loss_mask_4: 0.02215  loss_dice_4: 0.1268  loss_ce_5: 0.004874  loss_mask_5: 0.02191  loss_dice_5: 0.1231  loss_ce_6: 0.003864  loss_mask_6: 0.02197  loss_dice_6: 0.1237  loss_ce_7: 0.009351  loss_mask_7: 0.02216  loss_dice_7: 0.1278  loss_ce_8: 0.007631  loss_mask_8: 0.02361  loss_dice_8: 0.1248  loss_mgm_entropy: 0.004792    time: 0.4301  last_time: 0.4272  data_time: 0.0031  last_data_time: 0.0031   lr: 0.0002  max_mem: 15320M
[08/30 16:15:12] d2.utils.events INFO:  eta: 0:38:22  iter: 2639  total_loss: 1.483  loss_ce: 0.00548  loss_mask: 0.01947  loss_dice: 0.1116  loss_ce_0: 0.09117  loss_mask_0: 0.01618  loss_dice_0: 0.1221  loss_ce_1: 0.00127  loss_mask_1: 0.01844  loss_dice_1: 0.1128  loss_ce_2: 0.0004501  loss_mask_2: 0.01802  loss_dice_2: 0.1095  loss_ce_3: 0.0009123  loss_mask_3: 0.01887  loss_dice_3: 0.1067  loss_ce_4: 0.0036  loss_mask_4: 0.01806  loss_dice_4: 0.1134  loss_ce_5: 0.002305  loss_mask_5: 0.01989  loss_dice_5: 0.1187  loss_ce_6: 0.002353  loss_mask_6: 0.01818  loss_dice_6: 0.1122  loss_ce_7: 0.007948  loss_mask_7: 0.01846  loss_dice_7: 0.1123  loss_ce_8: 0.005057  loss_mask_8: 0.01838  loss_dice_8: 0.1096  loss_mgm_entropy: 0.004734    time: 0.4301  last_time: 0.4344  data_time: 0.0031  last_data_time: 0.0028   lr: 0.0002  max_mem: 15320M
[08/30 16:15:20] d2.utils.events INFO:  eta: 0:38:13  iter: 2659  total_loss: 1.526  loss_ce: 0.00358  loss_mask: 0.01838  loss_dice: 0.1125  loss_ce_0: 0.09967  loss_mask_0: 0.01761  loss_dice_0: 0.1315  loss_ce_1: 0.001268  loss_mask_1: 0.01928  loss_dice_1: 0.1144  loss_ce_2: 0.0003859  loss_mask_2: 0.01961  loss_dice_2: 0.1192  loss_ce_3: 0.0006638  loss_mask_3: 0.01868  loss_dice_3: 0.112  loss_ce_4: 0.002171  loss_mask_4: 0.01826  loss_dice_4: 0.1187  loss_ce_5: 0.001333  loss_mask_5: 0.01965  loss_dice_5: 0.1143  loss_ce_6: 0.002413  loss_mask_6: 0.01814  loss_dice_6: 0.1162  loss_ce_7: 0.005007  loss_mask_7: 0.01996  loss_dice_7: 0.1153  loss_ce_8: 0.004473  loss_mask_8: 0.02009  loss_dice_8: 0.1146  loss_mgm_entropy: 0.00469    time: 0.4301  last_time: 0.4289  data_time: 0.0032  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 16:15:29] d2.utils.events INFO:  eta: 0:38:05  iter: 2679  total_loss: 1.552  loss_ce: 0.003901  loss_mask: 0.01923  loss_dice: 0.1146  loss_ce_0: 0.09686  loss_mask_0: 0.01838  loss_dice_0: 0.1307  loss_ce_1: 0.003619  loss_mask_1: 0.01948  loss_dice_1: 0.1188  loss_ce_2: 0.001561  loss_mask_2: 0.02036  loss_dice_2: 0.1164  loss_ce_3: 0.002602  loss_mask_3: 0.02009  loss_dice_3: 0.1119  loss_ce_4: 0.003745  loss_mask_4: 0.01917  loss_dice_4: 0.1156  loss_ce_5: 0.002505  loss_mask_5: 0.02091  loss_dice_5: 0.1183  loss_ce_6: 0.001752  loss_mask_6: 0.02058  loss_dice_6: 0.117  loss_ce_7: 0.004353  loss_mask_7: 0.02052  loss_dice_7: 0.1179  loss_ce_8: 0.003078  loss_mask_8: 0.0212  loss_dice_8: 0.1163  loss_mgm_entropy: 0.004641    time: 0.4301  last_time: 0.4282  data_time: 0.0032  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 16:15:37] d2.utils.events INFO:  eta: 0:37:56  iter: 2699  total_loss: 1.774  loss_ce: 0.003586  loss_mask: 0.02321  loss_dice: 0.1298  loss_ce_0: 0.09476  loss_mask_0: 0.02008  loss_dice_0: 0.1496  loss_ce_1: 0.001999  loss_mask_1: 0.02402  loss_dice_1: 0.1323  loss_ce_2: 0.0006503  loss_mask_2: 0.02319  loss_dice_2: 0.1299  loss_ce_3: 0.001606  loss_mask_3: 0.02275  loss_dice_3: 0.1252  loss_ce_4: 0.003171  loss_mask_4: 0.02191  loss_dice_4: 0.1258  loss_ce_5: 0.001856  loss_mask_5: 0.02247  loss_dice_5: 0.1263  loss_ce_6: 0.001421  loss_mask_6: 0.02276  loss_dice_6: 0.1272  loss_ce_7: 0.006418  loss_mask_7: 0.02313  loss_dice_7: 0.1301  loss_ce_8: 0.003932  loss_mask_8: 0.02325  loss_dice_8: 0.1281  loss_mgm_entropy: 0.004593    time: 0.4301  last_time: 0.4288  data_time: 0.0031  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:15:46] d2.utils.events INFO:  eta: 0:37:47  iter: 2719  total_loss: 1.495  loss_ce: 0.002205  loss_mask: 0.02238  loss_dice: 0.1139  loss_ce_0: 0.09451  loss_mask_0: 0.01856  loss_dice_0: 0.1274  loss_ce_1: 0.001071  loss_mask_1: 0.02258  loss_dice_1: 0.1162  loss_ce_2: 0.0003625  loss_mask_2: 0.02098  loss_dice_2: 0.1129  loss_ce_3: 0.0009209  loss_mask_3: 0.02103  loss_dice_3: 0.1141  loss_ce_4: 0.001545  loss_mask_4: 0.02123  loss_dice_4: 0.1161  loss_ce_5: 0.001568  loss_mask_5: 0.02056  loss_dice_5: 0.1156  loss_ce_6: 0.001532  loss_mask_6: 0.0217  loss_dice_6: 0.1154  loss_ce_7: 0.00344  loss_mask_7: 0.02165  loss_dice_7: 0.1193  loss_ce_8: 0.002422  loss_mask_8: 0.02131  loss_dice_8: 0.1148  loss_mgm_entropy: 0.00449    time: 0.4301  last_time: 0.4293  data_time: 0.0031  last_data_time: 0.0028   lr: 0.0002  max_mem: 15320M
[08/30 16:15:55] d2.utils.events INFO:  eta: 0:37:39  iter: 2739  total_loss: 1.396  loss_ce: 0.00157  loss_mask: 0.01935  loss_dice: 0.1051  loss_ce_0: 0.08896  loss_mask_0: 0.01535  loss_dice_0: 0.1244  loss_ce_1: 0.001406  loss_mask_1: 0.01769  loss_dice_1: 0.1034  loss_ce_2: 0.0004951  loss_mask_2: 0.01706  loss_dice_2: 0.1029  loss_ce_3: 0.001127  loss_mask_3: 0.01787  loss_dice_3: 0.103  loss_ce_4: 0.001648  loss_mask_4: 0.01781  loss_dice_4: 0.1041  loss_ce_5: 0.002405  loss_mask_5: 0.01837  loss_dice_5: 0.1093  loss_ce_6: 0.001731  loss_mask_6: 0.0172  loss_dice_6: 0.1036  loss_ce_7: 0.001988  loss_mask_7: 0.01855  loss_dice_7: 0.1036  loss_ce_8: 0.002119  loss_mask_8: 0.01712  loss_dice_8: 0.1066  loss_mgm_entropy: 0.004523    time: 0.4301  last_time: 0.4303  data_time: 0.0033  last_data_time: 0.0034   lr: 0.0002  max_mem: 15320M
[08/30 16:16:03] d2.utils.events INFO:  eta: 0:37:30  iter: 2759  total_loss: 1.371  loss_ce: 0.001  loss_mask: 0.01727  loss_dice: 0.09603  loss_ce_0: 0.09545  loss_mask_0: 0.01526  loss_dice_0: 0.1174  loss_ce_1: 0.002036  loss_mask_1: 0.01754  loss_dice_1: 0.09699  loss_ce_2: 0.0006646  loss_mask_2: 0.01688  loss_dice_2: 0.1006  loss_ce_3: 0.0008107  loss_mask_3: 0.01678  loss_dice_3: 0.1042  loss_ce_4: 0.001282  loss_mask_4: 0.01618  loss_dice_4: 0.1004  loss_ce_5: 0.00137  loss_mask_5: 0.01665  loss_dice_5: 0.09916  loss_ce_6: 0.0009226  loss_mask_6: 0.01703  loss_dice_6: 0.1013  loss_ce_7: 0.002159  loss_mask_7: 0.01734  loss_dice_7: 0.1023  loss_ce_8: 0.00163  loss_mask_8: 0.017  loss_dice_8: 0.1049  loss_mgm_entropy: 0.004501    time: 0.4301  last_time: 0.4334  data_time: 0.0031  last_data_time: 0.0034   lr: 0.0002  max_mem: 15320M
[08/30 16:16:12] d2.utils.events INFO:  eta: 0:37:22  iter: 2779  total_loss: 1.439  loss_ce: 0.0008936  loss_mask: 0.01771  loss_dice: 0.1049  loss_ce_0: 0.09777  loss_mask_0: 0.01589  loss_dice_0: 0.1219  loss_ce_1: 0.001908  loss_mask_1: 0.01755  loss_dice_1: 0.1098  loss_ce_2: 0.0004998  loss_mask_2: 0.01724  loss_dice_2: 0.11  loss_ce_3: 0.0006264  loss_mask_3: 0.01723  loss_dice_3: 0.1055  loss_ce_4: 0.001738  loss_mask_4: 0.01815  loss_dice_4: 0.1121  loss_ce_5: 0.001011  loss_mask_5: 0.01765  loss_dice_5: 0.1091  loss_ce_6: 0.0008812  loss_mask_6: 0.01819  loss_dice_6: 0.1094  loss_ce_7: 0.001426  loss_mask_7: 0.01821  loss_dice_7: 0.108  loss_ce_8: 0.001413  loss_mask_8: 0.01805  loss_dice_8: 0.1091  loss_mgm_entropy: 0.004486    time: 0.4301  last_time: 0.4307  data_time: 0.0031  last_data_time: 0.0034   lr: 0.0002  max_mem: 15320M
[08/30 16:16:21] d2.utils.events INFO:  eta: 0:37:13  iter: 2799  total_loss: 1.344  loss_ce: 0.001128  loss_mask: 0.01437  loss_dice: 0.1009  loss_ce_0: 0.09442  loss_mask_0: 0.01222  loss_dice_0: 0.114  loss_ce_1: 0.00231  loss_mask_1: 0.01535  loss_dice_1: 0.1007  loss_ce_2: 0.000634  loss_mask_2: 0.01426  loss_dice_2: 0.1018  loss_ce_3: 0.001494  loss_mask_3: 0.01514  loss_dice_3: 0.1015  loss_ce_4: 0.003602  loss_mask_4: 0.01498  loss_dice_4: 0.1052  loss_ce_5: 0.0008783  loss_mask_5: 0.01543  loss_dice_5: 0.09915  loss_ce_6: 0.001016  loss_mask_6: 0.0154  loss_dice_6: 0.1012  loss_ce_7: 0.001423  loss_mask_7: 0.01465  loss_dice_7: 0.1028  loss_ce_8: 0.001145  loss_mask_8: 0.01449  loss_dice_8: 0.098  loss_mgm_entropy: 0.004488    time: 0.4301  last_time: 0.4307  data_time: 0.0033  last_data_time: 0.0034   lr: 0.0002  max_mem: 15320M
[08/30 16:16:29] d2.utils.events INFO:  eta: 0:37:04  iter: 2819  total_loss: 1.355  loss_ce: 0.00122  loss_mask: 0.01792  loss_dice: 0.1022  loss_ce_0: 0.09504  loss_mask_0: 0.01494  loss_dice_0: 0.12  loss_ce_1: 0.002049  loss_mask_1: 0.01872  loss_dice_1: 0.1021  loss_ce_2: 0.0007382  loss_mask_2: 0.01804  loss_dice_2: 0.1026  loss_ce_3: 0.001087  loss_mask_3: 0.01764  loss_dice_3: 0.1042  loss_ce_4: 0.001824  loss_mask_4: 0.01853  loss_dice_4: 0.1085  loss_ce_5: 0.002127  loss_mask_5: 0.01835  loss_dice_5: 0.1063  loss_ce_6: 0.002507  loss_mask_6: 0.01804  loss_dice_6: 0.102  loss_ce_7: 0.001479  loss_mask_7: 0.01912  loss_dice_7: 0.1078  loss_ce_8: 0.001681  loss_mask_8: 0.0179  loss_dice_8: 0.1061  loss_mgm_entropy: 0.004485    time: 0.4301  last_time: 0.4290  data_time: 0.0031  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:16:38] d2.utils.events INFO:  eta: 0:36:56  iter: 2839  total_loss: 1.325  loss_ce: 0.0005894  loss_mask: 0.01657  loss_dice: 0.1075  loss_ce_0: 0.09198  loss_mask_0: 0.01515  loss_dice_0: 0.1126  loss_ce_1: 0.001419  loss_mask_1: 0.0161  loss_dice_1: 0.1013  loss_ce_2: 0.0005835  loss_mask_2: 0.01605  loss_dice_2: 0.1035  loss_ce_3: 0.0008077  loss_mask_3: 0.0162  loss_dice_3: 0.1012  loss_ce_4: 0.001293  loss_mask_4: 0.01716  loss_dice_4: 0.1036  loss_ce_5: 0.001106  loss_mask_5: 0.01604  loss_dice_5: 0.1018  loss_ce_6: 0.001037  loss_mask_6: 0.01667  loss_dice_6: 0.1012  loss_ce_7: 0.001061  loss_mask_7: 0.01661  loss_dice_7: 0.1014  loss_ce_8: 0.00134  loss_mask_8: 0.01557  loss_dice_8: 0.09914  loss_mgm_entropy: 0.004448    time: 0.4301  last_time: 0.4296  data_time: 0.0031  last_data_time: 0.0031   lr: 0.0002  max_mem: 15320M
[08/30 16:16:46] d2.utils.events INFO:  eta: 0:36:47  iter: 2859  total_loss: 1.41  loss_ce: 0.0007006  loss_mask: 0.01983  loss_dice: 0.1057  loss_ce_0: 0.09352  loss_mask_0: 0.01805  loss_dice_0: 0.1209  loss_ce_1: 0.00179  loss_mask_1: 0.02025  loss_dice_1: 0.1048  loss_ce_2: 0.001135  loss_mask_2: 0.01971  loss_dice_2: 0.1027  loss_ce_3: 0.002047  loss_mask_3: 0.01974  loss_dice_3: 0.1012  loss_ce_4: 0.002737  loss_mask_4: 0.02051  loss_dice_4: 0.1095  loss_ce_5: 0.0009993  loss_mask_5: 0.02001  loss_dice_5: 0.1047  loss_ce_6: 0.000984  loss_mask_6: 0.02013  loss_dice_6: 0.1066  loss_ce_7: 0.001837  loss_mask_7: 0.02039  loss_dice_7: 0.1033  loss_ce_8: 0.001154  loss_mask_8: 0.02133  loss_dice_8: 0.103  loss_mgm_entropy: 0.004437    time: 0.4301  last_time: 0.4330  data_time: 0.0032  last_data_time: 0.0028   lr: 0.0002  max_mem: 15320M
[08/30 16:16:55] d2.utils.events INFO:  eta: 0:36:39  iter: 2879  total_loss: 1.354  loss_ce: 0.0007818  loss_mask: 0.01804  loss_dice: 0.1025  loss_ce_0: 0.09147  loss_mask_0: 0.01463  loss_dice_0: 0.1274  loss_ce_1: 0.001619  loss_mask_1: 0.01811  loss_dice_1: 0.1053  loss_ce_2: 0.0008679  loss_mask_2: 0.01755  loss_dice_2: 0.1005  loss_ce_3: 0.002268  loss_mask_3: 0.01921  loss_dice_3: 0.1008  loss_ce_4: 0.00218  loss_mask_4: 0.01736  loss_dice_4: 0.1023  loss_ce_5: 0.001144  loss_mask_5: 0.01799  loss_dice_5: 0.104  loss_ce_6: 0.0009405  loss_mask_6: 0.01782  loss_dice_6: 0.1064  loss_ce_7: 0.001519  loss_mask_7: 0.01851  loss_dice_7: 0.1068  loss_ce_8: 0.0009896  loss_mask_8: 0.01752  loss_dice_8: 0.1051  loss_mgm_entropy: 0.004405    time: 0.4301  last_time: 0.4293  data_time: 0.0031  last_data_time: 0.0040   lr: 0.0002  max_mem: 15320M
[08/30 16:17:04] d2.utils.events INFO:  eta: 0:36:30  iter: 2899  total_loss: 1.34  loss_ce: 0.001131  loss_mask: 0.01831  loss_dice: 0.09681  loss_ce_0: 0.09018  loss_mask_0: 0.01608  loss_dice_0: 0.1203  loss_ce_1: 0.001816  loss_mask_1: 0.01855  loss_dice_1: 0.1016  loss_ce_2: 0.002651  loss_mask_2: 0.0174  loss_dice_2: 0.09967  loss_ce_3: 0.008732  loss_mask_3: 0.01865  loss_dice_3: 0.1001  loss_ce_4: 0.005786  loss_mask_4: 0.01761  loss_dice_4: 0.1024  loss_ce_5: 0.000744  loss_mask_5: 0.01694  loss_dice_5: 0.0992  loss_ce_6: 0.002453  loss_mask_6: 0.01727  loss_dice_6: 0.1019  loss_ce_7: 0.002311  loss_mask_7: 0.01772  loss_dice_7: 0.1054  loss_ce_8: 0.001147  loss_mask_8: 0.01803  loss_dice_8: 0.1025  loss_mgm_entropy: 0.004474    time: 0.4301  last_time: 0.4282  data_time: 0.0031  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:17:12] d2.utils.events INFO:  eta: 0:36:21  iter: 2919  total_loss: 1.294  loss_ce: 0.0003821  loss_mask: 0.01685  loss_dice: 0.09608  loss_ce_0: 0.09239  loss_mask_0: 0.01427  loss_dice_0: 0.1085  loss_ce_1: 0.001016  loss_mask_1: 0.01721  loss_dice_1: 0.09797  loss_ce_2: 0.000517  loss_mask_2: 0.01609  loss_dice_2: 0.09338  loss_ce_3: 0.0009632  loss_mask_3: 0.01726  loss_dice_3: 0.1021  loss_ce_4: 0.001261  loss_mask_4: 0.01707  loss_dice_4: 0.09368  loss_ce_5: 0.0008685  loss_mask_5: 0.01634  loss_dice_5: 0.1007  loss_ce_6: 0.0008389  loss_mask_6: 0.01713  loss_dice_6: 0.09692  loss_ce_7: 0.00139  loss_mask_7: 0.01727  loss_dice_7: 0.09991  loss_ce_8: 0.0008928  loss_mask_8: 0.01677  loss_dice_8: 0.09954  loss_mgm_entropy: 0.004451    time: 0.4301  last_time: 0.4300  data_time: 0.0032  last_data_time: 0.0036   lr: 0.0002  max_mem: 15320M
[08/30 16:17:21] d2.utils.events INFO:  eta: 0:36:13  iter: 2939  total_loss: 1.248  loss_ce: 0.0006053  loss_mask: 0.01689  loss_dice: 0.09767  loss_ce_0: 0.0915  loss_mask_0: 0.01511  loss_dice_0: 0.115  loss_ce_1: 0.0007917  loss_mask_1: 0.01657  loss_dice_1: 0.09438  loss_ce_2: 0.0004856  loss_mask_2: 0.0164  loss_dice_2: 0.09378  loss_ce_3: 0.0007893  loss_mask_3: 0.01706  loss_dice_3: 0.09424  loss_ce_4: 0.001184  loss_mask_4: 0.01672  loss_dice_4: 0.0939  loss_ce_5: 0.0005021  loss_mask_5: 0.01645  loss_dice_5: 0.09466  loss_ce_6: 0.0006012  loss_mask_6: 0.01621  loss_dice_6: 0.09613  loss_ce_7: 0.001219  loss_mask_7: 0.01676  loss_dice_7: 0.09318  loss_ce_8: 0.000971  loss_mask_8: 0.0166  loss_dice_8: 0.09362  loss_mgm_entropy: 0.004341    time: 0.4301  last_time: 0.4300  data_time: 0.0031  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:17:29] d2.utils.events INFO:  eta: 0:36:04  iter: 2959  total_loss: 1.324  loss_ce: 0.0004671  loss_mask: 0.01678  loss_dice: 0.1033  loss_ce_0: 0.09185  loss_mask_0: 0.01375  loss_dice_0: 0.1187  loss_ce_1: 0.0008841  loss_mask_1: 0.01688  loss_dice_1: 0.09964  loss_ce_2: 0.0003212  loss_mask_2: 0.01679  loss_dice_2: 0.09935  loss_ce_3: 0.0005446  loss_mask_3: 0.01715  loss_dice_3: 0.09852  loss_ce_4: 0.0008509  loss_mask_4: 0.01676  loss_dice_4: 0.101  loss_ce_5: 0.0005772  loss_mask_5: 0.01579  loss_dice_5: 0.09984  loss_ce_6: 0.0007086  loss_mask_6: 0.01604  loss_dice_6: 0.1024  loss_ce_7: 0.0007578  loss_mask_7: 0.01723  loss_dice_7: 0.0987  loss_ce_8: 0.0005648  loss_mask_8: 0.01597  loss_dice_8: 0.1018  loss_mgm_entropy: 0.004423    time: 0.4301  last_time: 0.4275  data_time: 0.0031  last_data_time: 0.0030   lr: 0.0002  max_mem: 15320M
[08/30 16:17:38] d2.utils.events INFO:  eta: 0:35:56  iter: 2979  total_loss: 1.237  loss_ce: 0.0005499  loss_mask: 0.01679  loss_dice: 0.09402  loss_ce_0: 0.0915  loss_mask_0: 0.01344  loss_dice_0: 0.1079  loss_ce_1: 0.0006541  loss_mask_1: 0.01569  loss_dice_1: 0.0943  loss_ce_2: 0.0003096  loss_mask_2: 0.01573  loss_dice_2: 0.09306  loss_ce_3: 0.0004146  loss_mask_3: 0.01571  loss_dice_3: 0.09205  loss_ce_4: 0.0005373  loss_mask_4: 0.01586  loss_dice_4: 0.09493  loss_ce_5: 0.0008451  loss_mask_5: 0.01575  loss_dice_5: 0.09368  loss_ce_6: 0.0005354  loss_mask_6: 0.01557  loss_dice_6: 0.09452  loss_ce_7: 0.0009833  loss_mask_7: 0.01603  loss_dice_7: 0.0978  loss_ce_8: 0.0007026  loss_mask_8: 0.0158  loss_dice_8: 0.09381  loss_mgm_entropy: 0.004401    time: 0.4301  last_time: 0.4334  data_time: 0.0029  last_data_time: 0.0031   lr: 0.0002  max_mem: 15320M
[08/30 16:17:47] d2.utils.events INFO:  eta: 0:35:47  iter: 2999  total_loss: 1.247  loss_ce: 0.0006018  loss_mask: 0.01667  loss_dice: 0.09368  loss_ce_0: 0.09161  loss_mask_0: 0.01467  loss_dice_0: 0.1074  loss_ce_1: 0.0007183  loss_mask_1: 0.01675  loss_dice_1: 0.094  loss_ce_2: 0.0003246  loss_mask_2: 0.01599  loss_dice_2: 0.09142  loss_ce_3: 0.0004285  loss_mask_3: 0.01653  loss_dice_3: 0.09798  loss_ce_4: 0.0006852  loss_mask_4: 0.01622  loss_dice_4: 0.09504  loss_ce_5: 0.0006872  loss_mask_5: 0.01601  loss_dice_5: 0.09879  loss_ce_6: 0.001231  loss_mask_6: 0.01613  loss_dice_6: 0.09212  loss_ce_7: 0.0009474  loss_mask_7: 0.01621  loss_dice_7: 0.09497  loss_ce_8: 0.0008062  loss_mask_8: 0.01756  loss_dice_8: 0.09721  loss_mgm_entropy: 0.004382    time: 0.4301  last_time: 0.4291  data_time: 0.0032  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:17:56] d2.utils.events INFO:  eta: 0:35:38  iter: 3019  total_loss: 1.232  loss_ce: 0.0004459  loss_mask: 0.01608  loss_dice: 0.09543  loss_ce_0: 0.08943  loss_mask_0: 0.01273  loss_dice_0: 0.1093  loss_ce_1: 0.0004381  loss_mask_1: 0.01606  loss_dice_1: 0.09878  loss_ce_2: 0.0003222  loss_mask_2: 0.01582  loss_dice_2: 0.09495  loss_ce_3: 0.0002851  loss_mask_3: 0.01533  loss_dice_3: 0.09253  loss_ce_4: 0.000655  loss_mask_4: 0.01554  loss_dice_4: 0.09443  loss_ce_5: 0.0007716  loss_mask_5: 0.01612  loss_dice_5: 0.09738  loss_ce_6: 0.0005405  loss_mask_6: 0.01595  loss_dice_6: 0.09596  loss_ce_7: 0.0009885  loss_mask_7: 0.01506  loss_dice_7: 0.09527  loss_ce_8: 0.0005733  loss_mask_8: 0.01516  loss_dice_8: 0.09378  loss_mgm_entropy: 0.004389    time: 0.4301  last_time: 0.4290  data_time: 0.0031  last_data_time: 0.0029   lr: 0.0002  max_mem: 15320M
[08/30 16:18:04] d2.utils.events INFO:  eta: 0:35:30  iter: 3039  total_loss: 1.229  loss_ce: 0.0003316  loss_mask: 0.0163  loss_dice: 0.09799  loss_ce_0: 0.09184  loss_mask_0: 0.01353  loss_dice_0: 0.1099  loss_ce_1: 0.0005668  loss_mask_1: 0.01595  loss_dice_1: 0.09537  loss_ce_2: 0.0002492  loss_mask_2: 0.01627  loss_dice_2: 0.09455  loss_ce_3: 0.0004277  loss_mask_3: 0.01605  loss_dice_3: 0.0951  loss_ce_4: 0.0005403  loss_mask_4: 0.01592  loss_dice_4: 0.0983  loss_ce_5: 0.0004671  loss_mask_5: 0.01594  loss_dice_5: 0.09496  loss_ce_6: 0.0004062  loss_mask_6: 0.01642  loss_dice_6: 0.09576  loss_ce_7: 0.0006794  loss_mask_7: 0.01634  loss_dice_7: 0.09354  loss_ce_8: 0.0005009  loss_mask_8: 0.01586  loss_dice_8: 0.09611  loss_mgm_entropy: 0.004358    time: 0.4301  last_time: 0.4307  data_time: 0.0031  last_data_time: 0.0033   lr: 0.0002  max_mem: 15320M
[08/30 16:18:13] d2.utils.events INFO:  eta: 0:35:21  iter: 3059  total_loss: 1.383  loss_ce: 0.0002551  loss_mask: 0.01838  loss_dice: 0.1059  loss_ce_0: 0.0919  loss_mask_0: 0.01526  loss_dice_0: 0.1131  loss_ce_1: 0.0006274  loss_mask_1: 0.01805  loss_dice_1: 0.1044  loss_ce_2: 0.0002049  loss_mask_2: 0.01779  loss_dice_2: 0.0996  loss_ce_3: 0.0004199  loss_mask_3: 0.01725  loss_dice_3: 0.09585  loss_ce_4: 0.0005522  loss_mask_4: 0.01752  loss_dice_4: 0.1004  loss_ce_5: 0.0008021  loss_mask_5: 0.01877  loss_dice_5: 0.1055  loss_ce_6: 0.0005127  loss_mask_6: 0.01713  loss_dice_6: 0.1002  loss_ce_7: 0.0005881  loss_mask_7: 0.01824  loss_dice_7: 0.1087  loss_ce_8: 0.0005531  loss_mask_8: 0.01801  loss_dice_8: 0.1059  loss_mgm_entropy: 0.004431    time: 0.4301  last_time: 0.4296  data_time: 0.0031  last_data_time: 0.0031   lr: 0.0002  max_mem: 15320M
[08/30 16:18:21] d2.utils.events INFO:  eta: 0:35:12  iter: 3079  total_loss: 1.243  loss_ce: 0.0005291  loss_mask: 0.01731  loss_dice: 0.09395  loss_ce_0: 0.08684  loss_mask_0: 0.01481  loss_dice_0: 0.1026  loss_ce_1: 0.002554  loss_mask_1: 0.01817  loss_dice_1: 0.09471  loss_ce_2: 0.0006868  loss_mask_2: 0.01723  loss_dice_2: 0.09014  loss_ce_3: 0.001366  loss_mask_3: 0.01761  loss_dice_3: 0.09438  loss_ce_4: 0.001108  loss_mask_4: 0.01717  loss_dice_4: 0.08808  loss_ce_5: 0.0009429  loss_mask_5: 0.01796  loss_dice_5: 0.09642  loss_ce_6: 0.0007629  loss_mask_6: 0.01849  loss_dice_6: 0.09169  loss_ce_7: 0.0008601  loss_mask_7: 0.01753  loss_dice_7: 0.09654  loss_ce_8: 0.0006611  loss_mask_8: 0.018  loss_dice_8: 0.09515  loss_mgm_entropy: 0.004339    time: 0.4301  last_time: 0.4277  data_time: 0.0030  last_data_time: 0.0030   lr: 0.0002  max_mem: 15320M
[08/30 16:18:30] d2.utils.events INFO:  eta: 0:35:04  iter: 3099  total_loss: 1.249  loss_ce: 0.000506  loss_mask: 0.01749  loss_dice: 0.09088  loss_ce_0: 0.09148  loss_mask_0: 0.01457  loss_dice_0: 0.1064  loss_ce_1: 0.0006479  loss_mask_1: 0.01814  loss_dice_1: 0.0965  loss_ce_2: 0.0003331  loss_mask_2: 0.01814  loss_dice_2: 0.09377  loss_ce_3: 0.0004583  loss_mask_3: 0.0177  loss_dice_3: 0.09223  loss_ce_4: 0.001228  loss_mask_4: 0.0174  loss_dice_4: 0.0945  loss_ce_5: 0.001008  loss_mask_5: 0.01843  loss_dice_5: 0.09597  loss_ce_6: 0.0007031  loss_mask_6: 0.01723  loss_dice_6: 0.09032  loss_ce_7: 0.0007645  loss_mask_7: 0.01859  loss_dice_7: 0.09881  loss_ce_8: 0.0007177  loss_mask_8: 0.01858  loss_dice_8: 0.0942  loss_mgm_entropy: 0.00437    time: 0.4301  last_time: 0.4330  data_time: 0.0031  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 16:18:39] d2.utils.events INFO:  eta: 0:34:55  iter: 3119  total_loss: 1.178  loss_ce: 0.0003344  loss_mask: 0.01505  loss_dice: 0.09347  loss_ce_0: 0.08458  loss_mask_0: 0.01289  loss_dice_0: 0.1044  loss_ce_1: 0.0007054  loss_mask_1: 0.01511  loss_dice_1: 0.09045  loss_ce_2: 0.0001769  loss_mask_2: 0.01528  loss_dice_2: 0.09034  loss_ce_3: 0.0002582  loss_mask_3: 0.01546  loss_dice_3: 0.09321  loss_ce_4: 0.0004082  loss_mask_4: 0.01495  loss_dice_4: 0.0905  loss_ce_5: 0.0005938  loss_mask_5: 0.01522  loss_dice_5: 0.09202  loss_ce_6: 0.0004358  loss_mask_6: 0.01483  loss_dice_6: 0.09271  loss_ce_7: 0.0005535  loss_mask_7: 0.01512  loss_dice_7: 0.09328  loss_ce_8: 0.0004811  loss_mask_8: 0.01515  loss_dice_8: 0.09297  loss_mgm_entropy: 0.00438    time: 0.4301  last_time: 0.4296  data_time: 0.0030  last_data_time: 0.0027   lr: 0.0002  max_mem: 15320M
[08/30 16:18:47] d2.utils.events INFO:  eta: 0:34:47  iter: 3139  total_loss: 1.178  loss_ce: 0.0005032  loss_mask: 0.01464  loss_dice: 0.08842  loss_ce_0: 0.09072  loss_mask_0: 0.01286  loss_dice_0: 0.1025  loss_ce_1: 0.0003555  loss_mask_1: 0.01488  loss_dice_1: 0.08812  loss_ce_2: 0.0001979  loss_mask_2: 0.01469  loss_dice_2: 0.09048  loss_ce_3: 0.0005137  loss_mask_3: 0.01445  loss_dice_3: 0.08866  loss_ce_4: 0.0006162  loss_mask_4: 0.0145  loss_dice_4: 0.08607  loss_ce_5: 0.0005623  loss_mask_5: 0.01474  loss_dice_5: 0.08989  loss_ce_6: 0.000444  loss_mask_6: 0.01462  loss_dice_6: 0.08772  loss_ce_7: 0.000652  loss_mask_7: 0.01527  loss_dice_7: 0.09027  loss_ce_8: 0.0004323  loss_mask_8: 0.01505  loss_dice_8: 0.0903  loss_mgm_entropy: 0.004355    time: 0.4301  last_time: 0.4334  data_time: 0.0032  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 16:18:56] d2.utils.events INFO:  eta: 0:34:38  iter: 3159  total_loss: 1.17  loss_ce: 0.0003151  loss_mask: 0.01494  loss_dice: 0.09251  loss_ce_0: 0.08886  loss_mask_0: 0.01195  loss_dice_0: 0.09977  loss_ce_1: 0.0003809  loss_mask_1: 0.01465  loss_dice_1: 0.09466  loss_ce_2: 0.0002039  loss_mask_2: 0.01451  loss_dice_2: 0.09204  loss_ce_3: 0.000412  loss_mask_3: 0.0147  loss_dice_3: 0.0958  loss_ce_4: 0.0006067  loss_mask_4: 0.01472  loss_dice_4: 0.09668  loss_ce_5: 0.0005783  loss_mask_5: 0.01397  loss_dice_5: 0.09403  loss_ce_6: 0.0004235  loss_mask_6: 0.01467  loss_dice_6: 0.09262  loss_ce_7: 0.0006281  loss_mask_7: 0.01429  loss_dice_7: 0.09368  loss_ce_8: 0.0003472  loss_mask_8: 0.01464  loss_dice_8: 0.09276  loss_mgm_entropy: 0.004373    time: 0.4301  last_time: 0.4408  data_time: 0.0031  last_data_time: 0.0034   lr: 0.0002  max_mem: 15320M
[08/30 16:19:05] d2.utils.events INFO:  eta: 0:34:29  iter: 3179  total_loss: 1.259  loss_ce: 0.0002157  loss_mask: 0.01505  loss_dice: 0.09587  loss_ce_0: 0.08876  loss_mask_0: 0.01215  loss_dice_0: 0.1094  loss_ce_1: 0.000407  loss_mask_1: 0.01515  loss_dice_1: 0.101  loss_ce_2: 0.0001386  loss_mask_2: 0.01441  loss_dice_2: 0.09864  loss_ce_3: 0.0002247  loss_mask_3: 0.0153  loss_dice_3: 0.09864  loss_ce_4: 0.0003061  loss_mask_4: 0.01476  loss_dice_4: 0.1017  loss_ce_5: 0.0004221  loss_mask_5: 0.01462  loss_dice_5: 0.1  loss_ce_6: 0.0002709  loss_mask_6: 0.01522  loss_dice_6: 0.1002  loss_ce_7: 0.0004674  loss_mask_7: 0.01428  loss_dice_7: 0.09913  loss_ce_8: 0.0003726  loss_mask_8: 0.01513  loss_dice_8: 0.1009  loss_mgm_entropy: 0.004403    time: 0.4301  last_time: 0.4303  data_time: 0.0032  last_data_time: 0.0036   lr: 0.0002  max_mem: 15320M
[08/30 16:19:13] d2.utils.events INFO:  eta: 0:34:21  iter: 3199  total_loss: 1.222  loss_ce: 0.0002057  loss_mask: 0.01567  loss_dice: 0.09421  loss_ce_0: 0.09044  loss_mask_0: 0.01335  loss_dice_0: 0.1069  loss_ce_1: 0.0005445  loss_mask_1: 0.01489  loss_dice_1: 0.09301  loss_ce_2: 0.0001499  loss_mask_2: 0.01519  loss_dice_2: 0.09139  loss_ce_3: 0.0003144  loss_mask_3: 0.01469  loss_dice_3: 0.09523  loss_ce_4: 0.000309  loss_mask_4: 0.01484  loss_dice_4: 0.09428  loss_ce_5: 0.000393  loss_mask_5: 0.01462  loss_dice_5: 0.09685  loss_ce_6: 0.0002528  loss_mask_6: 0.01513  loss_dice_6: 0.09535  loss_ce_7: 0.0007254  loss_mask_7: 0.01578  loss_dice_7: 0.09718  loss_ce_8: 0.0003564  loss_mask_8: 0.01623  loss_dice_8: 0.0976  loss_mgm_entropy: 0.004365    time: 0.4301  last_time: 0.4418  data_time: 0.0031  last_data_time: 0.0031   lr: 0.0002  max_mem: 15320M
[08/30 16:19:22] d2.utils.events INFO:  eta: 0:34:12  iter: 3219  total_loss: 1.182  loss_ce: 0.0002333  loss_mask: 0.01568  loss_dice: 0.09477  loss_ce_0: 0.09062  loss_mask_0: 0.01335  loss_dice_0: 0.1035  loss_ce_1: 0.0007739  loss_mask_1: 0.01643  loss_dice_1: 0.09259  loss_ce_2: 0.0008397  loss_mask_2: 0.01516  loss_dice_2: 0.09247  loss_ce_3: 0.0004125  loss_mask_3: 0.01543  loss_dice_3: 0.08858  loss_ce_4: 0.0003386  loss_mask_4: 0.01578  loss_dice_4: 0.09176  loss_ce_5: 0.0004122  loss_mask_5: 0.01513  loss_dice_5: 0.09065  loss_ce_6: 0.0004218  loss_mask_6: 0.01527  loss_dice_6: 0.09092  loss_ce_7: 0.0004584  loss_mask_7: 0.01592  loss_dice_7: 0.09429  loss_ce_8: 0.001261  loss_mask_8: 0.01552  loss_dice_8: 0.08917  loss_mgm_entropy: 0.004359    time: 0.4301  last_time: 0.4296  data_time: 0.0031  last_data_time: 0.0029   lr: 0.0002  max_mem: 15320M
[08/30 16:19:30] d2.utils.events INFO:  eta: 0:34:04  iter: 3239  total_loss: 1.217  loss_ce: 0.0002106  loss_mask: 0.01532  loss_dice: 0.09251  loss_ce_0: 0.09016  loss_mask_0: 0.01252  loss_dice_0: 0.09995  loss_ce_1: 0.0005243  loss_mask_1: 0.01373  loss_dice_1: 0.09115  loss_ce_2: 0.0002344  loss_mask_2: 0.01488  loss_dice_2: 0.09173  loss_ce_3: 0.0002212  loss_mask_3: 0.01516  loss_dice_3: 0.09  loss_ce_4: 0.0003283  loss_mask_4: 0.01444  loss_dice_4: 0.08752  loss_ce_5: 0.0003314  loss_mask_5: 0.0143  loss_dice_5: 0.08761  loss_ce_6: 0.0003684  loss_mask_6: 0.01446  loss_dice_6: 0.08859  loss_ce_7: 0.0005826  loss_mask_7: 0.01479  loss_dice_7: 0.08963  loss_ce_8: 0.0006218  loss_mask_8: 0.0153  loss_dice_8: 0.08886  loss_mgm_entropy: 0.004365    time: 0.4301  last_time: 0.4304  data_time: 0.0032  last_data_time: 0.0037   lr: 0.0002  max_mem: 15320M
[08/30 16:19:39] d2.utils.events INFO:  eta: 0:33:55  iter: 3259  total_loss: 1.132  loss_ce: 0.0001925  loss_mask: 0.01442  loss_dice: 0.08503  loss_ce_0: 0.08332  loss_mask_0: 0.01301  loss_dice_0: 0.09957  loss_ce_1: 0.0004138  loss_mask_1: 0.01439  loss_dice_1: 0.08761  loss_ce_2: 0.0001541  loss_mask_2: 0.0146  loss_dice_2: 0.08851  loss_ce_3: 0.0002267  loss_mask_3: 0.01474  loss_dice_3: 0.08487  loss_ce_4: 0.0003966  loss_mask_4: 0.0147  loss_dice_4: 0.08678  loss_ce_5: 0.0002783  loss_mask_5: 0.01442  loss_dice_5: 0.08651  loss_ce_6: 0.0002119  loss_mask_6: 0.01425  loss_dice_6: 0.08631  loss_ce_7: 0.0003483  loss_mask_7: 0.01465  loss_dice_7: 0.08975  loss_ce_8: 0.000476  loss_mask_8: 0.01414  loss_dice_8: 0.08521  loss_mgm_entropy: 0.00435    time: 0.4301  last_time: 0.4284  data_time: 0.0031  last_data_time: 0.0029   lr: 0.0002  max_mem: 15320M
[08/30 16:19:48] d2.utils.events INFO:  eta: 0:33:46  iter: 3279  total_loss: 1.156  loss_ce: 0.000194  loss_mask: 0.01436  loss_dice: 0.09151  loss_ce_0: 0.095  loss_mask_0: 0.01286  loss_dice_0: 0.09738  loss_ce_1: 0.000275  loss_mask_1: 0.0141  loss_dice_1: 0.08823  loss_ce_2: 9.719e-05  loss_mask_2: 0.01405  loss_dice_2: 0.08778  loss_ce_3: 0.0002113  loss_mask_3: 0.01471  loss_dice_3: 0.08799  loss_ce_4: 0.0003261  loss_mask_4: 0.01429  loss_dice_4: 0.09006  loss_ce_5: 0.0002827  loss_mask_5: 0.01404  loss_dice_5: 0.0897  loss_ce_6: 0.0001743  loss_mask_6: 0.01384  loss_dice_6: 0.09123  loss_ce_7: 0.0003591  loss_mask_7: 0.01416  loss_dice_7: 0.0919  loss_ce_8: 0.0002651  loss_mask_8: 0.01419  loss_dice_8: 0.08845  loss_mgm_entropy: 0.004405    time: 0.4301  last_time: 0.4287  data_time: 0.0031  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:19:56] d2.utils.events INFO:  eta: 0:33:38  iter: 3299  total_loss: 1.124  loss_ce: 0.0002306  loss_mask: 0.0152  loss_dice: 0.08713  loss_ce_0: 0.08995  loss_mask_0: 0.0119  loss_dice_0: 0.09545  loss_ce_1: 0.0003656  loss_mask_1: 0.01443  loss_dice_1: 0.08699  loss_ce_2: 0.0001429  loss_mask_2: 0.01456  loss_dice_2: 0.08296  loss_ce_3: 0.000234  loss_mask_3: 0.01437  loss_dice_3: 0.08515  loss_ce_4: 0.0002921  loss_mask_4: 0.01417  loss_dice_4: 0.08591  loss_ce_5: 0.0002965  loss_mask_5: 0.01417  loss_dice_5: 0.08794  loss_ce_6: 0.000241  loss_mask_6: 0.01451  loss_dice_6: 0.08706  loss_ce_7: 0.0003514  loss_mask_7: 0.01446  loss_dice_7: 0.08843  loss_ce_8: 0.0003016  loss_mask_8: 0.01392  loss_dice_8: 0.08538  loss_mgm_entropy: 0.004339    time: 0.4301  last_time: 0.4296  data_time: 0.0031  last_data_time: 0.0033   lr: 0.0002  max_mem: 15320M
[08/30 16:20:05] d2.utils.events INFO:  eta: 0:33:29  iter: 3319  total_loss: 1.182  loss_ce: 0.0001723  loss_mask: 0.01537  loss_dice: 0.09032  loss_ce_0: 0.08696  loss_mask_0: 0.01327  loss_dice_0: 0.09855  loss_ce_1: 0.0003408  loss_mask_1: 0.01561  loss_dice_1: 0.08969  loss_ce_2: 0.0002847  loss_mask_2: 0.01532  loss_dice_2: 0.08958  loss_ce_3: 0.000422  loss_mask_3: 0.01538  loss_dice_3: 0.08667  loss_ce_4: 0.0002846  loss_mask_4: 0.01554  loss_dice_4: 0.09275  loss_ce_5: 0.0004113  loss_mask_5: 0.01503  loss_dice_5: 0.09029  loss_ce_6: 0.0002615  loss_mask_6: 0.0152  loss_dice_6: 0.09049  loss_ce_7: 0.0002641  loss_mask_7: 0.01545  loss_dice_7: 0.08906  loss_ce_8: 0.00028  loss_mask_8: 0.01492  loss_dice_8: 0.08854  loss_mgm_entropy: 0.004307    time: 0.4301  last_time: 0.4313  data_time: 0.0032  last_data_time: 0.0038   lr: 0.0002  max_mem: 15320M
[08/30 16:20:14] d2.utils.events INFO:  eta: 0:33:21  iter: 3339  total_loss: 1.146  loss_ce: 0.0003004  loss_mask: 0.01458  loss_dice: 0.08662  loss_ce_0: 0.09916  loss_mask_0: 0.01237  loss_dice_0: 0.09702  loss_ce_1: 0.001113  loss_mask_1: 0.01499  loss_dice_1: 0.08714  loss_ce_2: 0.0002485  loss_mask_2: 0.01493  loss_dice_2: 0.08212  loss_ce_3: 0.0009213  loss_mask_3: 0.01428  loss_dice_3: 0.08597  loss_ce_4: 0.002612  loss_mask_4: 0.0161  loss_dice_4: 0.09387  loss_ce_5: 0.0004291  loss_mask_5: 0.01471  loss_dice_5: 0.08684  loss_ce_6: 0.0002057  loss_mask_6: 0.01509  loss_dice_6: 0.08446  loss_ce_7: 0.0003984  loss_mask_7: 0.0155  loss_dice_7: 0.08453  loss_ce_8: 0.0003424  loss_mask_8: 0.01465  loss_dice_8: 0.08627  loss_mgm_entropy: 0.004311    time: 0.4301  last_time: 0.4379  data_time: 0.0031  last_data_time: 0.0025   lr: 0.0002  max_mem: 15320M
[08/30 16:20:22] d2.utils.events INFO:  eta: 0:33:12  iter: 3359  total_loss: 1.215  loss_ce: 0.0002494  loss_mask: 0.01586  loss_dice: 0.08414  loss_ce_0: 0.08604  loss_mask_0: 0.01488  loss_dice_0: 0.1018  loss_ce_1: 0.00124  loss_mask_1: 0.01598  loss_dice_1: 0.08611  loss_ce_2: 0.001576  loss_mask_2: 0.01674  loss_dice_2: 0.08691  loss_ce_3: 0.003395  loss_mask_3: 0.01637  loss_dice_3: 0.08829  loss_ce_4: 0.00294  loss_mask_4: 0.01781  loss_dice_4: 0.09213  loss_ce_5: 0.001319  loss_mask_5: 0.0162  loss_dice_5: 0.08852  loss_ce_6: 0.00178  loss_mask_6: 0.01662  loss_dice_6: 0.08672  loss_ce_7: 0.00356  loss_mask_7: 0.01681  loss_dice_7: 0.08828  loss_ce_8: 0.000395  loss_mask_8: 0.01643  loss_dice_8: 0.08807  loss_mgm_entropy: 0.004339    time: 0.4301  last_time: 0.4298  data_time: 0.0030  last_data_time: 0.0033   lr: 0.0002  max_mem: 15320M
[08/30 16:20:31] d2.utils.events INFO:  eta: 0:33:03  iter: 3379  total_loss: 1.186  loss_ce: 0.00043  loss_mask: 0.01465  loss_dice: 0.09044  loss_ce_0: 0.09147  loss_mask_0: 0.01256  loss_dice_0: 0.0971  loss_ce_1: 0.001773  loss_mask_1: 0.01425  loss_dice_1: 0.08423  loss_ce_2: 0.0008532  loss_mask_2: 0.01456  loss_dice_2: 0.0896  loss_ce_3: 0.001746  loss_mask_3: 0.01442  loss_dice_3: 0.09236  loss_ce_4: 0.002495  loss_mask_4: 0.01517  loss_dice_4: 0.09016  loss_ce_5: 0.002044  loss_mask_5: 0.01522  loss_dice_5: 0.09461  loss_ce_6: 0.001823  loss_mask_6: 0.01432  loss_dice_6: 0.0893  loss_ce_7: 0.003795  loss_mask_7: 0.01482  loss_dice_7: 0.09233  loss_ce_8: 0.0009899  loss_mask_8: 0.01405  loss_dice_8: 0.08689  loss_mgm_entropy: 0.004379    time: 0.4301  last_time: 0.4290  data_time: 0.0031  last_data_time: 0.0031   lr: 0.0002  max_mem: 15320M
[08/30 16:20:39] d2.utils.events INFO:  eta: 0:32:55  iter: 3399  total_loss: 1.136  loss_ce: 0.0002269  loss_mask: 0.01402  loss_dice: 0.08723  loss_ce_0: 0.09076  loss_mask_0: 0.01232  loss_dice_0: 0.09707  loss_ce_1: 0.0008673  loss_mask_1: 0.01433  loss_dice_1: 0.08815  loss_ce_2: 0.0003964  loss_mask_2: 0.01402  loss_dice_2: 0.08722  loss_ce_3: 0.0008399  loss_mask_3: 0.01383  loss_dice_3: 0.08831  loss_ce_4: 0.001269  loss_mask_4: 0.01437  loss_dice_4: 0.08921  loss_ce_5: 0.0009551  loss_mask_5: 0.01394  loss_dice_5: 0.09168  loss_ce_6: 0.0007437  loss_mask_6: 0.01412  loss_dice_6: 0.08711  loss_ce_7: 0.0009075  loss_mask_7: 0.01438  loss_dice_7: 0.0883  loss_ce_8: 0.0005315  loss_mask_8: 0.01416  loss_dice_8: 0.08662  loss_mgm_entropy: 0.004377    time: 0.4301  last_time: 0.4293  data_time: 0.0032  last_data_time: 0.0029   lr: 0.0002  max_mem: 15320M
[08/30 16:20:48] d2.utils.events INFO:  eta: 0:32:46  iter: 3419  total_loss: 1.255  loss_ce: 0.0002228  loss_mask: 0.01627  loss_dice: 0.0923  loss_ce_0: 0.09051  loss_mask_0: 0.01454  loss_dice_0: 0.1056  loss_ce_1: 0.0007499  loss_mask_1: 0.01805  loss_dice_1: 0.09533  loss_ce_2: 0.0003923  loss_mask_2: 0.01661  loss_dice_2: 0.09269  loss_ce_3: 0.0007556  loss_mask_3: 0.01663  loss_dice_3: 0.0914  loss_ce_4: 0.00112  loss_mask_4: 0.01624  loss_dice_4: 0.09833  loss_ce_5: 0.001088  loss_mask_5: 0.01712  loss_dice_5: 0.09313  loss_ce_6: 0.0003857  loss_mask_6: 0.01638  loss_dice_6: 0.09105  loss_ce_7: 0.0008193  loss_mask_7: 0.01796  loss_dice_7: 0.09688  loss_ce_8: 0.0005319  loss_mask_8: 0.01806  loss_dice_8: 0.1019  loss_mgm_entropy: 0.004329    time: 0.4301  last_time: 0.4330  data_time: 0.0031  last_data_time: 0.0033   lr: 0.0002  max_mem: 15320M
[08/30 16:20:57] d2.utils.events INFO:  eta: 0:32:38  iter: 3439  total_loss: 1.318  loss_ce: 0.0001206  loss_mask: 0.0171  loss_dice: 0.1042  loss_ce_0: 0.08709  loss_mask_0: 0.01485  loss_dice_0: 0.1073  loss_ce_1: 0.001704  loss_mask_1: 0.01707  loss_dice_1: 0.09816  loss_ce_2: 0.001305  loss_mask_2: 0.01682  loss_dice_2: 0.09357  loss_ce_3: 0.0004772  loss_mask_3: 0.0167  loss_dice_3: 0.098  loss_ce_4: 0.0009323  loss_mask_4: 0.01772  loss_dice_4: 0.0992  loss_ce_5: 0.0006711  loss_mask_5: 0.01745  loss_dice_5: 0.1042  loss_ce_6: 0.0002911  loss_mask_6: 0.01779  loss_dice_6: 0.1003  loss_ce_7: 0.000481  loss_mask_7: 0.01768  loss_dice_7: 0.1037  loss_ce_8: 0.0004419  loss_mask_8: 0.01735  loss_dice_8: 0.1002  loss_mgm_entropy: 0.004386    time: 0.4302  last_time: 0.4306  data_time: 0.0031  last_data_time: 0.0033   lr: 0.0002  max_mem: 15320M
[08/30 16:21:05] d2.utils.events INFO:  eta: 0:32:29  iter: 3459  total_loss: 1.261  loss_ce: 0.0001946  loss_mask: 0.01694  loss_dice: 0.09213  loss_ce_0: 0.08692  loss_mask_0: 0.01443  loss_dice_0: 0.1004  loss_ce_1: 0.0005715  loss_mask_1: 0.01778  loss_dice_1: 0.09653  loss_ce_2: 0.0004839  loss_mask_2: 0.01593  loss_dice_2: 0.09237  loss_ce_3: 0.0005135  loss_mask_3: 0.01602  loss_dice_3: 0.09225  loss_ce_4: 0.004426  loss_mask_4: 0.01626  loss_dice_4: 0.09592  loss_ce_5: 0.0008891  loss_mask_5: 0.01613  loss_dice_5: 0.09702  loss_ce_6: 0.0003558  loss_mask_6: 0.01661  loss_dice_6: 0.0944  loss_ce_7: 0.0005627  loss_mask_7: 0.01707  loss_dice_7: 0.09658  loss_ce_8: 0.0005792  loss_mask_8: 0.01668  loss_dice_8: 0.09326  loss_mgm_entropy: 0.004381    time: 0.4302  last_time: 0.4296  data_time: 0.0033  last_data_time: 0.0035   lr: 0.0002  max_mem: 15320M
[08/30 16:21:14] d2.utils.events INFO:  eta: 0:32:20  iter: 3479  total_loss: 1.205  loss_ce: 0.0002552  loss_mask: 0.01496  loss_dice: 0.09023  loss_ce_0: 0.09468  loss_mask_0: 0.01452  loss_dice_0: 0.1021  loss_ce_1: 0.0004575  loss_mask_1: 0.0161  loss_dice_1: 0.09381  loss_ce_2: 0.0003485  loss_mask_2: 0.0165  loss_dice_2: 0.09341  loss_ce_3: 0.0005165  loss_mask_3: 0.0157  loss_dice_3: 0.08981  loss_ce_4: 0.002587  loss_mask_4: 0.01619  loss_dice_4: 0.09404  loss_ce_5: 0.0006967  loss_mask_5: 0.01646  loss_dice_5: 0.09343  loss_ce_6: 0.0003004  loss_mask_6: 0.01675  loss_dice_6: 0.0894  loss_ce_7: 0.0005504  loss_mask_7: 0.01623  loss_dice_7: 0.09236  loss_ce_8: 0.0002984  loss_mask_8: 0.01579  loss_dice_8: 0.09411  loss_mgm_entropy: 0.004392    time: 0.4302  last_time: 0.4295  data_time: 0.0031  last_data_time: 0.0031   lr: 0.0002  max_mem: 15320M
[08/30 16:21:23] d2.utils.events INFO:  eta: 0:32:12  iter: 3499  total_loss: 1.196  loss_ce: 0.0001779  loss_mask: 0.01501  loss_dice: 0.09071  loss_ce_0: 0.08696  loss_mask_0: 0.01347  loss_dice_0: 0.09975  loss_ce_1: 0.0005713  loss_mask_1: 0.01519  loss_dice_1: 0.09203  loss_ce_2: 0.0002421  loss_mask_2: 0.01521  loss_dice_2: 0.09185  loss_ce_3: 0.0007876  loss_mask_3: 0.01508  loss_dice_3: 0.08886  loss_ce_4: 0.001978  loss_mask_4: 0.01575  loss_dice_4: 0.0888  loss_ce_5: 0.00076  loss_mask_5: 0.01555  loss_dice_5: 0.09594  loss_ce_6: 0.0002667  loss_mask_6: 0.01579  loss_dice_6: 0.09216  loss_ce_7: 0.0005757  loss_mask_7: 0.01506  loss_dice_7: 0.09361  loss_ce_8: 0.0003422  loss_mask_8: 0.01533  loss_dice_8: 0.08894  loss_mgm_entropy: 0.00439    time: 0.4302  last_time: 0.4300  data_time: 0.0031  last_data_time: 0.0030   lr: 0.0002  max_mem: 15320M
[08/30 16:21:31] d2.utils.events INFO:  eta: 0:32:03  iter: 3519  total_loss: 1.132  loss_ce: 0.0001241  loss_mask: 0.01389  loss_dice: 0.08443  loss_ce_0: 0.09154  loss_mask_0: 0.01242  loss_dice_0: 0.09693  loss_ce_1: 0.0002922  loss_mask_1: 0.01395  loss_dice_1: 0.08563  loss_ce_2: 0.0002065  loss_mask_2: 0.0143  loss_dice_2: 0.08417  loss_ce_3: 0.0001971  loss_mask_3: 0.01399  loss_dice_3: 0.08498  loss_ce_4: 0.0005386  loss_mask_4: 0.01465  loss_dice_4: 0.08653  loss_ce_5: 0.0003409  loss_mask_5: 0.0147  loss_dice_5: 0.08809  loss_ce_6: 0.0002538  loss_mask_6: 0.01459  loss_dice_6: 0.08895  loss_ce_7: 0.0004698  loss_mask_7: 0.01469  loss_dice_7: 0.09176  loss_ce_8: 0.0002752  loss_mask_8: 0.01466  loss_dice_8: 0.08299  loss_mgm_entropy: 0.004375    time: 0.4302  last_time: 0.4330  data_time: 0.0032  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:21:40] d2.utils.events INFO:  eta: 0:31:55  iter: 3539  total_loss: 1.151  loss_ce: 0.0001153  loss_mask: 0.01543  loss_dice: 0.08764  loss_ce_0: 0.0844  loss_mask_0: 0.0126  loss_dice_0: 0.09566  loss_ce_1: 0.0002611  loss_mask_1: 0.01551  loss_dice_1: 0.08863  loss_ce_2: 0.0001934  loss_mask_2: 0.01508  loss_dice_2: 0.08681  loss_ce_3: 0.0001797  loss_mask_3: 0.01429  loss_dice_3: 0.0877  loss_ce_4: 0.0004903  loss_mask_4: 0.01487  loss_dice_4: 0.08878  loss_ce_5: 0.000305  loss_mask_5: 0.01457  loss_dice_5: 0.08908  loss_ce_6: 0.0003104  loss_mask_6: 0.01484  loss_dice_6: 0.09102  loss_ce_7: 0.0003944  loss_mask_7: 0.01529  loss_dice_7: 0.08754  loss_ce_8: 0.0003122  loss_mask_8: 0.01456  loss_dice_8: 0.08955  loss_mgm_entropy: 0.004355    time: 0.4302  last_time: 0.4275  data_time: 0.0031  last_data_time: 0.0031   lr: 0.0002  max_mem: 15320M
[08/30 16:21:48] d2.utils.events INFO:  eta: 0:31:46  iter: 3559  total_loss: 1.165  loss_ce: 0.0001632  loss_mask: 0.0142  loss_dice: 0.09345  loss_ce_0: 0.09067  loss_mask_0: 0.01169  loss_dice_0: 0.09751  loss_ce_1: 0.0002681  loss_mask_1: 0.01413  loss_dice_1: 0.09091  loss_ce_2: 0.0002159  loss_mask_2: 0.01442  loss_dice_2: 0.08727  loss_ce_3: 0.000592  loss_mask_3: 0.01402  loss_dice_3: 0.08923  loss_ce_4: 0.001049  loss_mask_4: 0.01423  loss_dice_4: 0.09059  loss_ce_5: 0.000687  loss_mask_5: 0.0147  loss_dice_5: 0.09484  loss_ce_6: 0.0003779  loss_mask_6: 0.01427  loss_dice_6: 0.0934  loss_ce_7: 0.0004731  loss_mask_7: 0.0151  loss_dice_7: 0.0941  loss_ce_8: 0.0006016  loss_mask_8: 0.01485  loss_dice_8: 0.09253  loss_mgm_entropy: 0.004346    time: 0.4302  last_time: 0.4304  data_time: 0.0031  last_data_time: 0.0029   lr: 0.0002  max_mem: 15320M
[08/30 16:21:57] d2.utils.events INFO:  eta: 0:31:37  iter: 3579  total_loss: 1.195  loss_ce: 0.000144  loss_mask: 0.01461  loss_dice: 0.09242  loss_ce_0: 0.08324  loss_mask_0: 0.01229  loss_dice_0: 0.1003  loss_ce_1: 0.0001876  loss_mask_1: 0.01434  loss_dice_1: 0.09402  loss_ce_2: 0.0001507  loss_mask_2: 0.01432  loss_dice_2: 0.09215  loss_ce_3: 0.0001909  loss_mask_3: 0.01434  loss_dice_3: 0.09172  loss_ce_4: 0.0004552  loss_mask_4: 0.01462  loss_dice_4: 0.09229  loss_ce_5: 0.0003669  loss_mask_5: 0.01434  loss_dice_5: 0.09101  loss_ce_6: 0.0001778  loss_mask_6: 0.01481  loss_dice_6: 0.09312  loss_ce_7: 0.0002651  loss_mask_7: 0.0148  loss_dice_7: 0.09199  loss_ce_8: 0.0002182  loss_mask_8: 0.01415  loss_dice_8: 0.0889  loss_mgm_entropy: 0.004365    time: 0.4302  last_time: 0.4297  data_time: 0.0031  last_data_time: 0.0033   lr: 0.0002  max_mem: 15320M
[08/30 16:22:06] d2.utils.events INFO:  eta: 0:31:29  iter: 3599  total_loss: 1.143  loss_ce: 0.0001129  loss_mask: 0.01461  loss_dice: 0.08915  loss_ce_0: 0.08327  loss_mask_0: 0.01289  loss_dice_0: 0.09603  loss_ce_1: 8.435e-05  loss_mask_1: 0.01488  loss_dice_1: 0.08698  loss_ce_2: 8.939e-05  loss_mask_2: 0.01455  loss_dice_2: 0.08931  loss_ce_3: 0.0001312  loss_mask_3: 0.01469  loss_dice_3: 0.08339  loss_ce_4: 0.0003615  loss_mask_4: 0.01451  loss_dice_4: 0.08859  loss_ce_5: 0.0002593  loss_mask_5: 0.0143  loss_dice_5: 0.08696  loss_ce_6: 0.0001698  loss_mask_6: 0.0147  loss_dice_6: 0.09004  loss_ce_7: 0.0001952  loss_mask_7: 0.01481  loss_dice_7: 0.08701  loss_ce_8: 0.0002233  loss_mask_8: 0.01411  loss_dice_8: 0.0859  loss_mgm_entropy: 0.004383    time: 0.4302  last_time: 0.4418  data_time: 0.0032  last_data_time: 0.0040   lr: 0.0002  max_mem: 15320M
[08/30 16:22:14] d2.utils.events INFO:  eta: 0:31:20  iter: 3619  total_loss: 1.086  loss_ce: 0.0001265  loss_mask: 0.0142  loss_dice: 0.0853  loss_ce_0: 0.0874  loss_mask_0: 0.01225  loss_dice_0: 0.08919  loss_ce_1: 0.0001485  loss_mask_1: 0.01408  loss_dice_1: 0.08297  loss_ce_2: 9.874e-05  loss_mask_2: 0.01403  loss_dice_2: 0.084  loss_ce_3: 0.0001378  loss_mask_3: 0.01373  loss_dice_3: 0.08366  loss_ce_4: 0.0002238  loss_mask_4: 0.01455  loss_dice_4: 0.08384  loss_ce_5: 0.0002205  loss_mask_5: 0.0137  loss_dice_5: 0.08397  loss_ce_6: 0.0001714  loss_mask_6: 0.01446  loss_dice_6: 0.08274  loss_ce_7: 0.0002934  loss_mask_7: 0.01359  loss_dice_7: 0.07951  loss_ce_8: 0.0001739  loss_mask_8: 0.01407  loss_dice_8: 0.08189  loss_mgm_entropy: 0.004333    time: 0.4302  last_time: 0.4291  data_time: 0.0032  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:22:23] d2.utils.events INFO:  eta: 0:31:12  iter: 3639  total_loss: 1.088  loss_ce: 0.0004189  loss_mask: 0.01488  loss_dice: 0.08425  loss_ce_0: 0.1001  loss_mask_0: 0.01327  loss_dice_0: 0.09269  loss_ce_1: 0.0001542  loss_mask_1: 0.015  loss_dice_1: 0.08416  loss_ce_2: 0.0001965  loss_mask_2: 0.01444  loss_dice_2: 0.08401  loss_ce_3: 0.0003783  loss_mask_3: 0.01486  loss_dice_3: 0.08383  loss_ce_4: 0.0005866  loss_mask_4: 0.01513  loss_dice_4: 0.08517  loss_ce_5: 0.0005012  loss_mask_5: 0.01522  loss_dice_5: 0.08892  loss_ce_6: 0.0002835  loss_mask_6: 0.0156  loss_dice_6: 0.0842  loss_ce_7: 0.0006258  loss_mask_7: 0.0149  loss_dice_7: 0.08466  loss_ce_8: 0.0003367  loss_mask_8: 0.0147  loss_dice_8: 0.08311  loss_mgm_entropy: 0.004355    time: 0.4302  last_time: 0.4298  data_time: 0.0031  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:22:32] d2.utils.events INFO:  eta: 0:31:03  iter: 3659  total_loss: 1.193  loss_ce: 0.0001741  loss_mask: 0.01441  loss_dice: 0.09511  loss_ce_0: 0.08432  loss_mask_0: 0.01253  loss_dice_0: 0.1002  loss_ce_1: 0.0001964  loss_mask_1: 0.01398  loss_dice_1: 0.0919  loss_ce_2: 0.0002194  loss_mask_2: 0.01469  loss_dice_2: 0.09592  loss_ce_3: 0.000266  loss_mask_3: 0.01445  loss_dice_3: 0.09195  loss_ce_4: 0.0004171  loss_mask_4: 0.01427  loss_dice_4: 0.09199  loss_ce_5: 0.0003131  loss_mask_5: 0.01445  loss_dice_5: 0.09739  loss_ce_6: 0.0002141  loss_mask_6: 0.01438  loss_dice_6: 0.09391  loss_ce_7: 0.000368  loss_mask_7: 0.01474  loss_dice_7: 0.09604  loss_ce_8: 0.0002612  loss_mask_8: 0.01452  loss_dice_8: 0.09402  loss_mgm_entropy: 0.00433    time: 0.4302  last_time: 0.4287  data_time: 0.0031  last_data_time: 0.0028   lr: 0.0002  max_mem: 15320M
[08/30 16:22:40] d2.utils.events INFO:  eta: 0:30:55  iter: 3679  total_loss: 1.204  loss_ce: 0.0001981  loss_mask: 0.01607  loss_dice: 0.08942  loss_ce_0: 0.0879  loss_mask_0: 0.01394  loss_dice_0: 0.09925  loss_ce_1: 0.0001434  loss_mask_1: 0.01553  loss_dice_1: 0.08852  loss_ce_2: 0.000152  loss_mask_2: 0.01543  loss_dice_2: 0.08657  loss_ce_3: 0.0002619  loss_mask_3: 0.01631  loss_dice_3: 0.08967  loss_ce_4: 0.0004108  loss_mask_4: 0.01564  loss_dice_4: 0.0874  loss_ce_5: 0.0002771  loss_mask_5: 0.01567  loss_dice_5: 0.08798  loss_ce_6: 0.0002448  loss_mask_6: 0.01604  loss_dice_6: 0.0848  loss_ce_7: 0.0002878  loss_mask_7: 0.01582  loss_dice_7: 0.08806  loss_ce_8: 0.0003425  loss_mask_8: 0.01483  loss_dice_8: 0.09349  loss_mgm_entropy: 0.004268    time: 0.4302  last_time: 0.4283  data_time: 0.0033  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:22:49] d2.utils.events INFO:  eta: 0:30:47  iter: 3699  total_loss: 1.172  loss_ce: 0.000241  loss_mask: 0.01487  loss_dice: 0.09072  loss_ce_0: 0.09168  loss_mask_0: 0.01301  loss_dice_0: 0.09793  loss_ce_1: 0.000263  loss_mask_1: 0.01438  loss_dice_1: 0.09123  loss_ce_2: 0.0003101  loss_mask_2: 0.01505  loss_dice_2: 0.08633  loss_ce_3: 0.0005239  loss_mask_3: 0.01441  loss_dice_3: 0.08855  loss_ce_4: 0.0004582  loss_mask_4: 0.01467  loss_dice_4: 0.08976  loss_ce_5: 0.000365  loss_mask_5: 0.01466  loss_dice_5: 0.08815  loss_ce_6: 0.0002702  loss_mask_6: 0.01469  loss_dice_6: 0.08679  loss_ce_7: 0.0003663  loss_mask_7: 0.01557  loss_dice_7: 0.08946  loss_ce_8: 0.0002992  loss_mask_8: 0.01501  loss_dice_8: 0.09355  loss_mgm_entropy: 0.004311    time: 0.4302  last_time: 0.4287  data_time: 0.0032  last_data_time: 0.0028   lr: 0.0002  max_mem: 15320M
[08/30 16:22:57] d2.utils.events INFO:  eta: 0:30:38  iter: 3719  total_loss: 1.092  loss_ce: 0.0001785  loss_mask: 0.01494  loss_dice: 0.08319  loss_ce_0: 0.0913  loss_mask_0: 0.01367  loss_dice_0: 0.09179  loss_ce_1: 0.0002371  loss_mask_1: 0.01521  loss_dice_1: 0.08093  loss_ce_2: 0.0002675  loss_mask_2: 0.01493  loss_dice_2: 0.08227  loss_ce_3: 0.0003724  loss_mask_3: 0.01494  loss_dice_3: 0.08265  loss_ce_4: 0.0006827  loss_mask_4: 0.01542  loss_dice_4: 0.08354  loss_ce_5: 0.0003059  loss_mask_5: 0.01494  loss_dice_5: 0.08365  loss_ce_6: 0.0001612  loss_mask_6: 0.0155  loss_dice_6: 0.08258  loss_ce_7: 0.000233  loss_mask_7: 0.01558  loss_dice_7: 0.08492  loss_ce_8: 0.000205  loss_mask_8: 0.01628  loss_dice_8: 0.08573  loss_mgm_entropy: 0.004276    time: 0.4302  last_time: 0.4296  data_time: 0.0032  last_data_time: 0.0033   lr: 0.0002  max_mem: 15320M
[08/30 16:23:06] d2.utils.events INFO:  eta: 0:30:29  iter: 3739  total_loss: 1.126  loss_ce: 0.000163  loss_mask: 0.01503  loss_dice: 0.08713  loss_ce_0: 0.08747  loss_mask_0: 0.01386  loss_dice_0: 0.09477  loss_ce_1: 0.0001554  loss_mask_1: 0.01621  loss_dice_1: 0.0869  loss_ce_2: 0.0001108  loss_mask_2: 0.0154  loss_dice_2: 0.08576  loss_ce_3: 0.0001225  loss_mask_3: 0.0151  loss_dice_3: 0.08498  loss_ce_4: 0.0002046  loss_mask_4: 0.01496  loss_dice_4: 0.0862  loss_ce_5: 0.0002633  loss_mask_5: 0.01633  loss_dice_5: 0.08629  loss_ce_6: 0.0001024  loss_mask_6: 0.01533  loss_dice_6: 0.08849  loss_ce_7: 0.0002339  loss_mask_7: 0.01647  loss_dice_7: 0.08604  loss_ce_8: 0.0001474  loss_mask_8: 0.01612  loss_dice_8: 0.08941  loss_mgm_entropy: 0.004272    time: 0.4302  last_time: 0.4322  data_time: 0.0032  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:23:15] d2.utils.events INFO:  eta: 0:30:21  iter: 3759  total_loss: 1.124  loss_ce: 0.0003942  loss_mask: 0.01404  loss_dice: 0.08511  loss_ce_0: 0.09223  loss_mask_0: 0.01242  loss_dice_0: 0.09153  loss_ce_1: 0.0001902  loss_mask_1: 0.01437  loss_dice_1: 0.08348  loss_ce_2: 0.0001507  loss_mask_2: 0.01463  loss_dice_2: 0.08376  loss_ce_3: 0.0002653  loss_mask_3: 0.01534  loss_dice_3: 0.08345  loss_ce_4: 0.0004538  loss_mask_4: 0.01487  loss_dice_4: 0.08368  loss_ce_5: 0.0003471  loss_mask_5: 0.01466  loss_dice_5: 0.08576  loss_ce_6: 0.0001719  loss_mask_6: 0.0149  loss_dice_6: 0.0842  loss_ce_7: 0.0003562  loss_mask_7: 0.01549  loss_dice_7: 0.08709  loss_ce_8: 0.0002249  loss_mask_8: 0.01453  loss_dice_8: 0.08414  loss_mgm_entropy: 0.004274    time: 0.4302  last_time: 0.4323  data_time: 0.0032  last_data_time: 0.0031   lr: 0.0002  max_mem: 15320M
[08/30 16:23:23] d2.utils.events INFO:  eta: 0:30:12  iter: 3779  total_loss: 1.06  loss_ce: 0.0001011  loss_mask: 0.01431  loss_dice: 0.08003  loss_ce_0: 0.09203  loss_mask_0: 0.01237  loss_dice_0: 0.08661  loss_ce_1: 0.000175  loss_mask_1: 0.014  loss_dice_1: 0.08365  loss_ce_2: 0.000132  loss_mask_2: 0.01417  loss_dice_2: 0.08078  loss_ce_3: 0.0002583  loss_mask_3: 0.01388  loss_dice_3: 0.07958  loss_ce_4: 0.0004855  loss_mask_4: 0.01445  loss_dice_4: 0.08112  loss_ce_5: 0.0006081  loss_mask_5: 0.01377  loss_dice_5: 0.0812  loss_ce_6: 0.0001964  loss_mask_6: 0.01507  loss_dice_6: 0.08351  loss_ce_7: 0.0003984  loss_mask_7: 0.01396  loss_dice_7: 0.08074  loss_ce_8: 0.0001727  loss_mask_8: 0.01426  loss_dice_8: 0.08194  loss_mgm_entropy: 0.004294    time: 0.4302  last_time: 0.4295  data_time: 0.0031  last_data_time: 0.0030   lr: 0.0002  max_mem: 15320M
[08/30 16:23:32] d2.utils.events INFO:  eta: 0:30:04  iter: 3799  total_loss: 1.209  loss_ce: 0.0001318  loss_mask: 0.01403  loss_dice: 0.08782  loss_ce_0: 0.09249  loss_mask_0: 0.01239  loss_dice_0: 0.09561  loss_ce_1: 0.0007388  loss_mask_1: 0.01475  loss_dice_1: 0.09097  loss_ce_2: 0.0004751  loss_mask_2: 0.01422  loss_dice_2: 0.08593  loss_ce_3: 0.001196  loss_mask_3: 0.01411  loss_dice_3: 0.09033  loss_ce_4: 0.005169  loss_mask_4: 0.01498  loss_dice_4: 0.08887  loss_ce_5: 0.004965  loss_mask_5: 0.01431  loss_dice_5: 0.09099  loss_ce_6: 0.00157  loss_mask_6: 0.01452  loss_dice_6: 0.08896  loss_ce_7: 0.001431  loss_mask_7: 0.01411  loss_dice_7: 0.08582  loss_ce_8: 0.0003251  loss_mask_8: 0.01392  loss_dice_8: 0.08689  loss_mgm_entropy: 0.004292    time: 0.4302  last_time: 0.4415  data_time: 0.0031  last_data_time: 0.0034   lr: 0.0002  max_mem: 15320M
[08/30 16:23:41] d2.utils.events INFO:  eta: 0:29:55  iter: 3819  total_loss: 1.121  loss_ce: 0.0001011  loss_mask: 0.01301  loss_dice: 0.08487  loss_ce_0: 0.09231  loss_mask_0: 0.01092  loss_dice_0: 0.09081  loss_ce_1: 0.000573  loss_mask_1: 0.01234  loss_dice_1: 0.08319  loss_ce_2: 0.001182  loss_mask_2: 0.01374  loss_dice_2: 0.08456  loss_ce_3: 0.001372  loss_mask_3: 0.01357  loss_dice_3: 0.08579  loss_ce_4: 0.0008625  loss_mask_4: 0.01295  loss_dice_4: 0.08563  loss_ce_5: 0.005433  loss_mask_5: 0.01311  loss_dice_5: 0.08559  loss_ce_6: 0.001345  loss_mask_6: 0.01301  loss_dice_6: 0.08241  loss_ce_7: 0.001331  loss_mask_7: 0.01338  loss_dice_7: 0.08588  loss_ce_8: 0.0003935  loss_mask_8: 0.01381  loss_dice_8: 0.08425  loss_mgm_entropy: 0.004275    time: 0.4302  last_time: 0.4300  data_time: 0.0032  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:23:49] d2.utils.events INFO:  eta: 0:29:47  iter: 3839  total_loss: 1.245  loss_ce: 0.0002138  loss_mask: 0.01482  loss_dice: 0.08779  loss_ce_0: 0.08495  loss_mask_0: 0.01241  loss_dice_0: 0.09123  loss_ce_1: 0.0003481  loss_mask_1: 0.01508  loss_dice_1: 0.08935  loss_ce_2: 0.0002074  loss_mask_2: 0.01326  loss_dice_2: 0.08503  loss_ce_3: 0.0005272  loss_mask_3: 0.01365  loss_dice_3: 0.08516  loss_ce_4: 0.001174  loss_mask_4: 0.01426  loss_dice_4: 0.08493  loss_ce_5: 0.003267  loss_mask_5: 0.01484  loss_dice_5: 0.09168  loss_ce_6: 0.001724  loss_mask_6: 0.01425  loss_dice_6: 0.08781  loss_ce_7: 0.0006642  loss_mask_7: 0.01528  loss_dice_7: 0.08903  loss_ce_8: 0.005399  loss_mask_8: 0.01512  loss_dice_8: 0.08827  loss_mgm_entropy: 0.004257    time: 0.4302  last_time: 0.4286  data_time: 0.0031  last_data_time: 0.0026   lr: 0.0002  max_mem: 15320M
[08/30 16:23:58] d2.utils.events INFO:  eta: 0:29:38  iter: 3859  total_loss: 1.304  loss_ce: 0.003501  loss_mask: 0.0151  loss_dice: 0.09444  loss_ce_0: 0.09218  loss_mask_0: 0.01373  loss_dice_0: 0.1054  loss_ce_1: 0.0008601  loss_mask_1: 0.01437  loss_dice_1: 0.09268  loss_ce_2: 0.0003887  loss_mask_2: 0.01525  loss_dice_2: 0.08899  loss_ce_3: 0.001844  loss_mask_3: 0.01548  loss_dice_3: 0.0962  loss_ce_4: 0.001141  loss_mask_4: 0.015  loss_dice_4: 0.09037  loss_ce_5: 0.004358  loss_mask_5: 0.01576  loss_dice_5: 0.09369  loss_ce_6: 0.002194  loss_mask_6: 0.01478  loss_dice_6: 0.09072  loss_ce_7: 0.002758  loss_mask_7: 0.0159  loss_dice_7: 0.09882  loss_ce_8: 0.0045  loss_mask_8: 0.01573  loss_dice_8: 0.09724  loss_mgm_entropy: 0.004255    time: 0.4302  last_time: 0.4298  data_time: 0.0033  last_data_time: 0.0034   lr: 0.0002  max_mem: 15320M
[08/30 16:24:07] d2.utils.events INFO:  eta: 0:29:30  iter: 3879  total_loss: 1.233  loss_ce: 0.0127  loss_mask: 0.01482  loss_dice: 0.08726  loss_ce_0: 0.08334  loss_mask_0: 0.01414  loss_dice_0: 0.09552  loss_ce_1: 0.002487  loss_mask_1: 0.01515  loss_dice_1: 0.08584  loss_ce_2: 0.0007009  loss_mask_2: 0.01499  loss_dice_2: 0.08474  loss_ce_3: 0.001138  loss_mask_3: 0.01537  loss_dice_3: 0.08391  loss_ce_4: 0.0005152  loss_mask_4: 0.01565  loss_dice_4: 0.08657  loss_ce_5: 0.00257  loss_mask_5: 0.01621  loss_dice_5: 0.08518  loss_ce_6: 0.00129  loss_mask_6: 0.01565  loss_dice_6: 0.08758  loss_ce_7: 0.003444  loss_mask_7: 0.01601  loss_dice_7: 0.0918  loss_ce_8: 0.009078  loss_mask_8: 0.01536  loss_dice_8: 0.0875  loss_mgm_entropy: 0.004318    time: 0.4302  last_time: 0.4293  data_time: 0.0032  last_data_time: 0.0032   lr: 0.0002  max_mem: 15320M
[08/30 16:24:15] d2.utils.events INFO:  eta: 0:29:21  iter: 3899  total_loss: 1.326  loss_ce: 0.03276  loss_mask: 0.01525  loss_dice: 0.09882  loss_ce_0: 0.08277  loss_mask_0: 0.01253  loss_dice_0: 0.09724  loss_ce_1: 0.0009804  loss_mask_1: 0.01437  loss_dice_1: 0.09468  loss_ce_2: 0.0001803  loss_mask_2: 0.01377  loss_dice_2: 0.0897  loss_ce_3: 0.0004178  loss_mask_3: 0.01392  loss_dice_3: 0.09329  loss_ce_4: 0.0009551  loss_mask_4: 0.01457  loss_dice_4: 0.09174  loss_ce_5: 0.002046  loss_mask_5: 0.01499  loss_dice_5: 0.09329  loss_ce_6: 0.001756  loss_mask_6: 0.01503  loss_dice_6: 0.09369  loss_ce_7: 0.03838  loss_mask_7: 0.01641  loss_dice_7: 0.1022  loss_ce_8: 0.004986  loss_mask_8: 0.0162  loss_dice_8: 0.098  loss_mgm_entropy: 0.004279    time: 0.4302  last_time: 0.4297  data_time: 0.0032  last_data_time: 0.0029   lr: 0.0002  max_mem: 15320M
[08/30 16:24:24] d2.utils.events INFO:  eta: 0:29:13  iter: 3919  total_loss: 2.294  loss_ce: 0.1638  loss_mask: 0.01802  loss_dice: 0.114  loss_ce_0: 0.0825  loss_mask_0: 0.01511  loss_dice_0: 0.111  loss_ce_1: 0.001351  loss_mask_1: 0.01719  loss_dice_1: 0.107  loss_ce_2: 0.0004843  loss_mask_2: 0.01742  loss_dice_2: 0.1069  loss_ce_3: 0.00154  loss_mask_3: 0.01655  loss_dice_3: 0.1046  loss_ce_4: 0.006147  loss_mask_4: 0.01691  loss_dice_4: 0.1065  loss_ce_5: 0.05227  loss_mask_5: 0.01807  loss_dice_5: 0.1184  loss_ce_6: 0.08583  loss_mask_6: 0.01832  loss_dice_6: 0.1246  loss_ce_7: 0.1492  loss_mask_7: 0.01811  loss_dice_7: 0.1313  loss_ce_8: 0.1496  loss_mask_8: 0.02545  loss_dice_8: 0.1501  loss_mgm_entropy: 0.004313    time: 0.4302  last_time: 0.4297  data_time: 0.0031  last_data_time: 0.0030   lr: 0.0002  max_mem: 15320M
[08/30 16:24:32] d2.utils.events INFO:  eta: 0:29:04  iter: 3939  total_loss: 2.498  loss_ce: 0.13  loss_mask: 0.02598  loss_dice: 0.1515  loss_ce_0: 0.09121  loss_mask_0: 0.02025  loss_dice_0: 0.1354  loss_ce_1: 0.07608  loss_mask_1: 0.02108  loss_dice_1: 0.1155  loss_ce_2: 0.02059  loss_mask_2: 0.02008  loss_dice_2: 0.1203  loss_ce_3: 0.02944  loss_mask_3: 0.02084  loss_dice_3: 0.1211  loss_ce_4: 0.02519  loss_mask_4: 0.02391  loss_dice_4: 0.1477  loss_ce_5: 0.0892  loss_mask_5: 0.02038  loss_dice_5: 0.1306  loss_ce_6: 0.06113  loss_mask_6: 0.02575  loss_dice_6: 0.1461  loss_ce_7: 0.1056  loss_mask_7: 0.02514  loss_dice_7: 0.1579  loss_ce_8: 0.08141  loss_mask_8: 0.02895  loss_dice_8: 0.1717  loss_mgm_entropy: 0.004232    time: 0.4302  last_time: 0.4289  data_time: 0.0031  last_data_time: 0.0039   lr: 0.0002  max_mem: 15320M
[08/30 16:24:41] d2.utils.events INFO:  eta: 0:28:55  iter: 3959  total_loss: 3.803  loss_ce: 0.1074  loss_mask: 0.03592  loss_dice: 0.2056  loss_ce_0: 0.08391  loss_mask_0: 0.02344  loss_dice_0: 0.1728  loss_ce_1: 0.05952  loss_mask_1: 0.02875  loss_dice_1: 0.1653  loss_ce_2: 0.06071  loss_mask_2: 0.02713  loss_dice_2: 0.1702  loss_ce_3: 0.1483  loss_mask_3: 0.0302  loss_dice_3: 0.1923  loss_ce_4: 0.09902  loss_mask_4: 0.0344  loss_dice_4: 0.1909  loss_ce_5: 0.1001  loss_mask_5: 0.03234  loss_dice_5: 0.1917  loss_ce_6: 0.1093  loss_mask_6: 0.03263  loss_dice_6: 0.184  loss_ce_7: 0.1191  loss_mask_7: 0.0376  loss_dice_7: 0.211  loss_ce_8: 0.1289  loss_mask_8: 0.03418  loss_dice_8: 0.2371  loss_mgm_entropy: 0.004158    time: 0.4302  last_time: 0.4307  data_time: 0.0033  last_data_time: 0.0038   lr: 0.0002  max_mem: 15320M
[08/30 16:24:50] d2.utils.events INFO:  eta: 0:28:47  iter: 3979  total_loss: 4.001  loss_ce: 0.09208  loss_mask: 0.04638  loss_dice: 0.2483  loss_ce_0: 0.09855  loss_mask_0: 0.02983  loss_dice_0: 0.2463  loss_ce_1: 0.04838  loss_mask_1: 0.03618  loss_dice_1: 0.2229  loss_ce_2: 0.03818  loss_mask_2: 0.03431  loss_dice_2: 0.2086  loss_ce_3: 0.05076  loss_mask_3: 0.05061  loss_dice_3: 0.2564  loss_ce_4: 0.08672  loss_mask_4: 0.04421  loss_dice_4: 0.263  loss_ce_5: 0.06953  loss_mask_5: 0.05078  loss_dice_5: 0.2582  loss_ce_6: 0.08043  loss_mask_6: 0.04512  loss_dice_6: 0.2538  loss_ce_7: 0.1562  loss_mask_7: 0.04982  loss_dice_7: 0.2803  loss_ce_8: 0.09786  loss_mask_8: 0.04148  loss_dice_8: 0.2557  loss_mgm_entropy: 0.004125    time: 0.4302  last_time: 0.4303  data_time: 0.0032  last_data_time: 0.0028   lr: 0.0002  max_mem: 15320M
[08/30 16:24:58] d2.utils.events INFO:  eta: 0:28:38  iter: 3999  total_loss: 5.06  loss_ce: 0.06116  loss_mask: 0.0678  loss_dice: 0.3472  loss_ce_0: 0.09522  loss_mask_0: 0.06813  loss_dice_0: 0.354  loss_ce_1: 0.0597  loss_mask_1: 0.08586  loss_dice_1: 0.335  loss_ce_2: 0.02658  loss_mask_2: 0.09212  loss_dice_2: 0.3481  loss_ce_3: 0.07236  loss_mask_3: 0.08391  loss_dice_3: 0.3717  loss_ce_4: 0.07864  loss_mask_4: 0.07145  loss_dice_4: 0.3384  loss_ce_5: 0.07557  loss_mask_5: 0.07564  loss_dice_5: 0.3656  loss_ce_6: 0.08255  loss_mask_6: 0.07777  loss_dice_6: 0.3457  loss_ce_7: 0.08781  loss_mask_7: 0.08586  loss_dice_7: 0.3671  loss_ce_8: 0.0858  loss_mask_8: 0.09001  loss_dice_8: 0.3988  loss_mgm_entropy: 0.004144    time: 0.4302  last_time: 0.4316  data_time: 0.0032  last_data_time: 0.0031   lr: 0.0002  max_mem: 15320M
[08/30 16:25:07] d2.utils.events INFO:  eta: 0:28:30  iter: 4019  total_loss: 3.484  loss_ce: 0.05686  loss_mask: 0.04691  loss_dice: 0.2128  loss_ce_0: 0.08797  loss_mask_0: 0.04846  loss_dice_0: 0.2562  loss_ce_1: 0.02674  loss_mask_1: 0.04202  loss_dice_1: 0.2051  loss_ce_2: 0.01625  loss_mask_2: 0.04371  loss_dice_2: 0.218  loss_ce_3: 0.03359  loss_mask_3: 0.04083  loss_dice_3: 0.2041  loss_ce_4: 0.04454  loss_mask_4: 0.04236  loss_dice_4: 0.2293  loss_ce_5: 0.07778  loss_mask_5: 0.04176  loss_dice_5: 0.2184  loss_ce_6: 0.0667  loss_mask_6: 0.04508  loss_dice_6: 0.2178  loss_ce_7: 0.08473  loss_mask_7: 0.04909  loss_dice_7: 0.243  loss_ce_8: 0.05642  loss_mask_8: 0.0469  loss_dice_8: 0.2172  loss_mgm_entropy: 0.004113    time: 0.4302  last_time: 0.4297  data_time: 0.0032  last_data_time: 0.0036   lr: 2e-05  max_mem: 15320M
[08/30 16:25:15] d2.utils.events INFO:  eta: 0:28:21  iter: 4039  total_loss: 2.202  loss_ce: 0.03783  loss_mask: 0.02584  loss_dice: 0.1365  loss_ce_0: 0.09601  loss_mask_0: 0.0226  loss_dice_0: 0.1528  loss_ce_1: 0.009031  loss_mask_1: 0.02377  loss_dice_1: 0.1324  loss_ce_2: 0.007371  loss_mask_2: 0.02266  loss_dice_2: 0.1361  loss_ce_3: 0.0157  loss_mask_3: 0.02404  loss_dice_3: 0.1403  loss_ce_4: 0.03421  loss_mask_4: 0.02484  loss_dice_4: 0.1418  loss_ce_5: 0.04705  loss_mask_5: 0.02382  loss_dice_5: 0.141  loss_ce_6: 0.03318  loss_mask_6: 0.02517  loss_dice_6: 0.1448  loss_ce_7: 0.0544  loss_mask_7: 0.02553  loss_dice_7: 0.1428  loss_ce_8: 0.0477  loss_mask_8: 0.02508  loss_dice_8: 0.1383  loss_mgm_entropy: 0.004114    time: 0.4302  last_time: 0.4284  data_time: 0.0032  last_data_time: 0.0035   lr: 2e-05  max_mem: 15320M
[08/30 16:25:24] d2.utils.events INFO:  eta: 0:28:13  iter: 4059  total_loss: 2.007  loss_ce: 0.03929  loss_mask: 0.02127  loss_dice: 0.1134  loss_ce_0: 0.1049  loss_mask_0: 0.01903  loss_dice_0: 0.1288  loss_ce_1: 0.02974  loss_mask_1: 0.0204  loss_dice_1: 0.1154  loss_ce_2: 0.006052  loss_mask_2: 0.01988  loss_dice_2: 0.1098  loss_ce_3: 0.01251  loss_mask_3: 0.02179  loss_dice_3: 0.1161  loss_ce_4: 0.03927  loss_mask_4: 0.02122  loss_dice_4: 0.1142  loss_ce_5: 0.03153  loss_mask_5: 0.02152  loss_dice_5: 0.1148  loss_ce_6: 0.03035  loss_mask_6: 0.02139  loss_dice_6: 0.1153  loss_ce_7: 0.05908  loss_mask_7: 0.02066  loss_dice_7: 0.1185  loss_ce_8: 0.05099  loss_mask_8: 0.02107  loss_dice_8: 0.1103  loss_mgm_entropy: 0.004139    time: 0.4302  last_time: 0.4298  data_time: 0.0033  last_data_time: 0.0035   lr: 2e-05  max_mem: 15320M
[08/30 16:25:33] d2.utils.events INFO:  eta: 0:28:04  iter: 4079  total_loss: 1.708  loss_ce: 0.03206  loss_mask: 0.02063  loss_dice: 0.1097  loss_ce_0: 0.08793  loss_mask_0: 0.01758  loss_dice_0: 0.1272  loss_ce_1: 0.007332  loss_mask_1: 0.01973  loss_dice_1: 0.1098  loss_ce_2: 0.005579  loss_mask_2: 0.01934  loss_dice_2: 0.107  loss_ce_3: 0.01156  loss_mask_3: 0.02056  loss_dice_3: 0.1137  loss_ce_4: 0.01518  loss_mask_4: 0.01927  loss_dice_4: 0.1092  loss_ce_5: 0.03188  loss_mask_5: 0.02084  loss_dice_5: 0.1119  loss_ce_6: 0.02384  loss_mask_6: 0.01983  loss_dice_6: 0.1114  loss_ce_7: 0.05283  loss_mask_7: 0.01968  loss_dice_7: 0.1149  loss_ce_8: 0.04492  loss_mask_8: 0.02067  loss_dice_8: 0.1142  loss_mgm_entropy: 0.004124    time: 0.4302  last_time: 0.4290  data_time: 0.0030  last_data_time: 0.0028   lr: 2e-05  max_mem: 15320M
[08/30 16:25:41] d2.utils.events INFO:  eta: 0:27:55  iter: 4099  total_loss: 1.597  loss_ce: 0.02868  loss_mask: 0.01845  loss_dice: 0.1082  loss_ce_0: 0.0878  loss_mask_0: 0.01602  loss_dice_0: 0.1254  loss_ce_1: 0.00862  loss_mask_1: 0.0178  loss_dice_1: 0.1049  loss_ce_2: 0.003887  loss_mask_2: 0.01732  loss_dice_2: 0.1067  loss_ce_3: 0.008669  loss_mask_3: 0.01718  loss_dice_3: 0.1091  loss_ce_4: 0.01039  loss_mask_4: 0.01716  loss_dice_4: 0.1068  loss_ce_5: 0.01771  loss_mask_5: 0.01723  loss_dice_5: 0.1084  loss_ce_6: 0.01978  loss_mask_6: 0.01823  loss_dice_6: 0.109  loss_ce_7: 0.04162  loss_mask_7: 0.01754  loss_dice_7: 0.1135  loss_ce_8: 0.03863  loss_mask_8: 0.01691  loss_dice_8: 0.11  loss_mgm_entropy: 0.004168    time: 0.4303  last_time: 0.4314  data_time: 0.0032  last_data_time: 0.0040   lr: 2e-05  max_mem: 15320M
[08/30 16:25:50] d2.utils.events INFO:  eta: 0:27:47  iter: 4119  total_loss: 1.52  loss_ce: 0.03031  loss_mask: 0.01767  loss_dice: 0.09715  loss_ce_0: 0.09079  loss_mask_0: 0.01598  loss_dice_0: 0.1119  loss_ce_1: 0.007432  loss_mask_1: 0.01738  loss_dice_1: 0.09775  loss_ce_2: 0.003206  loss_mask_2: 0.01675  loss_dice_2: 0.09929  loss_ce_3: 0.007966  loss_mask_3: 0.01735  loss_dice_3: 0.09869  loss_ce_4: 0.0111  loss_mask_4: 0.01702  loss_dice_4: 0.1014  loss_ce_5: 0.0181  loss_mask_5: 0.01682  loss_dice_5: 0.1018  loss_ce_6: 0.01891  loss_mask_6: 0.01642  loss_dice_6: 0.09866  loss_ce_7: 0.04134  loss_mask_7: 0.01712  loss_dice_7: 0.1001  loss_ce_8: 0.03704  loss_mask_8: 0.0173  loss_dice_8: 0.1001  loss_mgm_entropy: 0.004178    time: 0.4303  last_time: 0.4293  data_time: 0.0032  last_data_time: 0.0033   lr: 2e-05  max_mem: 15320M
[08/30 16:25:59] d2.utils.events INFO:  eta: 0:27:38  iter: 4139  total_loss: 1.522  loss_ce: 0.03171  loss_mask: 0.01747  loss_dice: 0.1014  loss_ce_0: 0.09575  loss_mask_0: 0.01512  loss_dice_0: 0.1107  loss_ce_1: 0.0111  loss_mask_1: 0.01696  loss_dice_1: 0.1035  loss_ce_2: 0.003294  loss_mask_2: 0.01621  loss_dice_2: 0.1016  loss_ce_3: 0.008531  loss_mask_3: 0.0157  loss_dice_3: 0.1013  loss_ce_4: 0.01434  loss_mask_4: 0.01631  loss_dice_4: 0.1015  loss_ce_5: 0.01328  loss_mask_5: 0.01676  loss_dice_5: 0.1043  loss_ce_6: 0.01662  loss_mask_6: 0.01632  loss_dice_6: 0.1043  loss_ce_7: 0.03504  loss_mask_7: 0.01608  loss_dice_7: 0.1038  loss_ce_8: 0.03767  loss_mask_8: 0.01763  loss_dice_8: 0.1049  loss_mgm_entropy: 0.004186    time: 0.4303  last_time: 0.4297  data_time: 0.0032  last_data_time: 0.0034   lr: 2e-05  max_mem: 15320M
[08/30 16:26:07] d2.utils.events INFO:  eta: 0:27:30  iter: 4159  total_loss: 1.516  loss_ce: 0.01993  loss_mask: 0.01642  loss_dice: 0.0951  loss_ce_0: 0.09558  loss_mask_0: 0.01467  loss_dice_0: 0.1094  loss_ce_1: 0.007647  loss_mask_1: 0.0152  loss_dice_1: 0.09619  loss_ce_2: 0.002814  loss_mask_2: 0.01572  loss_dice_2: 0.094  loss_ce_3: 0.005341  loss_mask_3: 0.01577  loss_dice_3: 0.09465  loss_ce_4: 0.01231  loss_mask_4: 0.01608  loss_dice_4: 0.09693  loss_ce_5: 0.01102  loss_mask_5: 0.01651  loss_dice_5: 0.09517  loss_ce_6: 0.01792  loss_mask_6: 0.01587  loss_dice_6: 0.09955  loss_ce_7: 0.03755  loss_mask_7: 0.01589  loss_dice_7: 0.096  loss_ce_8: 0.03482  loss_mask_8: 0.01602  loss_dice_8: 0.09641  loss_mgm_entropy: 0.004243    time: 0.4303  last_time: 0.4331  data_time: 0.0032  last_data_time: 0.0038   lr: 2e-05  max_mem: 15320M
[08/30 16:26:16] d2.utils.events INFO:  eta: 0:27:21  iter: 4179  total_loss: 1.341  loss_ce: 0.02028  loss_mask: 0.01427  loss_dice: 0.09358  loss_ce_0: 0.0873  loss_mask_0: 0.01335  loss_dice_0: 0.1076  loss_ce_1: 0.00413  loss_mask_1: 0.01522  loss_dice_1: 0.0967  loss_ce_2: 0.002735  loss_mask_2: 0.0138  loss_dice_2: 0.09449  loss_ce_3: 0.004972  loss_mask_3: 0.01445  loss_dice_3: 0.09621  loss_ce_4: 0.0125  loss_mask_4: 0.01485  loss_dice_4: 0.09593  loss_ce_5: 0.01089  loss_mask_5: 0.01515  loss_dice_5: 0.09873  loss_ce_6: 0.01616  loss_mask_6: 0.01489  loss_dice_6: 0.09544  loss_ce_7: 0.03469  loss_mask_7: 0.01525  loss_dice_7: 0.103  loss_ce_8: 0.02923  loss_mask_8: 0.01452  loss_dice_8: 0.09739  loss_mgm_entropy: 0.004235    time: 0.4303  last_time: 0.4374  data_time: 0.0033  last_data_time: 0.0037   lr: 2e-05  max_mem: 15320M
[08/30 16:26:25] d2.utils.events INFO:  eta: 0:27:12  iter: 4199  total_loss: 1.362  loss_ce: 0.02345  loss_mask: 0.01507  loss_dice: 0.0919  loss_ce_0: 0.09358  loss_mask_0: 0.0137  loss_dice_0: 0.1026  loss_ce_1: 0.008291  loss_mask_1: 0.01522  loss_dice_1: 0.09344  loss_ce_2: 0.002264  loss_mask_2: 0.01463  loss_dice_2: 0.09229  loss_ce_3: 0.00585  loss_mask_3: 0.01421  loss_dice_3: 0.09378  loss_ce_4: 0.0152  loss_mask_4: 0.01504  loss_dice_4: 0.09436  loss_ce_5: 0.01275  loss_mask_5: 0.01414  loss_dice_5: 0.09035  loss_ce_6: 0.01453  loss_mask_6: 0.01549  loss_dice_6: 0.09518  loss_ce_7: 0.03398  loss_mask_7: 0.01531  loss_dice_7: 0.1006  loss_ce_8: 0.03237  loss_mask_8: 0.01482  loss_dice_8: 0.09438  loss_mgm_entropy: 0.004256    time: 0.4303  last_time: 0.4295  data_time: 0.0033  last_data_time: 0.0037   lr: 2e-05  max_mem: 15320M
[08/30 16:26:33] d2.utils.events INFO:  eta: 0:27:04  iter: 4219  total_loss: 1.378  loss_ce: 0.02075  loss_mask: 0.01529  loss_dice: 0.09051  loss_ce_0: 0.09522  loss_mask_0: 0.01257  loss_dice_0: 0.1002  loss_ce_1: 0.009632  loss_mask_1: 0.01529  loss_dice_1: 0.09189  loss_ce_2: 0.002313  loss_mask_2: 0.01497  loss_dice_2: 0.09156  loss_ce_3: 0.005226  loss_mask_3: 0.01496  loss_dice_3: 0.09192  loss_ce_4: 0.01396  loss_mask_4: 0.01553  loss_dice_4: 0.0926  loss_ce_5: 0.01126  loss_mask_5: 0.01471  loss_dice_5: 0.08991  loss_ce_6: 0.0134  loss_mask_6: 0.01442  loss_dice_6: 0.09069  loss_ce_7: 0.03034  loss_mask_7: 0.01429  loss_dice_7: 0.09309  loss_ce_8: 0.03102  loss_mask_8: 0.01499  loss_dice_8: 0.09064  loss_mgm_entropy: 0.004283    time: 0.4303  last_time: 0.4285  data_time: 0.0032  last_data_time: 0.0027   lr: 2e-05  max_mem: 15320M
[08/30 16:26:42] d2.utils.events INFO:  eta: 0:26:55  iter: 4239  total_loss: 1.303  loss_ce: 0.01927  loss_mask: 0.01589  loss_dice: 0.08797  loss_ce_0: 0.09685  loss_mask_0: 0.01341  loss_dice_0: 0.1011  loss_ce_1: 0.004945  loss_mask_1: 0.01491  loss_dice_1: 0.09238  loss_ce_2: 0.002059  loss_mask_2: 0.01527  loss_dice_2: 0.09097  loss_ce_3: 0.004043  loss_mask_3: 0.01469  loss_dice_3: 0.09161  loss_ce_4: 0.01208  loss_mask_4: 0.01499  loss_dice_4: 0.09011  loss_ce_5: 0.008598  loss_mask_5: 0.01491  loss_dice_5: 0.0903  loss_ce_6: 0.01117  loss_mask_6: 0.0145  loss_dice_6: 0.09235  loss_ce_7: 0.02836  loss_mask_7: 0.01512  loss_dice_7: 0.0925  loss_ce_8: 0.02887  loss_mask_8: 0.01465  loss_dice_8: 0.09031  loss_mgm_entropy: 0.004305    time: 0.4303  last_time: 0.4277  data_time: 0.0031  last_data_time: 0.0029   lr: 2e-05  max_mem: 15320M
[08/30 16:26:50] d2.utils.events INFO:  eta: 0:26:47  iter: 4259  total_loss: 1.299  loss_ce: 0.0167  loss_mask: 0.01466  loss_dice: 0.08621  loss_ce_0: 0.08639  loss_mask_0: 0.01287  loss_dice_0: 0.1015  loss_ce_1: 0.005588  loss_mask_1: 0.0146  loss_dice_1: 0.08926  loss_ce_2: 0.001836  loss_mask_2: 0.01438  loss_dice_2: 0.08712  loss_ce_3: 0.004264  loss_mask_3: 0.01417  loss_dice_3: 0.0873  loss_ce_4: 0.01029  loss_mask_4: 0.0146  loss_dice_4: 0.08977  loss_ce_5: 0.007905  loss_mask_5: 0.01363  loss_dice_5: 0.08953  loss_ce_6: 0.01166  loss_mask_6: 0.01442  loss_dice_6: 0.08625  loss_ce_7: 0.02906  loss_mask_7: 0.01428  loss_dice_7: 0.08801  loss_ce_8: 0.025  loss_mask_8: 0.0147  loss_dice_8: 0.08876  loss_mgm_entropy: 0.004296    time: 0.4303  last_time: 0.4292  data_time: 0.0031  last_data_time: 0.0040   lr: 2e-05  max_mem: 15320M
[08/30 16:26:59] d2.utils.events INFO:  eta: 0:26:38  iter: 4279  total_loss: 1.213  loss_ce: 0.01235  loss_mask: 0.01526  loss_dice: 0.08696  loss_ce_0: 0.08999  loss_mask_0: 0.01202  loss_dice_0: 0.09497  loss_ce_1: 0.006381  loss_mask_1: 0.01366  loss_dice_1: 0.08692  loss_ce_2: 0.001937  loss_mask_2: 0.01397  loss_dice_2: 0.08386  loss_ce_3: 0.003896  loss_mask_3: 0.0134  loss_dice_3: 0.08592  loss_ce_4: 0.008861  loss_mask_4: 0.01396  loss_dice_4: 0.08615  loss_ce_5: 0.006734  loss_mask_5: 0.01408  loss_dice_5: 0.08827  loss_ce_6: 0.01086  loss_mask_6: 0.01353  loss_dice_6: 0.08618  loss_ce_7: 0.0261  loss_mask_7: 0.01402  loss_dice_7: 0.08834  loss_ce_8: 0.0276  loss_mask_8: 0.01383  loss_dice_8: 0.08909  loss_mgm_entropy: 0.004327    time: 0.4303  last_time: 0.4283  data_time: 0.0032  last_data_time: 0.0034   lr: 2e-05  max_mem: 15320M
[08/30 16:27:08] d2.utils.events INFO:  eta: 0:26:30  iter: 4299  total_loss: 1.252  loss_ce: 0.01417  loss_mask: 0.01589  loss_dice: 0.08556  loss_ce_0: 0.09151  loss_mask_0: 0.01391  loss_dice_0: 0.09897  loss_ce_1: 0.005716  loss_mask_1: 0.01443  loss_dice_1: 0.0884  loss_ce_2: 0.002383  loss_mask_2: 0.01454  loss_dice_2: 0.09012  loss_ce_3: 0.00585  loss_mask_3: 0.01463  loss_dice_3: 0.08648  loss_ce_4: 0.007858  loss_mask_4: 0.01493  loss_dice_4: 0.09069  loss_ce_5: 0.007002  loss_mask_5: 0.01479  loss_dice_5: 0.08923  loss_ce_6: 0.01128  loss_mask_6: 0.01392  loss_dice_6: 0.08459  loss_ce_7: 0.02808  loss_mask_7: 0.01504  loss_dice_7: 0.08697  loss_ce_8: 0.02072  loss_mask_8: 0.01545  loss_dice_8: 0.08809  loss_mgm_entropy: 0.004304    time: 0.4303  last_time: 0.4328  data_time: 0.0033  last_data_time: 0.0037   lr: 2e-05  max_mem: 15320M
[08/30 16:27:16] d2.utils.events INFO:  eta: 0:26:21  iter: 4319  total_loss: 1.21  loss_ce: 0.01044  loss_mask: 0.0146  loss_dice: 0.0837  loss_ce_0: 0.08612  loss_mask_0: 0.01259  loss_dice_0: 0.08968  loss_ce_1: 0.005313  loss_mask_1: 0.01349  loss_dice_1: 0.08637  loss_ce_2: 0.001746  loss_mask_2: 0.01428  loss_dice_2: 0.08506  loss_ce_3: 0.003462  loss_mask_3: 0.01384  loss_dice_3: 0.08526  loss_ce_4: 0.007329  loss_mask_4: 0.01341  loss_dice_4: 0.0854  loss_ce_5: 0.006009  loss_mask_5: 0.01419  loss_dice_5: 0.08825  loss_ce_6: 0.00968  loss_mask_6: 0.01424  loss_dice_6: 0.0853  loss_ce_7: 0.02444  loss_mask_7: 0.01353  loss_dice_7: 0.08451  loss_ce_8: 0.02057  loss_mask_8: 0.01464  loss_dice_8: 0.08613  loss_mgm_entropy: 0.004334    time: 0.4303  last_time: 0.4313  data_time: 0.0032  last_data_time: 0.0029   lr: 2e-05  max_mem: 15320M
[08/30 16:27:25] d2.utils.events INFO:  eta: 0:26:12  iter: 4339  total_loss: 1.248  loss_ce: 0.009502  loss_mask: 0.01556  loss_dice: 0.08426  loss_ce_0: 0.1019  loss_mask_0: 0.01288  loss_dice_0: 0.09692  loss_ce_1: 0.004718  loss_mask_1: 0.01458  loss_dice_1: 0.08778  loss_ce_2: 0.001977  loss_mask_2: 0.01461  loss_dice_2: 0.08361  loss_ce_3: 0.003954  loss_mask_3: 0.01487  loss_dice_3: 0.08298  loss_ce_4: 0.007156  loss_mask_4: 0.01456  loss_dice_4: 0.08402  loss_ce_5: 0.007145  loss_mask_5: 0.01425  loss_dice_5: 0.08559  loss_ce_6: 0.009722  loss_mask_6: 0.01421  loss_dice_6: 0.083  loss_ce_7: 0.02534  loss_mask_7: 0.01391  loss_dice_7: 0.08531  loss_ce_8: 0.01635  loss_mask_8: 0.01541  loss_dice_8: 0.08681  loss_mgm_entropy: 0.004306    time: 0.4303  last_time: 0.4293  data_time: 0.0033  last_data_time: 0.0035   lr: 2e-05  max_mem: 15320M
[08/30 16:27:34] d2.utils.events INFO:  eta: 0:26:04  iter: 4359  total_loss: 1.254  loss_ce: 0.00911  loss_mask: 0.01337  loss_dice: 0.08754  loss_ce_0: 0.08963  loss_mask_0: 0.0116  loss_dice_0: 0.09759  loss_ce_1: 0.004835  loss_mask_1: 0.01253  loss_dice_1: 0.09237  loss_ce_2: 0.001374  loss_mask_2: 0.01314  loss_dice_2: 0.09184  loss_ce_3: 0.003605  loss_mask_3: 0.01259  loss_dice_3: 0.09493  loss_ce_4: 0.007618  loss_mask_4: 0.01273  loss_dice_4: 0.0919  loss_ce_5: 0.005378  loss_mask_5: 0.01307  loss_dice_5: 0.08995  loss_ce_6: 0.008616  loss_mask_6: 0.01341  loss_dice_6: 0.09319  loss_ce_7: 0.02071  loss_mask_7: 0.01247  loss_dice_7: 0.08864  loss_ce_8: 0.0209  loss_mask_8: 0.01327  loss_dice_8: 0.09079  loss_mgm_entropy: 0.004341    time: 0.4303  last_time: 0.4291  data_time: 0.0033  last_data_time: 0.0036   lr: 2e-05  max_mem: 15320M
[08/30 16:27:42] d2.utils.events INFO:  eta: 0:25:55  iter: 4379  total_loss: 1.179  loss_ce: 0.009382  loss_mask: 0.01485  loss_dice: 0.081  loss_ce_0: 0.09281  loss_mask_0: 0.01222  loss_dice_0: 0.0896  loss_ce_1: 0.00384  loss_mask_1: 0.01364  loss_dice_1: 0.08595  loss_ce_2: 0.001149  loss_mask_2: 0.01385  loss_dice_2: 0.08298  loss_ce_3: 0.003546  loss_mask_3: 0.01372  loss_dice_3: 0.08666  loss_ce_4: 0.006534  loss_mask_4: 0.01377  loss_dice_4: 0.08408  loss_ce_5: 0.005802  loss_mask_5: 0.01374  loss_dice_5: 0.08194  loss_ce_6: 0.007254  loss_mask_6: 0.01364  loss_dice_6: 0.08441  loss_ce_7: 0.02127  loss_mask_7: 0.0135  loss_dice_7: 0.0861  loss_ce_8: 0.01807  loss_mask_8: 0.01446  loss_dice_8: 0.08624  loss_mgm_entropy: 0.004342    time: 0.4303  last_time: 0.4300  data_time: 0.0032  last_data_time: 0.0033   lr: 2e-05  max_mem: 15320M
[08/30 16:27:51] d2.utils.events INFO:  eta: 0:25:47  iter: 4399  total_loss: 1.151  loss_ce: 0.007813  loss_mask: 0.01449  loss_dice: 0.07975  loss_ce_0: 0.08601  loss_mask_0: 0.01214  loss_dice_0: 0.08911  loss_ce_1: 0.005837  loss_mask_1: 0.01363  loss_dice_1: 0.08367  loss_ce_2: 0.001205  loss_mask_2: 0.0135  loss_dice_2: 0.08098  loss_ce_3: 0.003338  loss_mask_3: 0.01401  loss_dice_3: 0.07838  loss_ce_4: 0.005539  loss_mask_4: 0.01397  loss_dice_4: 0.08513  loss_ce_5: 0.004831  loss_mask_5: 0.01373  loss_dice_5: 0.0823  loss_ce_6: 0.007122  loss_mask_6: 0.01332  loss_dice_6: 0.08088  loss_ce_7: 0.02133  loss_mask_7: 0.01394  loss_dice_7: 0.08102  loss_ce_8: 0.013  loss_mask_8: 0.01501  loss_dice_8: 0.08432  loss_mgm_entropy: 0.004351    time: 0.4303  last_time: 0.4291  data_time: 0.0031  last_data_time: 0.0028   lr: 2e-05  max_mem: 15320M
[08/30 16:27:59] d2.utils.events INFO:  eta: 0:25:38  iter: 4419  total_loss: 1.207  loss_ce: 0.006911  loss_mask: 0.01321  loss_dice: 0.08483  loss_ce_0: 0.09254  loss_mask_0: 0.01219  loss_dice_0: 0.09293  loss_ce_1: 0.005259  loss_mask_1: 0.01266  loss_dice_1: 0.08464  loss_ce_2: 0.0009861  loss_mask_2: 0.01338  loss_dice_2: 0.08799  loss_ce_3: 0.002319  loss_mask_3: 0.0136  loss_dice_3: 0.08603  loss_ce_4: 0.005006  loss_mask_4: 0.01289  loss_dice_4: 0.08608  loss_ce_5: 0.004227  loss_mask_5: 0.01338  loss_dice_5: 0.08498  loss_ce_6: 0.007061  loss_mask_6: 0.01308  loss_dice_6: 0.08539  loss_ce_7: 0.01904  loss_mask_7: 0.01333  loss_dice_7: 0.08505  loss_ce_8: 0.01568  loss_mask_8: 0.01334  loss_dice_8: 0.08379  loss_mgm_entropy: 0.004378    time: 0.4303  last_time: 0.4295  data_time: 0.0033  last_data_time: 0.0034   lr: 2e-05  max_mem: 15320M
[08/30 16:28:08] d2.utils.events INFO:  eta: 0:25:29  iter: 4439  total_loss: 1.146  loss_ce: 0.005635  loss_mask: 0.01342  loss_dice: 0.08506  loss_ce_0: 0.08588  loss_mask_0: 0.01159  loss_dice_0: 0.09572  loss_ce_1: 0.003201  loss_mask_1: 0.01313  loss_dice_1: 0.0863  loss_ce_2: 0.0008297  loss_mask_2: 0.01255  loss_dice_2: 0.08402  loss_ce_3: 0.002674  loss_mask_3: 0.01299  loss_dice_3: 0.08508  loss_ce_4: 0.004516  loss_mask_4: 0.01358  loss_dice_4: 0.08356  loss_ce_5: 0.004504  loss_mask_5: 0.01285  loss_dice_5: 0.08691  loss_ce_6: 0.006479  loss_mask_6: 0.01307  loss_dice_6: 0.0844  loss_ce_7: 0.018  loss_mask_7: 0.01301  loss_dice_7: 0.08377  loss_ce_8: 0.01144  loss_mask_8: 0.0132  loss_dice_8: 0.08558  loss_mgm_entropy: 0.004337    time: 0.4303  last_time: 0.4295  data_time: 0.0031  last_data_time: 0.0026   lr: 2e-05  max_mem: 15320M
[08/30 16:28:17] d2.utils.events INFO:  eta: 0:25:21  iter: 4459  total_loss: 1.144  loss_ce: 0.009643  loss_mask: 0.01416  loss_dice: 0.08108  loss_ce_0: 0.09383  loss_mask_0: 0.01283  loss_dice_0: 0.0894  loss_ce_1: 0.003875  loss_mask_1: 0.01383  loss_dice_1: 0.08336  loss_ce_2: 0.0007054  loss_mask_2: 0.01343  loss_dice_2: 0.0812  loss_ce_3: 0.002431  loss_mask_3: 0.01324  loss_dice_3: 0.08067  loss_ce_4: 0.00653  loss_mask_4: 0.01339  loss_dice_4: 0.08308  loss_ce_5: 0.003782  loss_mask_5: 0.01325  loss_dice_5: 0.08014  loss_ce_6: 0.006531  loss_mask_6: 0.01349  loss_dice_6: 0.08094  loss_ce_7: 0.01806  loss_mask_7: 0.0142  loss_dice_7: 0.08286  loss_ce_8: 0.01456  loss_mask_8: 0.01467  loss_dice_8: 0.08429  loss_mgm_entropy: 0.004356    time: 0.4303  last_time: 0.4298  data_time: 0.0032  last_data_time: 0.0034   lr: 2e-05  max_mem: 15320M
[08/30 16:28:25] d2.utils.events INFO:  eta: 0:25:12  iter: 4479  total_loss: 1.113  loss_ce: 0.006827  loss_mask: 0.01395  loss_dice: 0.07917  loss_ce_0: 0.09385  loss_mask_0: 0.01155  loss_dice_0: 0.08767  loss_ce_1: 0.002418  loss_mask_1: 0.01347  loss_dice_1: 0.08  loss_ce_2: 0.0006742  loss_mask_2: 0.01338  loss_dice_2: 0.08054  loss_ce_3: 0.002097  loss_mask_3: 0.01314  loss_dice_3: 0.08067  loss_ce_4: 0.005004  loss_mask_4: 0.01265  loss_dice_4: 0.07823  loss_ce_5: 0.00344  loss_mask_5: 0.0128  loss_dice_5: 0.08004  loss_ce_6: 0.005151  loss_mask_6: 0.01304  loss_dice_6: 0.07951  loss_ce_7: 0.01561  loss_mask_7: 0.014  loss_dice_7: 0.08125  loss_ce_8: 0.01307  loss_mask_8: 0.01383  loss_dice_8: 0.07989  loss_mgm_entropy: 0.004347    time: 0.4303  last_time: 0.4339  data_time: 0.0032  last_data_time: 0.0036   lr: 2e-05  max_mem: 15320M
[08/30 16:28:34] d2.utils.events INFO:  eta: 0:25:03  iter: 4499  total_loss: 1.181  loss_ce: 0.007462  loss_mask: 0.01227  loss_dice: 0.08365  loss_ce_0: 0.0985  loss_mask_0: 0.01106  loss_dice_0: 0.09354  loss_ce_1: 0.003367  loss_mask_1: 0.0123  loss_dice_1: 0.08688  loss_ce_2: 0.0006394  loss_mask_2: 0.0123  loss_dice_2: 0.0861  loss_ce_3: 0.002029  loss_mask_3: 0.0123  loss_dice_3: 0.0884  loss_ce_4: 0.005729  loss_mask_4: 0.01273  loss_dice_4: 0.08834  loss_ce_5: 0.002915  loss_mask_5: 0.01228  loss_dice_5: 0.08195  loss_ce_6: 0.005337  loss_mask_6: 0.01247  loss_dice_6: 0.08573  loss_ce_7: 0.01504  loss_mask_7: 0.01264  loss_dice_7: 0.08768  loss_ce_8: 0.01419  loss_mask_8: 0.01275  loss_dice_8: 0.08754  loss_mgm_entropy: 0.004353    time: 0.4303  last_time: 0.4297  data_time: 0.0032  last_data_time: 0.0027   lr: 2e-05  max_mem: 15320M
[08/30 16:28:43] d2.utils.events INFO:  eta: 0:24:55  iter: 4519  total_loss: 1.127  loss_ce: 0.004805  loss_mask: 0.01423  loss_dice: 0.07978  loss_ce_0: 0.08574  loss_mask_0: 0.01285  loss_dice_0: 0.09066  loss_ce_1: 0.003252  loss_mask_1: 0.01372  loss_dice_1: 0.08204  loss_ce_2: 0.0007455  loss_mask_2: 0.01441  loss_dice_2: 0.08046  loss_ce_3: 0.001806  loss_mask_3: 0.01359  loss_dice_3: 0.08216  loss_ce_4: 0.003974  loss_mask_4: 0.0136  loss_dice_4: 0.08356  loss_ce_5: 0.003588  loss_mask_5: 0.01377  loss_dice_5: 0.07893  loss_ce_6: 0.004886  loss_mask_6: 0.01413  loss_dice_6: 0.07926  loss_ce_7: 0.0183  loss_mask_7: 0.01333  loss_dice_7: 0.08091  loss_ce_8: 0.01202  loss_mask_8: 0.01401  loss_dice_8: 0.08254  loss_mgm_entropy: 0.004345    time: 0.4303  last_time: 0.4309  data_time: 0.0031  last_data_time: 0.0030   lr: 2e-05  max_mem: 15320M
[08/30 16:28:51] d2.utils.events INFO:  eta: 0:24:46  iter: 4539  total_loss: 1.101  loss_ce: 0.004758  loss_mask: 0.01317  loss_dice: 0.07953  loss_ce_0: 0.09508  loss_mask_0: 0.01147  loss_dice_0: 0.08775  loss_ce_1: 0.002232  loss_mask_1: 0.01336  loss_dice_1: 0.07795  loss_ce_2: 0.0006414  loss_mask_2: 0.01349  loss_dice_2: 0.07939  loss_ce_3: 0.002011  loss_mask_3: 0.01384  loss_dice_3: 0.07945  loss_ce_4: 0.00431  loss_mask_4: 0.01294  loss_dice_4: 0.08038  loss_ce_5: 0.003333  loss_mask_5: 0.01298  loss_dice_5: 0.07828  loss_ce_6: 0.004499  loss_mask_6: 0.0131  loss_dice_6: 0.0788  loss_ce_7: 0.01249  loss_mask_7: 0.01321  loss_dice_7: 0.08033  loss_ce_8: 0.009957  loss_mask_8: 0.01296  loss_dice_8: 0.07829  loss_mgm_entropy: 0.004367    time: 0.4303  last_time: 0.4330  data_time: 0.0031  last_data_time: 0.0036   lr: 2e-05  max_mem: 15320M
[08/30 16:29:00] d2.utils.events INFO:  eta: 0:24:38  iter: 4559  total_loss: 1.107  loss_ce: 0.004535  loss_mask: 0.01389  loss_dice: 0.07878  loss_ce_0: 0.1005  loss_mask_0: 0.01179  loss_dice_0: 0.08666  loss_ce_1: 0.003361  loss_mask_1: 0.01372  loss_dice_1: 0.08121  loss_ce_2: 0.0009319  loss_mask_2: 0.01367  loss_dice_2: 0.08296  loss_ce_3: 0.002169  loss_mask_3: 0.01418  loss_dice_3: 0.08064  loss_ce_4: 0.004161  loss_mask_4: 0.01313  loss_dice_4: 0.08302  loss_ce_5: 0.003253  loss_mask_5: 0.01259  loss_dice_5: 0.08388  loss_ce_6: 0.006566  loss_mask_6: 0.01299  loss_dice_6: 0.08206  loss_ce_7: 0.01283  loss_mask_7: 0.01383  loss_dice_7: 0.08505  loss_ce_8: 0.01016  loss_mask_8: 0.01398  loss_dice_8: 0.08228  loss_mgm_entropy: 0.004373    time: 0.4303  last_time: 0.4364  data_time: 0.0031  last_data_time: 0.0029   lr: 2e-05  max_mem: 15320M
[08/30 16:29:08] d2.utils.events INFO:  eta: 0:24:29  iter: 4579  total_loss: 1.099  loss_ce: 0.004768  loss_mask: 0.01304  loss_dice: 0.08169  loss_ce_0: 0.08562  loss_mask_0: 0.01101  loss_dice_0: 0.08574  loss_ce_1: 0.004757  loss_mask_1: 0.0125  loss_dice_1: 0.08127  loss_ce_2: 0.00104  loss_mask_2: 0.01252  loss_dice_2: 0.08085  loss_ce_3: 0.002126  loss_mask_3: 0.01227  loss_dice_3: 0.07764  loss_ce_4: 0.003537  loss_mask_4: 0.0128  loss_dice_4: 0.08094  loss_ce_5: 0.00293  loss_mask_5: 0.01288  loss_dice_5: 0.08135  loss_ce_6: 0.005007  loss_mask_6: 0.01252  loss_dice_6: 0.08123  loss_ce_7: 0.01384  loss_mask_7: 0.01223  loss_dice_7: 0.08215  loss_ce_8: 0.009241  loss_mask_8: 0.01312  loss_dice_8: 0.07947  loss_mgm_entropy: 0.004374    time: 0.4303  last_time: 0.4296  data_time: 0.0032  last_data_time: 0.0035   lr: 2e-05  max_mem: 15320M
[08/30 16:29:17] d2.utils.events INFO:  eta: 0:24:21  iter: 4599  total_loss: 1.079  loss_ce: 0.003998  loss_mask: 0.01408  loss_dice: 0.07911  loss_ce_0: 0.08557  loss_mask_0: 0.01225  loss_dice_0: 0.08686  loss_ce_1: 0.003895  loss_mask_1: 0.01362  loss_dice_1: 0.07764  loss_ce_2: 0.001056  loss_mask_2: 0.0134  loss_dice_2: 0.08004  loss_ce_3: 0.002078  loss_mask_3: 0.01341  loss_dice_3: 0.07891  loss_ce_4: 0.003191  loss_mask_4: 0.01358  loss_dice_4: 0.0765  loss_ce_5: 0.002704  loss_mask_5: 0.01331  loss_dice_5: 0.07928  loss_ce_6: 0.004358  loss_mask_6: 0.01326  loss_dice_6: 0.07901  loss_ce_7: 0.01347  loss_mask_7: 0.01328  loss_dice_7: 0.07998  loss_ce_8: 0.01027  loss_mask_8: 0.01387  loss_dice_8: 0.07924  loss_mgm_entropy: 0.004336    time: 0.4303  last_time: 0.4282  data_time: 0.0032  last_data_time: 0.0033   lr: 2e-05  max_mem: 15320M
[08/30 16:29:26] d2.utils.events INFO:  eta: 0:24:12  iter: 4619  total_loss: 1.078  loss_ce: 0.002924  loss_mask: 0.01268  loss_dice: 0.07852  loss_ce_0: 0.08549  loss_mask_0: 0.01086  loss_dice_0: 0.08961  loss_ce_1: 0.003533  loss_mask_1: 0.01219  loss_dice_1: 0.08113  loss_ce_2: 0.0006303  loss_mask_2: 0.01213  loss_dice_2: 0.07815  loss_ce_3: 0.001841  loss_mask_3: 0.01197  loss_dice_3: 0.07746  loss_ce_4: 0.003136  loss_mask_4: 0.01192  loss_dice_4: 0.07982  loss_ce_5: 0.002681  loss_mask_5: 0.01231  loss_dice_5: 0.08128  loss_ce_6: 0.004245  loss_mask_6: 0.01206  loss_dice_6: 0.08252  loss_ce_7: 0.01346  loss_mask_7: 0.01196  loss_dice_7: 0.07938  loss_ce_8: 0.007817  loss_mask_8: 0.01311  loss_dice_8: 0.08149  loss_mgm_entropy: 0.004366    time: 0.4303  last_time: 0.4327  data_time: 0.0032  last_data_time: 0.0032   lr: 2e-05  max_mem: 15320M
[08/30 16:29:34] d2.utils.events INFO:  eta: 0:24:03  iter: 4639  total_loss: 1.049  loss_ce: 0.003561  loss_mask: 0.01319  loss_dice: 0.07739  loss_ce_0: 0.08885  loss_mask_0: 0.01129  loss_dice_0: 0.08521  loss_ce_1: 0.002663  loss_mask_1: 0.0126  loss_dice_1: 0.07888  loss_ce_2: 0.0005299  loss_mask_2: 0.01266  loss_dice_2: 0.07808  loss_ce_3: 0.001296  loss_mask_3: 0.01238  loss_dice_3: 0.07748  loss_ce_4: 0.003047  loss_mask_4: 0.01315  loss_dice_4: 0.07842  loss_ce_5: 0.00248  loss_mask_5: 0.01251  loss_dice_5: 0.07867  loss_ce_6: 0.003463  loss_mask_6: 0.01263  loss_dice_6: 0.07774  loss_ce_7: 0.0111  loss_mask_7: 0.01262  loss_dice_7: 0.07723  loss_ce_8: 0.007385  loss_mask_8: 0.01313  loss_dice_8: 0.07506  loss_mgm_entropy: 0.004368    time: 0.4303  last_time: 0.4415  data_time: 0.0031  last_data_time: 0.0030   lr: 2e-05  max_mem: 15320M
[08/30 16:29:43] d2.utils.events INFO:  eta: 0:23:55  iter: 4659  total_loss: 1.073  loss_ce: 0.003722  loss_mask: 0.01248  loss_dice: 0.078  loss_ce_0: 0.08542  loss_mask_0: 0.01121  loss_dice_0: 0.09065  loss_ce_1: 0.002809  loss_mask_1: 0.01239  loss_dice_1: 0.07759  loss_ce_2: 0.0005193  loss_mask_2: 0.01278  loss_dice_2: 0.08223  loss_ce_3: 0.001582  loss_mask_3: 0.01204  loss_dice_3: 0.08127  loss_ce_4: 0.003546  loss_mask_4: 0.01247  loss_dice_4: 0.07848  loss_ce_5: 0.001984  loss_mask_5: 0.01273  loss_dice_5: 0.07939  loss_ce_6: 0.003923  loss_mask_6: 0.01264  loss_dice_6: 0.0789  loss_ce_7: 0.01168  loss_mask_7: 0.01253  loss_dice_7: 0.07722  loss_ce_8: 0.01076  loss_mask_8: 0.01319  loss_dice_8: 0.07763  loss_mgm_entropy: 0.004362    time: 0.4303  last_time: 0.4384  data_time: 0.0031  last_data_time: 0.0033   lr: 2e-05  max_mem: 15320M
[08/30 16:29:52] d2.utils.events INFO:  eta: 0:23:46  iter: 4679  total_loss: 1.055  loss_ce: 0.003335  loss_mask: 0.013  loss_dice: 0.07786  loss_ce_0: 0.09337  loss_mask_0: 0.01079  loss_dice_0: 0.08696  loss_ce_1: 0.003348  loss_mask_1: 0.01237  loss_dice_1: 0.08281  loss_ce_2: 0.0006193  loss_mask_2: 0.01194  loss_dice_2: 0.08335  loss_ce_3: 0.001966  loss_mask_3: 0.0126  loss_dice_3: 0.08023  loss_ce_4: 0.003675  loss_mask_4: 0.01313  loss_dice_4: 0.0792  loss_ce_5: 0.002435  loss_mask_5: 0.01303  loss_dice_5: 0.08152  loss_ce_6: 0.003763  loss_mask_6: 0.01252  loss_dice_6: 0.082  loss_ce_7: 0.009778  loss_mask_7: 0.01234  loss_dice_7: 0.07782  loss_ce_8: 0.007543  loss_mask_8: 0.01304  loss_dice_8: 0.08226  loss_mgm_entropy: 0.004361    time: 0.4304  last_time: 0.4363  data_time: 0.0030  last_data_time: 0.0031   lr: 2e-05  max_mem: 15320M
[08/30 16:30:00] d2.utils.events INFO:  eta: 0:23:38  iter: 4699  total_loss: 1.034  loss_ce: 0.003067  loss_mask: 0.01253  loss_dice: 0.07471  loss_ce_0: 0.08881  loss_mask_0: 0.01193  loss_dice_0: 0.0857  loss_ce_1: 0.002513  loss_mask_1: 0.01352  loss_dice_1: 0.07826  loss_ce_2: 0.0005476  loss_mask_2: 0.01315  loss_dice_2: 0.0768  loss_ce_3: 0.001447  loss_mask_3: 0.01267  loss_dice_3: 0.07563  loss_ce_4: 0.002633  loss_mask_4: 0.01309  loss_dice_4: 0.07556  loss_ce_5: 0.002502  loss_mask_5: 0.01324  loss_dice_5: 0.07605  loss_ce_6: 0.003233  loss_mask_6: 0.01349  loss_dice_6: 0.078  loss_ce_7: 0.01026  loss_mask_7: 0.01328  loss_dice_7: 0.07713  loss_ce_8: 0.006771  loss_mask_8: 0.01315  loss_dice_8: 0.07757  loss_mgm_entropy: 0.004359    time: 0.4304  last_time: 0.4300  data_time: 0.0032  last_data_time: 0.0036   lr: 2e-05  max_mem: 15320M
[08/30 16:30:09] d2.utils.events INFO:  eta: 0:23:29  iter: 4719  total_loss: 1.101  loss_ce: 0.002785  loss_mask: 0.01361  loss_dice: 0.08324  loss_ce_0: 0.09444  loss_mask_0: 0.0119  loss_dice_0: 0.0924  loss_ce_1: 0.002269  loss_mask_1: 0.01238  loss_dice_1: 0.08133  loss_ce_2: 0.0004321  loss_mask_2: 0.013  loss_dice_2: 0.08329  loss_ce_3: 0.00142  loss_mask_3: 0.013  loss_dice_3: 0.08384  loss_ce_4: 0.003845  loss_mask_4: 0.01337  loss_dice_4: 0.08259  loss_ce_5: 0.001811  loss_mask_5: 0.01252  loss_dice_5: 0.08057  loss_ce_6: 0.003107  loss_mask_6: 0.01284  loss_dice_6: 0.08225  loss_ce_7: 0.009836  loss_mask_7: 0.01221  loss_dice_7: 0.08402  loss_ce_8: 0.006948  loss_mask_8: 0.0124  loss_dice_8: 0.08068  loss_mgm_entropy: 0.00435    time: 0.4304  last_time: 0.4287  data_time: 0.0031  last_data_time: 0.0036   lr: 2e-05  max_mem: 15320M
[08/30 16:30:18] d2.utils.events INFO:  eta: 0:23:20  iter: 4739  total_loss: 1.05  loss_ce: 0.002302  loss_mask: 0.01275  loss_dice: 0.07724  loss_ce_0: 0.08542  loss_mask_0: 0.01121  loss_dice_0: 0.08853  loss_ce_1: 0.002444  loss_mask_1: 0.01202  loss_dice_1: 0.07846  loss_ce_2: 0.0006309  loss_mask_2: 0.01172  loss_dice_2: 0.07762  loss_ce_3: 0.001301  loss_mask_3: 0.01145  loss_dice_3: 0.07868  loss_ce_4: 0.002598  loss_mask_4: 0.01196  loss_dice_4: 0.07543  loss_ce_5: 0.002224  loss_mask_5: 0.0117  loss_dice_5: 0.07839  loss_ce_6: 0.003711  loss_mask_6: 0.01211  loss_dice_6: 0.07775  loss_ce_7: 0.009484  loss_mask_7: 0.01227  loss_dice_7: 0.0803  loss_ce_8: 0.005622  loss_mask_8: 0.01244  loss_dice_8: 0.07646  loss_mgm_entropy: 0.004368    time: 0.4304  last_time: 0.4289  data_time: 0.0031  last_data_time: 0.0029   lr: 2e-05  max_mem: 15320M
[08/30 16:30:26] d2.utils.events INFO:  eta: 0:23:12  iter: 4759  total_loss: 1.041  loss_ce: 0.002269  loss_mask: 0.01311  loss_dice: 0.08224  loss_ce_0: 0.08521  loss_mask_0: 0.0105  loss_dice_0: 0.0914  loss_ce_1: 0.00271  loss_mask_1: 0.01195  loss_dice_1: 0.07657  loss_ce_2: 0.0004533  loss_mask_2: 0.0119  loss_dice_2: 0.0774  loss_ce_3: 0.001199  loss_mask_3: 0.01168  loss_dice_3: 0.07736  loss_ce_4: 0.002507  loss_mask_4: 0.01114  loss_dice_4: 0.07575  loss_ce_5: 0.001727  loss_mask_5: 0.01212  loss_dice_5: 0.07826  loss_ce_6: 0.002758  loss_mask_6: 0.01194  loss_dice_6: 0.07729  loss_ce_7: 0.01046  loss_mask_7: 0.01184  loss_dice_7: 0.07975  loss_ce_8: 0.006473  loss_mask_8: 0.01226  loss_dice_8: 0.07792  loss_mgm_entropy: 0.004394    time: 0.4304  last_time: 0.4291  data_time: 0.0032  last_data_time: 0.0034   lr: 2e-05  max_mem: 15320M
[08/30 16:30:35] d2.utils.events INFO:  eta: 0:23:03  iter: 4779  total_loss: 1.069  loss_ce: 0.002747  loss_mask: 0.0133  loss_dice: 0.07635  loss_ce_0: 0.09206  loss_mask_0: 0.01149  loss_dice_0: 0.0872  loss_ce_1: 0.003586  loss_mask_1: 0.01238  loss_dice_1: 0.07802  loss_ce_2: 0.0003819  loss_mask_2: 0.01288  loss_dice_2: 0.0792  loss_ce_3: 0.0009794  loss_mask_3: 0.01261  loss_dice_3: 0.07907  loss_ce_4: 0.003035  loss_mask_4: 0.01265  loss_dice_4: 0.07777  loss_ce_5: 0.001749  loss_mask_5: 0.01276  loss_dice_5: 0.07742  loss_ce_6: 0.002832  loss_mask_6: 0.01276  loss_dice_6: 0.07789  loss_ce_7: 0.00894  loss_mask_7: 0.01271  loss_dice_7: 0.08023  loss_ce_8: 0.007245  loss_mask_8: 0.01282  loss_dice_8: 0.07765  loss_mgm_entropy: 0.004365    time: 0.4304  last_time: 0.4304  data_time: 0.0032  last_data_time: 0.0034   lr: 2e-05  max_mem: 15320M
[08/30 16:30:43] d2.utils.events INFO:  eta: 0:22:55  iter: 4799  total_loss: 1.03  loss_ce: 0.002221  loss_mask: 0.01268  loss_dice: 0.0769  loss_ce_0: 0.1015  loss_mask_0: 0.01115  loss_dice_0: 0.08624  loss_ce_1: 0.00272  loss_mask_1: 0.01202  loss_dice_1: 0.07772  loss_ce_2: 0.0006107  loss_mask_2: 0.01255  loss_dice_2: 0.07595  loss_ce_3: 0.001237  loss_mask_3: 0.01232  loss_dice_3: 0.07575  loss_ce_4: 0.002683  loss_mask_4: 0.01192  loss_dice_4: 0.07672  loss_ce_5: 0.00205  loss_mask_5: 0.01222  loss_dice_5: 0.07766  loss_ce_6: 0.003458  loss_mask_6: 0.01267  loss_dice_6: 0.0798  loss_ce_7: 0.009711  loss_mask_7: 0.01256  loss_dice_7: 0.07776  loss_ce_8: 0.005556  loss_mask_8: 0.01278  loss_dice_8: 0.07757  loss_mgm_entropy: 0.004385    time: 0.4304  last_time: 0.4305  data_time: 0.0032  last_data_time: 0.0033   lr: 2e-05  max_mem: 15320M
[08/30 16:30:52] d2.utils.events INFO:  eta: 0:22:46  iter: 4819  total_loss: 1.051  loss_ce: 0.002626  loss_mask: 0.01323  loss_dice: 0.07774  loss_ce_0: 0.09205  loss_mask_0: 0.01107  loss_dice_0: 0.08581  loss_ce_1: 0.001668  loss_mask_1: 0.0126  loss_dice_1: 0.07725  loss_ce_2: 0.0003368  loss_mask_2: 0.01231  loss_dice_2: 0.07979  loss_ce_3: 0.001043  loss_mask_3: 0.01218  loss_dice_3: 0.07984  loss_ce_4: 0.002296  loss_mask_4: 0.01199  loss_dice_4: 0.07903  loss_ce_5: 0.002211  loss_mask_5: 0.01199  loss_dice_5: 0.07786  loss_ce_6: 0.002457  loss_mask_6: 0.01202  loss_dice_6: 0.07517  loss_ce_7: 0.009898  loss_mask_7: 0.0126  loss_dice_7: 0.08095  loss_ce_8: 0.00504  loss_mask_8: 0.01274  loss_dice_8: 0.07715  loss_mgm_entropy: 0.004368    time: 0.4304  last_time: 0.4296  data_time: 0.0031  last_data_time: 0.0032   lr: 2e-05  max_mem: 15320M
[08/30 16:31:01] d2.utils.events INFO:  eta: 0:22:37  iter: 4839  total_loss: 1.02  loss_ce: 0.002172  loss_mask: 0.01272  loss_dice: 0.07766  loss_ce_0: 0.084  loss_mask_0: 0.0106  loss_dice_0: 0.08443  loss_ce_1: 0.001852  loss_mask_1: 0.01255  loss_dice_1: 0.07605  loss_ce_2: 0.0005239  loss_mask_2: 0.01255  loss_dice_2: 0.07786  loss_ce_3: 0.00109  loss_mask_3: 0.01284  loss_dice_3: 0.08011  loss_ce_4: 0.001968  loss_mask_4: 0.01255  loss_dice_4: 0.07654  loss_ce_5: 0.001438  loss_mask_5: 0.01216  loss_dice_5: 0.0775  loss_ce_6: 0.00265  loss_mask_6: 0.01292  loss_dice_6: 0.0794  loss_ce_7: 0.008725  loss_mask_7: 0.01256  loss_dice_7: 0.08014  loss_ce_8: 0.005738  loss_mask_8: 0.01269  loss_dice_8: 0.07637  loss_mgm_entropy: 0.004384    time: 0.4304  last_time: 0.4304  data_time: 0.0031  last_data_time: 0.0035   lr: 2e-05  max_mem: 15320M
[08/30 16:31:09] d2.utils.events INFO:  eta: 0:22:29  iter: 4859  total_loss: 1.049  loss_ce: 0.00219  loss_mask: 0.01212  loss_dice: 0.08323  loss_ce_0: 0.0853  loss_mask_0: 0.01069  loss_dice_0: 0.08749  loss_ce_1: 0.002895  loss_mask_1: 0.01191  loss_dice_1: 0.07935  loss_ce_2: 0.0003456  loss_mask_2: 0.01167  loss_dice_2: 0.07991  loss_ce_3: 0.001214  loss_mask_3: 0.01189  loss_dice_3: 0.07889  loss_ce_4: 0.002478  loss_mask_4: 0.01151  loss_dice_4: 0.08087  loss_ce_5: 0.001216  loss_mask_5: 0.0116  loss_dice_5: 0.08  loss_ce_6: 0.002177  loss_mask_6: 0.01152  loss_dice_6: 0.07752  loss_ce_7: 0.008091  loss_mask_7: 0.0119  loss_dice_7: 0.08095  loss_ce_8: 0.005371  loss_mask_8: 0.01244  loss_dice_8: 0.08125  loss_mgm_entropy: 0.004365    time: 0.4304  last_time: 0.4283  data_time: 0.0031  last_data_time: 0.0041   lr: 2e-05  max_mem: 15320M
[08/30 16:31:18] d2.utils.events INFO:  eta: 0:22:20  iter: 4879  total_loss: 1.047  loss_ce: 0.00188  loss_mask: 0.01206  loss_dice: 0.07938  loss_ce_0: 0.08877  loss_mask_0: 0.01006  loss_dice_0: 0.08459  loss_ce_1: 0.002636  loss_mask_1: 0.0116  loss_dice_1: 0.0811  loss_ce_2: 0.0004344  loss_mask_2: 0.01146  loss_dice_2: 0.07956  loss_ce_3: 0.001025  loss_mask_3: 0.01171  loss_dice_3: 0.07993  loss_ce_4: 0.001766  loss_mask_4: 0.01118  loss_dice_4: 0.07756  loss_ce_5: 0.001249  loss_mask_5: 0.01153  loss_dice_5: 0.0799  loss_ce_6: 0.002333  loss_mask_6: 0.0115  loss_dice_6: 0.08054  loss_ce_7: 0.007428  loss_mask_7: 0.0117  loss_dice_7: 0.0791  loss_ce_8: 0.00494  loss_mask_8: 0.01172  loss_dice_8: 0.07823  loss_mgm_entropy: 0.004379    time: 0.4304  last_time: 0.4319  data_time: 0.0031  last_data_time: 0.0030   lr: 2e-05  max_mem: 15320M
[08/30 16:31:27] d2.utils.events INFO:  eta: 0:22:12  iter: 4899  total_loss: 1.068  loss_ce: 0.002014  loss_mask: 0.01242  loss_dice: 0.0787  loss_ce_0: 0.09447  loss_mask_0: 0.01078  loss_dice_0: 0.08872  loss_ce_1: 0.002019  loss_mask_1: 0.01233  loss_dice_1: 0.078  loss_ce_2: 0.0004713  loss_mask_2: 0.01303  loss_dice_2: 0.08008  loss_ce_3: 0.001149  loss_mask_3: 0.01294  loss_dice_3: 0.07847  loss_ce_4: 0.003004  loss_mask_4: 0.01228  loss_dice_4: 0.07765  loss_ce_5: 0.001335  loss_mask_5: 0.0124  loss_dice_5: 0.08045  loss_ce_6: 0.002192  loss_mask_6: 0.01282  loss_dice_6: 0.07828  loss_ce_7: 0.007171  loss_mask_7: 0.01231  loss_dice_7: 0.07922  loss_ce_8: 0.004777  loss_mask_8: 0.01276  loss_dice_8: 0.08076  loss_mgm_entropy: 0.004374    time: 0.4304  last_time: 0.4299  data_time: 0.0031  last_data_time: 0.0038   lr: 2e-05  max_mem: 15320M
[08/30 16:31:35] d2.utils.events INFO:  eta: 0:22:03  iter: 4919  total_loss: 1.04  loss_ce: 0.001693  loss_mask: 0.01238  loss_dice: 0.07791  loss_ce_0: 0.08867  loss_mask_0: 0.01045  loss_dice_0: 0.08724  loss_ce_1: 0.002937  loss_mask_1: 0.01141  loss_dice_1: 0.07588  loss_ce_2: 0.0003327  loss_mask_2: 0.01166  loss_dice_2: 0.07495  loss_ce_3: 0.0009806  loss_mask_3: 0.01198  loss_dice_3: 0.07618  loss_ce_4: 0.002091  loss_mask_4: 0.01199  loss_dice_4: 0.07747  loss_ce_5: 0.001036  loss_mask_5: 0.01203  loss_dice_5: 0.07518  loss_ce_6: 0.002021  loss_mask_6: 0.01202  loss_dice_6: 0.08057  loss_ce_7: 0.00668  loss_mask_7: 0.01173  loss_dice_7: 0.07568  loss_ce_8: 0.004687  loss_mask_8: 0.01223  loss_dice_8: 0.08016  loss_mgm_entropy: 0.004381    time: 0.4304  last_time: 0.4292  data_time: 0.0030  last_data_time: 0.0027   lr: 2e-05  max_mem: 15320M
[08/30 16:31:44] d2.utils.events INFO:  eta: 0:21:54  iter: 4939  total_loss: 1.026  loss_ce: 0.001635  loss_mask: 0.01286  loss_dice: 0.07601  loss_ce_0: 0.08985  loss_mask_0: 0.01082  loss_dice_0: 0.08592  loss_ce_1: 0.002657  loss_mask_1: 0.01227  loss_dice_1: 0.07944  loss_ce_2: 0.0005742  loss_mask_2: 0.01186  loss_dice_2: 0.07871  loss_ce_3: 0.001142  loss_mask_3: 0.0126  loss_dice_3: 0.0794  loss_ce_4: 0.001567  loss_mask_4: 0.01207  loss_dice_4: 0.07544  loss_ce_5: 0.001641  loss_mask_5: 0.01242  loss_dice_5: 0.07818  loss_ce_6: 0.002564  loss_mask_6: 0.0126  loss_dice_6: 0.07877  loss_ce_7: 0.006587  loss_mask_7: 0.01313  loss_dice_7: 0.0808  loss_ce_8: 0.004055  loss_mask_8: 0.01269  loss_dice_8: 0.07861  loss_mgm_entropy: 0.0044    time: 0.4304  last_time: 0.4310  data_time: 0.0032  last_data_time: 0.0034   lr: 2e-05  max_mem: 15320M
[08/30 16:31:52] d2.utils.events INFO:  eta: 0:21:46  iter: 4959  total_loss: 1.032  loss_ce: 0.001632  loss_mask: 0.01228  loss_dice: 0.07926  loss_ce_0: 0.08519  loss_mask_0: 0.01072  loss_dice_0: 0.08439  loss_ce_1: 0.002042  loss_mask_1: 0.01197  loss_dice_1: 0.07882  loss_ce_2: 0.0003229  loss_mask_2: 0.01161  loss_dice_2: 0.0799  loss_ce_3: 0.000755  loss_mask_3: 0.01221  loss_dice_3: 0.0781  loss_ce_4: 0.00156  loss_mask_4: 0.01176  loss_dice_4: 0.07428  loss_ce_5: 0.001149  loss_mask_5: 0.01214  loss_dice_5: 0.07723  loss_ce_6: 0.002009  loss_mask_6: 0.01204  loss_dice_6: 0.07696  loss_ce_7: 0.006694  loss_mask_7: 0.01202  loss_dice_7: 0.07977  loss_ce_8: 0.005122  loss_mask_8: 0.01195  loss_dice_8: 0.07735  loss_mgm_entropy: 0.004385    time: 0.4304  last_time: 0.4298  data_time: 0.0032  last_data_time: 0.0027   lr: 2e-05  max_mem: 15320M
[08/30 16:32:01] d2.utils.events INFO:  eta: 0:21:37  iter: 4979  total_loss: 1.019  loss_ce: 0.001738  loss_mask: 0.01199  loss_dice: 0.07555  loss_ce_0: 0.09331  loss_mask_0: 0.009997  loss_dice_0: 0.08636  loss_ce_1: 0.002401  loss_mask_1: 0.0115  loss_dice_1: 0.07803  loss_ce_2: 0.000321  loss_mask_2: 0.01138  loss_dice_2: 0.07633  loss_ce_3: 0.0008795  loss_mask_3: 0.01166  loss_dice_3: 0.07737  loss_ce_4: 0.001772  loss_mask_4: 0.01201  loss_dice_4: 0.0766  loss_ce_5: 0.001465  loss_mask_5: 0.01147  loss_dice_5: 0.07494  loss_ce_6: 0.001938  loss_mask_6: 0.01199  loss_dice_6: 0.07782  loss_ce_7: 0.006787  loss_mask_7: 0.01192  loss_dice_7: 0.07786  loss_ce_8: 0.003788  loss_mask_8: 0.01142  loss_dice_8: 0.07612  loss_mgm_entropy: 0.004366    time: 0.4304  last_time: 0.4315  data_time: 0.0031  last_data_time: 0.0034   lr: 2e-05  max_mem: 15320M
[08/30 16:32:10] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/mgm_training/model_0004999.pth
[08/30 16:32:10] d2.data.datasets.coco INFO: Loaded 0 images in COCO format from /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/annotations/instances_val.json
[08/30 16:32:10] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/fuyx/hch/detectron2/detectron2/engine/train_loop.py", line 156, in train
    self.after_step()
  File "/home/fuyx/hch/detectron2/detectron2/engine/train_loop.py", line 190, in after_step
    h.after_step()
  File "/home/fuyx/hch/detectron2/detectron2/engine/hooks.py", line 556, in after_step
    self._do_eval()
  File "/home/fuyx/hch/detectron2/detectron2/engine/hooks.py", line 529, in _do_eval
    results = self._func()
              ^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/engine/defaults.py", line 489, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/engine/defaults.py", line 638, in test
    data_loader = cls.build_test_loader(cfg, dataset_name)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/engine/defaults.py", line 594, in build_test_loader
    return build_detection_test_loader(cfg, dataset_name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/config/config.py", line 207, in wrapped
    explicit_args = _get_args_from_config(from_config, *args, **kwargs)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/config/config.py", line 245, in _get_args_from_config
    ret = from_config_func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/data/build.py", line 594, in _test_loader_from_config
    dataset = get_detection_dataset_dicts(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fuyx/hch/detectron2/detectron2/data/build.py", line 264, in get_detection_dataset_dicts
    assert len(dicts), "Dataset '{}' is empty!".format(dataset_name)
           ^^^^^^^^^^
AssertionError: Dataset 'coco_instance_rgbd_val' is empty!
[08/30 16:32:10] d2.engine.hooks INFO: Overall training speed: 4997 iterations in 0:35:51 (0.4305 s / it)
[08/30 16:32:10] d2.engine.hooks INFO: Total training time: 0:35:55 (0:00:04 on hooks)
[08/30 16:32:10] d2.utils.events INFO:  eta: 0:21:29  iter: 4999  total_loss: 1.013  loss_ce: 0.001723  loss_mask: 0.01285  loss_dice: 0.07563  loss_ce_0: 0.09788  loss_mask_0: 0.01157  loss_dice_0: 0.08363  loss_ce_1: 0.001778  loss_mask_1: 0.01325  loss_dice_1: 0.07524  loss_ce_2: 0.0005212  loss_mask_2: 0.0131  loss_dice_2: 0.07381  loss_ce_3: 0.001024  loss_mask_3: 0.01335  loss_dice_3: 0.07426  loss_ce_4: 0.001651  loss_mask_4: 0.01277  loss_dice_4: 0.07173  loss_ce_5: 0.001646  loss_mask_5: 0.01349  loss_dice_5: 0.07412  loss_ce_6: 0.002272  loss_mask_6: 0.0135  loss_dice_6: 0.07613  loss_ce_7: 0.006632  loss_mask_7: 0.01357  loss_dice_7: 0.0755  loss_ce_8: 0.0052  loss_mask_8: 0.01316  loss_dice_8: 0.07335  loss_mgm_entropy: 0.004344    time: 0.4304  last_time: 0.4288  data_time: 0.0031  last_data_time: 0.0032   lr: 2e-05  max_mem: 15320M
[08/30 16:46:05] detectron2 INFO: Rank of current process: 0. World size: 1
[08/30 16:46:06] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:43:55) [GCC 13.3.0]
numpy                            2.2.6
detectron2                       0.6 @/home/fuyx/hch/detectron2/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6, 8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   575.64.03
CUDA_HOME                        /home/fuyx/anaconda3/envs/m2f
Pillow                           11.3.0
torchvision                      0.20.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[08/30 16:46:06] detectron2 INFO: Command line arguments: Namespace(config_file='MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=['OUTPUT_DIR', './output/mgm_training'])
[08/30 16:46:06] detectron2 INFO: Contents of args.config_file=MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml:
MODEL:
  META_ARCHITECTURE: "MGMMaskFormer"

  # RGB Backbone: Swin Transformer Tiny
  RGB_BACKBONE:
    NAME: "D2SwinTransformer"
    WEIGHTS: ""
    SWIN:
      EMBED_DIM: 96
      DEPTHS: [2, 2, 6, 2]
      NUM_HEADS: [3, 6, 12, 24]
      WINDOW_SIZE: 7
      APE: False
      DROP_PATH_RATE: 0.3
      PATCH_NORM: True
      OUT_FEATURES: ["res2", "res3", "res4", "res5"]

  # Depth Backbone: ConvNeXt Tiny
  DEPTH_BACKBONE:
    NAME: "ConvNeXtDepthBackbone"
    WEIGHTS: ""
    CONVNEXT:
      DEPTHS: [3, 3, 9, 3]
      DIMS: [96, 192, 384, 768]
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1e-6

  # MGM Fusion Configuration
  MGM:
    ENABLED: True
    SHARED: True
    RESIDUAL_ALPHA: 0.05
    POST_FUSE_NORM: True # 新增：融合后GN
    LOSS_ENTROPY_W: 0.01
    TEMP_INIT: 1.5
    TEMP_FINAL: 1.0
    TEMP_STEPS: 3000 # 建议略短，收敛更快
    CLAMP_MIN: 0.05
    CLAMP_MAX: 0.95
    NOISE_MASK_WEIGHT: 0.0 # 前期建议关；有噪声掩码再开到0.05~0.1
    HIDDEN_DIM: 256
    FEATURE_DIMS: [96, 192, 384, 768]
    SCALE_KEYS: ["res2", "res3", "res4", "res5"]

    PRIOR:
      ENABLED: False # 总开关
      USE_GRADIENT: True # 先验逐项开关
      USE_VARIANCE: True
      USE_VALID_HOLE: True
      USE_RGB_EDGE: False # 前期建议关（最耗时）
      VAR_KERNEL: 5
      Z_MIN: 0.0
      Z_MAX: 1.0
      COMPUTE_ON: "res3" # "full"|"res2"|"res3"|"res4"|"res5"；前期建议用res3提速

    ROBUST_NORM:
      ENABLED: False # 前期建议关；要稳健再开
      METHOD: "minmax" # "minmax"|"quantile"

  # DPE Configuration
  DPE:
    ENABLED: True

  # Boundary Configuration
  BOUNDARY:
    ENABLED: False

  # RGB Input Pixel Mean/Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]

  # Semantic Segmentation Head
  SEM_SEG_HEAD:
    NAME: "MGMHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 1
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MGMMSDeformAttnPixelDecoder"
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6

  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MGMMultiScaleMaskedTransformerDecoder"
    TRANSFORMER_IN_FEATURE: "multi_scale_pixel_decoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 2.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 100
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    DEC_LAYERS: 10
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.8

# 数据集配置
DATASETS:
  TRAIN: ("coco_instance_rgbd_train",)
  TEST: ("coco_instance_rgbd_val",)

# 数据加载器配置
DATALOADER:
  NUM_WORKERS: 4
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  REPEAT_THRESHOLD: 0.0

  # RGB-D Input Configuration - 快速训练模式
INPUT:
  DATASET_ROOT: "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input"
  IMAGE_SIZE: 1024
  MIN_SCALE: 0.8
  MAX_SCALE: 1.2
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "coco_instance_lsj_rgbd"
  RANDOM_FLIP: "horizontal"
  SIZE_DIVISIBILITY: 32

  # RGB光度增强
  RGB_PHOTO_AUG:
    ENABLED: False
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    SATURATION: 0.1
    HUE: 0.0

  # 深度数据配置
  DEPTH_FORMAT: "I"
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_CLIP_MAX: 1.0
  DEPTH_NORM: "minmax"
  DEPTH_NOISE:
    ENABLED: False
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
    DROP_PROB: 0.0
    DROP_VAL: 0.0

# 求解器配置 - 快速训练模式 (2小时) - 解决OOM
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0002
  STEPS: (4000, 6000)
  MAX_ITER: 8000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  GAMMA: 0.1
  OPTIMIZER: ADAMW
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_EMBED: 0.0
  CLIP_GRADIENTS:
    ENABLED: False
  AMP:
    ENABLED: True

# 测试配置
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False

# 输出配置
OUTPUT_DIR: "./output"

# 版本号
VERSION: 2.0

[08/30 16:46:06] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  LOAD_PROPOSALS: false
  NUM_WORKERS: 4
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_instance_rgbd_val
  TRAIN:
  - coco_instance_rgbd_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj_rgbd
  DATASET_ROOT: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
  DEPTH_CLIP_MAX: 1.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_FORMAT: I
  DEPTH_NOISE:
    DROP_PROB: 0.0
    DROP_VAL: 0.0
    ENABLED: false
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
  DEPTH_NORM: minmax
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 1.2
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.8
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  RGB_PHOTO_AUG:
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    ENABLED: false
    HUE: 0.0
    SATURATION: 0.1
  SIZE_DIVISIBILITY: 32
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BOUNDARY:
    ENABLED: false
  DEPTH_BACKBONE:
    CONVNEXT:
      DEPTHS:
      - 3
      - 3
      - 9
      - 3
      DIMS:
      - 96
      - 192
      - 384
      - 768
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1.0e-06
    NAME: ConvNeXtDepthBackbone
    WEIGHTS: ''
  DEVICE: cuda
  DPE:
    ENABLED: true
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MGMMultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MGMMaskFormer
  MGM:
    CLAMP_MAX: 0.95
    CLAMP_MIN: 0.05
    ENABLED: true
    FEATURE_DIMS:
    - 96
    - 192
    - 384
    - 768
    HIDDEN_DIM: 256
    LOSS_ENTROPY_W: 0.01
    NOISE_MASK_WEIGHT: 0.0
    POST_FUSE_NORM: true
    PRIOR:
      COMPUTE_ON: res3
      ENABLED: false
      USE_GRADIENT: true
      USE_RGB_EDGE: false
      USE_VALID_HOLE: true
      USE_VARIANCE: true
      VAR_KERNEL: 5
      Z_MAX: 1.0
      Z_MIN: 0.0
    RESIDUAL_ALPHA: 0.05
    ROBUST_NORM:
      ENABLED: false
      METHOD: minmax
    SCALE_KEYS:
    - res2
    - res3
    - res4
    - res5
    SHARED: true
    TEMP_FINAL: 1.0
    TEMP_INIT: 1.5
    TEMP_STEPS: 3000
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  RGB_BACKBONE:
    NAME: D2SwinTransformer
    SWIN:
      APE: false
      ATTN_DROP_RATE: 0.0
      DEPTHS:
      - 2
      - 2
      - 6
      - 2
      DROP_PATH_RATE: 0.3
      DROP_RATE: 0.0
      EMBED_DIM: 96
      MLP_RATIO: 4.0
      NUM_HEADS:
      - 3
      - 6
      - 12
      - 24
      OUT_FEATURES:
      - res2
      - res3
      - res4
      - res5
      PATCH_NORM: true
      PATCH_SIZE: 4
      PRETRAIN_IMG_SIZE: 224
      QKV_BIAS: true
      QK_SCALE: null
      USE_CHECKPOINT: false
      WINDOW_SIZE: 7
    WEIGHTS: ''
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MGMHead
    NORM: GN
    NUM_CLASSES: 1
    PIXEL_DECODER_NAME: MGMMSDeformAttnPixelDecoder
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: ''
OUTPUT_DIR: ./output/mgm_training
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 8000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 4000
  - 6000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2.0
VIS_PERIOD: 0

[08/30 16:46:06] detectron2 INFO: Full config saved to ./output/mgm_training/config.yaml
[08/30 16:46:06] d2.utils.env INFO: Using a generated random seed 7923793
[08/30 16:46:26] d2.engine.defaults INFO: Model:
MGMMaskFormer(
  (rgb_backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.055)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.109)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.136)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.164)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.191)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.218)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.245)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.273)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.300)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (depth_backbone): ConvNeXtDepthBackbone(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
  )
  (mgm): MultiModalGatedFusion(
    (prior_extractor): DepthPriorExtractor()
    (conf_pred): ConfidencePredictor(
      (proj_image): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_depth): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (head): Sequential(
        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): GroupNorm(8, 128, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (align_image): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (align_depth): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (post_norm): ModuleList(
      (0): GroupNorm(8, 96, eps=1e-05, affine=True)
      (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      (2): GroupNorm(8, 384, eps=1e-05, affine=True)
      (3): GroupNorm(8, 768, eps=1e-05, affine=True)
    )
  )
  (sem_seg_head): MGMHead(
    (pixel_decoder): MGMMSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (depth_pe): DepthPosEncoding(
        (mlp): Sequential(
          (0): Conv2d(1, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MGMMultiScaleMaskedTransformerDecoder(
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x MGMCrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=2, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 1
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/30 16:46:26] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[08/30 16:46:26] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[08/30 16:46:26] d2.data.datasets.coco INFO: Loaded 0 images in COCO format from /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/annotations/instances_val.json
[08/30 16:48:54] detectron2 INFO: Rank of current process: 0. World size: 1
[08/30 16:48:54] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:43:55) [GCC 13.3.0]
numpy                            2.2.6
detectron2                       0.6 @/home/fuyx/hch/detectron2/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6, 8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   575.64.03
CUDA_HOME                        /home/fuyx/anaconda3/envs/m2f
Pillow                           11.3.0
torchvision                      0.20.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[08/30 16:48:54] detectron2 INFO: Command line arguments: Namespace(config_file='MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=['OUTPUT_DIR', './output/mgm_training'])
[08/30 16:48:54] detectron2 INFO: Contents of args.config_file=MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml:
MODEL:
  META_ARCHITECTURE: "MGMMaskFormer"

  # RGB Backbone: Swin Transformer Tiny
  RGB_BACKBONE:
    NAME: "D2SwinTransformer"
    WEIGHTS: "./output/mgm_training/model_0004999.pth"
    SWIN:
      EMBED_DIM: 96
      DEPTHS: [2, 2, 6, 2]
      NUM_HEADS: [3, 6, 12, 24]
      WINDOW_SIZE: 7
      APE: False
      DROP_PATH_RATE: 0.3
      PATCH_NORM: True
      OUT_FEATURES: ["res2", "res3", "res4", "res5"]

  # Depth Backbone: ConvNeXt Tiny
  DEPTH_BACKBONE:
    NAME: "ConvNeXtDepthBackbone"
    WEIGHTS: ""
    CONVNEXT:
      DEPTHS: [3, 3, 9, 3]
      DIMS: [96, 192, 384, 768]
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1e-6

  # MGM Fusion Configuration
  MGM:
    ENABLED: True
    SHARED: True
    RESIDUAL_ALPHA: 0.05
    POST_FUSE_NORM: True # 新增：融合后GN
    LOSS_ENTROPY_W: 0.01
    TEMP_INIT: 1.5
    TEMP_FINAL: 1.0
    TEMP_STEPS: 3000 # 建议略短，收敛更快
    CLAMP_MIN: 0.05
    CLAMP_MAX: 0.95
    NOISE_MASK_WEIGHT: 0.0 # 前期建议关；有噪声掩码再开到0.05~0.1
    HIDDEN_DIM: 256
    FEATURE_DIMS: [96, 192, 384, 768]
    SCALE_KEYS: ["res2", "res3", "res4", "res5"]

    PRIOR:
      ENABLED: False # 总开关
      USE_GRADIENT: True # 先验逐项开关
      USE_VARIANCE: True
      USE_VALID_HOLE: True
      USE_RGB_EDGE: False # 前期建议关（最耗时）
      VAR_KERNEL: 5
      Z_MIN: 0.0
      Z_MAX: 1.0
      COMPUTE_ON: "res3" # "full"|"res2"|"res3"|"res4"|"res5"；前期建议用res3提速

    ROBUST_NORM:
      ENABLED: False # 前期建议关；要稳健再开
      METHOD: "minmax" # "minmax"|"quantile"

  # DPE Configuration
  DPE:
    ENABLED: True

  # Boundary Configuration
  BOUNDARY:
    ENABLED: False

  # RGB Input Pixel Mean/Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]

  # Semantic Segmentation Head
  SEM_SEG_HEAD:
    NAME: "MGMHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 1
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MGMMSDeformAttnPixelDecoder"
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6

  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MGMMultiScaleMaskedTransformerDecoder"
    TRANSFORMER_IN_FEATURE: "multi_scale_pixel_decoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 2.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 100
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    DEC_LAYERS: 10
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.8

# 数据集配置
DATASETS:
  TRAIN: ("coco_instance_rgbd_train",)
  TEST: ("coco_instance_rgbd_val",)

# 数据加载器配置
DATALOADER:
  NUM_WORKERS: 4
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  REPEAT_THRESHOLD: 0.0

  # RGB-D Input Configuration - 快速训练模式
INPUT:
  DATASET_ROOT: "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input"
  IMAGE_SIZE: 1024
  MIN_SCALE: 0.8
  MAX_SCALE: 1.2
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "coco_instance_lsj_rgbd"
  RANDOM_FLIP: "horizontal"
  SIZE_DIVISIBILITY: 32

  # RGB光度增强
  RGB_PHOTO_AUG:
    ENABLED: False
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    SATURATION: 0.1
    HUE: 0.0

  # 深度数据配置
  DEPTH_FORMAT: "I"
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_CLIP_MAX: 1.0
  DEPTH_NORM: "minmax"
  DEPTH_NOISE:
    ENABLED: False
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
    DROP_PROB: 0.0
    DROP_VAL: 0.0

# 求解器配置 - 快速训练模式 (2小时) - 解决OOM
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0002
  STEPS: (4000, 6000)
  MAX_ITER: 8000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  GAMMA: 0.1
  OPTIMIZER: ADAMW
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_EMBED: 0.0
  CLIP_GRADIENTS:
    ENABLED: False
  AMP:
    ENABLED: True

# 测试配置
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False

# 输出配置
OUTPUT_DIR: "./output"

# 版本号
VERSION: 2.0

[08/30 16:48:54] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  LOAD_PROPOSALS: false
  NUM_WORKERS: 4
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_instance_rgbd_val
  TRAIN:
  - coco_instance_rgbd_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj_rgbd
  DATASET_ROOT: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
  DEPTH_CLIP_MAX: 1.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_FORMAT: I
  DEPTH_NOISE:
    DROP_PROB: 0.0
    DROP_VAL: 0.0
    ENABLED: false
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
  DEPTH_NORM: minmax
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 1.2
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.8
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  RGB_PHOTO_AUG:
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    ENABLED: false
    HUE: 0.0
    SATURATION: 0.1
  SIZE_DIVISIBILITY: 32
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BOUNDARY:
    ENABLED: false
  DEPTH_BACKBONE:
    CONVNEXT:
      DEPTHS:
      - 3
      - 3
      - 9
      - 3
      DIMS:
      - 96
      - 192
      - 384
      - 768
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1.0e-06
    NAME: ConvNeXtDepthBackbone
    WEIGHTS: ''
  DEVICE: cuda
  DPE:
    ENABLED: true
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MGMMultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MGMMaskFormer
  MGM:
    CLAMP_MAX: 0.95
    CLAMP_MIN: 0.05
    ENABLED: true
    FEATURE_DIMS:
    - 96
    - 192
    - 384
    - 768
    HIDDEN_DIM: 256
    LOSS_ENTROPY_W: 0.01
    NOISE_MASK_WEIGHT: 0.0
    POST_FUSE_NORM: true
    PRIOR:
      COMPUTE_ON: res3
      ENABLED: false
      USE_GRADIENT: true
      USE_RGB_EDGE: false
      USE_VALID_HOLE: true
      USE_VARIANCE: true
      VAR_KERNEL: 5
      Z_MAX: 1.0
      Z_MIN: 0.0
    RESIDUAL_ALPHA: 0.05
    ROBUST_NORM:
      ENABLED: false
      METHOD: minmax
    SCALE_KEYS:
    - res2
    - res3
    - res4
    - res5
    SHARED: true
    TEMP_FINAL: 1.0
    TEMP_INIT: 1.5
    TEMP_STEPS: 3000
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  RGB_BACKBONE:
    NAME: D2SwinTransformer
    SWIN:
      APE: false
      ATTN_DROP_RATE: 0.0
      DEPTHS:
      - 2
      - 2
      - 6
      - 2
      DROP_PATH_RATE: 0.3
      DROP_RATE: 0.0
      EMBED_DIM: 96
      MLP_RATIO: 4.0
      NUM_HEADS:
      - 3
      - 6
      - 12
      - 24
      OUT_FEATURES:
      - res2
      - res3
      - res4
      - res5
      PATCH_NORM: true
      PATCH_SIZE: 4
      PRETRAIN_IMG_SIZE: 224
      QKV_BIAS: true
      QK_SCALE: null
      USE_CHECKPOINT: false
      WINDOW_SIZE: 7
    WEIGHTS: ./output/mgm_training/model_0004999.pth
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MGMHead
    NORM: GN
    NUM_CLASSES: 1
    PIXEL_DECODER_NAME: MGMMSDeformAttnPixelDecoder
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: ''
OUTPUT_DIR: ./output/mgm_training
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 8000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 4000
  - 6000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2.0
VIS_PERIOD: 0

[08/30 16:48:54] detectron2 INFO: Full config saved to ./output/mgm_training/config.yaml
[08/30 16:48:54] d2.utils.env INFO: Using a generated random seed 56513661
[08/30 16:49:15] d2.engine.defaults INFO: Model:
MGMMaskFormer(
  (rgb_backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.055)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.109)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.136)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.164)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.191)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.218)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.245)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.273)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.300)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (depth_backbone): ConvNeXtDepthBackbone(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
  )
  (mgm): MultiModalGatedFusion(
    (prior_extractor): DepthPriorExtractor()
    (conf_pred): ConfidencePredictor(
      (proj_image): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_depth): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (head): Sequential(
        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): GroupNorm(8, 128, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (align_image): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (align_depth): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (post_norm): ModuleList(
      (0): GroupNorm(8, 96, eps=1e-05, affine=True)
      (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      (2): GroupNorm(8, 384, eps=1e-05, affine=True)
      (3): GroupNorm(8, 768, eps=1e-05, affine=True)
    )
  )
  (sem_seg_head): MGMHead(
    (pixel_decoder): MGMMSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (depth_pe): DepthPosEncoding(
        (mlp): Sequential(
          (0): Conv2d(1, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MGMMultiScaleMaskedTransformerDecoder(
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x MGMCrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=2, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 1
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/30 16:49:15] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[08/30 16:49:15] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[08/30 16:49:15] d2.data.datasets.coco INFO: Loaded 6 images in COCO format from /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/annotations/instances_val.json
[08/30 16:49:15] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| component  | 147          |
|            |              |[0m
[08/30 16:49:15] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/30 16:49:15] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[08/30 16:49:15] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[08/30 16:49:15] d2.data.common INFO: Serialized dataset takes 0.16 MiB
[08/30 16:49:15] d2.evaluation.evaluator INFO: Start inference on 6 batches
