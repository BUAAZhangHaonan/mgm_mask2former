[08/30 23:00:05] detectron2 INFO: Rank of current process: 0. World size: 1
[08/30 23:00:05] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:43:55) [GCC 13.3.0]
numpy                            2.2.6
detectron2                       0.6 @/home/fuyx/hch/detectron2/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6, 8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   575.64.03
CUDA_HOME                        /home/fuyx/anaconda3/envs/m2f
Pillow                           11.3.0
torchvision                      0.20.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[08/30 23:00:05] detectron2 INFO: Command line arguments: Namespace(config_file='MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[08/30 23:00:05] detectron2 INFO: Contents of args.config_file=MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml:
MODEL:
  META_ARCHITECTURE: "MGMMaskFormer"

  # RGB Backbone: Swin Transformer Tiny
  RGB_BACKBONE:
    NAME: "D2SwinTransformer"
    WEIGHTS: "checkpoint_convertor/checkpoint_swin/checkpoint_swin_slice/swin_backbone.pth"
    SWIN:
      EMBED_DIM: 96
      DEPTHS: [2, 2, 6, 2]
      NUM_HEADS: [3, 6, 12, 24]
      WINDOW_SIZE: 7
      APE: False
      DROP_PATH_RATE: 0.3
      PATCH_NORM: True
      OUT_FEATURES: ["res2", "res3", "res4", "res5"]

  # Depth Backbone: ConvNeXt Tiny
  DEPTH_BACKBONE:
    NAME: "ConvNeXtDepthBackbone"
    WEIGHTS: "checkpoint_convertor/convnext-checkpoint/convnext_tiny_depth_22k_converted.pth"
    CONVNEXT:
      DEPTHS: [3, 3, 9, 3]
      DIMS: [96, 192, 384, 768]
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1e-6

  # MGM Fusion Configuration
  MGM:
    ENABLED: True
    SHARED: True
    RESIDUAL_ALPHA: 0.05
    POST_FUSE_NORM: True # 新增：融合后GN
    LOSS_ENTROPY_W: 0.01
    TEMP_INIT: 1.5
    TEMP_FINAL: 1.0
    TEMP_STEPS: 3000 # 建议略短，收敛更快
    CLAMP_MIN: 0.05
    CLAMP_MAX: 0.95
    NOISE_MASK_WEIGHT: 0.0 # 前期建议关；有噪声掩码再开到0.05~0.1
    HIDDEN_DIM: 256
    FEATURE_DIMS: [96, 192, 384, 768]
    SCALE_KEYS: ["res2", "res3", "res4", "res5"]

    PRIOR:
      ENABLED: True # 总开关
      USE_GRADIENT: True # 先验逐项开关
      USE_VARIANCE: True
      USE_VALID_HOLE: True
      USE_RGB_EDGE: True # 前期建议关（最耗时）
      VAR_KERNEL: 5
      Z_MIN: 0.0
      Z_MAX: 1.0
      COMPUTE_ON: "res3" # "full"|"res2"|"res3"|"res4"|"res5"；前期建议用res3提速

    ROBUST_NORM:
      ENABLED: True # 前期建议关；要稳健再开
      METHOD: "minmax" # "minmax"|"quantile"

  # DPE Configuration
  DPE:
    ENABLED: True

  # Boundary Configuration
  BOUNDARY:
    ENABLED: False

  # RGB Input Pixel Mean/Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]

  # Semantic Segmentation Head
  SEM_SEG_HEAD:
    NAME: "MGMHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 1
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MGMMSDeformAttnPixelDecoder"
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6

  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MGMMultiScaleMaskedTransformerDecoder"
    TRANSFORMER_IN_FEATURE: "multi_scale_pixel_decoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 2.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 100
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    DEC_LAYERS: 10
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.8

# 数据集配置
DATASETS:
  TRAIN: ("coco_instance_rgbd_train",)
  TEST: ("coco_instance_rgbd_val",)

# 数据加载器配置
DATALOADER:
  NUM_WORKERS: 16
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  REPEAT_THRESHOLD: 0.0

  # RGB-D Input Configuration - 快速训练模式
INPUT:
  DATASET_ROOT: "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input"
  IMAGE_SIZE: 1024
  MIN_SCALE: 0.8
  MAX_SCALE: 1.2
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "coco_instance_lsj_rgbd"
  RANDOM_FLIP: "horizontal"
  SIZE_DIVISIBILITY: 32

  # RGB光度增强
  RGB_PHOTO_AUG:
    ENABLED: False
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    SATURATION: 0.1
    HUE: 0.0

  # 深度数据配置
  DEPTH_FORMAT: "I"
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_CLIP_MAX: 1.0
  DEPTH_NORM: "minmax"
  DEPTH_NOISE:
    ENABLED: False
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
    DROP_PROB: 0.0
    DROP_VAL: 0.0

# 求解器配置
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 1e-5
  STEPS: (1000, 1500)
  MAX_ITER: 2000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  GAMMA: 0.1
  OPTIMIZER: ADAMW
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_EMBED: 0.0
  CLIP_GRADIENTS:
    ENABLED: False
  AMP:
    ENABLED: True

# 测试配置
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False

# 输出配置
OUTPUT_DIR: "./output"

# 版本号
VERSION: 2.0

[08/30 23:00:05] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  LOAD_PROPOSALS: false
  NUM_WORKERS: 16
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_instance_rgbd_val
  TRAIN:
  - coco_instance_rgbd_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj_rgbd
  DATASET_ROOT: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
  DEPTH_CLIP_MAX: 1.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_FORMAT: I
  DEPTH_NOISE:
    DROP_PROB: 0.0
    DROP_VAL: 0.0
    ENABLED: false
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
  DEPTH_NORM: minmax
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 1.2
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.8
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  RGB_PHOTO_AUG:
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    ENABLED: false
    HUE: 0.0
    SATURATION: 0.1
  SIZE_DIVISIBILITY: 32
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BOUNDARY:
    ENABLED: false
  DEPTH_BACKBONE:
    CONVNEXT:
      DEPTHS:
      - 3
      - 3
      - 9
      - 3
      DIMS:
      - 96
      - 192
      - 384
      - 768
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1.0e-06
    NAME: ConvNeXtDepthBackbone
    WEIGHTS: checkpoint_convertor/convnext-checkpoint/convnext_tiny_depth_22k_converted.pth
  DEVICE: cuda
  DPE:
    ENABLED: true
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MGMMultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MGMMaskFormer
  MGM:
    CLAMP_MAX: 0.95
    CLAMP_MIN: 0.05
    ENABLED: true
    FEATURE_DIMS:
    - 96
    - 192
    - 384
    - 768
    HIDDEN_DIM: 256
    LOSS_ENTROPY_W: 0.01
    NOISE_MASK_WEIGHT: 0.0
    POST_FUSE_NORM: true
    PRIOR:
      COMPUTE_ON: res3
      ENABLED: true
      USE_GRADIENT: true
      USE_RGB_EDGE: true
      USE_VALID_HOLE: true
      USE_VARIANCE: true
      VAR_KERNEL: 5
      Z_MAX: 1.0
      Z_MIN: 0.0
    RESIDUAL_ALPHA: 0.05
    ROBUST_NORM:
      ENABLED: true
      METHOD: minmax
    SCALE_KEYS:
    - res2
    - res3
    - res4
    - res5
    SHARED: true
    TEMP_FINAL: 1.0
    TEMP_INIT: 1.5
    TEMP_STEPS: 3000
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  RGB_BACKBONE:
    NAME: D2SwinTransformer
    SWIN:
      APE: false
      ATTN_DROP_RATE: 0.0
      DEPTHS:
      - 2
      - 2
      - 6
      - 2
      DROP_PATH_RATE: 0.3
      DROP_RATE: 0.0
      EMBED_DIM: 96
      MLP_RATIO: 4.0
      NUM_HEADS:
      - 3
      - 6
      - 12
      - 24
      OUT_FEATURES:
      - res2
      - res3
      - res4
      - res5
      PATCH_NORM: true
      PATCH_SIZE: 4
      PRETRAIN_IMG_SIZE: 224
      QKV_BIAS: true
      QK_SCALE: null
      USE_CHECKPOINT: false
      WINDOW_SIZE: 7
    WEIGHTS: checkpoint_convertor/checkpoint_swin/checkpoint_swin_slice/swin_backbone.pth
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MGMHead
    NORM: GN
    NUM_CLASSES: 1
    PIXEL_DECODER_NAME: MGMMSDeformAttnPixelDecoder
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: ''
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 1.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 2000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 1000
  - 1500
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2.0
VIS_PERIOD: 0

[08/30 23:00:05] detectron2 INFO: Full config saved to ./output/config.yaml
[08/30 23:00:05] d2.utils.env INFO: Using a generated random seed 9105334
[08/30 23:00:26] d2.engine.defaults INFO: Model:
MGMMaskFormer(
  (rgb_backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.055)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.109)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.136)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.164)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.191)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.218)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.245)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.273)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.300)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (depth_backbone): ConvNeXtDepthBackbone(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
  )
  (mgm): MultiModalGatedFusion(
    (prior_extractor): DepthPriorExtractor()
    (conf_pred): ConfidencePredictor(
      (proj_image): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_depth): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_prior): Sequential(
        (0): Conv2d(5, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
      )
      (head): Sequential(
        (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): GroupNorm(8, 128, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (align_image): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (align_depth): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (post_norm): ModuleList(
      (0): GroupNorm(8, 96, eps=1e-05, affine=True)
      (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      (2): GroupNorm(8, 384, eps=1e-05, affine=True)
      (3): GroupNorm(8, 768, eps=1e-05, affine=True)
    )
  )
  (sem_seg_head): MGMHead(
    (pixel_decoder): MGMMSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (depth_pe): DepthPosEncoding(
        (mlp): Sequential(
          (0): Conv2d(1, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MGMMultiScaleMaskedTransformerDecoder(
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x MGMCrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=2, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 1
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/30 23:00:26] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [Mapper] Noise-mask dir not found, will skip masks: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/depth/depth_noise_mask
[08/30 23:00:26] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [COCOInstanceRGBDDatasetMapper] Augs: [RandomFlip(), ResizeScale(min_scale=0.8, max_scale=1.2, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=(1024, 1024))] | RGB: RGB | DATASET_ROOT=/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
[08/30 23:00:26] d2.data.datasets.coco INFO: Loaded 6 images in COCO format from /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/annotations/instances_train.json
[08/30 23:00:26] d2.data.build INFO: Removed 0 images with no usable annotations. 6 images left.
[08/30 23:00:26] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| component  | 147          |
|            |              |[0m
[08/30 23:00:26] d2.data.build INFO: Using training sampler TrainingSampler
[08/30 23:00:26] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[08/30 23:00:26] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[08/30 23:00:26] d2.data.common INFO: Serialized dataset takes 0.16 MiB
[08/30 23:00:26] d2.data.build INFO: Making batched data loader with batch_size=1
[08/30 23:00:26] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[08/30 23:00:26] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[08/30 23:00:26] d2.engine.train_loop INFO: Starting training from iteration 0
[08/30 23:00:36] d2.utils.events INFO:  eta: 0:14:11  iter: 19  total_loss: 76.49  loss_ce: 1.169  loss_mask: 1.163  loss_dice: 4.977  loss_ce_0: 0.9824  loss_mask_0: 0.8712  loss_dice_0: 4.887  loss_ce_1: 1.1  loss_mask_1: 0.6911  loss_dice_1: 4.884  loss_ce_2: 1.392  loss_mask_2: 0.5067  loss_dice_2: 4.966  loss_ce_3: 1.527  loss_mask_3: 0.8434  loss_dice_3: 4.915  loss_ce_4: 2.108  loss_mask_4: 1.149  loss_dice_4: 4.929  loss_ce_5: 2.259  loss_mask_5: 1.72  loss_dice_5: 4.916  loss_ce_6: 2.273  loss_mask_6: 0.8351  loss_dice_6: 4.966  loss_ce_7: 2.303  loss_mask_7: 0.7504  loss_dice_7: 4.909  loss_ce_8: 1.807  loss_mask_8: 1.554  loss_dice_8: 4.849  loss_mgm_entropy: 0.006824    time: 0.4259  last_time: 0.4296  data_time: 0.0289  last_data_time: 0.0025   lr: 4.762e-07  max_mem: 15533M
[08/30 23:00:45] d2.utils.events INFO:  eta: 0:14:03  iter: 39  total_loss: 71.43  loss_ce: 1.11  loss_mask: 0.5076  loss_dice: 4.976  loss_ce_0: 0.9033  loss_mask_0: 0.7757  loss_dice_0: 4.886  loss_ce_1: 1.023  loss_mask_1: 0.5762  loss_dice_1: 4.874  loss_ce_2: 1.284  loss_mask_2: 0.3742  loss_dice_2: 4.97  loss_ce_3: 1.385  loss_mask_3: 0.5926  loss_dice_3: 4.943  loss_ce_4: 1.884  loss_mask_4: 0.7684  loss_dice_4: 4.939  loss_ce_5: 1.917  loss_mask_5: 1.034  loss_dice_5: 4.956  loss_ce_6: 1.914  loss_mask_6: 0.5465  loss_dice_6: 4.966  loss_ce_7: 2.026  loss_mask_7: 0.5865  loss_dice_7: 4.938  loss_ce_8: 1.654  loss_mask_8: 0.9981  loss_dice_8: 4.847  loss_mgm_entropy: 0.006764    time: 0.4337  last_time: 0.4312  data_time: 0.0030  last_data_time: 0.0037   lr: 8.722e-07  max_mem: 15533M
[08/30 23:00:53] d2.utils.events INFO:  eta: 0:13:57  iter: 59  total_loss: 66.46  loss_ce: 1.082  loss_mask: 0.2486  loss_dice: 4.968  loss_ce_0: 0.8122  loss_mask_0: 0.6965  loss_dice_0: 4.887  loss_ce_1: 1.001  loss_mask_1: 0.4992  loss_dice_1: 4.894  loss_ce_2: 1.103  loss_mask_2: 0.3003  loss_dice_2: 4.965  loss_ce_3: 1.187  loss_mask_3: 0.4018  loss_dice_3: 4.967  loss_ce_4: 1.398  loss_mask_4: 0.5708  loss_dice_4: 4.951  loss_ce_5: 1.314  loss_mask_5: 0.5862  loss_dice_5: 4.968  loss_ce_6: 1.389  loss_mask_6: 0.3671  loss_dice_6: 4.971  loss_ce_7: 1.563  loss_mask_7: 0.4645  loss_dice_7: 4.948  loss_ce_8: 1.436  loss_mask_8: 0.661  loss_dice_8: 4.887  loss_mgm_entropy: 0.006664    time: 0.4332  last_time: 0.4311  data_time: 0.0035  last_data_time: 0.0035   lr: 1.2682e-06  max_mem: 15535M
[08/30 23:01:02] d2.utils.events INFO:  eta: 0:13:49  iter: 79  total_loss: 63.84  loss_ce: 1.098  loss_mask: 0.2016  loss_dice: 4.961  loss_ce_0: 0.7898  loss_mask_0: 0.6274  loss_dice_0: 4.849  loss_ce_1: 0.926  loss_mask_1: 0.4798  loss_dice_1: 4.869  loss_ce_2: 0.9837  loss_mask_2: 0.2869  loss_dice_2: 4.945  loss_ce_3: 1.033  loss_mask_3: 0.2694  loss_dice_3: 4.949  loss_ce_4: 1.127  loss_mask_4: 0.4765  loss_dice_4: 4.895  loss_ce_5: 1.106  loss_mask_5: 0.3784  loss_dice_5: 4.93  loss_ce_6: 1.106  loss_mask_6: 0.2928  loss_dice_6: 4.949  loss_ce_7: 1.17  loss_mask_7: 0.4008  loss_dice_7: 4.915  loss_ce_8: 1.144  loss_mask_8: 0.5533  loss_dice_8: 4.851  loss_mgm_entropy: 0.00656    time: 0.4343  last_time: 0.4328  data_time: 0.0035  last_data_time: 0.0037   lr: 1.6642e-06  max_mem: 15535M
[08/30 23:01:11] d2.utils.events INFO:  eta: 0:13:41  iter: 99  total_loss: 64.11  loss_ce: 1.094  loss_mask: 0.4811  loss_dice: 4.929  loss_ce_0: 0.7837  loss_mask_0: 0.6741  loss_dice_0: 4.782  loss_ce_1: 0.868  loss_mask_1: 0.5778  loss_dice_1: 4.796  loss_ce_2: 0.9277  loss_mask_2: 0.5184  loss_dice_2: 4.897  loss_ce_3: 0.9923  loss_mask_3: 0.4639  loss_dice_3: 4.897  loss_ce_4: 1.049  loss_mask_4: 0.5936  loss_dice_4: 4.823  loss_ce_5: 1.058  loss_mask_5: 0.5273  loss_dice_5: 4.865  loss_ce_6: 1.071  loss_mask_6: 0.5208  loss_dice_6: 4.878  loss_ce_7: 1.09  loss_mask_7: 0.5742  loss_dice_7: 4.86  loss_ce_8: 1.097  loss_mask_8: 0.6242  loss_dice_8: 4.796  loss_mgm_entropy: 0.0065    time: 0.4341  last_time: 0.4310  data_time: 0.0036  last_data_time: 0.0043   lr: 2.0602e-06  max_mem: 15536M
[08/30 23:01:19] d2.utils.events INFO:  eta: 0:13:32  iter: 119  total_loss: 64.15  loss_ce: 1.082  loss_mask: 0.5868  loss_dice: 4.857  loss_ce_0: 0.79  loss_mask_0: 0.7659  loss_dice_0: 4.729  loss_ce_1: 0.8258  loss_mask_1: 0.6437  loss_dice_1: 4.738  loss_ce_2: 0.9207  loss_mask_2: 0.5671  loss_dice_2: 4.821  loss_ce_3: 0.9833  loss_mask_3: 0.6067  loss_dice_3: 4.816  loss_ce_4: 1.039  loss_mask_4: 0.6753  loss_dice_4: 4.759  loss_ce_5: 1.062  loss_mask_5: 0.6369  loss_dice_5: 4.785  loss_ce_6: 1.074  loss_mask_6: 0.6086  loss_dice_6: 4.785  loss_ce_7: 1.079  loss_mask_7: 0.6228  loss_dice_7: 4.775  loss_ce_8: 1.095  loss_mask_8: 0.7125  loss_dice_8: 4.746  loss_mgm_entropy: 0.006463    time: 0.4337  last_time: 0.4326  data_time: 0.0034  last_data_time: 0.0032   lr: 2.4562e-06  max_mem: 15538M
[08/30 23:01:28] d2.utils.events INFO:  eta: 0:13:24  iter: 139  total_loss: 63.55  loss_ce: 1.08  loss_mask: 0.5465  loss_dice: 4.821  loss_ce_0: 0.7742  loss_mask_0: 0.7319  loss_dice_0: 4.727  loss_ce_1: 0.8146  loss_mask_1: 0.592  loss_dice_1: 4.753  loss_ce_2: 0.9086  loss_mask_2: 0.5408  loss_dice_2: 4.808  loss_ce_3: 0.9781  loss_mask_3: 0.5467  loss_dice_3: 4.807  loss_ce_4: 1.03  loss_mask_4: 0.5887  loss_dice_4: 4.793  loss_ce_5: 1.055  loss_mask_5: 0.5932  loss_dice_5: 4.799  loss_ce_6: 1.071  loss_mask_6: 0.5477  loss_dice_6: 4.803  loss_ce_7: 1.084  loss_mask_7: 0.5624  loss_dice_7: 4.796  loss_ce_8: 1.093  loss_mask_8: 0.6019  loss_dice_8: 4.777  loss_mgm_entropy: 0.006471    time: 0.4335  last_time: 0.4343  data_time: 0.0034  last_data_time: 0.0030   lr: 2.8522e-06  max_mem: 15538M
[08/30 23:01:37] d2.utils.events INFO:  eta: 0:13:15  iter: 159  total_loss: 63.81  loss_ce: 1.096  loss_mask: 0.6438  loss_dice: 4.776  loss_ce_0: 0.7441  loss_mask_0: 0.7605  loss_dice_0: 4.713  loss_ce_1: 0.8009  loss_mask_1: 0.6135  loss_dice_1: 4.745  loss_ce_2: 0.8984  loss_mask_2: 0.5932  loss_dice_2: 4.774  loss_ce_3: 0.9701  loss_mask_3: 0.6187  loss_dice_3: 4.77  loss_ce_4: 1.024  loss_mask_4: 0.6181  loss_dice_4: 4.775  loss_ce_5: 1.055  loss_mask_5: 0.6207  loss_dice_5: 4.776  loss_ce_6: 1.071  loss_mask_6: 0.6233  loss_dice_6: 4.771  loss_ce_7: 1.087  loss_mask_7: 0.6284  loss_dice_7: 4.769  loss_ce_8: 1.093  loss_mask_8: 0.6076  loss_dice_8: 4.776  loss_mgm_entropy: 0.006424    time: 0.4335  last_time: 0.4347  data_time: 0.0035  last_data_time: 0.0040   lr: 3.2482e-06  max_mem: 15538M
[08/30 23:01:45] d2.utils.events INFO:  eta: 0:13:07  iter: 179  total_loss: 63.27  loss_ce: 1.074  loss_mask: 0.5921  loss_dice: 4.773  loss_ce_0: 0.7439  loss_mask_0: 0.6852  loss_dice_0: 4.726  loss_ce_1: 0.7859  loss_mask_1: 0.5827  loss_dice_1: 4.746  loss_ce_2: 0.8791  loss_mask_2: 0.5808  loss_dice_2: 4.756  loss_ce_3: 0.9546  loss_mask_3: 0.5885  loss_dice_3: 4.765  loss_ce_4: 1.014  loss_mask_4: 0.5719  loss_dice_4: 4.782  loss_ce_5: 1.042  loss_mask_5: 0.5861  loss_dice_5: 4.775  loss_ce_6: 1.062  loss_mask_6: 0.5935  loss_dice_6: 4.77  loss_ce_7: 1.075  loss_mask_7: 0.5704  loss_dice_7: 4.768  loss_ce_8: 1.079  loss_mask_8: 0.5875  loss_dice_8: 4.771  loss_mgm_entropy: 0.006366    time: 0.4336  last_time: 0.4331  data_time: 0.0035  last_data_time: 0.0033   lr: 3.6442e-06  max_mem: 15538M
[08/30 23:01:54] d2.utils.events INFO:  eta: 0:12:58  iter: 199  total_loss: 62.66  loss_ce: 1.074  loss_mask: 0.5519  loss_dice: 4.776  loss_ce_0: 0.7392  loss_mask_0: 0.6387  loss_dice_0: 4.73  loss_ce_1: 0.7629  loss_mask_1: 0.5395  loss_dice_1: 4.742  loss_ce_2: 0.8555  loss_mask_2: 0.5363  loss_dice_2: 4.744  loss_ce_3: 0.9289  loss_mask_3: 0.5461  loss_dice_3: 4.758  loss_ce_4: 0.9943  loss_mask_4: 0.5344  loss_dice_4: 4.774  loss_ce_5: 1.03  loss_mask_5: 0.5479  loss_dice_5: 4.766  loss_ce_6: 1.048  loss_mask_6: 0.5617  loss_dice_6: 4.766  loss_ce_7: 1.068  loss_mask_7: 0.5417  loss_dice_7: 4.765  loss_ce_8: 1.076  loss_mask_8: 0.5483  loss_dice_8: 4.762  loss_mgm_entropy: 0.006349    time: 0.4337  last_time: 0.4333  data_time: 0.0034  last_data_time: 0.0034   lr: 4.0402e-06  max_mem: 15538M
[08/30 23:02:03] d2.utils.events INFO:  eta: 0:12:50  iter: 219  total_loss: 63.49  loss_ce: 1.083  loss_mask: 0.6669  loss_dice: 4.761  loss_ce_0: 0.7369  loss_mask_0: 0.671  loss_dice_0: 4.721  loss_ce_1: 0.7493  loss_mask_1: 0.6152  loss_dice_1: 4.741  loss_ce_2: 0.8276  loss_mask_2: 0.6137  loss_dice_2: 4.746  loss_ce_3: 0.9081  loss_mask_3: 0.645  loss_dice_3: 4.744  loss_ce_4: 0.9812  loss_mask_4: 0.6389  loss_dice_4: 4.761  loss_ce_5: 1.02  loss_mask_5: 0.6421  loss_dice_5: 4.758  loss_ce_6: 1.043  loss_mask_6: 0.6421  loss_dice_6: 4.759  loss_ce_7: 1.073  loss_mask_7: 0.6335  loss_dice_7: 4.757  loss_ce_8: 1.079  loss_mask_8: 0.6391  loss_dice_8: 4.765  loss_mgm_entropy: 0.006314    time: 0.4338  last_time: 0.4356  data_time: 0.0033  last_data_time: 0.0031   lr: 4.4362e-06  max_mem: 15538M
[08/30 23:02:12] d2.utils.events INFO:  eta: 0:12:42  iter: 239  total_loss: 63.04  loss_ce: 1.079  loss_mask: 0.6193  loss_dice: 4.768  loss_ce_0: 0.7383  loss_mask_0: 0.6559  loss_dice_0: 4.72  loss_ce_1: 0.723  loss_mask_1: 0.6117  loss_dice_1: 4.734  loss_ce_2: 0.7877  loss_mask_2: 0.6207  loss_dice_2: 4.744  loss_ce_3: 0.8652  loss_mask_3: 0.6273  loss_dice_3: 4.744  loss_ce_4: 0.9494  loss_mask_4: 0.6105  loss_dice_4: 4.762  loss_ce_5: 0.9987  loss_mask_5: 0.6404  loss_dice_5: 4.764  loss_ce_6: 1.033  loss_mask_6: 0.6303  loss_dice_6: 4.755  loss_ce_7: 1.065  loss_mask_7: 0.6361  loss_dice_7: 4.756  loss_ce_8: 1.078  loss_mask_8: 0.6176  loss_dice_8: 4.765  loss_mgm_entropy: 0.006273    time: 0.4338  last_time: 0.4355  data_time: 0.0035  last_data_time: 0.0031   lr: 4.8322e-06  max_mem: 15538M
[08/30 23:02:20] d2.utils.events INFO:  eta: 0:12:33  iter: 259  total_loss: 62.45  loss_ce: 1.067  loss_mask: 0.6037  loss_dice: 4.759  loss_ce_0: 0.7347  loss_mask_0: 0.6184  loss_dice_0: 4.731  loss_ce_1: 0.6951  loss_mask_1: 0.5713  loss_dice_1: 4.733  loss_ce_2: 0.7372  loss_mask_2: 0.565  loss_dice_2: 4.732  loss_ce_3: 0.811  loss_mask_3: 0.585  loss_dice_3: 4.744  loss_ce_4: 0.9016  loss_mask_4: 0.5671  loss_dice_4: 4.764  loss_ce_5: 0.959  loss_mask_5: 0.594  loss_dice_5: 4.761  loss_ce_6: 1.002  loss_mask_6: 0.5969  loss_dice_6: 4.76  loss_ce_7: 1.041  loss_mask_7: 0.5868  loss_dice_7: 4.764  loss_ce_8: 1.062  loss_mask_8: 0.5921  loss_dice_8: 4.755  loss_mgm_entropy: 0.006124    time: 0.4340  last_time: 0.4344  data_time: 0.0034  last_data_time: 0.0035   lr: 5.2282e-06  max_mem: 15538M
[08/30 23:02:29] d2.utils.events INFO:  eta: 0:12:25  iter: 279  total_loss: 61.93  loss_ce: 1.056  loss_mask: 0.5856  loss_dice: 4.758  loss_ce_0: 0.735  loss_mask_0: 0.5967  loss_dice_0: 4.729  loss_ce_1: 0.6631  loss_mask_1: 0.5784  loss_dice_1: 4.728  loss_ce_2: 0.6769  loss_mask_2: 0.5719  loss_dice_2: 4.732  loss_ce_3: 0.732  loss_mask_3: 0.5777  loss_dice_3: 4.74  loss_ce_4: 0.823  loss_mask_4: 0.5641  loss_dice_4: 4.751  loss_ce_5: 0.8954  loss_mask_5: 0.5855  loss_dice_5: 4.751  loss_ce_6: 0.9542  loss_mask_6: 0.5812  loss_dice_6: 4.756  loss_ce_7: 1.012  loss_mask_7: 0.5768  loss_dice_7: 4.753  loss_ce_8: 1.045  loss_mask_8: 0.5763  loss_dice_8: 4.753  loss_mgm_entropy: 0.006065    time: 0.4341  last_time: 0.4360  data_time: 0.0035  last_data_time: 0.0031   lr: 5.6242e-06  max_mem: 15538M
[08/30 23:02:38] d2.utils.events INFO:  eta: 0:12:17  iter: 299  total_loss: 60.99  loss_ce: 1.034  loss_mask: 0.575  loss_dice: 4.766  loss_ce_0: 0.7255  loss_mask_0: 0.5904  loss_dice_0: 4.726  loss_ce_1: 0.6211  loss_mask_1: 0.5635  loss_dice_1: 4.714  loss_ce_2: 0.6023  loss_mask_2: 0.5463  loss_dice_2: 4.722  loss_ce_3: 0.6102  loss_mask_3: 0.5561  loss_dice_3: 4.736  loss_ce_4: 0.688  loss_mask_4: 0.559  loss_dice_4: 4.745  loss_ce_5: 0.7696  loss_mask_5: 0.5771  loss_dice_5: 4.748  loss_ce_6: 0.8475  loss_mask_6: 0.5864  loss_dice_6: 4.748  loss_ce_7: 0.9507  loss_mask_7: 0.5675  loss_dice_7: 4.763  loss_ce_8: 1.008  loss_mask_8: 0.5794  loss_dice_8: 4.755  loss_mgm_entropy: 0.005924    time: 0.4341  last_time: 0.4358  data_time: 0.0034  last_data_time: 0.0035   lr: 6.0202e-06  max_mem: 15538M
[08/30 23:02:46] d2.utils.events INFO:  eta: 0:12:08  iter: 319  total_loss: 59.49  loss_ce: 0.9653  loss_mask: 0.6235  loss_dice: 4.757  loss_ce_0: 0.7165  loss_mask_0: 0.6163  loss_dice_0: 4.723  loss_ce_1: 0.5713  loss_mask_1: 0.6015  loss_dice_1: 4.714  loss_ce_2: 0.4911  loss_mask_2: 0.589  loss_dice_2: 4.71  loss_ce_3: 0.4458  loss_mask_3: 0.6122  loss_dice_3: 4.726  loss_ce_4: 0.4526  loss_mask_4: 0.6048  loss_dice_4: 4.744  loss_ce_5: 0.4704  loss_mask_5: 0.6179  loss_dice_5: 4.733  loss_ce_6: 0.5546  loss_mask_6: 0.6248  loss_dice_6: 4.735  loss_ce_7: 0.734  loss_mask_7: 0.6053  loss_dice_7: 4.756  loss_ce_8: 0.8774  loss_mask_8: 0.6095  loss_dice_8: 4.751  loss_mgm_entropy: 0.005624    time: 0.4342  last_time: 0.4376  data_time: 0.0034  last_data_time: 0.0038   lr: 6.4162e-06  max_mem: 15538M
[08/30 23:02:55] d2.utils.events INFO:  eta: 0:12:00  iter: 339  total_loss: 56.82  loss_ce: 0.5909  loss_mask: 0.596  loss_dice: 4.758  loss_ce_0: 0.7214  loss_mask_0: 0.5949  loss_dice_0: 4.713  loss_ce_1: 0.5201  loss_mask_1: 0.5854  loss_dice_1: 4.702  loss_ce_2: 0.3706  loss_mask_2: 0.5885  loss_dice_2: 4.708  loss_ce_3: 0.2528  loss_mask_3: 0.5938  loss_dice_3: 4.718  loss_ce_4: 0.2117  loss_mask_4: 0.5516  loss_dice_4: 4.731  loss_ce_5: 0.1714  loss_mask_5: 0.6  loss_dice_5: 4.715  loss_ce_6: 0.1756  loss_mask_6: 0.5854  loss_dice_6: 4.731  loss_ce_7: 0.2741  loss_mask_7: 0.5921  loss_dice_7: 4.731  loss_ce_8: 0.4329  loss_mask_8: 0.6087  loss_dice_8: 4.74  loss_mgm_entropy: 0.005398    time: 0.4343  last_time: 0.4353  data_time: 0.0034  last_data_time: 0.0034   lr: 6.8122e-06  max_mem: 15538M
[08/30 23:03:04] d2.utils.events INFO:  eta: 0:11:51  iter: 359  total_loss: 55.25  loss_ce: 0.1749  loss_mask: 0.6068  loss_dice: 4.741  loss_ce_0: 0.7197  loss_mask_0: 0.6244  loss_dice_0: 4.693  loss_ce_1: 0.4698  loss_mask_1: 0.6127  loss_dice_1: 4.677  loss_ce_2: 0.2844  loss_mask_2: 0.6075  loss_dice_2: 4.686  loss_ce_3: 0.1571  loss_mask_3: 0.6133  loss_dice_3: 4.69  loss_ce_4: 0.09896  loss_mask_4: 0.6135  loss_dice_4: 4.701  loss_ce_5: 0.06017  loss_mask_5: 0.6106  loss_dice_5: 4.696  loss_ce_6: 0.05278  loss_mask_6: 0.6257  loss_dice_6: 4.714  loss_ce_7: 0.06061  loss_mask_7: 0.6161  loss_dice_7: 4.715  loss_ce_8: 0.09555  loss_mask_8: 0.6172  loss_dice_8: 4.727  loss_mgm_entropy: 0.00526    time: 0.4344  last_time: 0.4356  data_time: 0.0036  last_data_time: 0.0036   lr: 7.2082e-06  max_mem: 15538M
[08/30 23:03:13] d2.utils.events INFO:  eta: 0:11:43  iter: 379  total_loss: 54.1  loss_ce: 0.05789  loss_mask: 0.6032  loss_dice: 4.709  loss_ce_0: 0.7178  loss_mask_0: 0.5924  loss_dice_0: 4.665  loss_ce_1: 0.4383  loss_mask_1: 0.5732  loss_dice_1: 4.646  loss_ce_2: 0.2246  loss_mask_2: 0.5896  loss_dice_2: 4.64  loss_ce_3: 0.1092  loss_mask_3: 0.5729  loss_dice_3: 4.658  loss_ce_4: 0.06233  loss_mask_4: 0.5725  loss_dice_4: 4.661  loss_ce_5: 0.03976  loss_mask_5: 0.566  loss_dice_5: 4.652  loss_ce_6: 0.03494  loss_mask_6: 0.5738  loss_dice_6: 4.662  loss_ce_7: 0.04033  loss_mask_7: 0.5826  loss_dice_7: 4.675  loss_ce_8: 0.04466  loss_mask_8: 0.5962  loss_dice_8: 4.7  loss_mgm_entropy: 0.005042    time: 0.4345  last_time: 0.4354  data_time: 0.0034  last_data_time: 0.0035   lr: 7.6042e-06  max_mem: 15538M
[08/30 23:03:21] d2.utils.events INFO:  eta: 0:11:35  iter: 399  total_loss: 52.75  loss_ce: 0.05101  loss_mask: 0.5273  loss_dice: 4.65  loss_ce_0: 0.7171  loss_mask_0: 0.5449  loss_dice_0: 4.614  loss_ce_1: 0.4087  loss_mask_1: 0.5342  loss_dice_1: 4.572  loss_ce_2: 0.1874  loss_mask_2: 0.5381  loss_dice_2: 4.541  loss_ce_3: 0.08762  loss_mask_3: 0.534  loss_dice_3: 4.538  loss_ce_4: 0.05309  loss_mask_4: 0.5151  loss_dice_4: 4.563  loss_ce_5: 0.03541  loss_mask_5: 0.5372  loss_dice_5: 4.553  loss_ce_6: 0.0346  loss_mask_6: 0.5324  loss_dice_6: 4.539  loss_ce_7: 0.03152  loss_mask_7: 0.5351  loss_dice_7: 4.586  loss_ce_8: 0.03832  loss_mask_8: 0.5326  loss_dice_8: 4.614  loss_mgm_entropy: 0.004981    time: 0.4345  last_time: 0.4352  data_time: 0.0035  last_data_time: 0.0035   lr: 8.0002e-06  max_mem: 15538M
[08/30 23:03:30] d2.utils.events INFO:  eta: 0:11:26  iter: 419  total_loss: 51.17  loss_ce: 0.04899  loss_mask: 0.5236  loss_dice: 4.512  loss_ce_0: 0.7206  loss_mask_0: 0.485  loss_dice_0: 4.534  loss_ce_1: 0.3867  loss_mask_1: 0.4894  loss_dice_1: 4.491  loss_ce_2: 0.1639  loss_mask_2: 0.4802  loss_dice_2: 4.438  loss_ce_3: 0.07606  loss_mask_3: 0.4948  loss_dice_3: 4.415  loss_ce_4: 0.04881  loss_mask_4: 0.4722  loss_dice_4: 4.429  loss_ce_5: 0.03402  loss_mask_5: 0.5165  loss_dice_5: 4.397  loss_ce_6: 0.0391  loss_mask_6: 0.4842  loss_dice_6: 4.417  loss_ce_7: 0.04277  loss_mask_7: 0.5029  loss_dice_7: 4.423  loss_ce_8: 0.04436  loss_mask_8: 0.4974  loss_dice_8: 4.464  loss_mgm_entropy: 0.004944    time: 0.4346  last_time: 0.4357  data_time: 0.0034  last_data_time: 0.0038   lr: 8.3962e-06  max_mem: 15540M
[08/30 23:03:39] d2.utils.events INFO:  eta: 0:11:17  iter: 439  total_loss: 49.4  loss_ce: 0.04637  loss_mask: 0.4725  loss_dice: 4.365  loss_ce_0: 0.7229  loss_mask_0: 0.4715  loss_dice_0: 4.473  loss_ce_1: 0.3619  loss_mask_1: 0.4518  loss_dice_1: 4.391  loss_ce_2: 0.146  loss_mask_2: 0.4433  loss_dice_2: 4.281  loss_ce_3: 0.074  loss_mask_3: 0.4498  loss_dice_3: 4.244  loss_ce_4: 0.04557  loss_mask_4: 0.4426  loss_dice_4: 4.25  loss_ce_5: 0.04131  loss_mask_5: 0.4872  loss_dice_5: 4.225  loss_ce_6: 0.03685  loss_mask_6: 0.4483  loss_dice_6: 4.229  loss_ce_7: 0.04686  loss_mask_7: 0.4756  loss_dice_7: 4.243  loss_ce_8: 0.04237  loss_mask_8: 0.484  loss_dice_8: 4.287  loss_mgm_entropy: 0.004837    time: 0.4346  last_time: 0.4345  data_time: 0.0033  last_data_time: 0.0032   lr: 8.7922e-06  max_mem: 15541M
[08/30 23:03:47] d2.utils.events INFO:  eta: 0:11:09  iter: 459  total_loss: 47.46  loss_ce: 0.04521  loss_mask: 0.4946  loss_dice: 4.115  loss_ce_0: 0.7331  loss_mask_0: 0.4985  loss_dice_0: 4.37  loss_ce_1: 0.3488  loss_mask_1: 0.4913  loss_dice_1: 4.24  loss_ce_2: 0.1461  loss_mask_2: 0.4906  loss_dice_2: 4.112  loss_ce_3: 0.07948  loss_mask_3: 0.5076  loss_dice_3: 4.055  loss_ce_4: 0.05363  loss_mask_4: 0.5031  loss_dice_4: 4.062  loss_ce_5: 0.04343  loss_mask_5: 0.5048  loss_dice_5: 3.996  loss_ce_6: 0.04598  loss_mask_6: 0.5048  loss_dice_6: 4.019  loss_ce_7: 0.04268  loss_mask_7: 0.5094  loss_dice_7: 4.018  loss_ce_8: 0.04591  loss_mask_8: 0.508  loss_dice_8: 4.078  loss_mgm_entropy: 0.004731    time: 0.4346  last_time: 0.4356  data_time: 0.0034  last_data_time: 0.0030   lr: 9.1882e-06  max_mem: 15541M
[08/30 23:03:56] d2.utils.events INFO:  eta: 0:11:00  iter: 479  total_loss: 45.3  loss_ce: 0.05251  loss_mask: 0.4802  loss_dice: 3.937  loss_ce_0: 0.7605  loss_mask_0: 0.4513  loss_dice_0: 4.26  loss_ce_1: 0.3416  loss_mask_1: 0.4524  loss_dice_1: 4.105  loss_ce_2: 0.1378  loss_mask_2: 0.4537  loss_dice_2: 3.96  loss_ce_3: 0.06717  loss_mask_3: 0.453  loss_dice_3: 3.866  loss_ce_4: 0.05303  loss_mask_4: 0.448  loss_dice_4: 3.805  loss_ce_5: 0.04616  loss_mask_5: 0.4726  loss_dice_5: 3.783  loss_ce_6: 0.04548  loss_mask_6: 0.4614  loss_dice_6: 3.799  loss_ce_7: 0.04554  loss_mask_7: 0.4779  loss_dice_7: 3.785  loss_ce_8: 0.04975  loss_mask_8: 0.4553  loss_dice_8: 3.839  loss_mgm_entropy: 0.004664    time: 0.4346  last_time: 0.4339  data_time: 0.0034  last_data_time: 0.0041   lr: 9.5842e-06  max_mem: 15541M
[08/30 23:04:05] d2.utils.events INFO:  eta: 0:10:52  iter: 499  total_loss: 43.93  loss_ce: 0.04809  loss_mask: 0.4314  loss_dice: 3.736  loss_ce_0: 0.7744  loss_mask_0: 0.4245  loss_dice_0: 4.185  loss_ce_1: 0.3504  loss_mask_1: 0.4135  loss_dice_1: 3.955  loss_ce_2: 0.1333  loss_mask_2: 0.4347  loss_dice_2: 3.725  loss_ce_3: 0.06848  loss_mask_3: 0.4162  loss_dice_3: 3.66  loss_ce_4: 0.05966  loss_mask_4: 0.4372  loss_dice_4: 3.646  loss_ce_5: 0.04905  loss_mask_5: 0.421  loss_dice_5: 3.595  loss_ce_6: 0.044  loss_mask_6: 0.4341  loss_dice_6: 3.601  loss_ce_7: 0.04967  loss_mask_7: 0.4339  loss_dice_7: 3.603  loss_ce_8: 0.04651  loss_mask_8: 0.4452  loss_dice_8: 3.651  loss_mgm_entropy: 0.004609    time: 0.4346  last_time: 0.4362  data_time: 0.0034  last_data_time: 0.0038   lr: 9.9802e-06  max_mem: 15541M
[08/30 23:04:14] d2.utils.events INFO:  eta: 0:10:43  iter: 519  total_loss: 42.43  loss_ce: 0.05178  loss_mask: 0.531  loss_dice: 3.466  loss_ce_0: 0.7765  loss_mask_0: 0.4691  loss_dice_0: 4.108  loss_ce_1: 0.3546  loss_mask_1: 0.4801  loss_dice_1: 3.762  loss_ce_2: 0.127  loss_mask_2: 0.4912  loss_dice_2: 3.549  loss_ce_3: 0.06756  loss_mask_3: 0.5165  loss_dice_3: 3.44  loss_ce_4: 0.05157  loss_mask_4: 0.517  loss_dice_4: 3.438  loss_ce_5: 0.04909  loss_mask_5: 0.4821  loss_dice_5: 3.402  loss_ce_6: 0.05136  loss_mask_6: 0.5342  loss_dice_6: 3.427  loss_ce_7: 0.05077  loss_mask_7: 0.5407  loss_dice_7: 3.372  loss_ce_8: 0.04879  loss_mask_8: 0.5168  loss_dice_8: 3.454  loss_mgm_entropy: 0.004631    time: 0.4348  last_time: 0.4354  data_time: 0.0034  last_data_time: 0.0033   lr: 1e-05  max_mem: 15541M
[08/30 23:04:22] d2.utils.events INFO:  eta: 0:10:34  iter: 539  total_loss: 39.16  loss_ce: 0.05903  loss_mask: 0.4494  loss_dice: 3.253  loss_ce_0: 0.8028  loss_mask_0: 0.424  loss_dice_0: 3.991  loss_ce_1: 0.3487  loss_mask_1: 0.4228  loss_dice_1: 3.585  loss_ce_2: 0.1125  loss_mask_2: 0.439  loss_dice_2: 3.37  loss_ce_3: 0.06279  loss_mask_3: 0.4296  loss_dice_3: 3.241  loss_ce_4: 0.04779  loss_mask_4: 0.4319  loss_dice_4: 3.228  loss_ce_5: 0.04853  loss_mask_5: 0.4576  loss_dice_5: 3.172  loss_ce_6: 0.04606  loss_mask_6: 0.4211  loss_dice_6: 3.2  loss_ce_7: 0.04756  loss_mask_7: 0.4321  loss_dice_7: 3.177  loss_ce_8: 0.05182  loss_mask_8: 0.4436  loss_dice_8: 3.197  loss_mgm_entropy: 0.004748    time: 0.4348  last_time: 0.4347  data_time: 0.0034  last_data_time: 0.0035   lr: 1e-05  max_mem: 15541M
[08/30 23:04:31] d2.utils.events INFO:  eta: 0:10:26  iter: 559  total_loss: 37.57  loss_ce: 0.0574  loss_mask: 0.4596  loss_dice: 3.005  loss_ce_0: 0.8095  loss_mask_0: 0.4517  loss_dice_0: 3.886  loss_ce_1: 0.3465  loss_mask_1: 0.44  loss_dice_1: 3.453  loss_ce_2: 0.1174  loss_mask_2: 0.456  loss_dice_2: 3.212  loss_ce_3: 0.06621  loss_mask_3: 0.4515  loss_dice_3: 3.073  loss_ce_4: 0.05242  loss_mask_4: 0.4616  loss_dice_4: 2.997  loss_ce_5: 0.0499  loss_mask_5: 0.4697  loss_dice_5: 2.966  loss_ce_6: 0.04715  loss_mask_6: 0.4673  loss_dice_6: 2.964  loss_ce_7: 0.0482  loss_mask_7: 0.4481  loss_dice_7: 2.942  loss_ce_8: 0.05273  loss_mask_8: 0.4546  loss_dice_8: 2.982  loss_mgm_entropy: 0.004737    time: 0.4348  last_time: 0.4338  data_time: 0.0033  last_data_time: 0.0034   lr: 1e-05  max_mem: 15541M
[08/30 23:04:40] d2.utils.events INFO:  eta: 0:10:17  iter: 579  total_loss: 36.22  loss_ce: 0.1033  loss_mask: 0.4153  loss_dice: 2.851  loss_ce_0: 0.8072  loss_mask_0: 0.4133  loss_dice_0: 3.793  loss_ce_1: 0.3525  loss_mask_1: 0.4046  loss_dice_1: 3.329  loss_ce_2: 0.1454  loss_mask_2: 0.4244  loss_dice_2: 3.08  loss_ce_3: 0.06414  loss_mask_3: 0.4343  loss_dice_3: 2.937  loss_ce_4: 0.05458  loss_mask_4: 0.3904  loss_dice_4: 2.936  loss_ce_5: 0.04977  loss_mask_5: 0.4236  loss_dice_5: 2.807  loss_ce_6: 0.05652  loss_mask_6: 0.4084  loss_dice_6: 2.869  loss_ce_7: 0.06102  loss_mask_7: 0.4259  loss_dice_7: 2.826  loss_ce_8: 0.06233  loss_mask_8: 0.3938  loss_dice_8: 2.852  loss_mgm_entropy: 0.004924    time: 0.4348  last_time: 0.4345  data_time: 0.0035  last_data_time: 0.0037   lr: 1e-05  max_mem: 15541M
[08/30 23:04:48] d2.utils.events INFO:  eta: 0:10:08  iter: 599  total_loss: 33.9  loss_ce: 0.1022  loss_mask: 0.3431  loss_dice: 2.654  loss_ce_0: 0.8225  loss_mask_0: 0.3624  loss_dice_0: 3.671  loss_ce_1: 0.3462  loss_mask_1: 0.357  loss_dice_1: 3.138  loss_ce_2: 0.1364  loss_mask_2: 0.3302  loss_dice_2: 2.87  loss_ce_3: 0.1162  loss_mask_3: 0.3244  loss_dice_3: 2.698  loss_ce_4: 0.09551  loss_mask_4: 0.3186  loss_dice_4: 2.694  loss_ce_5: 0.07794  loss_mask_5: 0.3251  loss_dice_5: 2.631  loss_ce_6: 0.06925  loss_mask_6: 0.3409  loss_dice_6: 2.638  loss_ce_7: 0.07469  loss_mask_7: 0.3529  loss_dice_7: 2.588  loss_ce_8: 0.07863  loss_mask_8: 0.3444  loss_dice_8: 2.643  loss_mgm_entropy: 0.00475    time: 0.4349  last_time: 0.4347  data_time: 0.0034  last_data_time: 0.0031   lr: 1e-05  max_mem: 15541M
[08/30 23:04:57] d2.utils.events INFO:  eta: 0:10:00  iter: 619  total_loss: 33.07  loss_ce: 0.164  loss_mask: 0.3642  loss_dice: 2.549  loss_ce_0: 0.8197  loss_mask_0: 0.3682  loss_dice_0: 3.626  loss_ce_1: 0.3419  loss_mask_1: 0.3444  loss_dice_1: 3.033  loss_ce_2: 0.1569  loss_mask_2: 0.3424  loss_dice_2: 2.78  loss_ce_3: 0.1316  loss_mask_3: 0.3503  loss_dice_3: 2.622  loss_ce_4: 0.08574  loss_mask_4: 0.3352  loss_dice_4: 2.604  loss_ce_5: 0.09134  loss_mask_5: 0.3339  loss_dice_5: 2.55  loss_ce_6: 0.09048  loss_mask_6: 0.3451  loss_dice_6: 2.542  loss_ce_7: 0.1363  loss_mask_7: 0.3439  loss_dice_7: 2.501  loss_ce_8: 0.1202  loss_mask_8: 0.3364  loss_dice_8: 2.52  loss_mgm_entropy: 0.004901    time: 0.4349  last_time: 0.4374  data_time: 0.0036  last_data_time: 0.0030   lr: 1e-05  max_mem: 15541M
[08/30 23:05:06] d2.utils.events INFO:  eta: 0:09:51  iter: 639  total_loss: 32.69  loss_ce: 0.1835  loss_mask: 0.3678  loss_dice: 2.501  loss_ce_0: 0.8275  loss_mask_0: 0.358  loss_dice_0: 3.489  loss_ce_1: 0.3567  loss_mask_1: 0.339  loss_dice_1: 2.932  loss_ce_2: 0.1581  loss_mask_2: 0.3446  loss_dice_2: 2.683  loss_ce_3: 0.1162  loss_mask_3: 0.3285  loss_dice_3: 2.555  loss_ce_4: 0.1255  loss_mask_4: 0.3496  loss_dice_4: 2.535  loss_ce_5: 0.1279  loss_mask_5: 0.3766  loss_dice_5: 2.511  loss_ce_6: 0.1266  loss_mask_6: 0.3742  loss_dice_6: 2.511  loss_ce_7: 0.1461  loss_mask_7: 0.3588  loss_dice_7: 2.483  loss_ce_8: 0.1446  loss_mask_8: 0.3724  loss_dice_8: 2.511  loss_mgm_entropy: 0.004736    time: 0.4349  last_time: 0.4358  data_time: 0.0035  last_data_time: 0.0036   lr: 1e-05  max_mem: 15541M
[08/30 23:05:15] d2.utils.events INFO:  eta: 0:09:42  iter: 659  total_loss: 32.56  loss_ce: 0.1841  loss_mask: 0.3402  loss_dice: 2.491  loss_ce_0: 0.8357  loss_mask_0: 0.3212  loss_dice_0: 3.443  loss_ce_1: 0.3437  loss_mask_1: 0.3003  loss_dice_1: 2.88  loss_ce_2: 0.1484  loss_mask_2: 0.3184  loss_dice_2: 2.672  loss_ce_3: 0.1192  loss_mask_3: 0.3167  loss_dice_3: 2.564  loss_ce_4: 0.1137  loss_mask_4: 0.3105  loss_dice_4: 2.518  loss_ce_5: 0.1336  loss_mask_5: 0.301  loss_dice_5: 2.454  loss_ce_6: 0.1211  loss_mask_6: 0.3173  loss_dice_6: 2.491  loss_ce_7: 0.1295  loss_mask_7: 0.314  loss_dice_7: 2.458  loss_ce_8: 0.1487  loss_mask_8: 0.3497  loss_dice_8: 2.487  loss_mgm_entropy: 0.004775    time: 0.4350  last_time: 0.4361  data_time: 0.0034  last_data_time: 0.0038   lr: 1e-05  max_mem: 15541M
[08/30 23:05:23] d2.utils.events INFO:  eta: 0:09:34  iter: 679  total_loss: 31.68  loss_ce: 0.1745  loss_mask: 0.3807  loss_dice: 2.414  loss_ce_0: 0.8367  loss_mask_0: 0.3708  loss_dice_0: 3.387  loss_ce_1: 0.3227  loss_mask_1: 0.3558  loss_dice_1: 2.877  loss_ce_2: 0.1485  loss_mask_2: 0.3492  loss_dice_2: 2.629  loss_ce_3: 0.1312  loss_mask_3: 0.3552  loss_dice_3: 2.469  loss_ce_4: 0.1321  loss_mask_4: 0.3561  loss_dice_4: 2.443  loss_ce_5: 0.1684  loss_mask_5: 0.3609  loss_dice_5: 2.411  loss_ce_6: 0.141  loss_mask_6: 0.3536  loss_dice_6: 2.43  loss_ce_7: 0.1777  loss_mask_7: 0.3651  loss_dice_7: 2.402  loss_ce_8: 0.1688  loss_mask_8: 0.3895  loss_dice_8: 2.429  loss_mgm_entropy: 0.004772    time: 0.4350  last_time: 0.4356  data_time: 0.0035  last_data_time: 0.0038   lr: 1e-05  max_mem: 15541M
[08/30 23:05:32] d2.utils.events INFO:  eta: 0:09:25  iter: 699  total_loss: 30.19  loss_ce: 0.1363  loss_mask: 0.367  loss_dice: 2.28  loss_ce_0: 0.8065  loss_mask_0: 0.3651  loss_dice_0: 3.292  loss_ce_1: 0.3313  loss_mask_1: 0.3349  loss_dice_1: 2.76  loss_ce_2: 0.1383  loss_mask_2: 0.3335  loss_dice_2: 2.491  loss_ce_3: 0.1127  loss_mask_3: 0.3469  loss_dice_3: 2.363  loss_ce_4: 0.1039  loss_mask_4: 0.3383  loss_dice_4: 2.359  loss_ce_5: 0.1174  loss_mask_5: 0.3473  loss_dice_5: 2.347  loss_ce_6: 0.1099  loss_mask_6: 0.3386  loss_dice_6: 2.294  loss_ce_7: 0.1168  loss_mask_7: 0.3667  loss_dice_7: 2.264  loss_ce_8: 0.1311  loss_mask_8: 0.3606  loss_dice_8: 2.298  loss_mgm_entropy: 0.004726    time: 0.4350  last_time: 0.4360  data_time: 0.0035  last_data_time: 0.0038   lr: 1e-05  max_mem: 15541M
[08/30 23:05:41] d2.utils.events INFO:  eta: 0:09:16  iter: 719  total_loss: 28.92  loss_ce: 0.1426  loss_mask: 0.2847  loss_dice: 2.223  loss_ce_0: 0.8156  loss_mask_0: 0.2952  loss_dice_0: 3.265  loss_ce_1: 0.314  loss_mask_1: 0.2703  loss_dice_1: 2.633  loss_ce_2: 0.1522  loss_mask_2: 0.2727  loss_dice_2: 2.403  loss_ce_3: 0.128  loss_mask_3: 0.2831  loss_dice_3: 2.289  loss_ce_4: 0.1288  loss_mask_4: 0.2853  loss_dice_4: 2.293  loss_ce_5: 0.1252  loss_mask_5: 0.2873  loss_dice_5: 2.237  loss_ce_6: 0.1233  loss_mask_6: 0.2831  loss_dice_6: 2.216  loss_ce_7: 0.1297  loss_mask_7: 0.2953  loss_dice_7: 2.188  loss_ce_8: 0.1338  loss_mask_8: 0.2825  loss_dice_8: 2.188  loss_mgm_entropy: 0.00461    time: 0.4350  last_time: 0.4401  data_time: 0.0037  last_data_time: 0.0033   lr: 1e-05  max_mem: 15541M
[08/30 23:05:50] d2.utils.events INFO:  eta: 0:09:08  iter: 739  total_loss: 28.53  loss_ce: 0.1409  loss_mask: 0.2885  loss_dice: 2.098  loss_ce_0: 0.7996  loss_mask_0: 0.3311  loss_dice_0: 3.203  loss_ce_1: 0.3161  loss_mask_1: 0.2849  loss_dice_1: 2.597  loss_ce_2: 0.1371  loss_mask_2: 0.2899  loss_dice_2: 2.387  loss_ce_3: 0.1166  loss_mask_3: 0.298  loss_dice_3: 2.269  loss_ce_4: 0.1152  loss_mask_4: 0.2877  loss_dice_4: 2.205  loss_ce_5: 0.1261  loss_mask_5: 0.2875  loss_dice_5: 2.162  loss_ce_6: 0.13  loss_mask_6: 0.2975  loss_dice_6: 2.159  loss_ce_7: 0.1261  loss_mask_7: 0.3028  loss_dice_7: 2.142  loss_ce_8: 0.1384  loss_mask_8: 0.3045  loss_dice_8: 2.142  loss_mgm_entropy: 0.004664    time: 0.4350  last_time: 0.4360  data_time: 0.0034  last_data_time: 0.0039   lr: 1e-05  max_mem: 15541M
[08/30 23:05:58] d2.utils.events INFO:  eta: 0:08:59  iter: 759  total_loss: 27  loss_ce: 0.1439  loss_mask: 0.2736  loss_dice: 2.036  loss_ce_0: 0.8372  loss_mask_0: 0.2979  loss_dice_0: 3.11  loss_ce_1: 0.308  loss_mask_1: 0.254  loss_dice_1: 2.446  loss_ce_2: 0.1524  loss_mask_2: 0.2642  loss_dice_2: 2.216  loss_ce_3: 0.1234  loss_mask_3: 0.2487  loss_dice_3: 2.148  loss_ce_4: 0.1201  loss_mask_4: 0.2597  loss_dice_4: 2.125  loss_ce_5: 0.1238  loss_mask_5: 0.2514  loss_dice_5: 2.063  loss_ce_6: 0.1247  loss_mask_6: 0.2504  loss_dice_6: 2.034  loss_ce_7: 0.1329  loss_mask_7: 0.2569  loss_dice_7: 2.032  loss_ce_8: 0.1362  loss_mask_8: 0.2524  loss_dice_8: 2.023  loss_mgm_entropy: 0.004758    time: 0.4351  last_time: 0.4360  data_time: 0.0035  last_data_time: 0.0033   lr: 1e-05  max_mem: 15541M
[08/30 23:06:07] d2.utils.events INFO:  eta: 0:08:50  iter: 779  total_loss: 27.31  loss_ce: 0.1434  loss_mask: 0.2826  loss_dice: 2.024  loss_ce_0: 0.8212  loss_mask_0: 0.3214  loss_dice_0: 3.103  loss_ce_1: 0.3002  loss_mask_1: 0.3022  loss_dice_1: 2.461  loss_ce_2: 0.1571  loss_mask_2: 0.2665  loss_dice_2: 2.215  loss_ce_3: 0.1339  loss_mask_3: 0.2912  loss_dice_3: 2.132  loss_ce_4: 0.1366  loss_mask_4: 0.2912  loss_dice_4: 2.098  loss_ce_5: 0.131  loss_mask_5: 0.3004  loss_dice_5: 2.025  loss_ce_6: 0.132  loss_mask_6: 0.299  loss_dice_6: 2.035  loss_ce_7: 0.1297  loss_mask_7: 0.2829  loss_dice_7: 2.009  loss_ce_8: 0.1319  loss_mask_8: 0.2882  loss_dice_8: 2.002  loss_mgm_entropy: 0.004708    time: 0.4351  last_time: 0.4358  data_time: 0.0036  last_data_time: 0.0038   lr: 1e-05  max_mem: 15541M
[08/30 23:06:16] d2.utils.events INFO:  eta: 0:08:42  iter: 799  total_loss: 27.01  loss_ce: 0.1396  loss_mask: 0.3202  loss_dice: 1.991  loss_ce_0: 0.8038  loss_mask_0: 0.3267  loss_dice_0: 3.047  loss_ce_1: 0.2956  loss_mask_1: 0.2838  loss_dice_1: 2.432  loss_ce_2: 0.1504  loss_mask_2: 0.2883  loss_dice_2: 2.2  loss_ce_3: 0.1271  loss_mask_3: 0.3094  loss_dice_3: 2.102  loss_ce_4: 0.1228  loss_mask_4: 0.2992  loss_dice_4: 2.066  loss_ce_5: 0.1304  loss_mask_5: 0.299  loss_dice_5: 1.993  loss_ce_6: 0.1212  loss_mask_6: 0.2957  loss_dice_6: 2.011  loss_ce_7: 0.1291  loss_mask_7: 0.2944  loss_dice_7: 1.964  loss_ce_8: 0.1359  loss_mask_8: 0.3058  loss_dice_8: 1.99  loss_mgm_entropy: 0.004832    time: 0.4351  last_time: 0.4355  data_time: 0.0036  last_data_time: 0.0036   lr: 1e-05  max_mem: 15542M
[08/30 23:06:24] d2.utils.events INFO:  eta: 0:08:33  iter: 819  total_loss: 26.51  loss_ce: 0.1516  loss_mask: 0.2776  loss_dice: 1.996  loss_ce_0: 0.8081  loss_mask_0: 0.3365  loss_dice_0: 3.038  loss_ce_1: 0.2899  loss_mask_1: 0.2696  loss_dice_1: 2.298  loss_ce_2: 0.1447  loss_mask_2: 0.2653  loss_dice_2: 2.097  loss_ce_3: 0.1273  loss_mask_3: 0.2643  loss_dice_3: 2.016  loss_ce_4: 0.1335  loss_mask_4: 0.2695  loss_dice_4: 1.992  loss_ce_5: 0.1277  loss_mask_5: 0.2742  loss_dice_5: 1.978  loss_ce_6: 0.1246  loss_mask_6: 0.2687  loss_dice_6: 1.94  loss_ce_7: 0.1423  loss_mask_7: 0.2687  loss_dice_7: 1.964  loss_ce_8: 0.1422  loss_mask_8: 0.2812  loss_dice_8: 2.002  loss_mgm_entropy: 0.004764    time: 0.4351  last_time: 0.4360  data_time: 0.0035  last_data_time: 0.0033   lr: 1e-05  max_mem: 15542M
[08/30 23:06:33] d2.utils.events INFO:  eta: 0:08:24  iter: 839  total_loss: 26.85  loss_ce: 0.1656  loss_mask: 0.3126  loss_dice: 1.968  loss_ce_0: 0.7997  loss_mask_0: 0.3404  loss_dice_0: 3.011  loss_ce_1: 0.2791  loss_mask_1: 0.2924  loss_dice_1: 2.368  loss_ce_2: 0.1454  loss_mask_2: 0.285  loss_dice_2: 2.135  loss_ce_3: 0.1238  loss_mask_3: 0.2751  loss_dice_3: 2.011  loss_ce_4: 0.1234  loss_mask_4: 0.2888  loss_dice_4: 2.007  loss_ce_5: 0.1328  loss_mask_5: 0.2928  loss_dice_5: 1.967  loss_ce_6: 0.1283  loss_mask_6: 0.2926  loss_dice_6: 1.955  loss_ce_7: 0.1384  loss_mask_7: 0.296  loss_dice_7: 1.969  loss_ce_8: 0.1495  loss_mask_8: 0.294  loss_dice_8: 1.971  loss_mgm_entropy: 0.004777    time: 0.4351  last_time: 0.4358  data_time: 0.0035  last_data_time: 0.0039   lr: 1e-05  max_mem: 15542M
[08/30 23:06:42] d2.utils.events INFO:  eta: 0:08:16  iter: 859  total_loss: 25.35  loss_ce: 0.1524  loss_mask: 0.236  loss_dice: 1.867  loss_ce_0: 0.7914  loss_mask_0: 0.2962  loss_dice_0: 2.973  loss_ce_1: 0.2755  loss_mask_1: 0.2749  loss_dice_1: 2.295  loss_ce_2: 0.1506  loss_mask_2: 0.241  loss_dice_2: 2.039  loss_ce_3: 0.1262  loss_mask_3: 0.2344  loss_dice_3: 1.952  loss_ce_4: 0.1221  loss_mask_4: 0.2314  loss_dice_4: 1.94  loss_ce_5: 0.1356  loss_mask_5: 0.2401  loss_dice_5: 1.895  loss_ce_6: 0.1327  loss_mask_6: 0.2445  loss_dice_6: 1.896  loss_ce_7: 0.1513  loss_mask_7: 0.2387  loss_dice_7: 1.889  loss_ce_8: 0.1502  loss_mask_8: 0.2498  loss_dice_8: 1.903  loss_mgm_entropy: 0.004783    time: 0.4352  last_time: 0.4379  data_time: 0.0035  last_data_time: 0.0030   lr: 1e-05  max_mem: 15542M
[08/30 23:06:51] d2.utils.events INFO:  eta: 0:08:07  iter: 879  total_loss: 24.22  loss_ce: 0.1632  loss_mask: 0.2218  loss_dice: 1.8  loss_ce_0: 0.8116  loss_mask_0: 0.2516  loss_dice_0: 2.917  loss_ce_1: 0.2738  loss_mask_1: 0.2333  loss_dice_1: 2.214  loss_ce_2: 0.1486  loss_mask_2: 0.2154  loss_dice_2: 2.004  loss_ce_3: 0.1348  loss_mask_3: 0.2068  loss_dice_3: 1.897  loss_ce_4: 0.1255  loss_mask_4: 0.2025  loss_dice_4: 1.847  loss_ce_5: 0.1342  loss_mask_5: 0.2066  loss_dice_5: 1.825  loss_ce_6: 0.138  loss_mask_6: 0.2159  loss_dice_6: 1.811  loss_ce_7: 0.1461  loss_mask_7: 0.2252  loss_dice_7: 1.797  loss_ce_8: 0.1561  loss_mask_8: 0.2186  loss_dice_8: 1.802  loss_mgm_entropy: 0.004693    time: 0.4352  last_time: 0.4364  data_time: 0.0035  last_data_time: 0.0039   lr: 1e-05  max_mem: 15542M
[08/30 23:06:59] d2.utils.events INFO:  eta: 0:07:58  iter: 899  total_loss: 24.95  loss_ce: 0.1444  loss_mask: 0.2785  loss_dice: 1.838  loss_ce_0: 0.7907  loss_mask_0: 0.2753  loss_dice_0: 2.897  loss_ce_1: 0.2604  loss_mask_1: 0.2419  loss_dice_1: 2.2  loss_ce_2: 0.1389  loss_mask_2: 0.2494  loss_dice_2: 1.998  loss_ce_3: 0.1277  loss_mask_3: 0.2359  loss_dice_3: 1.893  loss_ce_4: 0.1238  loss_mask_4: 0.252  loss_dice_4: 1.874  loss_ce_5: 0.1307  loss_mask_5: 0.2444  loss_dice_5: 1.896  loss_ce_6: 0.1288  loss_mask_6: 0.2561  loss_dice_6: 1.876  loss_ce_7: 0.1329  loss_mask_7: 0.2578  loss_dice_7: 1.867  loss_ce_8: 0.1495  loss_mask_8: 0.2695  loss_dice_8: 1.865  loss_mgm_entropy: 0.004693    time: 0.4352  last_time: 0.4355  data_time: 0.0035  last_data_time: 0.0033   lr: 1e-05  max_mem: 15542M
[08/30 23:07:08] d2.utils.events INFO:  eta: 0:07:50  iter: 919  total_loss: 24.36  loss_ce: 0.1467  loss_mask: 0.2559  loss_dice: 1.779  loss_ce_0: 0.7906  loss_mask_0: 0.2975  loss_dice_0: 2.827  loss_ce_1: 0.2683  loss_mask_1: 0.2468  loss_dice_1: 2.163  loss_ce_2: 0.1456  loss_mask_2: 0.2622  loss_dice_2: 1.948  loss_ce_3: 0.1437  loss_mask_3: 0.2398  loss_dice_3: 1.858  loss_ce_4: 0.1502  loss_mask_4: 0.25  loss_dice_4: 1.815  loss_ce_5: 0.1462  loss_mask_5: 0.2547  loss_dice_5: 1.813  loss_ce_6: 0.1391  loss_mask_6: 0.2511  loss_dice_6: 1.797  loss_ce_7: 0.1438  loss_mask_7: 0.2456  loss_dice_7: 1.795  loss_ce_8: 0.1422  loss_mask_8: 0.2482  loss_dice_8: 1.795  loss_mgm_entropy: 0.004779    time: 0.4352  last_time: 0.4354  data_time: 0.0036  last_data_time: 0.0033   lr: 1e-05  max_mem: 15544M
[08/30 23:07:17] d2.utils.events INFO:  eta: 0:07:41  iter: 939  total_loss: 22.98  loss_ce: 0.1614  loss_mask: 0.197  loss_dice: 1.722  loss_ce_0: 0.8024  loss_mask_0: 0.2502  loss_dice_0: 2.757  loss_ce_1: 0.2615  loss_mask_1: 0.2141  loss_dice_1: 2.078  loss_ce_2: 0.1491  loss_mask_2: 0.1993  loss_dice_2: 1.874  loss_ce_3: 0.1354  loss_mask_3: 0.1978  loss_dice_3: 1.781  loss_ce_4: 0.1232  loss_mask_4: 0.1999  loss_dice_4: 1.752  loss_ce_5: 0.1483  loss_mask_5: 0.2081  loss_dice_5: 1.718  loss_ce_6: 0.1482  loss_mask_6: 0.1885  loss_dice_6: 1.707  loss_ce_7: 0.1521  loss_mask_7: 0.1769  loss_dice_7: 1.685  loss_ce_8: 0.1507  loss_mask_8: 0.1875  loss_dice_8: 1.674  loss_mgm_entropy: 0.004798    time: 0.4352  last_time: 0.4366  data_time: 0.0035  last_data_time: 0.0034   lr: 1e-05  max_mem: 15544M
[08/30 23:07:26] d2.utils.events INFO:  eta: 0:07:32  iter: 959  total_loss: 22.79  loss_ce: 0.17  loss_mask: 0.2126  loss_dice: 1.627  loss_ce_0: 0.8026  loss_mask_0: 0.2257  loss_dice_0: 2.736  loss_ce_1: 0.2563  loss_mask_1: 0.1918  loss_dice_1: 2.013  loss_ce_2: 0.1639  loss_mask_2: 0.199  loss_dice_2: 1.818  loss_ce_3: 0.1479  loss_mask_3: 0.1968  loss_dice_3: 1.715  loss_ce_4: 0.1423  loss_mask_4: 0.1981  loss_dice_4: 1.698  loss_ce_5: 0.1483  loss_mask_5: 0.2148  loss_dice_5: 1.671  loss_ce_6: 0.1495  loss_mask_6: 0.2135  loss_dice_6: 1.661  loss_ce_7: 0.1588  loss_mask_7: 0.2093  loss_dice_7: 1.635  loss_ce_8: 0.1606  loss_mask_8: 0.2108  loss_dice_8: 1.618  loss_mgm_entropy: 0.004658    time: 0.4352  last_time: 0.4386  data_time: 0.0034  last_data_time: 0.0037   lr: 1e-05  max_mem: 15544M
[08/30 23:07:34] d2.utils.events INFO:  eta: 0:07:23  iter: 979  total_loss: 22.04  loss_ce: 0.1551  loss_mask: 0.2037  loss_dice: 1.629  loss_ce_0: 0.8052  loss_mask_0: 0.2499  loss_dice_0: 2.694  loss_ce_1: 0.2598  loss_mask_1: 0.2032  loss_dice_1: 2.011  loss_ce_2: 0.1451  loss_mask_2: 0.204  loss_dice_2: 1.776  loss_ce_3: 0.1235  loss_mask_3: 0.2019  loss_dice_3: 1.66  loss_ce_4: 0.1211  loss_mask_4: 0.1958  loss_dice_4: 1.666  loss_ce_5: 0.1325  loss_mask_5: 0.1888  loss_dice_5: 1.644  loss_ce_6: 0.1341  loss_mask_6: 0.2003  loss_dice_6: 1.579  loss_ce_7: 0.1363  loss_mask_7: 0.2058  loss_dice_7: 1.635  loss_ce_8: 0.1456  loss_mask_8: 0.2079  loss_dice_8: 1.642  loss_mgm_entropy: 0.004698    time: 0.4352  last_time: 0.4358  data_time: 0.0035  last_data_time: 0.0040   lr: 1e-05  max_mem: 15544M
[08/30 23:07:43] d2.utils.events INFO:  eta: 0:07:15  iter: 999  total_loss: 22.12  loss_ce: 0.1557  loss_mask: 0.212  loss_dice: 1.6  loss_ce_0: 0.7827  loss_mask_0: 0.2781  loss_dice_0: 2.656  loss_ce_1: 0.2568  loss_mask_1: 0.2119  loss_dice_1: 1.955  loss_ce_2: 0.1448  loss_mask_2: 0.2062  loss_dice_2: 1.758  loss_ce_3: 0.1235  loss_mask_3: 0.2016  loss_dice_3: 1.681  loss_ce_4: 0.1215  loss_mask_4: 0.2042  loss_dice_4: 1.686  loss_ce_5: 0.1433  loss_mask_5: 0.194  loss_dice_5: 1.597  loss_ce_6: 0.1325  loss_mask_6: 0.2094  loss_dice_6: 1.615  loss_ce_7: 0.1444  loss_mask_7: 0.2072  loss_dice_7: 1.57  loss_ce_8: 0.1477  loss_mask_8: 0.213  loss_dice_8: 1.605  loss_mgm_entropy: 0.004797    time: 0.4352  last_time: 0.4358  data_time: 0.0035  last_data_time: 0.0033   lr: 1e-05  max_mem: 15544M
[08/30 23:07:52] d2.utils.events INFO:  eta: 0:07:06  iter: 1019  total_loss: 21.91  loss_ce: 0.1597  loss_mask: 0.2342  loss_dice: 1.524  loss_ce_0: 0.7927  loss_mask_0: 0.2855  loss_dice_0: 2.723  loss_ce_1: 0.2626  loss_mask_1: 0.2186  loss_dice_1: 1.965  loss_ce_2: 0.1665  loss_mask_2: 0.2195  loss_dice_2: 1.731  loss_ce_3: 0.1651  loss_mask_3: 0.221  loss_dice_3: 1.636  loss_ce_4: 0.1431  loss_mask_4: 0.2088  loss_dice_4: 1.608  loss_ce_5: 0.1436  loss_mask_5: 0.2108  loss_dice_5: 1.576  loss_ce_6: 0.15  loss_mask_6: 0.2087  loss_dice_6: 1.544  loss_ce_7: 0.1464  loss_mask_7: 0.2259  loss_dice_7: 1.538  loss_ce_8: 0.154  loss_mask_8: 0.2323  loss_dice_8: 1.547  loss_mgm_entropy: 0.004795    time: 0.4353  last_time: 0.4368  data_time: 0.0035  last_data_time: 0.0036   lr: 1e-06  max_mem: 15544M
[08/30 23:08:00] d2.utils.events INFO:  eta: 0:06:57  iter: 1039  total_loss: 20.81  loss_ce: 0.1547  loss_mask: 0.162  loss_dice: 1.477  loss_ce_0: 0.7892  loss_mask_0: 0.2243  loss_dice_0: 2.652  loss_ce_1: 0.2584  loss_mask_1: 0.1857  loss_dice_1: 1.897  loss_ce_2: 0.1625  loss_mask_2: 0.1807  loss_dice_2: 1.73  loss_ce_3: 0.1453  loss_mask_3: 0.171  loss_dice_3: 1.616  loss_ce_4: 0.1317  loss_mask_4: 0.1691  loss_dice_4: 1.543  loss_ce_5: 0.1375  loss_mask_5: 0.172  loss_dice_5: 1.532  loss_ce_6: 0.1412  loss_mask_6: 0.1714  loss_dice_6: 1.496  loss_ce_7: 0.1458  loss_mask_7: 0.1707  loss_dice_7: 1.473  loss_ce_8: 0.1456  loss_mask_8: 0.1639  loss_dice_8: 1.472  loss_mgm_entropy: 0.004703    time: 0.4353  last_time: 0.4364  data_time: 0.0033  last_data_time: 0.0034   lr: 1e-06  max_mem: 15544M
[08/30 23:08:09] d2.utils.events INFO:  eta: 0:06:49  iter: 1059  total_loss: 20.25  loss_ce: 0.149  loss_mask: 0.1405  loss_dice: 1.375  loss_ce_0: 0.7977  loss_mask_0: 0.2156  loss_dice_0: 2.626  loss_ce_1: 0.249  loss_mask_1: 0.1733  loss_dice_1: 1.89  loss_ce_2: 0.1535  loss_mask_2: 0.1663  loss_dice_2: 1.675  loss_ce_3: 0.1533  loss_mask_3: 0.155  loss_dice_3: 1.56  loss_ce_4: 0.1445  loss_mask_4: 0.1651  loss_dice_4: 1.514  loss_ce_5: 0.144  loss_mask_5: 0.1581  loss_dice_5: 1.465  loss_ce_6: 0.1418  loss_mask_6: 0.1525  loss_dice_6: 1.453  loss_ce_7: 0.1421  loss_mask_7: 0.146  loss_dice_7: 1.405  loss_ce_8: 0.1426  loss_mask_8: 0.1407  loss_dice_8: 1.381  loss_mgm_entropy: 0.004666    time: 0.4353  last_time: 0.4356  data_time: 0.0035  last_data_time: 0.0038   lr: 1e-06  max_mem: 15544M
[08/30 23:08:18] d2.utils.events INFO:  eta: 0:06:40  iter: 1079  total_loss: 20.37  loss_ce: 0.1571  loss_mask: 0.1552  loss_dice: 1.404  loss_ce_0: 0.7875  loss_mask_0: 0.2439  loss_dice_0: 2.647  loss_ce_1: 0.2592  loss_mask_1: 0.1891  loss_dice_1: 1.915  loss_ce_2: 0.1606  loss_mask_2: 0.1815  loss_dice_2: 1.658  loss_ce_3: 0.1574  loss_mask_3: 0.1765  loss_dice_3: 1.529  loss_ce_4: 0.1415  loss_mask_4: 0.1754  loss_dice_4: 1.54  loss_ce_5: 0.1487  loss_mask_5: 0.1668  loss_dice_5: 1.459  loss_ce_6: 0.1441  loss_mask_6: 0.1638  loss_dice_6: 1.421  loss_ce_7: 0.1481  loss_mask_7: 0.1639  loss_dice_7: 1.416  loss_ce_8: 0.1458  loss_mask_8: 0.1607  loss_dice_8: 1.415  loss_mgm_entropy: 0.004702    time: 0.4353  last_time: 0.4352  data_time: 0.0035  last_data_time: 0.0030   lr: 1e-06  max_mem: 15544M
[08/30 23:08:27] d2.utils.events INFO:  eta: 0:06:31  iter: 1099  total_loss: 21.74  loss_ce: 0.1591  loss_mask: 0.1645  loss_dice: 1.488  loss_ce_0: 0.7773  loss_mask_0: 0.2458  loss_dice_0: 2.632  loss_ce_1: 0.2553  loss_mask_1: 0.2021  loss_dice_1: 1.927  loss_ce_2: 0.1595  loss_mask_2: 0.1799  loss_dice_2: 1.732  loss_ce_3: 0.1403  loss_mask_3: 0.1772  loss_dice_3: 1.622  loss_ce_4: 0.1287  loss_mask_4: 0.1758  loss_dice_4: 1.605  loss_ce_5: 0.1355  loss_mask_5: 0.1695  loss_dice_5: 1.568  loss_ce_6: 0.144  loss_mask_6: 0.1671  loss_dice_6: 1.554  loss_ce_7: 0.1492  loss_mask_7: 0.1748  loss_dice_7: 1.498  loss_ce_8: 0.1504  loss_mask_8: 0.178  loss_dice_8: 1.512  loss_mgm_entropy: 0.00476    time: 0.4353  last_time: 0.4415  data_time: 0.0035  last_data_time: 0.0038   lr: 1e-06  max_mem: 15544M
[08/30 23:08:35] d2.utils.events INFO:  eta: 0:06:23  iter: 1119  total_loss: 20.34  loss_ce: 0.1563  loss_mask: 0.1681  loss_dice: 1.429  loss_ce_0: 0.7963  loss_mask_0: 0.2502  loss_dice_0: 2.593  loss_ce_1: 0.2469  loss_mask_1: 0.1891  loss_dice_1: 1.872  loss_ce_2: 0.1528  loss_mask_2: 0.1823  loss_dice_2: 1.676  loss_ce_3: 0.1332  loss_mask_3: 0.1851  loss_dice_3: 1.558  loss_ce_4: 0.1433  loss_mask_4: 0.172  loss_dice_4: 1.52  loss_ce_5: 0.1391  loss_mask_5: 0.1684  loss_dice_5: 1.484  loss_ce_6: 0.1375  loss_mask_6: 0.1592  loss_dice_6: 1.475  loss_ce_7: 0.1427  loss_mask_7: 0.1659  loss_dice_7: 1.453  loss_ce_8: 0.1442  loss_mask_8: 0.1605  loss_dice_8: 1.447  loss_mgm_entropy: 0.004742    time: 0.4353  last_time: 0.4348  data_time: 0.0035  last_data_time: 0.0035   lr: 1e-06  max_mem: 15544M
[08/30 23:08:44] d2.utils.events INFO:  eta: 0:06:14  iter: 1139  total_loss: 20.62  loss_ce: 0.1546  loss_mask: 0.1829  loss_dice: 1.443  loss_ce_0: 0.7879  loss_mask_0: 0.2544  loss_dice_0: 2.651  loss_ce_1: 0.2574  loss_mask_1: 0.2027  loss_dice_1: 1.863  loss_ce_2: 0.1596  loss_mask_2: 0.192  loss_dice_2: 1.663  loss_ce_3: 0.1447  loss_mask_3: 0.1882  loss_dice_3: 1.529  loss_ce_4: 0.1321  loss_mask_4: 0.1724  loss_dice_4: 1.562  loss_ce_5: 0.1391  loss_mask_5: 0.1839  loss_dice_5: 1.523  loss_ce_6: 0.1417  loss_mask_6: 0.1947  loss_dice_6: 1.495  loss_ce_7: 0.1462  loss_mask_7: 0.1886  loss_dice_7: 1.442  loss_ce_8: 0.1485  loss_mask_8: 0.1837  loss_dice_8: 1.469  loss_mgm_entropy: 0.004741    time: 0.4353  last_time: 0.4358  data_time: 0.0036  last_data_time: 0.0039   lr: 1e-06  max_mem: 15544M
[08/30 23:08:53] d2.utils.events INFO:  eta: 0:06:05  iter: 1159  total_loss: 19.62  loss_ce: 0.1469  loss_mask: 0.1372  loss_dice: 1.344  loss_ce_0: 0.7901  loss_mask_0: 0.2173  loss_dice_0: 2.577  loss_ce_1: 0.2515  loss_mask_1: 0.1717  loss_dice_1: 1.84  loss_ce_2: 0.1476  loss_mask_2: 0.1599  loss_dice_2: 1.636  loss_ce_3: 0.1323  loss_mask_3: 0.1627  loss_dice_3: 1.505  loss_ce_4: 0.1323  loss_mask_4: 0.1598  loss_dice_4: 1.481  loss_ce_5: 0.1366  loss_mask_5: 0.1525  loss_dice_5: 1.388  loss_ce_6: 0.1339  loss_mask_6: 0.1457  loss_dice_6: 1.396  loss_ce_7: 0.1403  loss_mask_7: 0.1435  loss_dice_7: 1.383  loss_ce_8: 0.1417  loss_mask_8: 0.1421  loss_dice_8: 1.343  loss_mgm_entropy: 0.004679    time: 0.4353  last_time: 0.4374  data_time: 0.0035  last_data_time: 0.0033   lr: 1e-06  max_mem: 15544M
[08/30 23:09:02] d2.utils.events INFO:  eta: 0:05:57  iter: 1179  total_loss: 21.14  loss_ce: 0.1519  loss_mask: 0.18  loss_dice: 1.468  loss_ce_0: 0.7884  loss_mask_0: 0.2816  loss_dice_0: 2.636  loss_ce_1: 0.2587  loss_mask_1: 0.215  loss_dice_1: 1.928  loss_ce_2: 0.1546  loss_mask_2: 0.2128  loss_dice_2: 1.719  loss_ce_3: 0.1495  loss_mask_3: 0.1959  loss_dice_3: 1.607  loss_ce_4: 0.1435  loss_mask_4: 0.1891  loss_dice_4: 1.566  loss_ce_5: 0.1424  loss_mask_5: 0.1926  loss_dice_5: 1.519  loss_ce_6: 0.1448  loss_mask_6: 0.1905  loss_dice_6: 1.492  loss_ce_7: 0.1461  loss_mask_7: 0.189  loss_dice_7: 1.474  loss_ce_8: 0.1526  loss_mask_8: 0.1864  loss_dice_8: 1.465  loss_mgm_entropy: 0.004733    time: 0.4353  last_time: 0.4352  data_time: 0.0035  last_data_time: 0.0035   lr: 1e-06  max_mem: 15544M
[08/30 23:09:10] d2.utils.events INFO:  eta: 0:05:48  iter: 1199  total_loss: 20.5  loss_ce: 0.1536  loss_mask: 0.155  loss_dice: 1.418  loss_ce_0: 0.7836  loss_mask_0: 0.2263  loss_dice_0: 2.596  loss_ce_1: 0.253  loss_mask_1: 0.1857  loss_dice_1: 1.92  loss_ce_2: 0.1607  loss_mask_2: 0.1981  loss_dice_2: 1.685  loss_ce_3: 0.1456  loss_mask_3: 0.1632  loss_dice_3: 1.56  loss_ce_4: 0.1382  loss_mask_4: 0.1619  loss_dice_4: 1.549  loss_ce_5: 0.1406  loss_mask_5: 0.1596  loss_dice_5: 1.451  loss_ce_6: 0.1393  loss_mask_6: 0.1607  loss_dice_6: 1.443  loss_ce_7: 0.1365  loss_mask_7: 0.1611  loss_dice_7: 1.434  loss_ce_8: 0.1413  loss_mask_8: 0.1579  loss_dice_8: 1.463  loss_mgm_entropy: 0.004698    time: 0.4354  last_time: 0.4358  data_time: 0.0035  last_data_time: 0.0033   lr: 1e-06  max_mem: 15544M
[08/30 23:09:19] d2.utils.events INFO:  eta: 0:05:39  iter: 1219  total_loss: 20.91  loss_ce: 0.1518  loss_mask: 0.1745  loss_dice: 1.405  loss_ce_0: 0.7907  loss_mask_0: 0.2462  loss_dice_0: 2.636  loss_ce_1: 0.2503  loss_mask_1: 0.1862  loss_dice_1: 1.855  loss_ce_2: 0.1505  loss_mask_2: 0.1769  loss_dice_2: 1.602  loss_ce_3: 0.1343  loss_mask_3: 0.1809  loss_dice_3: 1.54  loss_ce_4: 0.1326  loss_mask_4: 0.1583  loss_dice_4: 1.516  loss_ce_5: 0.1414  loss_mask_5: 0.1583  loss_dice_5: 1.479  loss_ce_6: 0.1373  loss_mask_6: 0.1583  loss_dice_6: 1.465  loss_ce_7: 0.1374  loss_mask_7: 0.1696  loss_dice_7: 1.428  loss_ce_8: 0.1422  loss_mask_8: 0.1713  loss_dice_8: 1.447  loss_mgm_entropy: 0.004734    time: 0.4354  last_time: 0.4374  data_time: 0.0034  last_data_time: 0.0034   lr: 1e-06  max_mem: 15544M
[08/30 23:09:28] d2.utils.events INFO:  eta: 0:05:31  iter: 1239  total_loss: 20.67  loss_ce: 0.1477  loss_mask: 0.1666  loss_dice: 1.411  loss_ce_0: 0.775  loss_mask_0: 0.2487  loss_dice_0: 2.569  loss_ce_1: 0.2409  loss_mask_1: 0.1957  loss_dice_1: 1.894  loss_ce_2: 0.1471  loss_mask_2: 0.1856  loss_dice_2: 1.671  loss_ce_3: 0.1415  loss_mask_3: 0.1781  loss_dice_3: 1.53  loss_ce_4: 0.1256  loss_mask_4: 0.176  loss_dice_4: 1.524  loss_ce_5: 0.1317  loss_mask_5: 0.1689  loss_dice_5: 1.458  loss_ce_6: 0.1355  loss_mask_6: 0.1656  loss_dice_6: 1.452  loss_ce_7: 0.1359  loss_mask_7: 0.1649  loss_dice_7: 1.44  loss_ce_8: 0.1384  loss_mask_8: 0.166  loss_dice_8: 1.434  loss_mgm_entropy: 0.004696    time: 0.4354  last_time: 0.4367  data_time: 0.0035  last_data_time: 0.0033   lr: 1e-06  max_mem: 15544M
[08/30 23:09:36] d2.utils.events INFO:  eta: 0:05:22  iter: 1259  total_loss: 20.59  loss_ce: 0.1495  loss_mask: 0.1842  loss_dice: 1.417  loss_ce_0: 0.7889  loss_mask_0: 0.2477  loss_dice_0: 2.594  loss_ce_1: 0.2451  loss_mask_1: 0.2013  loss_dice_1: 1.868  loss_ce_2: 0.1586  loss_mask_2: 0.1907  loss_dice_2: 1.668  loss_ce_3: 0.1428  loss_mask_3: 0.1997  loss_dice_3: 1.573  loss_ce_4: 0.1322  loss_mask_4: 0.1973  loss_dice_4: 1.523  loss_ce_5: 0.142  loss_mask_5: 0.1836  loss_dice_5: 1.466  loss_ce_6: 0.1379  loss_mask_6: 0.1872  loss_dice_6: 1.454  loss_ce_7: 0.1395  loss_mask_7: 0.1867  loss_dice_7: 1.436  loss_ce_8: 0.1442  loss_mask_8: 0.1848  loss_dice_8: 1.42  loss_mgm_entropy: 0.00473    time: 0.4354  last_time: 0.4363  data_time: 0.0035  last_data_time: 0.0030   lr: 1e-06  max_mem: 15544M
[08/30 23:09:45] d2.utils.events INFO:  eta: 0:05:13  iter: 1279  total_loss: 20.1  loss_ce: 0.1499  loss_mask: 0.157  loss_dice: 1.391  loss_ce_0: 0.7812  loss_mask_0: 0.2457  loss_dice_0: 2.595  loss_ce_1: 0.2417  loss_mask_1: 0.1931  loss_dice_1: 1.871  loss_ce_2: 0.1738  loss_mask_2: 0.1814  loss_dice_2: 1.613  loss_ce_3: 0.1498  loss_mask_3: 0.1773  loss_dice_3: 1.522  loss_ce_4: 0.1462  loss_mask_4: 0.1657  loss_dice_4: 1.469  loss_ce_5: 0.136  loss_mask_5: 0.1649  loss_dice_5: 1.455  loss_ce_6: 0.1447  loss_mask_6: 0.155  loss_dice_6: 1.425  loss_ce_7: 0.1458  loss_mask_7: 0.1515  loss_dice_7: 1.423  loss_ce_8: 0.1439  loss_mask_8: 0.1483  loss_dice_8: 1.41  loss_mgm_entropy: 0.004687    time: 0.4354  last_time: 0.4364  data_time: 0.0036  last_data_time: 0.0034   lr: 1e-06  max_mem: 15544M
[08/30 23:09:54] d2.utils.events INFO:  eta: 0:05:04  iter: 1299  total_loss: 20.32  loss_ce: 0.1561  loss_mask: 0.1576  loss_dice: 1.365  loss_ce_0: 0.7797  loss_mask_0: 0.2447  loss_dice_0: 2.558  loss_ce_1: 0.2583  loss_mask_1: 0.1888  loss_dice_1: 1.876  loss_ce_2: 0.161  loss_mask_2: 0.1887  loss_dice_2: 1.623  loss_ce_3: 0.1409  loss_mask_3: 0.1752  loss_dice_3: 1.517  loss_ce_4: 0.1416  loss_mask_4: 0.1573  loss_dice_4: 1.495  loss_ce_5: 0.1448  loss_mask_5: 0.1588  loss_dice_5: 1.418  loss_ce_6: 0.1425  loss_mask_6: 0.1561  loss_dice_6: 1.413  loss_ce_7: 0.1473  loss_mask_7: 0.1575  loss_dice_7: 1.386  loss_ce_8: 0.1498  loss_mask_8: 0.1561  loss_dice_8: 1.364  loss_mgm_entropy: 0.004724    time: 0.4355  last_time: 0.4357  data_time: 0.0036  last_data_time: 0.0038   lr: 1e-06  max_mem: 15544M
[08/30 23:10:03] d2.utils.events INFO:  eta: 0:04:56  iter: 1319  total_loss: 20.84  loss_ce: 0.1482  loss_mask: 0.1808  loss_dice: 1.423  loss_ce_0: 0.7891  loss_mask_0: 0.2485  loss_dice_0: 2.586  loss_ce_1: 0.2695  loss_mask_1: 0.2065  loss_dice_1: 1.906  loss_ce_2: 0.1623  loss_mask_2: 0.1851  loss_dice_2: 1.677  loss_ce_3: 0.1392  loss_mask_3: 0.1815  loss_dice_3: 1.605  loss_ce_4: 0.14  loss_mask_4: 0.1713  loss_dice_4: 1.542  loss_ce_5: 0.141  loss_mask_5: 0.1891  loss_dice_5: 1.494  loss_ce_6: 0.14  loss_mask_6: 0.1742  loss_dice_6: 1.46  loss_ce_7: 0.1448  loss_mask_7: 0.1639  loss_dice_7: 1.454  loss_ce_8: 0.145  loss_mask_8: 0.1689  loss_dice_8: 1.427  loss_mgm_entropy: 0.004697    time: 0.4355  last_time: 0.4347  data_time: 0.0035  last_data_time: 0.0035   lr: 1e-06  max_mem: 15544M
[08/30 23:10:11] d2.utils.events INFO:  eta: 0:04:47  iter: 1339  total_loss: 20.14  loss_ce: 0.1498  loss_mask: 0.1844  loss_dice: 1.394  loss_ce_0: 0.7868  loss_mask_0: 0.2891  loss_dice_0: 2.571  loss_ce_1: 0.2513  loss_mask_1: 0.2044  loss_dice_1: 1.862  loss_ce_2: 0.1416  loss_mask_2: 0.2005  loss_dice_2: 1.609  loss_ce_3: 0.1434  loss_mask_3: 0.1954  loss_dice_3: 1.503  loss_ce_4: 0.1405  loss_mask_4: 0.204  loss_dice_4: 1.475  loss_ce_5: 0.1393  loss_mask_5: 0.1947  loss_dice_5: 1.453  loss_ce_6: 0.1394  loss_mask_6: 0.2018  loss_dice_6: 1.435  loss_ce_7: 0.1429  loss_mask_7: 0.2105  loss_dice_7: 1.428  loss_ce_8: 0.1419  loss_mask_8: 0.2051  loss_dice_8: 1.404  loss_mgm_entropy: 0.004681    time: 0.4355  last_time: 0.4341  data_time: 0.0034  last_data_time: 0.0031   lr: 1e-06  max_mem: 15544M
[08/30 23:10:20] d2.utils.events INFO:  eta: 0:04:38  iter: 1359  total_loss: 19.65  loss_ce: 0.1486  loss_mask: 0.1549  loss_dice: 1.36  loss_ce_0: 0.7838  loss_mask_0: 0.2397  loss_dice_0: 2.543  loss_ce_1: 0.2391  loss_mask_1: 0.1956  loss_dice_1: 1.855  loss_ce_2: 0.1515  loss_mask_2: 0.1676  loss_dice_2: 1.615  loss_ce_3: 0.1278  loss_mask_3: 0.1618  loss_dice_3: 1.501  loss_ce_4: 0.1324  loss_mask_4: 0.1566  loss_dice_4: 1.478  loss_ce_5: 0.1297  loss_mask_5: 0.1559  loss_dice_5: 1.415  loss_ce_6: 0.1342  loss_mask_6: 0.1522  loss_dice_6: 1.38  loss_ce_7: 0.1413  loss_mask_7: 0.1552  loss_dice_7: 1.401  loss_ce_8: 0.1429  loss_mask_8: 0.1544  loss_dice_8: 1.375  loss_mgm_entropy: 0.004682    time: 0.4355  last_time: 0.4365  data_time: 0.0035  last_data_time: 0.0039   lr: 1e-06  max_mem: 15544M
[08/30 23:10:29] d2.utils.events INFO:  eta: 0:04:30  iter: 1379  total_loss: 19.74  loss_ce: 0.1436  loss_mask: 0.1625  loss_dice: 1.345  loss_ce_0: 0.7785  loss_mask_0: 0.2378  loss_dice_0: 2.541  loss_ce_1: 0.2494  loss_mask_1: 0.1913  loss_dice_1: 1.856  loss_ce_2: 0.1379  loss_mask_2: 0.1715  loss_dice_2: 1.651  loss_ce_3: 0.1227  loss_mask_3: 0.1646  loss_dice_3: 1.533  loss_ce_4: 0.1288  loss_mask_4: 0.164  loss_dice_4: 1.491  loss_ce_5: 0.1365  loss_mask_5: 0.1558  loss_dice_5: 1.434  loss_ce_6: 0.1382  loss_mask_6: 0.1632  loss_dice_6: 1.406  loss_ce_7: 0.1364  loss_mask_7: 0.1639  loss_dice_7: 1.36  loss_ce_8: 0.1413  loss_mask_8: 0.1616  loss_dice_8: 1.362  loss_mgm_entropy: 0.004663    time: 0.4355  last_time: 0.4348  data_time: 0.0035  last_data_time: 0.0030   lr: 1e-06  max_mem: 15544M
[08/30 23:10:38] d2.utils.events INFO:  eta: 0:04:21  iter: 1399  total_loss: 20.08  loss_ce: 0.154  loss_mask: 0.1657  loss_dice: 1.388  loss_ce_0: 0.7887  loss_mask_0: 0.2619  loss_dice_0: 2.588  loss_ce_1: 0.2379  loss_mask_1: 0.1938  loss_dice_1: 1.859  loss_ce_2: 0.1829  loss_mask_2: 0.1815  loss_dice_2: 1.589  loss_ce_3: 0.1469  loss_mask_3: 0.1817  loss_dice_3: 1.454  loss_ce_4: 0.1466  loss_mask_4: 0.1736  loss_dice_4: 1.446  loss_ce_5: 0.1472  loss_mask_5: 0.175  loss_dice_5: 1.437  loss_ce_6: 0.1433  loss_mask_6: 0.162  loss_dice_6: 1.424  loss_ce_7: 0.1427  loss_mask_7: 0.1589  loss_dice_7: 1.39  loss_ce_8: 0.1434  loss_mask_8: 0.1618  loss_dice_8: 1.396  loss_mgm_entropy: 0.004641    time: 0.4355  last_time: 0.4345  data_time: 0.0036  last_data_time: 0.0035   lr: 1e-06  max_mem: 15544M
[08/30 23:10:46] d2.utils.events INFO:  eta: 0:04:12  iter: 1419  total_loss: 19.1  loss_ce: 0.1485  loss_mask: 0.1442  loss_dice: 1.309  loss_ce_0: 0.7878  loss_mask_0: 0.2535  loss_dice_0: 2.537  loss_ce_1: 0.275  loss_mask_1: 0.1762  loss_dice_1: 1.747  loss_ce_2: 0.1585  loss_mask_2: 0.1722  loss_dice_2: 1.5  loss_ce_3: 0.149  loss_mask_3: 0.1573  loss_dice_3: 1.384  loss_ce_4: 0.1447  loss_mask_4: 0.1505  loss_dice_4: 1.38  loss_ce_5: 0.1409  loss_mask_5: 0.1481  loss_dice_5: 1.337  loss_ce_6: 0.1379  loss_mask_6: 0.1473  loss_dice_6: 1.317  loss_ce_7: 0.1413  loss_mask_7: 0.1435  loss_dice_7: 1.295  loss_ce_8: 0.1432  loss_mask_8: 0.1426  loss_dice_8: 1.308  loss_mgm_entropy: 0.004667    time: 0.4355  last_time: 0.4355  data_time: 0.0036  last_data_time: 0.0037   lr: 1e-06  max_mem: 15544M
[08/30 23:10:55] d2.utils.events INFO:  eta: 0:04:03  iter: 1439  total_loss: 19.7  loss_ce: 0.1443  loss_mask: 0.1612  loss_dice: 1.337  loss_ce_0: 0.7693  loss_mask_0: 0.2492  loss_dice_0: 2.59  loss_ce_1: 0.2738  loss_mask_1: 0.1936  loss_dice_1: 1.861  loss_ce_2: 0.1589  loss_mask_2: 0.1841  loss_dice_2: 1.615  loss_ce_3: 0.142  loss_mask_3: 0.1828  loss_dice_3: 1.516  loss_ce_4: 0.1423  loss_mask_4: 0.1701  loss_dice_4: 1.438  loss_ce_5: 0.1411  loss_mask_5: 0.1672  loss_dice_5: 1.412  loss_ce_6: 0.136  loss_mask_6: 0.1621  loss_dice_6: 1.382  loss_ce_7: 0.137  loss_mask_7: 0.162  loss_dice_7: 1.361  loss_ce_8: 0.1409  loss_mask_8: 0.1618  loss_dice_8: 1.35  loss_mgm_entropy: 0.004649    time: 0.4355  last_time: 0.4346  data_time: 0.0036  last_data_time: 0.0032   lr: 1e-06  max_mem: 15544M
[08/30 23:11:04] d2.utils.events INFO:  eta: 0:03:55  iter: 1459  total_loss: 19.98  loss_ce: 0.1505  loss_mask: 0.1468  loss_dice: 1.357  loss_ce_0: 0.7872  loss_mask_0: 0.2456  loss_dice_0: 2.548  loss_ce_1: 0.2508  loss_mask_1: 0.1793  loss_dice_1: 1.806  loss_ce_2: 0.1525  loss_mask_2: 0.1732  loss_dice_2: 1.606  loss_ce_3: 0.1394  loss_mask_3: 0.1689  loss_dice_3: 1.506  loss_ce_4: 0.1424  loss_mask_4: 0.1603  loss_dice_4: 1.474  loss_ce_5: 0.1409  loss_mask_5: 0.1663  loss_dice_5: 1.431  loss_ce_6: 0.1392  loss_mask_6: 0.1671  loss_dice_6: 1.424  loss_ce_7: 0.1402  loss_mask_7: 0.1578  loss_dice_7: 1.377  loss_ce_8: 0.1434  loss_mask_8: 0.1626  loss_dice_8: 1.374  loss_mgm_entropy: 0.004593    time: 0.4355  last_time: 0.4353  data_time: 0.0035  last_data_time: 0.0036   lr: 1e-06  max_mem: 15544M
[08/30 23:11:12] d2.utils.events INFO:  eta: 0:03:46  iter: 1479  total_loss: 19.74  loss_ce: 0.1515  loss_mask: 0.1568  loss_dice: 1.326  loss_ce_0: 0.7869  loss_mask_0: 0.252  loss_dice_0: 2.57  loss_ce_1: 0.2556  loss_mask_1: 0.1911  loss_dice_1: 1.804  loss_ce_2: 0.1651  loss_mask_2: 0.1842  loss_dice_2: 1.551  loss_ce_3: 0.1396  loss_mask_3: 0.1692  loss_dice_3: 1.438  loss_ce_4: 0.1384  loss_mask_4: 0.1618  loss_dice_4: 1.419  loss_ce_5: 0.1407  loss_mask_5: 0.1585  loss_dice_5: 1.385  loss_ce_6: 0.1393  loss_mask_6: 0.1542  loss_dice_6: 1.362  loss_ce_7: 0.136  loss_mask_7: 0.1565  loss_dice_7: 1.357  loss_ce_8: 0.1486  loss_mask_8: 0.1553  loss_dice_8: 1.334  loss_mgm_entropy: 0.004629    time: 0.4355  last_time: 0.4375  data_time: 0.0035  last_data_time: 0.0034   lr: 1e-06  max_mem: 15544M
[08/30 23:11:21] d2.utils.events INFO:  eta: 0:03:37  iter: 1499  total_loss: 20.83  loss_ce: 0.1492  loss_mask: 0.2142  loss_dice: 1.439  loss_ce_0: 0.7794  loss_mask_0: 0.2836  loss_dice_0: 2.597  loss_ce_1: 0.2749  loss_mask_1: 0.2257  loss_dice_1: 1.885  loss_ce_2: 0.1618  loss_mask_2: 0.2329  loss_dice_2: 1.665  loss_ce_3: 0.1413  loss_mask_3: 0.2335  loss_dice_3: 1.6  loss_ce_4: 0.1424  loss_mask_4: 0.2223  loss_dice_4: 1.535  loss_ce_5: 0.1358  loss_mask_5: 0.215  loss_dice_5: 1.5  loss_ce_6: 0.1392  loss_mask_6: 0.2244  loss_dice_6: 1.479  loss_ce_7: 0.143  loss_mask_7: 0.2201  loss_dice_7: 1.445  loss_ce_8: 0.1422  loss_mask_8: 0.2115  loss_dice_8: 1.462  loss_mgm_entropy: 0.004651    time: 0.4355  last_time: 0.4345  data_time: 0.0035  last_data_time: 0.0038   lr: 1e-06  max_mem: 15544M
[08/30 23:11:30] d2.utils.events INFO:  eta: 0:03:29  iter: 1519  total_loss: 19.59  loss_ce: 0.1465  loss_mask: 0.1598  loss_dice: 1.359  loss_ce_0: 0.7864  loss_mask_0: 0.2757  loss_dice_0: 2.544  loss_ce_1: 0.2625  loss_mask_1: 0.2061  loss_dice_1: 1.828  loss_ce_2: 0.1523  loss_mask_2: 0.1945  loss_dice_2: 1.606  loss_ce_3: 0.1407  loss_mask_3: 0.1697  loss_dice_3: 1.456  loss_ce_4: 0.1441  loss_mask_4: 0.1659  loss_dice_4: 1.394  loss_ce_5: 0.143  loss_mask_5: 0.1669  loss_dice_5: 1.385  loss_ce_6: 0.1391  loss_mask_6: 0.1589  loss_dice_6: 1.322  loss_ce_7: 0.1403  loss_mask_7: 0.1548  loss_dice_7: 1.382  loss_ce_8: 0.1427  loss_mask_8: 0.1605  loss_dice_8: 1.353  loss_mgm_entropy: 0.004619    time: 0.4355  last_time: 0.4354  data_time: 0.0035  last_data_time: 0.0035   lr: 1e-07  max_mem: 15544M
[08/30 23:11:39] d2.utils.events INFO:  eta: 0:03:20  iter: 1539  total_loss: 19.66  loss_ce: 0.1468  loss_mask: 0.1513  loss_dice: 1.389  loss_ce_0: 0.7851  loss_mask_0: 0.2264  loss_dice_0: 2.554  loss_ce_1: 0.2421  loss_mask_1: 0.1735  loss_dice_1: 1.841  loss_ce_2: 0.1856  loss_mask_2: 0.176  loss_dice_2: 1.612  loss_ce_3: 0.1492  loss_mask_3: 0.1698  loss_dice_3: 1.533  loss_ce_4: 0.1379  loss_mask_4: 0.1587  loss_dice_4: 1.477  loss_ce_5: 0.1429  loss_mask_5: 0.1611  loss_dice_5: 1.451  loss_ce_6: 0.1326  loss_mask_6: 0.1616  loss_dice_6: 1.4  loss_ce_7: 0.1408  loss_mask_7: 0.1532  loss_dice_7: 1.417  loss_ce_8: 0.1452  loss_mask_8: 0.1495  loss_dice_8: 1.408  loss_mgm_entropy: 0.004562    time: 0.4355  last_time: 0.4355  data_time: 0.0036  last_data_time: 0.0038   lr: 1e-07  max_mem: 15544M
[08/30 23:11:47] d2.utils.events INFO:  eta: 0:03:11  iter: 1559  total_loss: 19.19  loss_ce: 0.1497  loss_mask: 0.1457  loss_dice: 1.284  loss_ce_0: 0.7851  loss_mask_0: 0.2218  loss_dice_0: 2.53  loss_ce_1: 0.2552  loss_mask_1: 0.1699  loss_dice_1: 1.799  loss_ce_2: 0.1832  loss_mask_2: 0.1582  loss_dice_2: 1.541  loss_ce_3: 0.1488  loss_mask_3: 0.1619  loss_dice_3: 1.403  loss_ce_4: 0.1421  loss_mask_4: 0.1541  loss_dice_4: 1.399  loss_ce_5: 0.1414  loss_mask_5: 0.1533  loss_dice_5: 1.35  loss_ce_6: 0.1416  loss_mask_6: 0.1437  loss_dice_6: 1.339  loss_ce_7: 0.1446  loss_mask_7: 0.1448  loss_dice_7: 1.314  loss_ce_8: 0.1416  loss_mask_8: 0.1466  loss_dice_8: 1.302  loss_mgm_entropy: 0.004548    time: 0.4355  last_time: 0.4362  data_time: 0.0034  last_data_time: 0.0036   lr: 1e-07  max_mem: 15544M
[08/30 23:11:56] d2.utils.events INFO:  eta: 0:03:03  iter: 1579  total_loss: 19.24  loss_ce: 0.1499  loss_mask: 0.1331  loss_dice: 1.299  loss_ce_0: 0.7864  loss_mask_0: 0.2207  loss_dice_0: 2.473  loss_ce_1: 0.2506  loss_mask_1: 0.1678  loss_dice_1: 1.792  loss_ce_2: 0.1599  loss_mask_2: 0.1563  loss_dice_2: 1.558  loss_ce_3: 0.1427  loss_mask_3: 0.1509  loss_dice_3: 1.404  loss_ce_4: 0.1434  loss_mask_4: 0.1441  loss_dice_4: 1.416  loss_ce_5: 0.1431  loss_mask_5: 0.1425  loss_dice_5: 1.359  loss_ce_6: 0.1392  loss_mask_6: 0.1414  loss_dice_6: 1.364  loss_ce_7: 0.1414  loss_mask_7: 0.1398  loss_dice_7: 1.313  loss_ce_8: 0.143  loss_mask_8: 0.1318  loss_dice_8: 1.289  loss_mgm_entropy: 0.004549    time: 0.4355  last_time: 0.4353  data_time: 0.0035  last_data_time: 0.0037   lr: 1e-07  max_mem: 15544M
[08/30 23:12:05] d2.utils.events INFO:  eta: 0:02:54  iter: 1599  total_loss: 19.73  loss_ce: 0.1461  loss_mask: 0.157  loss_dice: 1.338  loss_ce_0: 0.7955  loss_mask_0: 0.2512  loss_dice_0: 2.519  loss_ce_1: 0.2476  loss_mask_1: 0.1904  loss_dice_1: 1.796  loss_ce_2: 0.1655  loss_mask_2: 0.1814  loss_dice_2: 1.588  loss_ce_3: 0.1361  loss_mask_3: 0.1752  loss_dice_3: 1.472  loss_ce_4: 0.1305  loss_mask_4: 0.1657  loss_dice_4: 1.441  loss_ce_5: 0.1342  loss_mask_5: 0.156  loss_dice_5: 1.408  loss_ce_6: 0.1302  loss_mask_6: 0.1565  loss_dice_6: 1.374  loss_ce_7: 0.1359  loss_mask_7: 0.1533  loss_dice_7: 1.357  loss_ce_8: 0.1381  loss_mask_8: 0.1475  loss_dice_8: 1.365  loss_mgm_entropy: 0.004611    time: 0.4355  last_time: 0.4389  data_time: 0.0037  last_data_time: 0.0035   lr: 1e-07  max_mem: 15544M
[08/30 23:12:14] d2.utils.events INFO:  eta: 0:02:45  iter: 1619  total_loss: 20.03  loss_ce: 0.1443  loss_mask: 0.1846  loss_dice: 1.373  loss_ce_0: 0.7925  loss_mask_0: 0.2776  loss_dice_0: 2.561  loss_ce_1: 0.259  loss_mask_1: 0.2145  loss_dice_1: 1.878  loss_ce_2: 0.1582  loss_mask_2: 0.2137  loss_dice_2: 1.63  loss_ce_3: 0.1467  loss_mask_3: 0.2133  loss_dice_3: 1.466  loss_ce_4: 0.1364  loss_mask_4: 0.1989  loss_dice_4: 1.433  loss_ce_5: 0.1414  loss_mask_5: 0.1869  loss_dice_5: 1.391  loss_ce_6: 0.14  loss_mask_6: 0.1869  loss_dice_6: 1.379  loss_ce_7: 0.1399  loss_mask_7: 0.1778  loss_dice_7: 1.37  loss_ce_8: 0.1416  loss_mask_8: 0.1819  loss_dice_8: 1.372  loss_mgm_entropy: 0.004653    time: 0.4355  last_time: 0.4365  data_time: 0.0033  last_data_time: 0.0036   lr: 1e-07  max_mem: 15544M
[08/30 23:12:22] d2.utils.events INFO:  eta: 0:02:36  iter: 1639  total_loss: 19.8  loss_ce: 0.1638  loss_mask: 0.1556  loss_dice: 1.374  loss_ce_0: 0.7888  loss_mask_0: 0.2131  loss_dice_0: 2.536  loss_ce_1: 0.2463  loss_mask_1: 0.1713  loss_dice_1: 1.826  loss_ce_2: 0.1438  loss_mask_2: 0.1872  loss_dice_2: 1.601  loss_ce_3: 0.1546  loss_mask_3: 0.174  loss_dice_3: 1.467  loss_ce_4: 0.1359  loss_mask_4: 0.1511  loss_dice_4: 1.479  loss_ce_5: 0.1353  loss_mask_5: 0.1614  loss_dice_5: 1.419  loss_ce_6: 0.14  loss_mask_6: 0.1586  loss_dice_6: 1.38  loss_ce_7: 0.1494  loss_mask_7: 0.1583  loss_dice_7: 1.376  loss_ce_8: 0.1513  loss_mask_8: 0.1517  loss_dice_8: 1.378  loss_mgm_entropy: 0.004465    time: 0.4355  last_time: 0.4370  data_time: 0.0036  last_data_time: 0.0035   lr: 1e-07  max_mem: 15544M
[08/30 23:12:31] d2.utils.events INFO:  eta: 0:02:28  iter: 1659  total_loss: 20.56  loss_ce: 0.1468  loss_mask: 0.1976  loss_dice: 1.438  loss_ce_0: 0.7814  loss_mask_0: 0.2843  loss_dice_0: 2.531  loss_ce_1: 0.2537  loss_mask_1: 0.2204  loss_dice_1: 1.877  loss_ce_2: 0.1591  loss_mask_2: 0.2049  loss_dice_2: 1.624  loss_ce_3: 0.1494  loss_mask_3: 0.2028  loss_dice_3: 1.515  loss_ce_4: 0.1365  loss_mask_4: 0.2142  loss_dice_4: 1.509  loss_ce_5: 0.1406  loss_mask_5: 0.2012  loss_dice_5: 1.462  loss_ce_6: 0.1436  loss_mask_6: 0.1987  loss_dice_6: 1.415  loss_ce_7: 0.1445  loss_mask_7: 0.194  loss_dice_7: 1.424  loss_ce_8: 0.1439  loss_mask_8: 0.1953  loss_dice_8: 1.42  loss_mgm_entropy: 0.004635    time: 0.4355  last_time: 0.4361  data_time: 0.0034  last_data_time: 0.0039   lr: 1e-07  max_mem: 15544M
[08/30 23:12:40] d2.utils.events INFO:  eta: 0:02:19  iter: 1679  total_loss: 19.44  loss_ce: 0.149  loss_mask: 0.1424  loss_dice: 1.325  loss_ce_0: 0.7814  loss_mask_0: 0.2307  loss_dice_0: 2.585  loss_ce_1: 0.2425  loss_mask_1: 0.1809  loss_dice_1: 1.828  loss_ce_2: 0.1567  loss_mask_2: 0.1749  loss_dice_2: 1.577  loss_ce_3: 0.1418  loss_mask_3: 0.1688  loss_dice_3: 1.492  loss_ce_4: 0.1428  loss_mask_4: 0.1602  loss_dice_4: 1.423  loss_ce_5: 0.141  loss_mask_5: 0.1559  loss_dice_5: 1.379  loss_ce_6: 0.1396  loss_mask_6: 0.1553  loss_dice_6: 1.345  loss_ce_7: 0.1411  loss_mask_7: 0.1485  loss_dice_7: 1.35  loss_ce_8: 0.1411  loss_mask_8: 0.1469  loss_dice_8: 1.328  loss_mgm_entropy: 0.004552    time: 0.4355  last_time: 0.4350  data_time: 0.0037  last_data_time: 0.0031   lr: 1e-07  max_mem: 15544M
[08/30 23:12:49] d2.utils.events INFO:  eta: 0:02:10  iter: 1699  total_loss: 19.25  loss_ce: 0.1458  loss_mask: 0.1442  loss_dice: 1.293  loss_ce_0: 0.779  loss_mask_0: 0.226  loss_dice_0: 2.519  loss_ce_1: 0.244  loss_mask_1: 0.1797  loss_dice_1: 1.82  loss_ce_2: 0.1812  loss_mask_2: 0.1632  loss_dice_2: 1.574  loss_ce_3: 0.1478  loss_mask_3: 0.1617  loss_dice_3: 1.454  loss_ce_4: 0.1315  loss_mask_4: 0.1493  loss_dice_4: 1.424  loss_ce_5: 0.1367  loss_mask_5: 0.1574  loss_dice_5: 1.367  loss_ce_6: 0.1373  loss_mask_6: 0.1502  loss_dice_6: 1.328  loss_ce_7: 0.1388  loss_mask_7: 0.1454  loss_dice_7: 1.321  loss_ce_8: 0.1393  loss_mask_8: 0.1401  loss_dice_8: 1.305  loss_mgm_entropy: 0.004566    time: 0.4355  last_time: 0.4364  data_time: 0.0034  last_data_time: 0.0036   lr: 1e-07  max_mem: 15544M
[08/30 23:12:57] d2.utils.events INFO:  eta: 0:02:02  iter: 1719  total_loss: 19.55  loss_ce: 0.1482  loss_mask: 0.156  loss_dice: 1.34  loss_ce_0: 0.7864  loss_mask_0: 0.2661  loss_dice_0: 2.592  loss_ce_1: 0.2471  loss_mask_1: 0.2017  loss_dice_1: 1.846  loss_ce_2: 0.1669  loss_mask_2: 0.1894  loss_dice_2: 1.594  loss_ce_3: 0.151  loss_mask_3: 0.1822  loss_dice_3: 1.482  loss_ce_4: 0.143  loss_mask_4: 0.1712  loss_dice_4: 1.419  loss_ce_5: 0.1431  loss_mask_5: 0.1699  loss_dice_5: 1.364  loss_ce_6: 0.1405  loss_mask_6: 0.1634  loss_dice_6: 1.359  loss_ce_7: 0.1399  loss_mask_7: 0.1664  loss_dice_7: 1.335  loss_ce_8: 0.1431  loss_mask_8: 0.1598  loss_dice_8: 1.329  loss_mgm_entropy: 0.004612    time: 0.4356  last_time: 0.4363  data_time: 0.0036  last_data_time: 0.0035   lr: 1e-07  max_mem: 15544M
[08/30 23:13:06] d2.utils.events INFO:  eta: 0:01:53  iter: 1739  total_loss: 19.92  loss_ce: 0.145  loss_mask: 0.1778  loss_dice: 1.371  loss_ce_0: 0.7737  loss_mask_0: 0.2518  loss_dice_0: 2.582  loss_ce_1: 0.2717  loss_mask_1: 0.2117  loss_dice_1: 1.824  loss_ce_2: 0.1639  loss_mask_2: 0.1873  loss_dice_2: 1.611  loss_ce_3: 0.1401  loss_mask_3: 0.1932  loss_dice_3: 1.521  loss_ce_4: 0.1301  loss_mask_4: 0.1743  loss_dice_4: 1.466  loss_ce_5: 0.1401  loss_mask_5: 0.1739  loss_dice_5: 1.417  loss_ce_6: 0.1339  loss_mask_6: 0.1729  loss_dice_6: 1.403  loss_ce_7: 0.1352  loss_mask_7: 0.1714  loss_dice_7: 1.382  loss_ce_8: 0.1377  loss_mask_8: 0.1732  loss_dice_8: 1.374  loss_mgm_entropy: 0.004598    time: 0.4356  last_time: 0.4348  data_time: 0.0034  last_data_time: 0.0031   lr: 1e-07  max_mem: 15544M
[08/30 23:13:15] d2.utils.events INFO:  eta: 0:01:44  iter: 1759  total_loss: 19.51  loss_ce: 0.1488  loss_mask: 0.1556  loss_dice: 1.318  loss_ce_0: 0.785  loss_mask_0: 0.229  loss_dice_0: 2.568  loss_ce_1: 0.2522  loss_mask_1: 0.1855  loss_dice_1: 1.835  loss_ce_2: 0.1801  loss_mask_2: 0.1728  loss_dice_2: 1.58  loss_ce_3: 0.1395  loss_mask_3: 0.1645  loss_dice_3: 1.459  loss_ce_4: 0.1417  loss_mask_4: 0.158  loss_dice_4: 1.419  loss_ce_5: 0.1366  loss_mask_5: 0.1515  loss_dice_5: 1.389  loss_ce_6: 0.1336  loss_mask_6: 0.1565  loss_dice_6: 1.357  loss_ce_7: 0.1408  loss_mask_7: 0.153  loss_dice_7: 1.333  loss_ce_8: 0.1416  loss_mask_8: 0.1587  loss_dice_8: 1.324  loss_mgm_entropy: 0.004513    time: 0.4356  last_time: 0.4353  data_time: 0.0036  last_data_time: 0.0035   lr: 1e-07  max_mem: 15544M
[08/30 23:13:23] d2.utils.events INFO:  eta: 0:01:35  iter: 1779  total_loss: 19.64  loss_ce: 0.1533  loss_mask: 0.1551  loss_dice: 1.351  loss_ce_0: 0.7862  loss_mask_0: 0.2275  loss_dice_0: 2.524  loss_ce_1: 0.2451  loss_mask_1: 0.1871  loss_dice_1: 1.839  loss_ce_2: 0.1646  loss_mask_2: 0.1783  loss_dice_2: 1.597  loss_ce_3: 0.1463  loss_mask_3: 0.1717  loss_dice_3: 1.48  loss_ce_4: 0.1354  loss_mask_4: 0.1499  loss_dice_4: 1.442  loss_ce_5: 0.1418  loss_mask_5: 0.1513  loss_dice_5: 1.427  loss_ce_6: 0.137  loss_mask_6: 0.1493  loss_dice_6: 1.384  loss_ce_7: 0.1415  loss_mask_7: 0.1561  loss_dice_7: 1.37  loss_ce_8: 0.1444  loss_mask_8: 0.1474  loss_dice_8: 1.366  loss_mgm_entropy: 0.004539    time: 0.4356  last_time: 0.4362  data_time: 0.0035  last_data_time: 0.0035   lr: 1e-07  max_mem: 15544M
[08/30 23:13:32] d2.utils.events INFO:  eta: 0:01:27  iter: 1799  total_loss: 20.03  loss_ce: 0.1477  loss_mask: 0.1756  loss_dice: 1.409  loss_ce_0: 0.786  loss_mask_0: 0.2591  loss_dice_0: 2.542  loss_ce_1: 0.2457  loss_mask_1: 0.2104  loss_dice_1: 1.85  loss_ce_2: 0.1844  loss_mask_2: 0.2056  loss_dice_2: 1.614  loss_ce_3: 0.1435  loss_mask_3: 0.1897  loss_dice_3: 1.544  loss_ce_4: 0.1421  loss_mask_4: 0.1749  loss_dice_4: 1.468  loss_ce_5: 0.1426  loss_mask_5: 0.1913  loss_dice_5: 1.452  loss_ce_6: 0.1369  loss_mask_6: 0.1812  loss_dice_6: 1.405  loss_ce_7: 0.1371  loss_mask_7: 0.1732  loss_dice_7: 1.408  loss_ce_8: 0.1424  loss_mask_8: 0.1795  loss_dice_8: 1.416  loss_mgm_entropy: 0.004583    time: 0.4356  last_time: 0.4363  data_time: 0.0034  last_data_time: 0.0036   lr: 1e-07  max_mem: 15544M
[08/30 23:13:41] d2.utils.events INFO:  eta: 0:01:18  iter: 1819  total_loss: 19.69  loss_ce: 0.1439  loss_mask: 0.1651  loss_dice: 1.349  loss_ce_0: 0.7813  loss_mask_0: 0.2297  loss_dice_0: 2.509  loss_ce_1: 0.25  loss_mask_1: 0.1807  loss_dice_1: 1.829  loss_ce_2: 0.1802  loss_mask_2: 0.1632  loss_dice_2: 1.587  loss_ce_3: 0.1495  loss_mask_3: 0.1642  loss_dice_3: 1.517  loss_ce_4: 0.1394  loss_mask_4: 0.1584  loss_dice_4: 1.453  loss_ce_5: 0.1382  loss_mask_5: 0.1673  loss_dice_5: 1.398  loss_ce_6: 0.1381  loss_mask_6: 0.1671  loss_dice_6: 1.393  loss_ce_7: 0.1413  loss_mask_7: 0.1618  loss_dice_7: 1.365  loss_ce_8: 0.1421  loss_mask_8: 0.1632  loss_dice_8: 1.355  loss_mgm_entropy: 0.004495    time: 0.4356  last_time: 0.4377  data_time: 0.0035  last_data_time: 0.0039   lr: 1e-07  max_mem: 15544M
[08/30 23:13:50] d2.utils.events INFO:  eta: 0:01:09  iter: 1839  total_loss: 19.94  loss_ce: 0.1479  loss_mask: 0.1407  loss_dice: 1.402  loss_ce_0: 0.7859  loss_mask_0: 0.2411  loss_dice_0: 2.545  loss_ce_1: 0.2453  loss_mask_1: 0.1758  loss_dice_1: 1.836  loss_ce_2: 0.1693  loss_mask_2: 0.1846  loss_dice_2: 1.611  loss_ce_3: 0.1351  loss_mask_3: 0.1694  loss_dice_3: 1.503  loss_ce_4: 0.1297  loss_mask_4: 0.1607  loss_dice_4: 1.461  loss_ce_5: 0.1337  loss_mask_5: 0.1493  loss_dice_5: 1.419  loss_ce_6: 0.1354  loss_mask_6: 0.1552  loss_dice_6: 1.388  loss_ce_7: 0.1389  loss_mask_7: 0.1442  loss_dice_7: 1.373  loss_ce_8: 0.1438  loss_mask_8: 0.1378  loss_dice_8: 1.386  loss_mgm_entropy: 0.00455    time: 0.4356  last_time: 0.4354  data_time: 0.0036  last_data_time: 0.0040   lr: 1e-07  max_mem: 15544M
[08/30 23:13:58] d2.utils.events INFO:  eta: 0:01:01  iter: 1859  total_loss: 19.13  loss_ce: 0.148  loss_mask: 0.1384  loss_dice: 1.304  loss_ce_0: 0.7849  loss_mask_0: 0.2263  loss_dice_0: 2.492  loss_ce_1: 0.2448  loss_mask_1: 0.1654  loss_dice_1: 1.784  loss_ce_2: 0.1717  loss_mask_2: 0.1616  loss_dice_2: 1.535  loss_ce_3: 0.1499  loss_mask_3: 0.1468  loss_dice_3: 1.405  loss_ce_4: 0.146  loss_mask_4: 0.144  loss_dice_4: 1.388  loss_ce_5: 0.1413  loss_mask_5: 0.1487  loss_dice_5: 1.357  loss_ce_6: 0.1392  loss_mask_6: 0.1483  loss_dice_6: 1.334  loss_ce_7: 0.1402  loss_mask_7: 0.1411  loss_dice_7: 1.318  loss_ce_8: 0.1426  loss_mask_8: 0.1407  loss_dice_8: 1.306  loss_mgm_entropy: 0.004467    time: 0.4356  last_time: 0.4364  data_time: 0.0035  last_data_time: 0.0035   lr: 1e-07  max_mem: 15544M
[08/30 23:14:07] d2.utils.events INFO:  eta: 0:00:52  iter: 1879  total_loss: 19.54  loss_ce: 0.1496  loss_mask: 0.1427  loss_dice: 1.335  loss_ce_0: 0.7759  loss_mask_0: 0.2086  loss_dice_0: 2.522  loss_ce_1: 0.2459  loss_mask_1: 0.1686  loss_dice_1: 1.826  loss_ce_2: 0.1757  loss_mask_2: 0.1577  loss_dice_2: 1.59  loss_ce_3: 0.1403  loss_mask_3: 0.1573  loss_dice_3: 1.516  loss_ce_4: 0.1439  loss_mask_4: 0.1445  loss_dice_4: 1.445  loss_ce_5: 0.1404  loss_mask_5: 0.1457  loss_dice_5: 1.393  loss_ce_6: 0.1369  loss_mask_6: 0.1396  loss_dice_6: 1.371  loss_ce_7: 0.1408  loss_mask_7: 0.1433  loss_dice_7: 1.349  loss_ce_8: 0.1419  loss_mask_8: 0.1452  loss_dice_8: 1.344  loss_mgm_entropy: 0.004484    time: 0.4356  last_time: 0.4359  data_time: 0.0035  last_data_time: 0.0035   lr: 1e-07  max_mem: 15544M
[08/30 23:14:16] d2.utils.events INFO:  eta: 0:00:43  iter: 1899  total_loss: 19.5  loss_ce: 0.1465  loss_mask: 0.155  loss_dice: 1.345  loss_ce_0: 0.7846  loss_mask_0: 0.2538  loss_dice_0: 2.551  loss_ce_1: 0.2443  loss_mask_1: 0.1985  loss_dice_1: 1.853  loss_ce_2: 0.1652  loss_mask_2: 0.1898  loss_dice_2: 1.602  loss_ce_3: 0.1414  loss_mask_3: 0.1809  loss_dice_3: 1.479  loss_ce_4: 0.1293  loss_mask_4: 0.1638  loss_dice_4: 1.415  loss_ce_5: 0.1373  loss_mask_5: 0.1592  loss_dice_5: 1.4  loss_ce_6: 0.1346  loss_mask_6: 0.1618  loss_dice_6: 1.36  loss_ce_7: 0.1388  loss_mask_7: 0.1587  loss_dice_7: 1.322  loss_ce_8: 0.1413  loss_mask_8: 0.1556  loss_dice_8: 1.332  loss_mgm_entropy: 0.004564    time: 0.4356  last_time: 0.4355  data_time: 0.0036  last_data_time: 0.0036   lr: 1e-07  max_mem: 15544M
[08/30 23:14:25] d2.utils.events INFO:  eta: 0:00:34  iter: 1919  total_loss: 18.83  loss_ce: 0.1471  loss_mask: 0.1288  loss_dice: 1.281  loss_ce_0: 0.7856  loss_mask_0: 0.2226  loss_dice_0: 2.52  loss_ce_1: 0.2475  loss_mask_1: 0.1684  loss_dice_1: 1.808  loss_ce_2: 0.1658  loss_mask_2: 0.1568  loss_dice_2: 1.554  loss_ce_3: 0.1373  loss_mask_3: 0.155  loss_dice_3: 1.421  loss_ce_4: 0.1388  loss_mask_4: 0.1456  loss_dice_4: 1.387  loss_ce_5: 0.1366  loss_mask_5: 0.1442  loss_dice_5: 1.36  loss_ce_6: 0.1393  loss_mask_6: 0.135  loss_dice_6: 1.294  loss_ce_7: 0.1425  loss_mask_7: 0.1324  loss_dice_7: 1.312  loss_ce_8: 0.1432  loss_mask_8: 0.131  loss_dice_8: 1.29  loss_mgm_entropy: 0.004499    time: 0.4356  last_time: 0.4361  data_time: 0.0035  last_data_time: 0.0038   lr: 1e-07  max_mem: 15544M
[08/30 23:14:33] d2.utils.events INFO:  eta: 0:00:26  iter: 1939  total_loss: 19.62  loss_ce: 0.1478  loss_mask: 0.154  loss_dice: 1.329  loss_ce_0: 0.7822  loss_mask_0: 0.2403  loss_dice_0: 2.512  loss_ce_1: 0.2516  loss_mask_1: 0.1885  loss_dice_1: 1.836  loss_ce_2: 0.1638  loss_mask_2: 0.1813  loss_dice_2: 1.58  loss_ce_3: 0.1362  loss_mask_3: 0.1794  loss_dice_3: 1.474  loss_ce_4: 0.1289  loss_mask_4: 0.1505  loss_dice_4: 1.43  loss_ce_5: 0.1364  loss_mask_5: 0.1658  loss_dice_5: 1.4  loss_ce_6: 0.1363  loss_mask_6: 0.1736  loss_dice_6: 1.363  loss_ce_7: 0.1396  loss_mask_7: 0.1565  loss_dice_7: 1.346  loss_ce_8: 0.1411  loss_mask_8: 0.1549  loss_dice_8: 1.346  loss_mgm_entropy: 0.004566    time: 0.4356  last_time: 0.4368  data_time: 0.0035  last_data_time: 0.0038   lr: 1e-07  max_mem: 15544M
[08/30 23:14:42] d2.utils.events INFO:  eta: 0:00:17  iter: 1959  total_loss: 18.97  loss_ce: 0.1527  loss_mask: 0.1524  loss_dice: 1.274  loss_ce_0: 0.7857  loss_mask_0: 0.2453  loss_dice_0: 2.48  loss_ce_1: 0.2515  loss_mask_1: 0.1917  loss_dice_1: 1.742  loss_ce_2: 0.1541  loss_mask_2: 0.1786  loss_dice_2: 1.544  loss_ce_3: 0.1463  loss_mask_3: 0.1707  loss_dice_3: 1.41  loss_ce_4: 0.1348  loss_mask_4: 0.1551  loss_dice_4: 1.38  loss_ce_5: 0.1418  loss_mask_5: 0.1597  loss_dice_5: 1.332  loss_ce_6: 0.1389  loss_mask_6: 0.1582  loss_dice_6: 1.303  loss_ce_7: 0.1412  loss_mask_7: 0.1541  loss_dice_7: 1.3  loss_ce_8: 0.1435  loss_mask_8: 0.1508  loss_dice_8: 1.279  loss_mgm_entropy: 0.004564    time: 0.4357  last_time: 0.4371  data_time: 0.0036  last_data_time: 0.0035   lr: 1e-07  max_mem: 15544M
[08/30 23:14:51] d2.utils.events INFO:  eta: 0:00:08  iter: 1979  total_loss: 19.62  loss_ce: 0.1488  loss_mask: 0.1449  loss_dice: 1.333  loss_ce_0: 0.7785  loss_mask_0: 0.2291  loss_dice_0: 2.515  loss_ce_1: 0.2399  loss_mask_1: 0.1824  loss_dice_1: 1.823  loss_ce_2: 0.1538  loss_mask_2: 0.1768  loss_dice_2: 1.608  loss_ce_3: 0.1356  loss_mask_3: 0.1653  loss_dice_3: 1.494  loss_ce_4: 0.1286  loss_mask_4: 0.1508  loss_dice_4: 1.433  loss_ce_5: 0.1315  loss_mask_5: 0.1561  loss_dice_5: 1.392  loss_ce_6: 0.1392  loss_mask_6: 0.1477  loss_dice_6: 1.382  loss_ce_7: 0.1395  loss_mask_7: 0.1465  loss_dice_7: 1.334  loss_ce_8: 0.141  loss_mask_8: 0.1482  loss_dice_8: 1.325  loss_mgm_entropy: 0.004523    time: 0.4357  last_time: 0.4354  data_time: 0.0035  last_data_time: 0.0038   lr: 1e-07  max_mem: 15544M
[08/30 23:15:00] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_final.pth
[08/30 23:15:00] d2.utils.events INFO:  eta: 0:00:00  iter: 1999  total_loss: 19.4  loss_ce: 0.1432  loss_mask: 0.153  loss_dice: 1.31  loss_ce_0: 0.7812  loss_mask_0: 0.2137  loss_dice_0: 2.467  loss_ce_1: 0.2501  loss_mask_1: 0.172  loss_dice_1: 1.858  loss_ce_2: 0.1607  loss_mask_2: 0.1479  loss_dice_2: 1.582  loss_ce_3: 0.1394  loss_mask_3: 0.1583  loss_dice_3: 1.46  loss_ce_4: 0.1396  loss_mask_4: 0.1373  loss_dice_4: 1.401  loss_ce_5: 0.1415  loss_mask_5: 0.1396  loss_dice_5: 1.376  loss_ce_6: 0.1352  loss_mask_6: 0.1398  loss_dice_6: 1.315  loss_ce_7: 0.1354  loss_mask_7: 0.1377  loss_dice_7: 1.316  loss_ce_8: 0.1385  loss_mask_8: 0.1364  loss_dice_8: 1.316  loss_mgm_entropy: 0.004364    time: 0.4357  last_time: 0.4369  data_time: 0.0035  last_data_time: 0.0032   lr: 1e-07  max_mem: 15544M
[08/30 23:15:00] d2.engine.hooks INFO: Overall training speed: 1998 iterations in 0:14:30 (0.4357 s / it)
[08/30 23:15:00] d2.engine.hooks INFO: Total training time: 0:14:31 (0:00:01 on hooks)
[08/30 23:15:00] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [Mapper] Noise-mask dir not found, will skip masks: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/depth/depth_noise_mask
[08/30 23:15:00] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [COCOInstanceRGBDDatasetMapper] Augs: [] | RGB: RGB | DATASET_ROOT=/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
[08/30 23:15:00] d2.data.datasets.coco INFO: Loaded 6 images in COCO format from /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/annotations/instances_val.json
[08/30 23:15:00] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[08/30 23:15:00] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[08/30 23:15:00] d2.data.common INFO: Serialized dataset takes 0.16 MiB
[08/30 23:15:00] d2.evaluation.evaluator INFO: Start inference on 6 batches
[08/30 23:15:03] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.390778 (0.390778 s / iter per device, on 1 devices)
[08/30 23:15:03] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.161194 s / iter per device, on 1 devices)
[08/30 23:15:03] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[08/30 23:15:03] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[08/30 23:15:03] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[08/30 23:15:03] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[08/30 23:15:03] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[08/30 23:15:03] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[08/30 23:15:03] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[08/30 23:15:03] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  |  nan  | 0.000 | 0.000 |
[08/30 23:15:03] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/30 23:15:03] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[08/30 23:15:03] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[08/30 23:15:03] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[08/30 23:15:03] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[08/30 23:15:03] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 39.836 | 80.261 | 30.143 |  nan  | 38.400 | 43.898 |
[08/30 23:15:03] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/30 23:15:03] d2.engine.defaults INFO: Evaluation results for coco_instance_rgbd_val in csv format:
[08/30 23:15:03] d2.evaluation.testing INFO: copypaste: Task: bbox
[08/30 23:15:03] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/30 23:15:03] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,nan,0.0000,0.0000
[08/30 23:15:03] d2.evaluation.testing INFO: copypaste: Task: segm
[08/30 23:15:03] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/30 23:15:03] d2.evaluation.testing INFO: copypaste: 39.8356,80.2606,30.1427,nan,38.4004,43.8977
[08/30 23:19:57] detectron2 INFO: Rank of current process: 0. World size: 1
[08/30 23:19:57] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:43:55) [GCC 13.3.0]
numpy                            2.2.6
detectron2                       0.6 @/home/fuyx/hch/detectron2/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6, 8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   575.64.03
CUDA_HOME                        /home/fuyx/anaconda3/envs/m2f
Pillow                           11.3.0
torchvision                      0.20.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[08/30 23:19:57] detectron2 INFO: Command line arguments: Namespace(config_file='MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[08/30 23:19:57] detectron2 INFO: Contents of args.config_file=MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml:
MODEL:
  META_ARCHITECTURE: "MGMMaskFormer"

  # RGB Backbone: Swin Transformer Tiny
  RGB_BACKBONE:
    NAME: "D2SwinTransformer"
    WEIGHTS: "checkpoint_convertor/checkpoint_swin/checkpoint_swin_slice/swin_backbone.pth"
    SWIN:
      EMBED_DIM: 96
      DEPTHS: [2, 2, 6, 2]
      NUM_HEADS: [3, 6, 12, 24]
      WINDOW_SIZE: 7
      APE: False
      DROP_PATH_RATE: 0.3
      PATCH_NORM: True
      OUT_FEATURES: ["res2", "res3", "res4", "res5"]

  # Depth Backbone: ConvNeXt Tiny
  DEPTH_BACKBONE:
    NAME: "ConvNeXtDepthBackbone"
    WEIGHTS: "checkpoint_convertor/convnext-checkpoint/convnext_tiny_depth_22k_converted.pth"
    CONVNEXT:
      DEPTHS: [3, 3, 9, 3]
      DIMS: [96, 192, 384, 768]
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1e-6

  # MGM Fusion Configuration
  MGM:
    ENABLED: True
    SHARED: True
    RESIDUAL_ALPHA: 0.05
    POST_FUSE_NORM: True # 新增：融合后GN
    LOSS_ENTROPY_W: 0.01
    TEMP_INIT: 1.5
    TEMP_FINAL: 1.0
    TEMP_STEPS: 3000 # 建议略短，收敛更快
    CLAMP_MIN: 0.05
    CLAMP_MAX: 0.95
    NOISE_MASK_WEIGHT: 0.0 # 前期建议关；有噪声掩码再开到0.05~0.1
    HIDDEN_DIM: 256
    FEATURE_DIMS: [96, 192, 384, 768]
    SCALE_KEYS: ["res2", "res3", "res4", "res5"]

    PRIOR:
      ENABLED: True # 总开关
      USE_GRADIENT: True # 先验逐项开关
      USE_VARIANCE: True
      USE_VALID_HOLE: True
      USE_RGB_EDGE: True # 前期建议关（最耗时）
      VAR_KERNEL: 5
      Z_MIN: 0.0
      Z_MAX: 1.0
      COMPUTE_ON: "res3" # "full"|"res2"|"res3"|"res4"|"res5"；前期建议用res3提速

    ROBUST_NORM:
      ENABLED: True # 前期建议关；要稳健再开
      METHOD: "minmax" # "minmax"|"quantile"

  # DPE Configuration
  DPE:
    ENABLED: True

  # Boundary Configuration
  BOUNDARY:
    ENABLED: False

  # RGB Input Pixel Mean/Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]

  # Semantic Segmentation Head
  SEM_SEG_HEAD:
    NAME: "MGMHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 1
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MGMMSDeformAttnPixelDecoder"
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6

  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MGMMultiScaleMaskedTransformerDecoder"
    TRANSFORMER_IN_FEATURE: "multi_scale_pixel_decoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 2.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 100
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    DEC_LAYERS: 10
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.8

# 数据集配置
DATASETS:
  TRAIN: ("coco_instance_rgbd_train",)
  TEST: ("coco_instance_rgbd_val",)

# 数据加载器配置
DATALOADER:
  NUM_WORKERS: 16
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  REPEAT_THRESHOLD: 0.0

  # RGB-D Input Configuration - 快速训练模式
INPUT:
  DATASET_ROOT: "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input"
  IMAGE_SIZE: 1024
  MIN_SCALE: 0.8
  MAX_SCALE: 1.2
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "coco_instance_lsj_rgbd"
  RANDOM_FLIP: "horizontal"
  SIZE_DIVISIBILITY: 32

  # RGB光度增强
  RGB_PHOTO_AUG:
    ENABLED: False
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    SATURATION: 0.1
    HUE: 0.0

  # 深度数据配置
  DEPTH_FORMAT: "I"
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_CLIP_MAX: 1.0
  DEPTH_NORM: "minmax"
  DEPTH_NOISE:
    ENABLED: False
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
    DROP_PROB: 0.0
    DROP_VAL: 0.0

# 求解器配置
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 1e-5
  STEPS: (5000, 7500)
  MAX_ITER: 10000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  GAMMA: 0.1
  OPTIMIZER: ADAMW
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_EMBED: 0.0
  CLIP_GRADIENTS:
    ENABLED: False
  AMP:
    ENABLED: True

# 测试配置
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False

# 输出配置
OUTPUT_DIR: "./output"

# 版本号
VERSION: 2.0

[08/30 23:19:57] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  LOAD_PROPOSALS: false
  NUM_WORKERS: 16
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_instance_rgbd_val
  TRAIN:
  - coco_instance_rgbd_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj_rgbd
  DATASET_ROOT: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
  DEPTH_CLIP_MAX: 1.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_FORMAT: I
  DEPTH_NOISE:
    DROP_PROB: 0.0
    DROP_VAL: 0.0
    ENABLED: false
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
  DEPTH_NORM: minmax
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 1.2
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.8
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  RGB_PHOTO_AUG:
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    ENABLED: false
    HUE: 0.0
    SATURATION: 0.1
  SIZE_DIVISIBILITY: 32
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BOUNDARY:
    ENABLED: false
  DEPTH_BACKBONE:
    CONVNEXT:
      DEPTHS:
      - 3
      - 3
      - 9
      - 3
      DIMS:
      - 96
      - 192
      - 384
      - 768
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1.0e-06
    NAME: ConvNeXtDepthBackbone
    WEIGHTS: checkpoint_convertor/convnext-checkpoint/convnext_tiny_depth_22k_converted.pth
  DEVICE: cuda
  DPE:
    ENABLED: true
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MGMMultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MGMMaskFormer
  MGM:
    CLAMP_MAX: 0.95
    CLAMP_MIN: 0.05
    ENABLED: true
    FEATURE_DIMS:
    - 96
    - 192
    - 384
    - 768
    HIDDEN_DIM: 256
    LOSS_ENTROPY_W: 0.01
    NOISE_MASK_WEIGHT: 0.0
    POST_FUSE_NORM: true
    PRIOR:
      COMPUTE_ON: res3
      ENABLED: true
      USE_GRADIENT: true
      USE_RGB_EDGE: true
      USE_VALID_HOLE: true
      USE_VARIANCE: true
      VAR_KERNEL: 5
      Z_MAX: 1.0
      Z_MIN: 0.0
    RESIDUAL_ALPHA: 0.05
    ROBUST_NORM:
      ENABLED: true
      METHOD: minmax
    SCALE_KEYS:
    - res2
    - res3
    - res4
    - res5
    SHARED: true
    TEMP_FINAL: 1.0
    TEMP_INIT: 1.5
    TEMP_STEPS: 3000
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  RGB_BACKBONE:
    NAME: D2SwinTransformer
    SWIN:
      APE: false
      ATTN_DROP_RATE: 0.0
      DEPTHS:
      - 2
      - 2
      - 6
      - 2
      DROP_PATH_RATE: 0.3
      DROP_RATE: 0.0
      EMBED_DIM: 96
      MLP_RATIO: 4.0
      NUM_HEADS:
      - 3
      - 6
      - 12
      - 24
      OUT_FEATURES:
      - res2
      - res3
      - res4
      - res5
      PATCH_NORM: true
      PATCH_SIZE: 4
      PRETRAIN_IMG_SIZE: 224
      QKV_BIAS: true
      QK_SCALE: null
      USE_CHECKPOINT: false
      WINDOW_SIZE: 7
    WEIGHTS: checkpoint_convertor/checkpoint_swin/checkpoint_swin_slice/swin_backbone.pth
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MGMHead
    NORM: GN
    NUM_CLASSES: 1
    PIXEL_DECODER_NAME: MGMMSDeformAttnPixelDecoder
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: ''
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 1.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 5000
  - 7500
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2.0
VIS_PERIOD: 0

[08/30 23:19:57] detectron2 INFO: Full config saved to ./output/config.yaml
[08/30 23:19:57] d2.utils.env INFO: Using a generated random seed 61014200
[08/30 23:20:18] d2.engine.defaults INFO: Model:
MGMMaskFormer(
  (rgb_backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.055)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.109)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.136)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.164)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.191)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.218)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.245)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.273)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.300)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (depth_backbone): ConvNeXtDepthBackbone(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
  )
  (mgm): MultiModalGatedFusion(
    (prior_extractor): DepthPriorExtractor()
    (conf_pred): ConfidencePredictor(
      (proj_image): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_depth): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_prior): Sequential(
        (0): Conv2d(5, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
      )
      (head): Sequential(
        (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): GroupNorm(8, 128, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (align_image): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (align_depth): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (post_norm): ModuleList(
      (0): GroupNorm(8, 96, eps=1e-05, affine=True)
      (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      (2): GroupNorm(8, 384, eps=1e-05, affine=True)
      (3): GroupNorm(8, 768, eps=1e-05, affine=True)
    )
  )
  (sem_seg_head): MGMHead(
    (pixel_decoder): MGMMSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (depth_pe): DepthPosEncoding(
        (mlp): Sequential(
          (0): Conv2d(1, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MGMMultiScaleMaskedTransformerDecoder(
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x MGMCrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=2, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 1
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/30 23:20:18] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [Mapper] Noise-mask dir not found, will skip masks: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/depth/depth_noise_mask
[08/30 23:20:18] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [COCOInstanceRGBDDatasetMapper] Augs: [RandomFlip(), ResizeScale(min_scale=0.8, max_scale=1.2, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=(1024, 1024))] | RGB: RGB | DATASET_ROOT=/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
[08/30 23:20:18] d2.data.datasets.coco INFO: Loaded 6 images in COCO format from /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/annotations/instances_train.json
[08/30 23:20:18] d2.data.build INFO: Removed 0 images with no usable annotations. 6 images left.
[08/30 23:20:18] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| component  | 147          |
|            |              |[0m
[08/30 23:20:18] d2.data.build INFO: Using training sampler TrainingSampler
[08/30 23:20:18] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[08/30 23:20:18] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[08/30 23:20:18] d2.data.common INFO: Serialized dataset takes 0.16 MiB
[08/30 23:20:18] d2.data.build INFO: Making batched data loader with batch_size=1
[08/30 23:20:18] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[08/30 23:20:18] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[08/30 23:20:18] d2.engine.train_loop INFO: Starting training from iteration 0
[08/30 23:20:28] d2.utils.events INFO:  eta: 1:11:19  iter: 19  total_loss: 109.3  loss_ce: 2.111  loss_mask: 5.568  loss_dice: 4.962  loss_ce_0: 1.518  loss_mask_0: 3.552  loss_dice_0: 4.923  loss_ce_1: 1.17  loss_mask_1: 4.056  loss_dice_1: 4.915  loss_ce_2: 1.22  loss_mask_2: 3.744  loss_dice_2: 4.934  loss_ce_3: 1.905  loss_mask_3: 3.277  loss_dice_3: 4.892  loss_ce_4: 2.494  loss_mask_4: 4.247  loss_dice_4: 4.964  loss_ce_5: 2.441  loss_mask_5: 5.431  loss_dice_5: 4.969  loss_ce_6: 1.986  loss_mask_6: 3.439  loss_dice_6: 4.946  loss_ce_7: 1.288  loss_mask_7: 3.048  loss_dice_7: 4.908  loss_ce_8: 2.154  loss_mask_8: 5.173  loss_dice_8: 4.828  loss_mgm_entropy: 0.006865    time: 0.4244  last_time: 0.4328  data_time: 0.0225  last_data_time: 0.0026   lr: 1.9981e-07  max_mem: 15539M
[08/30 23:20:36] d2.utils.events INFO:  eta: 1:11:29  iter: 39  total_loss: 102.6  loss_ce: 1.975  loss_mask: 4.241  loss_dice: 4.958  loss_ce_0: 1.499  loss_mask_0: 3.42  loss_dice_0: 4.906  loss_ce_1: 1.143  loss_mask_1: 3.71  loss_dice_1: 4.904  loss_ce_2: 1.202  loss_mask_2: 3.464  loss_dice_2: 4.921  loss_ce_3: 1.883  loss_mask_3: 3.061  loss_dice_3: 4.874  loss_ce_4: 2.4  loss_mask_4: 3.757  loss_dice_4: 4.958  loss_ce_5: 2.286  loss_mask_5: 4.294  loss_dice_5: 4.966  loss_ce_6: 1.866  loss_mask_6: 3.215  loss_dice_6: 4.854  loss_ce_7: 1.282  loss_mask_7: 2.659  loss_dice_7: 4.89  loss_ce_8: 1.959  loss_mask_8: 3.931  loss_dice_8: 4.85  loss_mgm_entropy: 0.006854    time: 0.4300  last_time: 0.4320  data_time: 0.0029  last_data_time: 0.0039   lr: 3.9961e-07  max_mem: 15542M
[08/30 23:20:45] d2.utils.events INFO:  eta: 1:11:30  iter: 59  total_loss: 96.03  loss_ce: 1.859  loss_mask: 3.732  loss_dice: 4.956  loss_ce_0: 1.461  loss_mask_0: 3.126  loss_dice_0: 4.865  loss_ce_1: 1.133  loss_mask_1: 3.369  loss_dice_1: 4.896  loss_ce_2: 1.155  loss_mask_2: 3.143  loss_dice_2: 4.868  loss_ce_3: 1.753  loss_mask_3: 2.458  loss_dice_3: 4.846  loss_ce_4: 2.109  loss_mask_4: 3.461  loss_dice_4: 4.9  loss_ce_5: 2.112  loss_mask_5: 3.492  loss_dice_5: 4.947  loss_ce_6: 1.752  loss_mask_6: 2.469  loss_dice_6: 4.779  loss_ce_7: 1.22  loss_mask_7: 1.912  loss_dice_7: 4.907  loss_ce_8: 1.819  loss_mask_8: 3.637  loss_dice_8: 4.873  loss_mgm_entropy: 0.006827    time: 0.4308  last_time: 0.4305  data_time: 0.0035  last_data_time: 0.0035   lr: 5.9941e-07  max_mem: 15542M
[08/30 23:20:54] d2.utils.events INFO:  eta: 1:11:23  iter: 79  total_loss: 88.26  loss_ce: 1.763  loss_mask: 3.21  loss_dice: 4.824  loss_ce_0: 1.423  loss_mask_0: 2.764  loss_dice_0: 4.814  loss_ce_1: 1.139  loss_mask_1: 2.894  loss_dice_1: 4.889  loss_ce_2: 1.115  loss_mask_2: 2.433  loss_dice_2: 4.907  loss_ce_3: 1.603  loss_mask_3: 1.497  loss_dice_3: 4.855  loss_ce_4: 1.917  loss_mask_4: 2.83  loss_dice_4: 4.788  loss_ce_5: 1.943  loss_mask_5: 3.256  loss_dice_5: 4.808  loss_ce_6: 1.624  loss_mask_6: 1.501  loss_dice_6: 4.792  loss_ce_7: 1.122  loss_mask_7: 1.067  loss_dice_7: 4.901  loss_ce_8: 1.696  loss_mask_8: 2.466  loss_dice_8: 4.961  loss_mgm_entropy: 0.006785    time: 0.4312  last_time: 0.4313  data_time: 0.0033  last_data_time: 0.0034   lr: 7.9921e-07  max_mem: 15547M
[08/30 23:21:02] d2.utils.events INFO:  eta: 1:11:16  iter: 99  total_loss: 77.75  loss_ce: 1.56  loss_mask: 1.774  loss_dice: 4.791  loss_ce_0: 1.361  loss_mask_0: 2.232  loss_dice_0: 4.823  loss_ce_1: 1.147  loss_mask_1: 2.119  loss_dice_1: 4.899  loss_ce_2: 1.073  loss_mask_2: 1.527  loss_dice_2: 4.921  loss_ce_3: 1.419  loss_mask_3: 1.064  loss_dice_3: 4.884  loss_ce_4: 1.738  loss_mask_4: 2.039  loss_dice_4: 4.83  loss_ce_5: 1.695  loss_mask_5: 2.023  loss_dice_5: 4.859  loss_ce_6: 1.348  loss_mask_6: 0.7796  loss_dice_6: 4.817  loss_ce_7: 1.08  loss_mask_7: 0.6898  loss_dice_7: 4.927  loss_ce_8: 1.349  loss_mask_8: 1.074  loss_dice_8: 4.964  loss_mgm_entropy: 0.006774    time: 0.4316  last_time: 0.4314  data_time: 0.0035  last_data_time: 0.0036   lr: 9.9901e-07  max_mem: 15547M
[08/30 23:21:11] d2.utils.events INFO:  eta: 1:11:09  iter: 119  total_loss: 71.48  loss_ce: 1.368  loss_mask: 0.8932  loss_dice: 4.851  loss_ce_0: 1.18  loss_mask_0: 1.808  loss_dice_0: 4.795  loss_ce_1: 1.088  loss_mask_1: 1.518  loss_dice_1: 4.886  loss_ce_2: 1.032  loss_mask_2: 0.9594  loss_dice_2: 4.896  loss_ce_3: 1.215  loss_mask_3: 0.6758  loss_dice_3: 4.883  loss_ce_4: 1.489  loss_mask_4: 1.141  loss_dice_4: 4.831  loss_ce_5: 1.41  loss_mask_5: 1.187  loss_dice_5: 4.834  loss_ce_6: 1.257  loss_mask_6: 0.7226  loss_dice_6: 4.794  loss_ce_7: 1.07  loss_mask_7: 0.4907  loss_dice_7: 4.921  loss_ce_8: 1.275  loss_mask_8: 0.6198  loss_dice_8: 4.957  loss_mgm_entropy: 0.006759    time: 0.4334  last_time: 0.4337  data_time: 0.0034  last_data_time: 0.0033   lr: 1.1988e-06  max_mem: 15547M
[08/30 23:21:20] d2.utils.events INFO:  eta: 1:11:03  iter: 139  total_loss: 68.36  loss_ce: 1.252  loss_mask: 0.6862  loss_dice: 4.856  loss_ce_0: 1.121  loss_mask_0: 1.527  loss_dice_0: 4.798  loss_ce_1: 1.054  loss_mask_1: 1.232  loss_dice_1: 4.858  loss_ce_2: 1.01  loss_mask_2: 0.8456  loss_dice_2: 4.865  loss_ce_3: 1.125  loss_mask_3: 0.5824  loss_dice_3: 4.875  loss_ce_4: 1.343  loss_mask_4: 0.8544  loss_dice_4: 4.855  loss_ce_5: 1.282  loss_mask_5: 0.817  loss_dice_5: 4.868  loss_ce_6: 1.202  loss_mask_6: 0.6586  loss_dice_6: 4.791  loss_ce_7: 1.084  loss_mask_7: 0.4681  loss_dice_7: 4.901  loss_ce_8: 1.214  loss_mask_8: 0.4426  loss_dice_8: 4.95  loss_mgm_entropy: 0.006735    time: 0.4336  last_time: 0.4344  data_time: 0.0034  last_data_time: 0.0041   lr: 1.3986e-06  max_mem: 15547M
[08/30 23:21:29] d2.utils.events INFO:  eta: 1:10:58  iter: 159  total_loss: 66.58  loss_ce: 1.162  loss_mask: 0.5993  loss_dice: 4.844  loss_ce_0: 1.11  loss_mask_0: 1.37  loss_dice_0: 4.819  loss_ce_1: 0.9987  loss_mask_1: 0.9619  loss_dice_1: 4.866  loss_ce_2: 0.9744  loss_mask_2: 0.6725  loss_dice_2: 4.874  loss_ce_3: 1.096  loss_mask_3: 0.4697  loss_dice_3: 4.89  loss_ce_4: 1.185  loss_mask_4: 0.6836  loss_dice_4: 4.841  loss_ce_5: 1.155  loss_mask_5: 0.6274  loss_dice_5: 4.867  loss_ce_6: 1.154  loss_mask_6: 0.567  loss_dice_6: 4.826  loss_ce_7: 1.089  loss_mask_7: 0.4425  loss_dice_7: 4.884  loss_ce_8: 1.123  loss_mask_8: 0.4087  loss_dice_8: 4.904  loss_mgm_entropy: 0.00672    time: 0.4337  last_time: 0.4349  data_time: 0.0035  last_data_time: 0.0032   lr: 1.5984e-06  max_mem: 15547M
[08/30 23:21:37] d2.utils.events INFO:  eta: 1:10:53  iter: 179  total_loss: 65.56  loss_ce: 1.106  loss_mask: 0.579  loss_dice: 4.829  loss_ce_0: 1.053  loss_mask_0: 1.259  loss_dice_0: 4.812  loss_ce_1: 0.9713  loss_mask_1: 0.8695  loss_dice_1: 4.832  loss_ce_2: 0.9518  loss_mask_2: 0.6026  loss_dice_2: 4.856  loss_ce_3: 1.048  loss_mask_3: 0.4929  loss_dice_3: 4.877  loss_ce_4: 1.097  loss_mask_4: 0.6207  loss_dice_4: 4.83  loss_ce_5: 1.088  loss_mask_5: 0.5885  loss_dice_5: 4.84  loss_ce_6: 1.093  loss_mask_6: 0.5485  loss_dice_6: 4.804  loss_ce_7: 1.112  loss_mask_7: 0.5108  loss_dice_7: 4.873  loss_ce_8: 1.09  loss_mask_8: 0.4454  loss_dice_8: 4.893  loss_mgm_entropy: 0.006705    time: 0.4339  last_time: 0.4348  data_time: 0.0033  last_data_time: 0.0030   lr: 1.7982e-06  max_mem: 15547M
[08/30 23:21:46] d2.utils.events INFO:  eta: 1:10:47  iter: 199  total_loss: 65.31  loss_ce: 1.1  loss_mask: 0.6137  loss_dice: 4.826  loss_ce_0: 0.9465  loss_mask_0: 1.155  loss_dice_0: 4.736  loss_ce_1: 0.9221  loss_mask_1: 0.782  loss_dice_1: 4.794  loss_ce_2: 0.9511  loss_mask_2: 0.6062  loss_dice_2: 4.816  loss_ce_3: 1.018  loss_mask_3: 0.5612  loss_dice_3: 4.873  loss_ce_4: 1.067  loss_mask_4: 0.5917  loss_dice_4: 4.825  loss_ce_5: 1.063  loss_mask_5: 0.6244  loss_dice_5: 4.811  loss_ce_6: 1.084  loss_mask_6: 0.6043  loss_dice_6: 4.802  loss_ce_7: 1.108  loss_mask_7: 0.5834  loss_dice_7: 4.863  loss_ce_8: 1.102  loss_mask_8: 0.5655  loss_dice_8: 4.868  loss_mgm_entropy: 0.006696    time: 0.4341  last_time: 0.4359  data_time: 0.0034  last_data_time: 0.0037   lr: 1.998e-06  max_mem: 15547M
[08/30 23:21:55] d2.utils.events INFO:  eta: 1:10:40  iter: 219  total_loss: 64.79  loss_ce: 1.083  loss_mask: 0.5795  loss_dice: 4.819  loss_ce_0: 0.9342  loss_mask_0: 1.126  loss_dice_0: 4.776  loss_ce_1: 0.8999  loss_mask_1: 0.7105  loss_dice_1: 4.804  loss_ce_2: 0.9458  loss_mask_2: 0.5765  loss_dice_2: 4.822  loss_ce_3: 0.998  loss_mask_3: 0.5183  loss_dice_3: 4.867  loss_ce_4: 1.036  loss_mask_4: 0.5531  loss_dice_4: 4.806  loss_ce_5: 1.055  loss_mask_5: 0.5812  loss_dice_5: 4.814  loss_ce_6: 1.073  loss_mask_6: 0.5515  loss_dice_6: 4.792  loss_ce_7: 1.116  loss_mask_7: 0.5462  loss_dice_7: 4.846  loss_ce_8: 1.086  loss_mask_8: 0.5515  loss_dice_8: 4.851  loss_mgm_entropy: 0.00668    time: 0.4342  last_time: 0.4375  data_time: 0.0034  last_data_time: 0.0036   lr: 2.1978e-06  max_mem: 15547M
[08/30 23:22:03] d2.utils.events INFO:  eta: 1:10:34  iter: 239  total_loss: 64.66  loss_ce: 1.085  loss_mask: 0.5828  loss_dice: 4.807  loss_ce_0: 0.901  loss_mask_0: 1.11  loss_dice_0: 4.739  loss_ce_1: 0.8659  loss_mask_1: 0.6928  loss_dice_1: 4.786  loss_ce_2: 0.9416  loss_mask_2: 0.5777  loss_dice_2: 4.813  loss_ce_3: 0.9989  loss_mask_3: 0.5438  loss_dice_3: 4.858  loss_ce_4: 1.037  loss_mask_4: 0.5744  loss_dice_4: 4.814  loss_ce_5: 1.057  loss_mask_5: 0.5888  loss_dice_5: 4.807  loss_ce_6: 1.074  loss_mask_6: 0.5638  loss_dice_6: 4.79  loss_ce_7: 1.095  loss_mask_7: 0.5554  loss_dice_7: 4.832  loss_ce_8: 1.089  loss_mask_8: 0.5664  loss_dice_8: 4.84  loss_mgm_entropy: 0.006666    time: 0.4344  last_time: 0.4373  data_time: 0.0036  last_data_time: 0.0035   lr: 2.3976e-06  max_mem: 15547M
[08/30 23:22:12] d2.utils.events INFO:  eta: 1:10:29  iter: 259  total_loss: 64.55  loss_ce: 1.086  loss_mask: 0.6077  loss_dice: 4.81  loss_ce_0: 0.877  loss_mask_0: 1.024  loss_dice_0: 4.725  loss_ce_1: 0.847  loss_mask_1: 0.6951  loss_dice_1: 4.772  loss_ce_2: 0.9327  loss_mask_2: 0.5939  loss_dice_2: 4.798  loss_ce_3: 0.992  loss_mask_3: 0.5721  loss_dice_3: 4.847  loss_ce_4: 1.032  loss_mask_4: 0.6012  loss_dice_4: 4.795  loss_ce_5: 1.057  loss_mask_5: 0.6024  loss_dice_5: 4.805  loss_ce_6: 1.074  loss_mask_6: 0.5944  loss_dice_6: 4.787  loss_ce_7: 1.088  loss_mask_7: 0.5842  loss_dice_7: 4.818  loss_ce_8: 1.092  loss_mask_8: 0.6054  loss_dice_8: 4.816  loss_mgm_entropy: 0.006665    time: 0.4345  last_time: 0.4392  data_time: 0.0035  last_data_time: 0.0035   lr: 2.5974e-06  max_mem: 15547M
[08/30 23:22:21] d2.utils.events INFO:  eta: 1:10:22  iter: 279  total_loss: 63.58  loss_ce: 1.082  loss_mask: 0.4976  loss_dice: 4.803  loss_ce_0: 0.8612  loss_mask_0: 0.9262  loss_dice_0: 4.769  loss_ce_1: 0.8268  loss_mask_1: 0.6031  loss_dice_1: 4.788  loss_ce_2: 0.9238  loss_mask_2: 0.4989  loss_dice_2: 4.806  loss_ce_3: 0.987  loss_mask_3: 0.4913  loss_dice_3: 4.841  loss_ce_4: 1.028  loss_mask_4: 0.5274  loss_dice_4: 4.792  loss_ce_5: 1.049  loss_mask_5: 0.4958  loss_dice_5: 4.795  loss_ce_6: 1.076  loss_mask_6: 0.4935  loss_dice_6: 4.785  loss_ce_7: 1.088  loss_mask_7: 0.4957  loss_dice_7: 4.814  loss_ce_8: 1.09  loss_mask_8: 0.4959  loss_dice_8: 4.819  loss_mgm_entropy: 0.006658    time: 0.4347  last_time: 0.4364  data_time: 0.0034  last_data_time: 0.0031   lr: 2.7972e-06  max_mem: 15547M
[08/30 23:22:30] d2.utils.events INFO:  eta: 1:10:16  iter: 299  total_loss: 63.83  loss_ce: 1.077  loss_mask: 0.5506  loss_dice: 4.792  loss_ce_0: 0.853  loss_mask_0: 0.9148  loss_dice_0: 4.732  loss_ce_1: 0.822  loss_mask_1: 0.6149  loss_dice_1: 4.766  loss_ce_2: 0.9163  loss_mask_2: 0.5432  loss_dice_2: 4.787  loss_ce_3: 0.9816  loss_mask_3: 0.5473  loss_dice_3: 4.829  loss_ce_4: 1.025  loss_mask_4: 0.5644  loss_dice_4: 4.792  loss_ce_5: 1.052  loss_mask_5: 0.5456  loss_dice_5: 4.787  loss_ce_6: 1.065  loss_mask_6: 0.5592  loss_dice_6: 4.767  loss_ce_7: 1.087  loss_mask_7: 0.5601  loss_dice_7: 4.794  loss_ce_8: 1.08  loss_mask_8: 0.5821  loss_dice_8: 4.793  loss_mgm_entropy: 0.006632    time: 0.4348  last_time: 0.4364  data_time: 0.0034  last_data_time: 0.0031   lr: 2.997e-06  max_mem: 15547M
[08/30 23:22:38] d2.utils.events INFO:  eta: 1:10:09  iter: 319  total_loss: 63.76  loss_ce: 1.085  loss_mask: 0.5672  loss_dice: 4.79  loss_ce_0: 0.8513  loss_mask_0: 0.8992  loss_dice_0: 4.721  loss_ce_1: 0.8069  loss_mask_1: 0.6103  loss_dice_1: 4.761  loss_ce_2: 0.9084  loss_mask_2: 0.5705  loss_dice_2: 4.774  loss_ce_3: 0.9796  loss_mask_3: 0.5566  loss_dice_3: 4.809  loss_ce_4: 1.024  loss_mask_4: 0.5646  loss_dice_4: 4.784  loss_ce_5: 1.051  loss_mask_5: 0.5976  loss_dice_5: 4.776  loss_ce_6: 1.072  loss_mask_6: 0.584  loss_dice_6: 4.764  loss_ce_7: 1.083  loss_mask_7: 0.5784  loss_dice_7: 4.79  loss_ce_8: 1.086  loss_mask_8: 0.5864  loss_dice_8: 4.791  loss_mgm_entropy: 0.006606    time: 0.4349  last_time: 0.4361  data_time: 0.0035  last_data_time: 0.0031   lr: 3.1968e-06  max_mem: 15547M
[08/30 23:22:47] d2.utils.events INFO:  eta: 1:10:01  iter: 339  total_loss: 63.7  loss_ce: 1.085  loss_mask: 0.57  loss_dice: 4.798  loss_ce_0: 0.8461  loss_mask_0: 0.7971  loss_dice_0: 4.73  loss_ce_1: 0.7942  loss_mask_1: 0.598  loss_dice_1: 4.765  loss_ce_2: 0.8984  loss_mask_2: 0.5606  loss_dice_2: 4.773  loss_ce_3: 0.9774  loss_mask_3: 0.5693  loss_dice_3: 4.801  loss_ce_4: 1.02  loss_mask_4: 0.5595  loss_dice_4: 4.778  loss_ce_5: 1.043  loss_mask_5: 0.5603  loss_dice_5: 4.783  loss_ce_6: 1.066  loss_mask_6: 0.5657  loss_dice_6: 4.771  loss_ce_7: 1.076  loss_mask_7: 0.5712  loss_dice_7: 4.783  loss_ce_8: 1.089  loss_mask_8: 0.5814  loss_dice_8: 4.788  loss_mgm_entropy: 0.006589    time: 0.4350  last_time: 0.4355  data_time: 0.0035  last_data_time: 0.0034   lr: 3.3966e-06  max_mem: 15547M
[08/30 23:22:56] d2.utils.events INFO:  eta: 1:09:53  iter: 359  total_loss: 62.71  loss_ce: 1.076  loss_mask: 0.4882  loss_dice: 4.781  loss_ce_0: 0.8426  loss_mask_0: 0.7557  loss_dice_0: 4.753  loss_ce_1: 0.7832  loss_mask_1: 0.5195  loss_dice_1: 4.773  loss_ce_2: 0.8839  loss_mask_2: 0.4855  loss_dice_2: 4.777  loss_ce_3: 0.9536  loss_mask_3: 0.4756  loss_dice_3: 4.789  loss_ce_4: 1.005  loss_mask_4: 0.4912  loss_dice_4: 4.767  loss_ce_5: 1.04  loss_mask_5: 0.5002  loss_dice_5: 4.772  loss_ce_6: 1.068  loss_mask_6: 0.501  loss_dice_6: 4.773  loss_ce_7: 1.079  loss_mask_7: 0.4937  loss_dice_7: 4.786  loss_ce_8: 1.081  loss_mask_8: 0.4875  loss_dice_8: 4.787  loss_mgm_entropy: 0.00657    time: 0.4351  last_time: 0.4364  data_time: 0.0036  last_data_time: 0.0039   lr: 3.5964e-06  max_mem: 15547M
[08/30 23:23:05] d2.utils.events INFO:  eta: 1:09:47  iter: 379  total_loss: 63.66  loss_ce: 1.079  loss_mask: 0.6054  loss_dice: 4.788  loss_ce_0: 0.8372  loss_mask_0: 0.7825  loss_dice_0: 4.713  loss_ce_1: 0.7728  loss_mask_1: 0.6095  loss_dice_1: 4.755  loss_ce_2: 0.8776  loss_mask_2: 0.5969  loss_dice_2: 4.759  loss_ce_3: 0.9497  loss_mask_3: 0.5972  loss_dice_3: 4.778  loss_ce_4: 1.008  loss_mask_4: 0.5995  loss_dice_4: 4.769  loss_ce_5: 1.034  loss_mask_5: 0.5995  loss_dice_5: 4.766  loss_ce_6: 1.055  loss_mask_6: 0.5963  loss_dice_6: 4.768  loss_ce_7: 1.073  loss_mask_7: 0.6087  loss_dice_7: 4.778  loss_ce_8: 1.077  loss_mask_8: 0.6128  loss_dice_8: 4.78  loss_mgm_entropy: 0.006452    time: 0.4352  last_time: 0.4360  data_time: 0.0033  last_data_time: 0.0027   lr: 3.7962e-06  max_mem: 15547M
[08/30 23:23:13] d2.utils.events INFO:  eta: 1:09:40  iter: 399  total_loss: 63.43  loss_ce: 1.076  loss_mask: 0.5748  loss_dice: 4.774  loss_ce_0: 0.8344  loss_mask_0: 0.7364  loss_dice_0: 4.728  loss_ce_1: 0.7569  loss_mask_1: 0.57  loss_dice_1: 4.756  loss_ce_2: 0.87  loss_mask_2: 0.5731  loss_dice_2: 4.764  loss_ce_3: 0.9449  loss_mask_3: 0.5758  loss_dice_3: 4.772  loss_ce_4: 0.9957  loss_mask_4: 0.5799  loss_dice_4: 4.77  loss_ce_5: 1.029  loss_mask_5: 0.5849  loss_dice_5: 4.76  loss_ce_6: 1.057  loss_mask_6: 0.576  loss_dice_6: 4.763  loss_ce_7: 1.069  loss_mask_7: 0.5941  loss_dice_7: 4.775  loss_ce_8: 1.079  loss_mask_8: 0.5922  loss_dice_8: 4.769  loss_mgm_entropy: 0.006432    time: 0.4353  last_time: 0.4355  data_time: 0.0036  last_data_time: 0.0037   lr: 3.996e-06  max_mem: 15547M
[08/30 23:23:22] d2.utils.events INFO:  eta: 1:09:32  iter: 419  total_loss: 63.75  loss_ce: 1.079  loss_mask: 0.6285  loss_dice: 4.775  loss_ce_0: 0.8148  loss_mask_0: 0.76  loss_dice_0: 4.718  loss_ce_1: 0.746  loss_mask_1: 0.6267  loss_dice_1: 4.756  loss_ce_2: 0.8508  loss_mask_2: 0.6184  loss_dice_2: 4.754  loss_ce_3: 0.9255  loss_mask_3: 0.6185  loss_dice_3: 4.761  loss_ce_4: 0.9834  loss_mask_4: 0.6135  loss_dice_4: 4.773  loss_ce_5: 1.015  loss_mask_5: 0.6429  loss_dice_5: 4.758  loss_ce_6: 1.05  loss_mask_6: 0.64  loss_dice_6: 4.769  loss_ce_7: 1.067  loss_mask_7: 0.6441  loss_dice_7: 4.761  loss_ce_8: 1.083  loss_mask_8: 0.6513  loss_dice_8: 4.773  loss_mgm_entropy: 0.006333    time: 0.4354  last_time: 0.4369  data_time: 0.0037  last_data_time: 0.0039   lr: 4.1958e-06  max_mem: 15547M
[08/30 23:23:31] d2.utils.events INFO:  eta: 1:09:24  iter: 439  total_loss: 63.08  loss_ce: 1.085  loss_mask: 0.5849  loss_dice: 4.772  loss_ce_0: 0.8077  loss_mask_0: 0.7232  loss_dice_0: 4.722  loss_ce_1: 0.7298  loss_mask_1: 0.5785  loss_dice_1: 4.752  loss_ce_2: 0.8328  loss_mask_2: 0.5894  loss_dice_2: 4.75  loss_ce_3: 0.9086  loss_mask_3: 0.5861  loss_dice_3: 4.756  loss_ce_4: 0.9715  loss_mask_4: 0.5852  loss_dice_4: 4.762  loss_ce_5: 1.007  loss_mask_5: 0.5761  loss_dice_5: 4.757  loss_ce_6: 1.045  loss_mask_6: 0.5961  loss_dice_6: 4.757  loss_ce_7: 1.064  loss_mask_7: 0.602  loss_dice_7: 4.763  loss_ce_8: 1.079  loss_mask_8: 0.5989  loss_dice_8: 4.77  loss_mgm_entropy: 0.006219    time: 0.4355  last_time: 0.4368  data_time: 0.0035  last_data_time: 0.0038   lr: 4.3956e-06  max_mem: 15547M
[08/30 23:23:40] d2.utils.events INFO:  eta: 1:09:16  iter: 459  total_loss: 62.97  loss_ce: 1.073  loss_mask: 0.5821  loss_dice: 4.766  loss_ce_0: 0.799  loss_mask_0: 0.6933  loss_dice_0: 4.723  loss_ce_1: 0.7131  loss_mask_1: 0.5822  loss_dice_1: 4.747  loss_ce_2: 0.8057  loss_mask_2: 0.5815  loss_dice_2: 4.749  loss_ce_3: 0.8832  loss_mask_3: 0.5829  loss_dice_3: 4.764  loss_ce_4: 0.9532  loss_mask_4: 0.581  loss_dice_4: 4.76  loss_ce_5: 0.9887  loss_mask_5: 0.5854  loss_dice_5: 4.748  loss_ce_6: 1.031  loss_mask_6: 0.5877  loss_dice_6: 4.749  loss_ce_7: 1.057  loss_mask_7: 0.5883  loss_dice_7: 4.761  loss_ce_8: 1.072  loss_mask_8: 0.586  loss_dice_8: 4.77  loss_mgm_entropy: 0.006175    time: 0.4355  last_time: 0.4367  data_time: 0.0036  last_data_time: 0.0032   lr: 4.5954e-06  max_mem: 15547M
[08/30 23:23:48] d2.utils.events INFO:  eta: 1:09:09  iter: 479  total_loss: 62.86  loss_ce: 1.064  loss_mask: 0.5831  loss_dice: 4.771  loss_ce_0: 0.7765  loss_mask_0: 0.702  loss_dice_0: 4.721  loss_ce_1: 0.6934  loss_mask_1: 0.5782  loss_dice_1: 4.752  loss_ce_2: 0.7757  loss_mask_2: 0.5743  loss_dice_2: 4.752  loss_ce_3: 0.8532  loss_mask_3: 0.5913  loss_dice_3: 4.758  loss_ce_4: 0.9195  loss_mask_4: 0.597  loss_dice_4: 4.755  loss_ce_5: 0.9618  loss_mask_5: 0.6069  loss_dice_5: 4.755  loss_ce_6: 1.007  loss_mask_6: 0.5909  loss_dice_6: 4.77  loss_ce_7: 1.033  loss_mask_7: 0.6033  loss_dice_7: 4.767  loss_ce_8: 1.052  loss_mask_8: 0.5902  loss_dice_8: 4.771  loss_mgm_entropy: 0.006011    time: 0.4356  last_time: 0.4376  data_time: 0.0035  last_data_time: 0.0035   lr: 4.7952e-06  max_mem: 15547M
[08/30 23:23:54] d2.engine.hooks INFO: Overall training speed: 491 iterations in 0:03:34 (0.4359 s / it)
[08/30 23:23:54] d2.engine.hooks INFO: Total training time: 0:03:34 (0:00:00 on hooks)
[08/30 23:23:54] d2.utils.events INFO:  eta: 1:09:03  iter: 493  total_loss: 62.23  loss_ce: 1.07  loss_mask: 0.5618  loss_dice: 4.767  loss_ce_0: 0.7712  loss_mask_0: 0.6968  loss_dice_0: 4.722  loss_ce_1: 0.6802  loss_mask_1: 0.5481  loss_dice_1: 4.74  loss_ce_2: 0.759  loss_mask_2: 0.5663  loss_dice_2: 4.742  loss_ce_3: 0.8282  loss_mask_3: 0.5661  loss_dice_3: 4.752  loss_ce_4: 0.8985  loss_mask_4: 0.5462  loss_dice_4: 4.755  loss_ce_5: 0.9459  loss_mask_5: 0.5573  loss_dice_5: 4.753  loss_ce_6: 1  loss_mask_6: 0.5663  loss_dice_6: 4.759  loss_ce_7: 1.032  loss_mask_7: 0.5634  loss_dice_7: 4.763  loss_ce_8: 1.061  loss_mask_8: 0.5607  loss_dice_8: 4.77  loss_mgm_entropy: 0.00608    time: 0.4356  last_time: 0.4369  data_time: 0.0034  last_data_time: 0.0034   lr: 4.9251e-06  max_mem: 15547M
[08/30 23:24:22] detectron2 INFO: Rank of current process: 0. World size: 1
[08/30 23:24:22] detectron2 INFO: Environment info:
-------------------------------  ------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:43:55) [GCC 13.3.0]
numpy                            2.2.6
detectron2                       0.6 @/home/fuyx/hch/detectron2/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6, 8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   575.64.03
CUDA_HOME                        /home/fuyx/anaconda3/envs/m2f
Pillow                           11.3.0
torchvision                      0.20.1+cu124 @/home/fuyx/anaconda3/envs/m2f/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.12.0
-------------------------------  ------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[08/30 23:24:22] detectron2 INFO: Command line arguments: Namespace(config_file='MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[08/30 23:24:22] detectron2 INFO: Contents of args.config_file=MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml:
MODEL:
  META_ARCHITECTURE: "MGMMaskFormer"

  # RGB Backbone: Swin Transformer Tiny
  RGB_BACKBONE:
    NAME: "D2SwinTransformer"
    WEIGHTS: "checkpoint_convertor/checkpoint_swin/checkpoint_swin_slice/swin_backbone.pth"
    SWIN:
      EMBED_DIM: 96
      DEPTHS: [2, 2, 6, 2]
      NUM_HEADS: [3, 6, 12, 24]
      WINDOW_SIZE: 7
      APE: False
      DROP_PATH_RATE: 0.3
      PATCH_NORM: True
      OUT_FEATURES: ["res2", "res3", "res4", "res5"]

  # Depth Backbone: ConvNeXt Tiny
  DEPTH_BACKBONE:
    NAME: "ConvNeXtDepthBackbone"
    WEIGHTS: "checkpoint_convertor/convnext-checkpoint/convnext_tiny_depth_22k_converted.pth"
    CONVNEXT:
      DEPTHS: [3, 3, 9, 3]
      DIMS: [96, 192, 384, 768]
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1e-6

  # MGM Fusion Configuration
  MGM:
    ENABLED: True
    SHARED: True
    RESIDUAL_ALPHA: 0.05
    POST_FUSE_NORM: True # 新增：融合后GN
    LOSS_ENTROPY_W: 0.01
    TEMP_INIT: 1.5
    TEMP_FINAL: 1.0
    TEMP_STEPS: 3000 # 建议略短，收敛更快
    CLAMP_MIN: 0.05
    CLAMP_MAX: 0.95
    NOISE_MASK_WEIGHT: 0.0 # 前期建议关；有噪声掩码再开到0.05~0.1
    HIDDEN_DIM: 256
    FEATURE_DIMS: [96, 192, 384, 768]
    SCALE_KEYS: ["res2", "res3", "res4", "res5"]

    PRIOR:
      ENABLED: True # 总开关
      USE_GRADIENT: True # 先验逐项开关
      USE_VARIANCE: True
      USE_VALID_HOLE: True
      USE_RGB_EDGE: True # 前期建议关（最耗时）
      VAR_KERNEL: 5
      Z_MIN: 0.0
      Z_MAX: 1.0
      COMPUTE_ON: "res3" # "full"|"res2"|"res3"|"res4"|"res5"；前期建议用res3提速

    ROBUST_NORM:
      ENABLED: True # 前期建议关；要稳健再开
      METHOD: "minmax" # "minmax"|"quantile"

  # DPE Configuration
  DPE:
    ENABLED: True

  # Boundary Configuration
  BOUNDARY:
    ENABLED: False

  # RGB Input Pixel Mean/Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]

  # Semantic Segmentation Head
  SEM_SEG_HEAD:
    NAME: "MGMHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 1
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MGMMSDeformAttnPixelDecoder"
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6

  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "MGMMultiScaleMaskedTransformerDecoder"
    TRANSFORMER_IN_FEATURE: "multi_scale_pixel_decoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 2.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 100
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    DEC_LAYERS: 10
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.8

# 数据集配置
DATASETS:
  TRAIN: ("coco_instance_rgbd_train",)
  TEST: ("coco_instance_rgbd_val",)

# 数据加载器配置
DATALOADER:
  NUM_WORKERS: 16
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  REPEAT_THRESHOLD: 0.0

  # RGB-D Input Configuration - 快速训练模式
INPUT:
  DATASET_ROOT: "/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input"
  IMAGE_SIZE: 1024
  MIN_SCALE: 0.8
  MAX_SCALE: 1.2
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "coco_instance_lsj_rgbd"
  RANDOM_FLIP: "horizontal"
  SIZE_DIVISIBILITY: 32

  # RGB光度增强
  RGB_PHOTO_AUG:
    ENABLED: False
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    SATURATION: 0.1
    HUE: 0.0

  # 深度数据配置
  DEPTH_FORMAT: "I"
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_CLIP_MAX: 1.0
  DEPTH_NORM: "minmax"
  DEPTH_NOISE:
    ENABLED: False
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
    DROP_PROB: 0.0
    DROP_VAL: 0.0

# 求解器配置
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 1e-5
  STEPS: (2000, 3000)
  MAX_ITER: 4000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  GAMMA: 0.1
  OPTIMIZER: ADAMW
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_EMBED: 0.0
  CLIP_GRADIENTS:
    ENABLED: False
  AMP:
    ENABLED: True

# 测试配置
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False

# 输出配置
OUTPUT_DIR: "./output"

# 版本号
VERSION: 2.0

[08/30 23:24:22] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  LOAD_PROPOSALS: false
  NUM_WORKERS: 16
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_instance_rgbd_val
  TRAIN:
  - coco_instance_rgbd_train
FLOAT32_PRECISION: ''
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: false
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  DATASET_MAPPER_NAME: coco_instance_lsj_rgbd
  DATASET_ROOT: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
  DEPTH_CLIP_MAX: 1.0
  DEPTH_CLIP_MIN: 0.0
  DEPTH_FORMAT: I
  DEPTH_NOISE:
    DROP_PROB: 0.0
    DROP_VAL: 0.0
    ENABLED: false
    GAUSSIAN_STD: 0.0
    SPECKLE_STD: 0.0
  DEPTH_NORM: minmax
  DEPTH_SCALE: 0.001
  DEPTH_SHIFT: 0.0
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 1.2
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SCALE: 0.8
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  RGB_PHOTO_AUG:
    BRIGHTNESS: 0.2
    CONTRAST: 0.2
    ENABLED: false
    HUE: 0.0
    SATURATION: 0.1
  SIZE_DIVISIBILITY: 32
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BOUNDARY:
    ENABLED: false
  DEPTH_BACKBONE:
    CONVNEXT:
      DEPTHS:
      - 3
      - 3
      - 9
      - 3
      DIMS:
      - 96
      - 192
      - 384
      - 768
      DROP_PATH_RATE: 0.0
      LAYER_SCALE: 1.0e-06
    NAME: ConvNeXtDepthBackbone
    WEIGHTS: checkpoint_convertor/convnext-checkpoint/convnext_tiny_depth_22k_converted.pth
  DEVICE: cuda
  DPE:
    ENABLED: true
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MGMMultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MGMMaskFormer
  MGM:
    CLAMP_MAX: 0.95
    CLAMP_MIN: 0.05
    ENABLED: true
    FEATURE_DIMS:
    - 96
    - 192
    - 384
    - 768
    HIDDEN_DIM: 256
    LOSS_ENTROPY_W: 0.01
    NOISE_MASK_WEIGHT: 0.0
    POST_FUSE_NORM: true
    PRIOR:
      COMPUTE_ON: res3
      ENABLED: true
      USE_GRADIENT: true
      USE_RGB_EDGE: true
      USE_VALID_HOLE: true
      USE_VARIANCE: true
      VAR_KERNEL: 5
      Z_MAX: 1.0
      Z_MIN: 0.0
    RESIDUAL_ALPHA: 0.05
    ROBUST_NORM:
      ENABLED: true
      METHOD: minmax
    SCALE_KEYS:
    - res2
    - res3
    - res4
    - res5
    SHARED: true
    TEMP_FINAL: 1.0
    TEMP_INIT: 1.5
    TEMP_STEPS: 3000
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  RGB_BACKBONE:
    NAME: D2SwinTransformer
    SWIN:
      APE: false
      ATTN_DROP_RATE: 0.0
      DEPTHS:
      - 2
      - 2
      - 6
      - 2
      DROP_PATH_RATE: 0.3
      DROP_RATE: 0.0
      EMBED_DIM: 96
      MLP_RATIO: 4.0
      NUM_HEADS:
      - 3
      - 6
      - 12
      - 24
      OUT_FEATURES:
      - res2
      - res3
      - res4
      - res5
      PATCH_NORM: true
      PATCH_SIZE: 4
      PRETRAIN_IMG_SIZE: 224
      QKV_BIAS: true
      QK_SCALE: null
      USE_CHECKPOINT: false
      WINDOW_SIZE: 7
    WEIGHTS: checkpoint_convertor/checkpoint_swin/checkpoint_swin_slice/swin_backbone.pth
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MGMHead
    NORM: GN
    NUM_CLASSES: 1
    PIXEL_DECODER_NAME: MGMMSDeformAttnPixelDecoder
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: ''
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 1.0e-05
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 4000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 2000
  - 3000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2.0
VIS_PERIOD: 0

[08/30 23:24:22] detectron2 INFO: Full config saved to ./output/config.yaml
[08/30 23:24:22] d2.utils.env INFO: Using a generated random seed 25677130
[08/30 23:24:43] d2.engine.defaults INFO: Model:
MGMMaskFormer(
  (rgb_backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.055)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.109)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.136)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.164)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.191)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.218)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.245)
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.273)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath(drop_prob=0.300)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (depth_backbone): ConvNeXtDepthBackbone(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
  )
  (mgm): MultiModalGatedFusion(
    (prior_extractor): DepthPriorExtractor()
    (conf_pred): ConfidencePredictor(
      (proj_image): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_depth): ModuleList(
        (0): Sequential(
          (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (1): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
        (3): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(16, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
        )
      )
      (proj_prior): Sequential(
        (0): Conv2d(5, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
      )
      (head): Sequential(
        (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(16, 256, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): GroupNorm(8, 128, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (align_image): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (align_depth): ModuleList(
      (0): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 384, eps=1e-05, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): GroupNorm(8, 768, eps=1e-05, affine=True)
      )
    )
    (post_norm): ModuleList(
      (0): GroupNorm(8, 96, eps=1e-05, affine=True)
      (1): GroupNorm(8, 192, eps=1e-05, affine=True)
      (2): GroupNorm(8, 384, eps=1e-05, affine=True)
      (3): GroupNorm(8, 768, eps=1e-05, affine=True)
    )
  )
  (sem_seg_head): MGMHead(
    (pixel_decoder): MGMMSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (depth_pe): DepthPosEncoding(
        (mlp): Sequential(
          (0): Conv2d(1, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          (2): GELU(approximate='none')
          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MGMMultiScaleMaskedTransformerDecoder(
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x MGMCrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=2, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 1
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/30 23:24:43] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [Mapper] Noise-mask dir not found, will skip masks: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/depth/depth_noise_mask
[08/30 23:24:43] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [COCOInstanceRGBDDatasetMapper] Augs: [RandomFlip(), ResizeScale(min_scale=0.8, max_scale=1.2, target_height=1024, target_width=1024), FixedSizeCrop(crop_size=(1024, 1024))] | RGB: RGB | DATASET_ROOT=/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
[08/30 23:24:43] d2.data.datasets.coco INFO: Loaded 6 images in COCO format from /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/annotations/instances_train.json
[08/30 23:24:43] d2.data.build INFO: Removed 0 images with no usable annotations. 6 images left.
[08/30 23:24:43] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| component  | 147          |
|            |              |[0m
[08/30 23:24:43] d2.data.build INFO: Using training sampler TrainingSampler
[08/30 23:24:43] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[08/30 23:24:43] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[08/30 23:24:43] d2.data.common INFO: Serialized dataset takes 0.16 MiB
[08/30 23:24:43] d2.data.build INFO: Making batched data loader with batch_size=1
[08/30 23:24:43] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[08/30 23:24:43] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[08/30 23:24:43] d2.engine.train_loop INFO: Starting training from iteration 0
[08/30 23:24:52] d2.utils.events INFO:  eta: 0:28:36  iter: 19  total_loss: 109.5  loss_ce: 1.645  loss_mask: 3.658  loss_dice: 4.955  loss_ce_0: 1.526  loss_mask_0: 2.933  loss_dice_0: 4.853  loss_ce_1: 2.096  loss_mask_1: 3.367  loss_dice_1: 4.913  loss_ce_2: 1.505  loss_mask_2: 4.039  loss_dice_2: 4.941  loss_ce_3: 1.862  loss_mask_3: 9.139  loss_dice_3: 4.963  loss_ce_4: 1.726  loss_mask_4: 4.874  loss_dice_4: 4.955  loss_ce_5: 2.193  loss_mask_5: 3.642  loss_dice_5: 4.952  loss_ce_6: 1.72  loss_mask_6: 3.255  loss_dice_6: 4.838  loss_ce_7: 1.777  loss_mask_7: 2.822  loss_dice_7: 4.881  loss_ce_8: 1.25  loss_mask_8: 5.286  loss_dice_8: 4.958  loss_mgm_entropy: 0.00678    time: 0.4274  last_time: 0.4340  data_time: 0.0232  last_data_time: 0.0025   lr: 1.9981e-07  max_mem: 15537M
[08/30 23:25:01] d2.utils.events INFO:  eta: 0:28:31  iter: 39  total_loss: 104  loss_ce: 1.62  loss_mask: 3.443  loss_dice: 4.95  loss_ce_0: 1.466  loss_mask_0: 2.767  loss_dice_0: 4.789  loss_ce_1: 2.044  loss_mask_1: 3.096  loss_dice_1: 4.85  loss_ce_2: 1.456  loss_mask_2: 3.552  loss_dice_2: 4.927  loss_ce_3: 1.819  loss_mask_3: 7.618  loss_dice_3: 4.96  loss_ce_4: 1.73  loss_mask_4: 3.982  loss_dice_4: 4.949  loss_ce_5: 2.178  loss_mask_5: 3.302  loss_dice_5: 4.868  loss_ce_6: 1.618  loss_mask_6: 3.016  loss_dice_6: 4.753  loss_ce_7: 1.726  loss_mask_7: 2.511  loss_dice_7: 4.815  loss_ce_8: 1.249  loss_mask_8: 3.959  loss_dice_8: 4.952  loss_mgm_entropy: 0.006789    time: 0.4321  last_time: 0.4335  data_time: 0.0030  last_data_time: 0.0042   lr: 3.9961e-07  max_mem: 15540M
[08/30 23:25:10] d2.utils.events INFO:  eta: 0:28:25  iter: 59  total_loss: 92.32  loss_ce: 1.485  loss_mask: 2.921  loss_dice: 4.779  loss_ce_0: 1.387  loss_mask_0: 2.318  loss_dice_0: 4.747  loss_ce_1: 1.978  loss_mask_1: 2.626  loss_dice_1: 4.789  loss_ce_2: 1.407  loss_mask_2: 2.953  loss_dice_2: 4.836  loss_ce_3: 1.73  loss_mask_3: 4.35  loss_dice_3: 4.957  loss_ce_4: 1.591  loss_mask_4: 3.284  loss_dice_4: 4.871  loss_ce_5: 2.047  loss_mask_5: 2.276  loss_dice_5: 4.831  loss_ce_6: 1.619  loss_mask_6: 1.998  loss_dice_6: 4.761  loss_ce_7: 1.482  loss_mask_7: 1.579  loss_dice_7: 4.862  loss_ce_8: 1.186  loss_mask_8: 3.333  loss_dice_8: 4.894  loss_mgm_entropy: 0.006814    time: 0.4361  last_time: 0.4338  data_time: 0.0035  last_data_time: 0.0032   lr: 5.9941e-07  max_mem: 15543M
[08/30 23:25:19] d2.utils.events INFO:  eta: 0:28:20  iter: 79  total_loss: 82.47  loss_ce: 1.366  loss_mask: 1.484  loss_dice: 4.792  loss_ce_0: 1.22  loss_mask_0: 1.923  loss_dice_0: 4.742  loss_ce_1: 1.851  loss_mask_1: 1.869  loss_dice_1: 4.77  loss_ce_2: 1.321  loss_mask_2: 2.304  loss_dice_2: 4.801  loss_ce_3: 1.683  loss_mask_3: 3.406  loss_dice_3: 4.9  loss_ce_4: 1.48  loss_mask_4: 2.083  loss_dice_4: 4.846  loss_ce_5: 1.969  loss_mask_5: 1.158  loss_dice_5: 4.823  loss_ce_6: 1.485  loss_mask_6: 1.29  loss_dice_6: 4.83  loss_ce_7: 1.363  loss_mask_7: 1.135  loss_dice_7: 4.85  loss_ce_8: 1.164  loss_mask_8: 2.371  loss_dice_8: 4.776  loss_mgm_entropy: 0.006842    time: 0.4357  last_time: 0.4383  data_time: 0.0035  last_data_time: 0.0036   lr: 7.9921e-07  max_mem: 15545M
[08/30 23:25:27] d2.utils.events INFO:  eta: 0:28:13  iter: 99  total_loss: 75.57  loss_ce: 1.32  loss_mask: 0.9462  loss_dice: 4.861  loss_ce_0: 1.13  loss_mask_0: 1.582  loss_dice_0: 4.837  loss_ce_1: 1.556  loss_mask_1: 1.431  loss_dice_1: 4.842  loss_ce_2: 1.227  loss_mask_2: 1.676  loss_dice_2: 4.931  loss_ce_3: 1.471  loss_mask_3: 2.46  loss_dice_3: 4.859  loss_ce_4: 1.263  loss_mask_4: 1.172  loss_dice_4: 4.9  loss_ce_5: 1.678  loss_mask_5: 0.7403  loss_dice_5: 4.91  loss_ce_6: 1.358  loss_mask_6: 0.8931  loss_dice_6: 4.908  loss_ce_7: 1.287  loss_mask_7: 0.7577  loss_dice_7: 4.879  loss_ce_8: 1.139  loss_mask_8: 1.214  loss_dice_8: 4.908  loss_mgm_entropy: 0.006874    time: 0.4356  last_time: 0.4381  data_time: 0.0035  last_data_time: 0.0039   lr: 9.9901e-07  max_mem: 15545M
[08/30 23:25:36] d2.utils.events INFO:  eta: 0:28:05  iter: 119  total_loss: 69.41  loss_ce: 1.272  loss_mask: 0.7207  loss_dice: 4.807  loss_ce_0: 1.015  loss_mask_0: 1.147  loss_dice_0: 4.738  loss_ce_1: 1.41  loss_mask_1: 0.9808  loss_dice_1: 4.761  loss_ce_2: 1.138  loss_mask_2: 0.788  loss_dice_2: 4.818  loss_ce_3: 1.396  loss_mask_3: 1.217  loss_dice_3: 4.774  loss_ce_4: 1.165  loss_mask_4: 0.6761  loss_dice_4: 4.843  loss_ce_5: 1.608  loss_mask_5: 0.5832  loss_dice_5: 4.858  loss_ce_6: 1.248  loss_mask_6: 0.7005  loss_dice_6: 4.811  loss_ce_7: 1.241  loss_mask_7: 0.6921  loss_dice_7: 4.804  loss_ce_8: 1.099  loss_mask_8: 0.9178  loss_dice_8: 4.783  loss_mgm_entropy: 0.006854    time: 0.4357  last_time: 0.4361  data_time: 0.0035  last_data_time: 0.0035   lr: 1.1988e-06  max_mem: 15545M
[08/30 23:25:45] d2.utils.events INFO:  eta: 0:27:58  iter: 139  total_loss: 67.23  loss_ce: 1.162  loss_mask: 0.6395  loss_dice: 4.838  loss_ce_0: 1.002  loss_mask_0: 1.037  loss_dice_0: 4.761  loss_ce_1: 1.277  loss_mask_1: 0.8622  loss_dice_1: 4.795  loss_ce_2: 1.051  loss_mask_2: 0.7324  loss_dice_2: 4.842  loss_ce_3: 1.231  loss_mask_3: 1  loss_dice_3: 4.809  loss_ce_4: 1.075  loss_mask_4: 0.6186  loss_dice_4: 4.845  loss_ce_5: 1.333  loss_mask_5: 0.5138  loss_dice_5: 4.88  loss_ce_6: 1.165  loss_mask_6: 0.6382  loss_dice_6: 4.854  loss_ce_7: 1.168  loss_mask_7: 0.6383  loss_dice_7: 4.819  loss_ce_8: 1.091  loss_mask_8: 0.7738  loss_dice_8: 4.803  loss_mgm_entropy: 0.006823    time: 0.4358  last_time: 0.4354  data_time: 0.0035  last_data_time: 0.0039   lr: 1.3986e-06  max_mem: 15545M
[08/30 23:25:54] d2.utils.events INFO:  eta: 0:27:49  iter: 159  total_loss: 66.18  loss_ce: 1.112  loss_mask: 0.6212  loss_dice: 4.835  loss_ce_0: 0.9465  loss_mask_0: 0.9374  loss_dice_0: 4.746  loss_ce_1: 1.142  loss_mask_1: 0.7606  loss_dice_1: 4.775  loss_ce_2: 0.9865  loss_mask_2: 0.6544  loss_dice_2: 4.827  loss_ce_3: 1.133  loss_mask_3: 0.8293  loss_dice_3: 4.766  loss_ce_4: 1.072  loss_mask_4: 0.611  loss_dice_4: 4.851  loss_ce_5: 1.229  loss_mask_5: 0.5934  loss_dice_5: 4.871  loss_ce_6: 1.089  loss_mask_6: 0.6382  loss_dice_6: 4.835  loss_ce_7: 1.107  loss_mask_7: 0.6529  loss_dice_7: 4.81  loss_ce_8: 1.089  loss_mask_8: 0.6901  loss_dice_8: 4.806  loss_mgm_entropy: 0.006779    time: 0.4358  last_time: 0.4362  data_time: 0.0034  last_data_time: 0.0039   lr: 1.5984e-06  max_mem: 15545M
[08/30 23:26:02] d2.utils.events INFO:  eta: 0:27:42  iter: 179  total_loss: 65.49  loss_ce: 1.091  loss_mask: 0.5986  loss_dice: 4.831  loss_ce_0: 0.9597  loss_mask_0: 0.9254  loss_dice_0: 4.775  loss_ce_1: 1.055  loss_mask_1: 0.7354  loss_dice_1: 4.789  loss_ce_2: 0.9523  loss_mask_2: 0.6401  loss_dice_2: 4.855  loss_ce_3: 1.057  loss_mask_3: 0.7129  loss_dice_3: 4.807  loss_ce_4: 1.032  loss_mask_4: 0.5898  loss_dice_4: 4.85  loss_ce_5: 1.125  loss_mask_5: 0.5812  loss_dice_5: 4.873  loss_ce_6: 1.068  loss_mask_6: 0.6101  loss_dice_6: 4.848  loss_ce_7: 1.088  loss_mask_7: 0.6032  loss_dice_7: 4.814  loss_ce_8: 1.085  loss_mask_8: 0.6405  loss_dice_8: 4.815  loss_mgm_entropy: 0.00677    time: 0.4359  last_time: 0.4364  data_time: 0.0034  last_data_time: 0.0036   lr: 1.7982e-06  max_mem: 15545M
[08/30 23:26:11] d2.utils.events INFO:  eta: 0:27:34  iter: 199  total_loss: 65.06  loss_ce: 1.091  loss_mask: 0.5384  loss_dice: 4.831  loss_ce_0: 0.9589  loss_mask_0: 0.9  loss_dice_0: 4.788  loss_ce_1: 1.01  loss_mask_1: 0.7155  loss_dice_1: 4.808  loss_ce_2: 0.9283  loss_mask_2: 0.6099  loss_dice_2: 4.888  loss_ce_3: 1.034  loss_mask_3: 0.7302  loss_dice_3: 4.826  loss_ce_4: 1.027  loss_mask_4: 0.5321  loss_dice_4: 4.846  loss_ce_5: 1.088  loss_mask_5: 0.5136  loss_dice_5: 4.864  loss_ce_6: 1.062  loss_mask_6: 0.5208  loss_dice_6: 4.849  loss_ce_7: 1.082  loss_mask_7: 0.5447  loss_dice_7: 4.812  loss_ce_8: 1.085  loss_mask_8: 0.59  loss_dice_8: 4.816  loss_mgm_entropy: 0.006777    time: 0.4360  last_time: 0.4380  data_time: 0.0035  last_data_time: 0.0035   lr: 1.998e-06  max_mem: 15545M
[08/30 23:26:20] d2.utils.events INFO:  eta: 0:27:26  iter: 219  total_loss: 64.51  loss_ce: 1.083  loss_mask: 0.6047  loss_dice: 4.825  loss_ce_0: 0.8745  loss_mask_0: 0.8736  loss_dice_0: 4.737  loss_ce_1: 0.9339  loss_mask_1: 0.6692  loss_dice_1: 4.774  loss_ce_2: 0.9146  loss_mask_2: 0.5912  loss_dice_2: 4.826  loss_ce_3: 1.002  loss_mask_3: 0.6654  loss_dice_3: 4.773  loss_ce_4: 1.031  loss_mask_4: 0.5952  loss_dice_4: 4.835  loss_ce_5: 1.063  loss_mask_5: 0.5983  loss_dice_5: 4.85  loss_ce_6: 1.064  loss_mask_6: 0.6233  loss_dice_6: 4.827  loss_ce_7: 1.082  loss_mask_7: 0.6381  loss_dice_7: 4.793  loss_ce_8: 1.088  loss_mask_8: 0.6255  loss_dice_8: 4.82  loss_mgm_entropy: 0.006674    time: 0.4361  last_time: 0.4380  data_time: 0.0033  last_data_time: 0.0034   lr: 2.1978e-06  max_mem: 15545M
[08/30 23:26:29] d2.utils.events INFO:  eta: 0:27:18  iter: 239  total_loss: 64.22  loss_ce: 1.086  loss_mask: 0.5962  loss_dice: 4.808  loss_ce_0: 0.8619  loss_mask_0: 0.8541  loss_dice_0: 4.74  loss_ce_1: 0.8965  loss_mask_1: 0.64  loss_dice_1: 4.772  loss_ce_2: 0.9082  loss_mask_2: 0.5763  loss_dice_2: 4.83  loss_ce_3: 0.9781  loss_mask_3: 0.6183  loss_dice_3: 4.777  loss_ce_4: 1.025  loss_mask_4: 0.5849  loss_dice_4: 4.818  loss_ce_5: 1.055  loss_mask_5: 0.5739  loss_dice_5: 4.831  loss_ce_6: 1.07  loss_mask_6: 0.5782  loss_dice_6: 4.813  loss_ce_7: 1.078  loss_mask_7: 0.608  loss_dice_7: 4.783  loss_ce_8: 1.088  loss_mask_8: 0.6044  loss_dice_8: 4.8  loss_mgm_entropy: 0.006637    time: 0.4362  last_time: 0.4398  data_time: 0.0034  last_data_time: 0.0039   lr: 2.3976e-06  max_mem: 15545M
[08/30 23:26:37] d2.utils.events INFO:  eta: 0:27:10  iter: 259  total_loss: 64.08  loss_ce: 1.077  loss_mask: 0.6158  loss_dice: 4.814  loss_ce_0: 0.8263  loss_mask_0: 0.831  loss_dice_0: 4.724  loss_ce_1: 0.8517  loss_mask_1: 0.6519  loss_dice_1: 4.764  loss_ce_2: 0.8964  loss_mask_2: 0.5885  loss_dice_2: 4.821  loss_ce_3: 0.9718  loss_mask_3: 0.6282  loss_dice_3: 4.782  loss_ce_4: 1.021  loss_mask_4: 0.5849  loss_dice_4: 4.814  loss_ce_5: 1.048  loss_mask_5: 0.6103  loss_dice_5: 4.807  loss_ce_6: 1.066  loss_mask_6: 0.6158  loss_dice_6: 4.809  loss_ce_7: 1.08  loss_mask_7: 0.6322  loss_dice_7: 4.789  loss_ce_8: 1.073  loss_mask_8: 0.6143  loss_dice_8: 4.807  loss_mgm_entropy: 0.006592    time: 0.4362  last_time: 0.4358  data_time: 0.0035  last_data_time: 0.0032   lr: 2.5974e-06  max_mem: 15545M
[08/30 23:26:46] d2.utils.events INFO:  eta: 0:27:01  iter: 279  total_loss: 64.19  loss_ce: 1.082  loss_mask: 0.628  loss_dice: 4.792  loss_ce_0: 0.8223  loss_mask_0: 0.838  loss_dice_0: 4.716  loss_ce_1: 0.8369  loss_mask_1: 0.6715  loss_dice_1: 4.752  loss_ce_2: 0.8986  loss_mask_2: 0.605  loss_dice_2: 4.795  loss_ce_3: 0.966  loss_mask_3: 0.6545  loss_dice_3: 4.763  loss_ce_4: 1.023  loss_mask_4: 0.6066  loss_dice_4: 4.804  loss_ce_5: 1.051  loss_mask_5: 0.6362  loss_dice_5: 4.792  loss_ce_6: 1.066  loss_mask_6: 0.6399  loss_dice_6: 4.795  loss_ce_7: 1.076  loss_mask_7: 0.6511  loss_dice_7: 4.773  loss_ce_8: 1.076  loss_mask_8: 0.6308  loss_dice_8: 4.787  loss_mgm_entropy: 0.006569    time: 0.4363  last_time: 0.4369  data_time: 0.0032  last_data_time: 0.0030   lr: 2.7972e-06  max_mem: 15545M
[08/30 23:26:55] d2.utils.events INFO:  eta: 0:26:53  iter: 299  total_loss: 63.67  loss_ce: 1.077  loss_mask: 0.5922  loss_dice: 4.791  loss_ce_0: 0.8254  loss_mask_0: 0.7789  loss_dice_0: 4.739  loss_ce_1: 0.8241  loss_mask_1: 0.6028  loss_dice_1: 4.766  loss_ce_2: 0.8905  loss_mask_2: 0.5702  loss_dice_2: 4.796  loss_ce_3: 0.9527  loss_mask_3: 0.5972  loss_dice_3: 4.766  loss_ce_4: 1.014  loss_mask_4: 0.5803  loss_dice_4: 4.793  loss_ce_5: 1.048  loss_mask_5: 0.5864  loss_dice_5: 4.777  loss_ce_6: 1.058  loss_mask_6: 0.5798  loss_dice_6: 4.799  loss_ce_7: 1.078  loss_mask_7: 0.5952  loss_dice_7: 4.784  loss_ce_8: 1.081  loss_mask_8: 0.58  loss_dice_8: 4.793  loss_mgm_entropy: 0.006549    time: 0.4363  last_time: 0.4376  data_time: 0.0035  last_data_time: 0.0039   lr: 2.997e-06  max_mem: 15545M
[08/30 23:27:04] d2.utils.events INFO:  eta: 0:26:45  iter: 319  total_loss: 63.29  loss_ce: 1.085  loss_mask: 0.5487  loss_dice: 4.789  loss_ce_0: 0.8144  loss_mask_0: 0.7789  loss_dice_0: 4.75  loss_ce_1: 0.8099  loss_mask_1: 0.5628  loss_dice_1: 4.772  loss_ce_2: 0.8877  loss_mask_2: 0.5242  loss_dice_2: 4.809  loss_ce_3: 0.9537  loss_mask_3: 0.548  loss_dice_3: 4.771  loss_ce_4: 1.015  loss_mask_4: 0.5361  loss_dice_4: 4.802  loss_ce_5: 1.047  loss_mask_5: 0.5467  loss_dice_5: 4.785  loss_ce_6: 1.066  loss_mask_6: 0.546  loss_dice_6: 4.786  loss_ce_7: 1.08  loss_mask_7: 0.5588  loss_dice_7: 4.78  loss_ce_8: 1.086  loss_mask_8: 0.5487  loss_dice_8: 4.787  loss_mgm_entropy: 0.006545    time: 0.4364  last_time: 0.4362  data_time: 0.0033  last_data_time: 0.0029   lr: 3.1968e-06  max_mem: 15545M
[08/30 23:27:12] d2.utils.events INFO:  eta: 0:26:36  iter: 339  total_loss: 62.95  loss_ce: 1.077  loss_mask: 0.5208  loss_dice: 4.78  loss_ce_0: 0.8183  loss_mask_0: 0.731  loss_dice_0: 4.763  loss_ce_1: 0.8002  loss_mask_1: 0.531  loss_dice_1: 4.771  loss_ce_2: 0.8797  loss_mask_2: 0.4948  loss_dice_2: 4.785  loss_ce_3: 0.9421  loss_mask_3: 0.5304  loss_dice_3: 4.768  loss_ce_4: 1.006  loss_mask_4: 0.5145  loss_dice_4: 4.779  loss_ce_5: 1.041  loss_mask_5: 0.5203  loss_dice_5: 4.774  loss_ce_6: 1.059  loss_mask_6: 0.5231  loss_dice_6: 4.773  loss_ce_7: 1.068  loss_mask_7: 0.5245  loss_dice_7: 4.778  loss_ce_8: 1.073  loss_mask_8: 0.5194  loss_dice_8: 4.779  loss_mgm_entropy: 0.006564    time: 0.4364  last_time: 0.4364  data_time: 0.0034  last_data_time: 0.0035   lr: 3.3966e-06  max_mem: 15545M
[08/30 23:27:21] d2.utils.events INFO:  eta: 0:26:28  iter: 359  total_loss: 63.05  loss_ce: 1.078  loss_mask: 0.5613  loss_dice: 4.787  loss_ce_0: 0.8048  loss_mask_0: 0.7207  loss_dice_0: 4.742  loss_ce_1: 0.7871  loss_mask_1: 0.5484  loss_dice_1: 4.76  loss_ce_2: 0.8705  loss_mask_2: 0.5249  loss_dice_2: 4.776  loss_ce_3: 0.938  loss_mask_3: 0.5469  loss_dice_3: 4.767  loss_ce_4: 0.9941  loss_mask_4: 0.5617  loss_dice_4: 4.779  loss_ce_5: 1.034  loss_mask_5: 0.5477  loss_dice_5: 4.771  loss_ce_6: 1.054  loss_mask_6: 0.5403  loss_dice_6: 4.787  loss_ce_7: 1.07  loss_mask_7: 0.5342  loss_dice_7: 4.775  loss_ce_8: 1.069  loss_mask_8: 0.551  loss_dice_8: 4.784  loss_mgm_entropy: 0.00651    time: 0.4364  last_time: 0.4372  data_time: 0.0034  last_data_time: 0.0037   lr: 3.5964e-06  max_mem: 15545M
[08/30 23:27:30] d2.utils.events INFO:  eta: 0:26:19  iter: 379  total_loss: 63.08  loss_ce: 1.074  loss_mask: 0.5676  loss_dice: 4.781  loss_ce_0: 0.7845  loss_mask_0: 0.7049  loss_dice_0: 4.733  loss_ce_1: 0.7821  loss_mask_1: 0.5708  loss_dice_1: 4.755  loss_ce_2: 0.8604  loss_mask_2: 0.5476  loss_dice_2: 4.777  loss_ce_3: 0.9264  loss_mask_3: 0.5597  loss_dice_3: 4.76  loss_ce_4: 0.9921  loss_mask_4: 0.554  loss_dice_4: 4.779  loss_ce_5: 1.028  loss_mask_5: 0.5665  loss_dice_5: 4.773  loss_ce_6: 1.05  loss_mask_6: 0.5604  loss_dice_6: 4.774  loss_ce_7: 1.066  loss_mask_7: 0.5621  loss_dice_7: 4.764  loss_ce_8: 1.071  loss_mask_8: 0.5626  loss_dice_8: 4.776  loss_mgm_entropy: 0.006443    time: 0.4365  last_time: 0.4368  data_time: 0.0034  last_data_time: 0.0034   lr: 3.7962e-06  max_mem: 15545M
[08/30 23:27:39] d2.utils.events INFO:  eta: 0:26:11  iter: 399  total_loss: 63.32  loss_ce: 1.078  loss_mask: 0.6041  loss_dice: 4.768  loss_ce_0: 0.7845  loss_mask_0: 0.7513  loss_dice_0: 4.712  loss_ce_1: 0.7708  loss_mask_1: 0.6072  loss_dice_1: 4.748  loss_ce_2: 0.8473  loss_mask_2: 0.6026  loss_dice_2: 4.759  loss_ce_3: 0.9166  loss_mask_3: 0.611  loss_dice_3: 4.751  loss_ce_4: 0.9807  loss_mask_4: 0.6017  loss_dice_4: 4.772  loss_ce_5: 1.023  loss_mask_5: 0.615  loss_dice_5: 4.749  loss_ce_6: 1.052  loss_mask_6: 0.6209  loss_dice_6: 4.765  loss_ce_7: 1.064  loss_mask_7: 0.6125  loss_dice_7: 4.764  loss_ce_8: 1.067  loss_mask_8: 0.6113  loss_dice_8: 4.77  loss_mgm_entropy: 0.006344    time: 0.4365  last_time: 0.4365  data_time: 0.0034  last_data_time: 0.0036   lr: 3.996e-06  max_mem: 15545M
[08/30 23:27:47] d2.utils.events INFO:  eta: 0:26:02  iter: 419  total_loss: 62.98  loss_ce: 1.071  loss_mask: 0.5969  loss_dice: 4.771  loss_ce_0: 0.7826  loss_mask_0: 0.6869  loss_dice_0: 4.732  loss_ce_1: 0.7595  loss_mask_1: 0.571  loss_dice_1: 4.754  loss_ce_2: 0.8289  loss_mask_2: 0.5626  loss_dice_2: 4.759  loss_ce_3: 0.8915  loss_mask_3: 0.5767  loss_dice_3: 4.757  loss_ce_4: 0.9615  loss_mask_4: 0.5829  loss_dice_4: 4.772  loss_ce_5: 1.004  loss_mask_5: 0.5898  loss_dice_5: 4.764  loss_ce_6: 1.038  loss_mask_6: 0.5779  loss_dice_6: 4.772  loss_ce_7: 1.057  loss_mask_7: 0.5842  loss_dice_7: 4.768  loss_ce_8: 1.064  loss_mask_8: 0.5845  loss_dice_8: 4.77  loss_mgm_entropy: 0.006336    time: 0.4365  last_time: 0.4362  data_time: 0.0034  last_data_time: 0.0036   lr: 4.1958e-06  max_mem: 15545M
[08/30 23:27:56] d2.utils.events INFO:  eta: 0:25:53  iter: 439  total_loss: 63.02  loss_ce: 1.078  loss_mask: 0.5972  loss_dice: 4.773  loss_ce_0: 0.7776  loss_mask_0: 0.6965  loss_dice_0: 4.723  loss_ce_1: 0.752  loss_mask_1: 0.5889  loss_dice_1: 4.752  loss_ce_2: 0.8147  loss_mask_2: 0.5932  loss_dice_2: 4.755  loss_ce_3: 0.8789  loss_mask_3: 0.5955  loss_dice_3: 4.749  loss_ce_4: 0.9501  loss_mask_4: 0.6098  loss_dice_4: 4.765  loss_ce_5: 0.9974  loss_mask_5: 0.6055  loss_dice_5: 4.756  loss_ce_6: 1.04  loss_mask_6: 0.5959  loss_dice_6: 4.767  loss_ce_7: 1.06  loss_mask_7: 0.6042  loss_dice_7: 4.765  loss_ce_8: 1.07  loss_mask_8: 0.5955  loss_dice_8: 4.768  loss_mgm_entropy: 0.006308    time: 0.4366  last_time: 0.4365  data_time: 0.0035  last_data_time: 0.0036   lr: 4.3956e-06  max_mem: 15545M
[08/30 23:28:05] d2.utils.events INFO:  eta: 0:25:45  iter: 459  total_loss: 63.57  loss_ce: 1.076  loss_mask: 0.6541  loss_dice: 4.761  loss_ce_0: 0.7626  loss_mask_0: 0.7277  loss_dice_0: 4.715  loss_ce_1: 0.7393  loss_mask_1: 0.6465  loss_dice_1: 4.743  loss_ce_2: 0.7987  loss_mask_2: 0.6474  loss_dice_2: 4.749  loss_ce_3: 0.8621  loss_mask_3: 0.65  loss_dice_3: 4.747  loss_ce_4: 0.9271  loss_mask_4: 0.6483  loss_dice_4: 4.768  loss_ce_5: 0.9822  loss_mask_5: 0.6545  loss_dice_5: 4.755  loss_ce_6: 1.03  loss_mask_6: 0.6595  loss_dice_6: 4.76  loss_ce_7: 1.056  loss_mask_7: 0.6668  loss_dice_7: 4.757  loss_ce_8: 1.067  loss_mask_8: 0.6596  loss_dice_8: 4.761  loss_mgm_entropy: 0.006293    time: 0.4366  last_time: 0.4369  data_time: 0.0034  last_data_time: 0.0037   lr: 4.5954e-06  max_mem: 15545M
[08/30 23:28:14] d2.utils.events INFO:  eta: 0:25:36  iter: 479  total_loss: 62.23  loss_ce: 1.061  loss_mask: 0.5529  loss_dice: 4.772  loss_ce_0: 0.7634  loss_mask_0: 0.6293  loss_dice_0: 4.735  loss_ce_1: 0.7229  loss_mask_1: 0.5392  loss_dice_1: 4.745  loss_ce_2: 0.7683  loss_mask_2: 0.5398  loss_dice_2: 4.744  loss_ce_3: 0.823  loss_mask_3: 0.5504  loss_dice_3: 4.742  loss_ce_4: 0.8963  loss_mask_4: 0.5507  loss_dice_4: 4.758  loss_ce_5: 0.9517  loss_mask_5: 0.5647  loss_dice_5: 4.753  loss_ce_6: 1.007  loss_mask_6: 0.5611  loss_dice_6: 4.761  loss_ce_7: 1.035  loss_mask_7: 0.5516  loss_dice_7: 4.758  loss_ce_8: 1.051  loss_mask_8: 0.5552  loss_dice_8: 4.766  loss_mgm_entropy: 0.006333    time: 0.4367  last_time: 0.4382  data_time: 0.0035  last_data_time: 0.0037   lr: 4.7952e-06  max_mem: 15545M
[08/30 23:28:22] d2.utils.events INFO:  eta: 0:25:28  iter: 499  total_loss: 62.06  loss_ce: 1.056  loss_mask: 0.5729  loss_dice: 4.765  loss_ce_0: 0.7602  loss_mask_0: 0.6368  loss_dice_0: 4.737  loss_ce_1: 0.7134  loss_mask_1: 0.5531  loss_dice_1: 4.745  loss_ce_2: 0.744  loss_mask_2: 0.5455  loss_dice_2: 4.744  loss_ce_3: 0.7938  loss_mask_3: 0.5648  loss_dice_3: 4.74  loss_ce_4: 0.8674  loss_mask_4: 0.5454  loss_dice_4: 4.755  loss_ce_5: 0.9327  loss_mask_5: 0.5685  loss_dice_5: 4.758  loss_ce_6: 0.9946  loss_mask_6: 0.5639  loss_dice_6: 4.758  loss_ce_7: 1.031  loss_mask_7: 0.575  loss_dice_7: 4.764  loss_ce_8: 1.044  loss_mask_8: 0.5571  loss_dice_8: 4.763  loss_mgm_entropy: 0.006299    time: 0.4367  last_time: 0.4372  data_time: 0.0033  last_data_time: 0.0037   lr: 4.995e-06  max_mem: 15545M
[08/30 23:28:31] d2.utils.events INFO:  eta: 0:25:19  iter: 519  total_loss: 62.14  loss_ce: 1.057  loss_mask: 0.5968  loss_dice: 4.762  loss_ce_0: 0.7581  loss_mask_0: 0.6474  loss_dice_0: 4.726  loss_ce_1: 0.6951  loss_mask_1: 0.5675  loss_dice_1: 4.746  loss_ce_2: 0.7134  loss_mask_2: 0.586  loss_dice_2: 4.741  loss_ce_3: 0.7437  loss_mask_3: 0.5929  loss_dice_3: 4.742  loss_ce_4: 0.8196  loss_mask_4: 0.5834  loss_dice_4: 4.756  loss_ce_5: 0.89  loss_mask_5: 0.595  loss_dice_5: 4.758  loss_ce_6: 0.9633  loss_mask_6: 0.5942  loss_dice_6: 4.756  loss_ce_7: 1.011  loss_mask_7: 0.6074  loss_dice_7: 4.764  loss_ce_8: 1.036  loss_mask_8: 0.6011  loss_dice_8: 4.77  loss_mgm_entropy: 0.006221    time: 0.4367  last_time: 0.4371  data_time: 0.0034  last_data_time: 0.0034   lr: 5.1948e-06  max_mem: 15545M
[08/30 23:28:40] d2.utils.events INFO:  eta: 0:25:10  iter: 539  total_loss: 61.24  loss_ce: 1.039  loss_mask: 0.5534  loss_dice: 4.761  loss_ce_0: 0.7569  loss_mask_0: 0.593  loss_dice_0: 4.736  loss_ce_1: 0.6746  loss_mask_1: 0.5303  loss_dice_1: 4.742  loss_ce_2: 0.6662  loss_mask_2: 0.5338  loss_dice_2: 4.736  loss_ce_3: 0.6806  loss_mask_3: 0.5381  loss_dice_3: 4.735  loss_ce_4: 0.7428  loss_mask_4: 0.539  loss_dice_4: 4.75  loss_ce_5: 0.8127  loss_mask_5: 0.5456  loss_dice_5: 4.751  loss_ce_6: 0.907  loss_mask_6: 0.5457  loss_dice_6: 4.753  loss_ce_7: 0.9716  loss_mask_7: 0.5464  loss_dice_7: 4.757  loss_ce_8: 1.01  loss_mask_8: 0.5442  loss_dice_8: 4.761  loss_mgm_entropy: 0.006175    time: 0.4367  last_time: 0.4371  data_time: 0.0035  last_data_time: 0.0034   lr: 5.3946e-06  max_mem: 15545M
[08/30 23:28:49] d2.utils.events INFO:  eta: 0:25:02  iter: 559  total_loss: 60.99  loss_ce: 1.013  loss_mask: 0.5924  loss_dice: 4.757  loss_ce_0: 0.7544  loss_mask_0: 0.6174  loss_dice_0: 4.729  loss_ce_1: 0.6506  loss_mask_1: 0.5587  loss_dice_1: 4.739  loss_ce_2: 0.6141  loss_mask_2: 0.5713  loss_dice_2: 4.727  loss_ce_3: 0.6023  loss_mask_3: 0.5795  loss_dice_3: 4.731  loss_ce_4: 0.6333  loss_mask_4: 0.5695  loss_dice_4: 4.743  loss_ce_5: 0.6979  loss_mask_5: 0.587  loss_dice_5: 4.744  loss_ce_6: 0.8212  loss_mask_6: 0.5871  loss_dice_6: 4.75  loss_ce_7: 0.9125  loss_mask_7: 0.5887  loss_dice_7: 4.755  loss_ce_8: 0.9673  loss_mask_8: 0.574  loss_dice_8: 4.765  loss_mgm_entropy: 0.006116    time: 0.4368  last_time: 0.4365  data_time: 0.0034  last_data_time: 0.0030   lr: 5.5944e-06  max_mem: 15545M
[08/30 23:28:57] d2.utils.events INFO:  eta: 0:24:53  iter: 579  total_loss: 60.39  loss_ce: 0.9633  loss_mask: 0.6187  loss_dice: 4.766  loss_ce_0: 0.7499  loss_mask_0: 0.6285  loss_dice_0: 4.736  loss_ce_1: 0.6274  loss_mask_1: 0.5853  loss_dice_1: 4.743  loss_ce_2: 0.5618  loss_mask_2: 0.6003  loss_dice_2: 4.743  loss_ce_3: 0.5142  loss_mask_3: 0.6139  loss_dice_3: 4.733  loss_ce_4: 0.5093  loss_mask_4: 0.5967  loss_dice_4: 4.752  loss_ce_5: 0.5527  loss_mask_5: 0.5975  loss_dice_5: 4.758  loss_ce_6: 0.672  loss_mask_6: 0.6106  loss_dice_6: 4.759  loss_ce_7: 0.8042  loss_mask_7: 0.6047  loss_dice_7: 4.759  loss_ce_8: 0.8881  loss_mask_8: 0.6028  loss_dice_8: 4.771  loss_mgm_entropy: 0.006013    time: 0.4368  last_time: 0.4371  data_time: 0.0034  last_data_time: 0.0033   lr: 5.7942e-06  max_mem: 15545M
[08/30 23:29:06] d2.utils.events INFO:  eta: 0:24:44  iter: 599  total_loss: 58.31  loss_ce: 0.8207  loss_mask: 0.5637  loss_dice: 4.756  loss_ce_0: 0.7502  loss_mask_0: 0.5838  loss_dice_0: 4.734  loss_ce_1: 0.5959  loss_mask_1: 0.5359  loss_dice_1: 4.739  loss_ce_2: 0.4922  loss_mask_2: 0.5509  loss_dice_2: 4.73  loss_ce_3: 0.3984  loss_mask_3: 0.5532  loss_dice_3: 4.731  loss_ce_4: 0.357  loss_mask_4: 0.5504  loss_dice_4: 4.74  loss_ce_5: 0.3355  loss_mask_5: 0.5633  loss_dice_5: 4.736  loss_ce_6: 0.436  loss_mask_6: 0.555  loss_dice_6: 4.755  loss_ce_7: 0.5624  loss_mask_7: 0.5719  loss_dice_7: 4.752  loss_ce_8: 0.6807  loss_mask_8: 0.5646  loss_dice_8: 4.758  loss_mgm_entropy: 0.005934    time: 0.4368  last_time: 0.4387  data_time: 0.0034  last_data_time: 0.0033   lr: 5.994e-06  max_mem: 15545M
[08/30 23:29:15] d2.utils.events INFO:  eta: 0:24:36  iter: 619  total_loss: 57.25  loss_ce: 0.5473  loss_mask: 0.6106  loss_dice: 4.761  loss_ce_0: 0.746  loss_mask_0: 0.63  loss_dice_0: 4.733  loss_ce_1: 0.5724  loss_mask_1: 0.5905  loss_dice_1: 4.74  loss_ce_2: 0.4336  loss_mask_2: 0.6022  loss_dice_2: 4.737  loss_ce_3: 0.3144  loss_mask_3: 0.5987  loss_dice_3: 4.731  loss_ce_4: 0.2272  loss_mask_4: 0.5849  loss_dice_4: 4.737  loss_ce_5: 0.1574  loss_mask_5: 0.5913  loss_dice_5: 4.741  loss_ce_6: 0.196  loss_mask_6: 0.5961  loss_dice_6: 4.741  loss_ce_7: 0.2659  loss_mask_7: 0.6027  loss_dice_7: 4.745  loss_ce_8: 0.3784  loss_mask_8: 0.6067  loss_dice_8: 4.75  loss_mgm_entropy: 0.00575    time: 0.4369  last_time: 0.4421  data_time: 0.0035  last_data_time: 0.0038   lr: 6.1938e-06  max_mem: 15545M
[08/30 23:29:24] d2.utils.events INFO:  eta: 0:24:27  iter: 639  total_loss: 56.17  loss_ce: 0.2373  loss_mask: 0.6177  loss_dice: 4.748  loss_ce_0: 0.744  loss_mask_0: 0.6469  loss_dice_0: 4.711  loss_ce_1: 0.5486  loss_mask_1: 0.6063  loss_dice_1: 4.73  loss_ce_2: 0.3864  loss_mask_2: 0.6184  loss_dice_2: 4.723  loss_ce_3: 0.2345  loss_mask_3: 0.6285  loss_dice_3: 4.721  loss_ce_4: 0.1427  loss_mask_4: 0.6181  loss_dice_4: 4.723  loss_ce_5: 0.07151  loss_mask_5: 0.6306  loss_dice_5: 4.718  loss_ce_6: 0.07595  loss_mask_6: 0.6157  loss_dice_6: 4.739  loss_ce_7: 0.09078  loss_mask_7: 0.6146  loss_dice_7: 4.736  loss_ce_8: 0.1331  loss_mask_8: 0.6136  loss_dice_8: 4.751  loss_mgm_entropy: 0.005679    time: 0.4369  last_time: 0.4369  data_time: 0.0034  last_data_time: 0.0035   lr: 6.3936e-06  max_mem: 15545M
[08/30 23:29:32] d2.utils.events INFO:  eta: 0:24:18  iter: 659  total_loss: 54.6  loss_ce: 0.09589  loss_mask: 0.5033  loss_dice: 4.75  loss_ce_0: 0.7419  loss_mask_0: 0.5384  loss_dice_0: 4.723  loss_ce_1: 0.525  loss_mask_1: 0.502  loss_dice_1: 4.726  loss_ce_2: 0.3453  loss_mask_2: 0.5064  loss_dice_2: 4.726  loss_ce_3: 0.1873  loss_mask_3: 0.5041  loss_dice_3: 4.724  loss_ce_4: 0.09766  loss_mask_4: 0.5053  loss_dice_4: 4.725  loss_ce_5: 0.04281  loss_mask_5: 0.5181  loss_dice_5: 4.716  loss_ce_6: 0.03798  loss_mask_6: 0.4986  loss_dice_6: 4.73  loss_ce_7: 0.03793  loss_mask_7: 0.5093  loss_dice_7: 4.74  loss_ce_8: 0.0487  loss_mask_8: 0.5229  loss_dice_8: 4.74  loss_mgm_entropy: 0.005687    time: 0.4369  last_time: 0.4376  data_time: 0.0034  last_data_time: 0.0039   lr: 6.5934e-06  max_mem: 15545M
[08/30 23:29:41] d2.utils.events INFO:  eta: 0:24:10  iter: 679  total_loss: 54.97  loss_ce: 0.04906  loss_mask: 0.569  loss_dice: 4.727  loss_ce_0: 0.7398  loss_mask_0: 0.5821  loss_dice_0: 4.709  loss_ce_1: 0.5048  loss_mask_1: 0.5449  loss_dice_1: 4.718  loss_ce_2: 0.3157  loss_mask_2: 0.5559  loss_dice_2: 4.708  loss_ce_3: 0.1572  loss_mask_3: 0.5491  loss_dice_3: 4.705  loss_ce_4: 0.07358  loss_mask_4: 0.5431  loss_dice_4: 4.706  loss_ce_5: 0.03213  loss_mask_5: 0.5488  loss_dice_5: 4.713  loss_ce_6: 0.02894  loss_mask_6: 0.5478  loss_dice_6: 4.717  loss_ce_7: 0.02905  loss_mask_7: 0.5632  loss_dice_7: 4.71  loss_ce_8: 0.03187  loss_mask_8: 0.5544  loss_dice_8: 4.735  loss_mgm_entropy: 0.005613    time: 0.4369  last_time: 0.4362  data_time: 0.0035  last_data_time: 0.0033   lr: 6.7932e-06  max_mem: 15545M
[08/30 23:29:50] d2.utils.events INFO:  eta: 0:24:01  iter: 699  total_loss: 53.73  loss_ce: 0.04218  loss_mask: 0.507  loss_dice: 4.714  loss_ce_0: 0.7381  loss_mask_0: 0.5299  loss_dice_0: 4.697  loss_ce_1: 0.4889  loss_mask_1: 0.5032  loss_dice_1: 4.699  loss_ce_2: 0.2849  loss_mask_2: 0.499  loss_dice_2: 4.692  loss_ce_3: 0.1303  loss_mask_3: 0.4898  loss_dice_3: 4.679  loss_ce_4: 0.06059  loss_mask_4: 0.4969  loss_dice_4: 4.685  loss_ce_5: 0.03062  loss_mask_5: 0.4936  loss_dice_5: 4.67  loss_ce_6: 0.02702  loss_mask_6: 0.5073  loss_dice_6: 4.688  loss_ce_7: 0.02728  loss_mask_7: 0.4991  loss_dice_7: 4.699  loss_ce_8: 0.02967  loss_mask_8: 0.5025  loss_dice_8: 4.713  loss_mgm_entropy: 0.005605    time: 0.4369  last_time: 0.4361  data_time: 0.0035  last_data_time: 0.0039   lr: 6.993e-06  max_mem: 15545M
[08/30 23:29:59] d2.utils.events INFO:  eta: 0:23:52  iter: 719  total_loss: 54.11  loss_ce: 0.03435  loss_mask: 0.5574  loss_dice: 4.691  loss_ce_0: 0.7364  loss_mask_0: 0.5732  loss_dice_0: 4.674  loss_ce_1: 0.4706  loss_mask_1: 0.5424  loss_dice_1: 4.684  loss_ce_2: 0.2645  loss_mask_2: 0.5412  loss_dice_2: 4.67  loss_ce_3: 0.1128  loss_mask_3: 0.5493  loss_dice_3: 4.642  loss_ce_4: 0.05283  loss_mask_4: 0.5452  loss_dice_4: 4.638  loss_ce_5: 0.02774  loss_mask_5: 0.5481  loss_dice_5: 4.624  loss_ce_6: 0.02372  loss_mask_6: 0.5433  loss_dice_6: 4.634  loss_ce_7: 0.02392  loss_mask_7: 0.5408  loss_dice_7: 4.647  loss_ce_8: 0.02587  loss_mask_8: 0.555  loss_dice_8: 4.663  loss_mgm_entropy: 0.005518    time: 0.4369  last_time: 0.4365  data_time: 0.0034  last_data_time: 0.0037   lr: 7.1928e-06  max_mem: 15545M
[08/30 23:30:07] d2.utils.events INFO:  eta: 0:23:44  iter: 739  total_loss: 53.44  loss_ce: 0.0488  loss_mask: 0.5726  loss_dice: 4.616  loss_ce_0: 0.7375  loss_mask_0: 0.5945  loss_dice_0: 4.645  loss_ce_1: 0.4538  loss_mask_1: 0.5569  loss_dice_1: 4.644  loss_ce_2: 0.2417  loss_mask_2: 0.5588  loss_dice_2: 4.615  loss_ce_3: 0.1054  loss_mask_3: 0.5594  loss_dice_3: 4.583  loss_ce_4: 0.05346  loss_mask_4: 0.5757  loss_dice_4: 4.562  loss_ce_5: 0.04172  loss_mask_5: 0.5822  loss_dice_5: 4.526  loss_ce_6: 0.03059  loss_mask_6: 0.5765  loss_dice_6: 4.556  loss_ce_7: 0.03362  loss_mask_7: 0.5773  loss_dice_7: 4.559  loss_ce_8: 0.03394  loss_mask_8: 0.5867  loss_dice_8: 4.579  loss_mgm_entropy: 0.005449    time: 0.4369  last_time: 0.4369  data_time: 0.0035  last_data_time: 0.0035   lr: 7.3926e-06  max_mem: 15545M
[08/30 23:30:16] d2.utils.events INFO:  eta: 0:23:35  iter: 759  total_loss: 52.5  loss_ce: 0.04888  loss_mask: 0.5863  loss_dice: 4.52  loss_ce_0: 0.7353  loss_mask_0: 0.6071  loss_dice_0: 4.593  loss_ce_1: 0.4351  loss_mask_1: 0.5595  loss_dice_1: 4.589  loss_ce_2: 0.2199  loss_mask_2: 0.5666  loss_dice_2: 4.536  loss_ce_3: 0.09854  loss_mask_3: 0.5624  loss_dice_3: 4.501  loss_ce_4: 0.06024  loss_mask_4: 0.5691  loss_dice_4: 4.485  loss_ce_5: 0.05172  loss_mask_5: 0.5854  loss_dice_5: 4.436  loss_ce_6: 0.04826  loss_mask_6: 0.5909  loss_dice_6: 4.47  loss_ce_7: 0.05013  loss_mask_7: 0.5823  loss_dice_7: 4.452  loss_ce_8: 0.04755  loss_mask_8: 0.5721  loss_dice_8: 4.463  loss_mgm_entropy: 0.005298    time: 0.4369  last_time: 0.4362  data_time: 0.0036  last_data_time: 0.0032   lr: 7.5924e-06  max_mem: 15545M
[08/30 23:30:25] d2.utils.events INFO:  eta: 0:23:26  iter: 779  total_loss: 50.95  loss_ce: 0.03375  loss_mask: 0.5292  loss_dice: 4.358  loss_ce_0: 0.7404  loss_mask_0: 0.5746  loss_dice_0: 4.564  loss_ce_1: 0.4185  loss_mask_1: 0.5409  loss_dice_1: 4.528  loss_ce_2: 0.1968  loss_mask_2: 0.5435  loss_dice_2: 4.448  loss_ce_3: 0.08417  loss_mask_3: 0.538  loss_dice_3: 4.399  loss_ce_4: 0.04867  loss_mask_4: 0.5327  loss_dice_4: 4.368  loss_ce_5: 0.03535  loss_mask_5: 0.5427  loss_dice_5: 4.306  loss_ce_6: 0.03513  loss_mask_6: 0.5419  loss_dice_6: 4.302  loss_ce_7: 0.03079  loss_mask_7: 0.5376  loss_dice_7: 4.304  loss_ce_8: 0.0295  loss_mask_8: 0.5515  loss_dice_8: 4.3  loss_mgm_entropy: 0.005227    time: 0.4369  last_time: 0.4372  data_time: 0.0035  last_data_time: 0.0032   lr: 7.7922e-06  max_mem: 15545M
[08/30 23:30:34] d2.utils.events INFO:  eta: 0:23:17  iter: 799  total_loss: 49.46  loss_ce: 0.04331  loss_mask: 0.4829  loss_dice: 4.22  loss_ce_0: 0.7351  loss_mask_0: 0.5265  loss_dice_0: 4.541  loss_ce_1: 0.4032  loss_mask_1: 0.4707  loss_dice_1: 4.48  loss_ce_2: 0.183  loss_mask_2: 0.4704  loss_dice_2: 4.351  loss_ce_3: 0.08633  loss_mask_3: 0.4777  loss_dice_3: 4.291  loss_ce_4: 0.05583  loss_mask_4: 0.4765  loss_dice_4: 4.27  loss_ce_5: 0.03593  loss_mask_5: 0.485  loss_dice_5: 4.226  loss_ce_6: 0.05046  loss_mask_6: 0.5063  loss_dice_6: 4.209  loss_ce_7: 0.03744  loss_mask_7: 0.4841  loss_dice_7: 4.188  loss_ce_8: 0.04213  loss_mask_8: 0.4895  loss_dice_8: 4.194  loss_mgm_entropy: 0.005194    time: 0.4369  last_time: 0.4373  data_time: 0.0034  last_data_time: 0.0033   lr: 7.992e-06  max_mem: 15545M
[08/30 23:30:42] d2.utils.events INFO:  eta: 0:23:09  iter: 819  total_loss: 48.55  loss_ce: 0.0382  loss_mask: 0.486  loss_dice: 4.123  loss_ce_0: 0.7346  loss_mask_0: 0.5257  loss_dice_0: 4.491  loss_ce_1: 0.3842  loss_mask_1: 0.4852  loss_dice_1: 4.405  loss_ce_2: 0.1675  loss_mask_2: 0.4788  loss_dice_2: 4.265  loss_ce_3: 0.07146  loss_mask_3: 0.4845  loss_dice_3: 4.189  loss_ce_4: 0.04309  loss_mask_4: 0.4766  loss_dice_4: 4.172  loss_ce_5: 0.03563  loss_mask_5: 0.4877  loss_dice_5: 4.12  loss_ce_6: 0.0384  loss_mask_6: 0.4963  loss_dice_6: 4.089  loss_ce_7: 0.03843  loss_mask_7: 0.5011  loss_dice_7: 4.088  loss_ce_8: 0.02886  loss_mask_8: 0.4996  loss_dice_8: 4.099  loss_mgm_entropy: 0.005135    time: 0.4369  last_time: 0.4359  data_time: 0.0035  last_data_time: 0.0042   lr: 8.1918e-06  max_mem: 15545M
[08/30 23:30:51] d2.utils.events INFO:  eta: 0:23:00  iter: 839  total_loss: 48.18  loss_ce: 0.0392  loss_mask: 0.544  loss_dice: 4.073  loss_ce_0: 0.731  loss_mask_0: 0.5406  loss_dice_0: 4.454  loss_ce_1: 0.3692  loss_mask_1: 0.5163  loss_dice_1: 4.334  loss_ce_2: 0.155  loss_mask_2: 0.5185  loss_dice_2: 4.195  loss_ce_3: 0.0758  loss_mask_3: 0.5208  loss_dice_3: 4.125  loss_ce_4: 0.05805  loss_mask_4: 0.5151  loss_dice_4: 4.082  loss_ce_5: 0.05261  loss_mask_5: 0.5366  loss_dice_5: 4.032  loss_ce_6: 0.03788  loss_mask_6: 0.5283  loss_dice_6: 4.022  loss_ce_7: 0.0428  loss_mask_7: 0.55  loss_dice_7: 4.018  loss_ce_8: 0.04007  loss_mask_8: 0.5599  loss_dice_8: 4.025  loss_mgm_entropy: 0.005125    time: 0.4370  last_time: 0.4373  data_time: 0.0034  last_data_time: 0.0032   lr: 8.3916e-06  max_mem: 15545M
[08/30 23:31:00] d2.utils.events INFO:  eta: 0:22:51  iter: 859  total_loss: 46.76  loss_ce: 0.03516  loss_mask: 0.5156  loss_dice: 3.951  loss_ce_0: 0.7354  loss_mask_0: 0.5171  loss_dice_0: 4.416  loss_ce_1: 0.3487  loss_mask_1: 0.4844  loss_dice_1: 4.273  loss_ce_2: 0.1447  loss_mask_2: 0.4856  loss_dice_2: 4.13  loss_ce_3: 0.06483  loss_mask_3: 0.5011  loss_dice_3: 4.008  loss_ce_4: 0.0501  loss_mask_4: 0.4842  loss_dice_4: 3.999  loss_ce_5: 0.03996  loss_mask_5: 0.4947  loss_dice_5: 3.932  loss_ce_6: 0.03837  loss_mask_6: 0.4943  loss_dice_6: 3.903  loss_ce_7: 0.03931  loss_mask_7: 0.5024  loss_dice_7: 3.913  loss_ce_8: 0.02789  loss_mask_8: 0.5136  loss_dice_8: 3.922  loss_mgm_entropy: 0.005089    time: 0.4370  last_time: 0.4361  data_time: 0.0034  last_data_time: 0.0032   lr: 8.5914e-06  max_mem: 15545M
[08/30 23:31:09] d2.utils.events INFO:  eta: 0:22:42  iter: 879  total_loss: 45.83  loss_ce: 0.03427  loss_mask: 0.439  loss_dice: 3.907  loss_ce_0: 0.7323  loss_mask_0: 0.4656  loss_dice_0: 4.402  loss_ce_1: 0.3429  loss_mask_1: 0.4344  loss_dice_1: 4.214  loss_ce_2: 0.137  loss_mask_2: 0.4448  loss_dice_2: 4.038  loss_ce_3: 0.06385  loss_mask_3: 0.4644  loss_dice_3: 3.937  loss_ce_4: 0.0533  loss_mask_4: 0.4301  loss_dice_4: 3.923  loss_ce_5: 0.04361  loss_mask_5: 0.4227  loss_dice_5: 3.875  loss_ce_6: 0.03919  loss_mask_6: 0.4122  loss_dice_6: 3.83  loss_ce_7: 0.03479  loss_mask_7: 0.4241  loss_dice_7: 3.83  loss_ce_8: 0.03287  loss_mask_8: 0.4323  loss_dice_8: 3.872  loss_mgm_entropy: 0.005069    time: 0.4369  last_time: 0.4361  data_time: 0.0035  last_data_time: 0.0029   lr: 8.7912e-06  max_mem: 15545M
[08/30 23:31:17] d2.utils.events INFO:  eta: 0:22:33  iter: 899  total_loss: 45.33  loss_ce: 0.03825  loss_mask: 0.4795  loss_dice: 3.784  loss_ce_0: 0.7421  loss_mask_0: 0.5147  loss_dice_0: 4.34  loss_ce_1: 0.3204  loss_mask_1: 0.4971  loss_dice_1: 4.15  loss_ce_2: 0.1353  loss_mask_2: 0.5047  loss_dice_2: 3.967  loss_ce_3: 0.06356  loss_mask_3: 0.4915  loss_dice_3: 3.873  loss_ce_4: 0.04783  loss_mask_4: 0.4894  loss_dice_4: 3.806  loss_ce_5: 0.04303  loss_mask_5: 0.4841  loss_dice_5: 3.747  loss_ce_6: 0.04652  loss_mask_6: 0.4874  loss_dice_6: 3.729  loss_ce_7: 0.04142  loss_mask_7: 0.5008  loss_dice_7: 3.727  loss_ce_8: 0.03535  loss_mask_8: 0.5072  loss_dice_8: 3.772  loss_mgm_entropy: 0.005089    time: 0.4369  last_time: 0.4360  data_time: 0.0034  last_data_time: 0.0032   lr: 8.991e-06  max_mem: 15545M
[08/30 23:31:26] d2.utils.events INFO:  eta: 0:22:25  iter: 919  total_loss: 43.48  loss_ce: 0.03625  loss_mask: 0.4185  loss_dice: 3.616  loss_ce_0: 0.7409  loss_mask_0: 0.4414  loss_dice_0: 4.32  loss_ce_1: 0.3107  loss_mask_1: 0.4276  loss_dice_1: 4.05  loss_ce_2: 0.1295  loss_mask_2: 0.4345  loss_dice_2: 3.825  loss_ce_3: 0.06103  loss_mask_3: 0.4368  loss_dice_3: 3.728  loss_ce_4: 0.04636  loss_mask_4: 0.4623  loss_dice_4: 3.676  loss_ce_5: 0.04116  loss_mask_5: 0.4232  loss_dice_5: 3.632  loss_ce_6: 0.04096  loss_mask_6: 0.4516  loss_dice_6: 3.598  loss_ce_7: 0.03916  loss_mask_7: 0.4265  loss_dice_7: 3.577  loss_ce_8: 0.0303  loss_mask_8: 0.4215  loss_dice_8: 3.617  loss_mgm_entropy: 0.005021    time: 0.4369  last_time: 0.4358  data_time: 0.0037  last_data_time: 0.0035   lr: 9.1908e-06  max_mem: 15545M
[08/30 23:31:35] d2.utils.events INFO:  eta: 0:22:16  iter: 939  total_loss: 41.9  loss_ce: 0.04399  loss_mask: 0.3925  loss_dice: 3.432  loss_ce_0: 0.7546  loss_mask_0: 0.4241  loss_dice_0: 4.223  loss_ce_1: 0.3003  loss_mask_1: 0.3932  loss_dice_1: 3.94  loss_ce_2: 0.1311  loss_mask_2: 0.4068  loss_dice_2: 3.719  loss_ce_3: 0.06191  loss_mask_3: 0.4022  loss_dice_3: 3.591  loss_ce_4: 0.04561  loss_mask_4: 0.4042  loss_dice_4: 3.535  loss_ce_5: 0.03938  loss_mask_5: 0.3924  loss_dice_5: 3.5  loss_ce_6: 0.04291  loss_mask_6: 0.4004  loss_dice_6: 3.421  loss_ce_7: 0.04211  loss_mask_7: 0.4118  loss_dice_7: 3.418  loss_ce_8: 0.03995  loss_mask_8: 0.393  loss_dice_8: 3.444  loss_mgm_entropy: 0.005034    time: 0.4369  last_time: 0.4363  data_time: 0.0035  last_data_time: 0.0035   lr: 9.3906e-06  max_mem: 15545M
[08/30 23:31:44] d2.utils.events INFO:  eta: 0:22:07  iter: 959  total_loss: 40.38  loss_ce: 0.03441  loss_mask: 0.4179  loss_dice: 3.283  loss_ce_0: 0.7616  loss_mask_0: 0.4611  loss_dice_0: 4.159  loss_ce_1: 0.2975  loss_mask_1: 0.4414  loss_dice_1: 3.832  loss_ce_2: 0.1165  loss_mask_2: 0.4411  loss_dice_2: 3.576  loss_ce_3: 0.05528  loss_mask_3: 0.4342  loss_dice_3: 3.445  loss_ce_4: 0.04329  loss_mask_4: 0.4341  loss_dice_4: 3.379  loss_ce_5: 0.04286  loss_mask_5: 0.4519  loss_dice_5: 3.318  loss_ce_6: 0.04141  loss_mask_6: 0.4612  loss_dice_6: 3.281  loss_ce_7: 0.0396  loss_mask_7: 0.4521  loss_dice_7: 3.262  loss_ce_8: 0.03454  loss_mask_8: 0.4166  loss_dice_8: 3.281  loss_mgm_entropy: 0.00496    time: 0.4368  last_time: 0.4351  data_time: 0.0035  last_data_time: 0.0031   lr: 9.5904e-06  max_mem: 15545M
[08/30 23:31:52] d2.utils.events INFO:  eta: 0:21:58  iter: 979  total_loss: 39.15  loss_ce: 0.03465  loss_mask: 0.4413  loss_dice: 3.196  loss_ce_0: 0.7649  loss_mask_0: 0.4351  loss_dice_0: 4.072  loss_ce_1: 0.2861  loss_mask_1: 0.4311  loss_dice_1: 3.733  loss_ce_2: 0.1154  loss_mask_2: 0.419  loss_dice_2: 3.505  loss_ce_3: 0.05599  loss_mask_3: 0.4282  loss_dice_3: 3.342  loss_ce_4: 0.04299  loss_mask_4: 0.4209  loss_dice_4: 3.275  loss_ce_5: 0.03835  loss_mask_5: 0.4242  loss_dice_5: 3.22  loss_ce_6: 0.03749  loss_mask_6: 0.4224  loss_dice_6: 3.165  loss_ce_7: 0.0368  loss_mask_7: 0.4124  loss_dice_7: 3.145  loss_ce_8: 0.0333  loss_mask_8: 0.4208  loss_dice_8: 3.154  loss_mgm_entropy: 0.004962    time: 0.4368  last_time: 0.4375  data_time: 0.0034  last_data_time: 0.0030   lr: 9.7902e-06  max_mem: 15545M
[08/30 23:32:01] d2.utils.events INFO:  eta: 0:21:50  iter: 999  total_loss: 38.35  loss_ce: 0.03415  loss_mask: 0.4788  loss_dice: 3.037  loss_ce_0: 0.7677  loss_mask_0: 0.4556  loss_dice_0: 4.02  loss_ce_1: 0.279  loss_mask_1: 0.4397  loss_dice_1: 3.578  loss_ce_2: 0.111  loss_mask_2: 0.4603  loss_dice_2: 3.361  loss_ce_3: 0.05158  loss_mask_3: 0.4239  loss_dice_3: 3.232  loss_ce_4: 0.0395  loss_mask_4: 0.4442  loss_dice_4: 3.153  loss_ce_5: 0.03457  loss_mask_5: 0.4366  loss_dice_5: 3.095  loss_ce_6: 0.03552  loss_mask_6: 0.4363  loss_dice_6: 3.042  loss_ce_7: 0.03523  loss_mask_7: 0.4301  loss_dice_7: 3.032  loss_ce_8: 0.03176  loss_mask_8: 0.4515  loss_dice_8: 3.007  loss_mgm_entropy: 0.004895    time: 0.4368  last_time: 0.4359  data_time: 0.0035  last_data_time: 0.0030   lr: 9.99e-06  max_mem: 15545M
[08/30 23:32:10] d2.utils.events INFO:  eta: 0:21:41  iter: 1019  total_loss: 37.08  loss_ce: 0.04294  loss_mask: 0.3899  loss_dice: 2.928  loss_ce_0: 0.775  loss_mask_0: 0.4022  loss_dice_0: 3.916  loss_ce_1: 0.2789  loss_mask_1: 0.3886  loss_dice_1: 3.502  loss_ce_2: 0.1168  loss_mask_2: 0.3975  loss_dice_2: 3.304  loss_ce_3: 0.06073  loss_mask_3: 0.3963  loss_dice_3: 3.165  loss_ce_4: 0.04861  loss_mask_4: 0.3978  loss_dice_4: 3.103  loss_ce_5: 0.03851  loss_mask_5: 0.404  loss_dice_5: 3.002  loss_ce_6: 0.0387  loss_mask_6: 0.4127  loss_dice_6: 2.954  loss_ce_7: 0.04211  loss_mask_7: 0.3905  loss_dice_7: 2.919  loss_ce_8: 0.03048  loss_mask_8: 0.3979  loss_dice_8: 2.958  loss_mgm_entropy: 0.004945    time: 0.4368  last_time: 0.4369  data_time: 0.0035  last_data_time: 0.0039   lr: 1e-05  max_mem: 15545M
[08/30 23:32:18] d2.utils.events INFO:  eta: 0:21:32  iter: 1039  total_loss: 36.37  loss_ce: 0.04578  loss_mask: 0.4433  loss_dice: 2.895  loss_ce_0: 0.7622  loss_mask_0: 0.4378  loss_dice_0: 3.864  loss_ce_1: 0.2797  loss_mask_1: 0.4323  loss_dice_1: 3.437  loss_ce_2: 0.1152  loss_mask_2: 0.4355  loss_dice_2: 3.191  loss_ce_3: 0.06206  loss_mask_3: 0.4255  loss_dice_3: 3.059  loss_ce_4: 0.04884  loss_mask_4: 0.4246  loss_dice_4: 2.957  loss_ce_5: 0.04527  loss_mask_5: 0.4133  loss_dice_5: 2.933  loss_ce_6: 0.04566  loss_mask_6: 0.4276  loss_dice_6: 2.924  loss_ce_7: 0.04391  loss_mask_7: 0.4119  loss_dice_7: 2.88  loss_ce_8: 0.04284  loss_mask_8: 0.4096  loss_dice_8: 2.885  loss_mgm_entropy: 0.004953    time: 0.4368  last_time: 0.4366  data_time: 0.0035  last_data_time: 0.0036   lr: 1e-05  max_mem: 15545M
[08/30 23:32:27] d2.utils.events INFO:  eta: 0:21:23  iter: 1059  total_loss: 35.36  loss_ce: 0.04493  loss_mask: 0.4033  loss_dice: 2.812  loss_ce_0: 0.7722  loss_mask_0: 0.4339  loss_dice_0: 3.799  loss_ce_1: 0.2723  loss_mask_1: 0.4113  loss_dice_1: 3.336  loss_ce_2: 0.1101  loss_mask_2: 0.3998  loss_dice_2: 3.112  loss_ce_3: 0.06334  loss_mask_3: 0.3901  loss_dice_3: 2.953  loss_ce_4: 0.05026  loss_mask_4: 0.3973  loss_dice_4: 2.867  loss_ce_5: 0.04745  loss_mask_5: 0.3744  loss_dice_5: 2.797  loss_ce_6: 0.04493  loss_mask_6: 0.4042  loss_dice_6: 2.799  loss_ce_7: 0.04381  loss_mask_7: 0.4014  loss_dice_7: 2.814  loss_ce_8: 0.04275  loss_mask_8: 0.4129  loss_dice_8: 2.813  loss_mgm_entropy: 0.004927    time: 0.4368  last_time: 0.4360  data_time: 0.0035  last_data_time: 0.0031   lr: 1e-05  max_mem: 15545M
[08/30 23:32:36] d2.utils.events INFO:  eta: 0:21:15  iter: 1079  total_loss: 35.23  loss_ce: 0.05344  loss_mask: 0.4315  loss_dice: 2.777  loss_ce_0: 0.7749  loss_mask_0: 0.4285  loss_dice_0: 3.772  loss_ce_1: 0.2832  loss_mask_1: 0.4011  loss_dice_1: 3.255  loss_ce_2: 0.1199  loss_mask_2: 0.3831  loss_dice_2: 3.032  loss_ce_3: 0.07973  loss_mask_3: 0.4177  loss_dice_3: 2.878  loss_ce_4: 0.06449  loss_mask_4: 0.4114  loss_dice_4: 2.807  loss_ce_5: 0.05497  loss_mask_5: 0.4218  loss_dice_5: 2.791  loss_ce_6: 0.05566  loss_mask_6: 0.4185  loss_dice_6: 2.743  loss_ce_7: 0.04522  loss_mask_7: 0.4258  loss_dice_7: 2.757  loss_ce_8: 0.05198  loss_mask_8: 0.4454  loss_dice_8: 2.735  loss_mgm_entropy: 0.005031    time: 0.4368  last_time: 0.4368  data_time: 0.0034  last_data_time: 0.0034   lr: 1e-05  max_mem: 15545M
[08/30 23:32:45] d2.utils.events INFO:  eta: 0:21:06  iter: 1099  total_loss: 34.7  loss_ce: 0.05691  loss_mask: 0.4018  loss_dice: 2.73  loss_ce_0: 0.7796  loss_mask_0: 0.4147  loss_dice_0: 3.674  loss_ce_1: 0.2814  loss_mask_1: 0.3946  loss_dice_1: 3.163  loss_ce_2: 0.1134  loss_mask_2: 0.3745  loss_dice_2: 2.951  loss_ce_3: 0.07792  loss_mask_3: 0.3727  loss_dice_3: 2.806  loss_ce_4: 0.07014  loss_mask_4: 0.3711  loss_dice_4: 2.749  loss_ce_5: 0.06093  loss_mask_5: 0.3946  loss_dice_5: 2.715  loss_ce_6: 0.06161  loss_mask_6: 0.387  loss_dice_6: 2.696  loss_ce_7: 0.05994  loss_mask_7: 0.377  loss_dice_7: 2.711  loss_ce_8: 0.05844  loss_mask_8: 0.368  loss_dice_8: 2.721  loss_mgm_entropy: 0.005072    time: 0.4368  last_time: 0.4356  data_time: 0.0035  last_data_time: 0.0037   lr: 1e-05  max_mem: 15545M
[08/30 23:32:53] d2.utils.events INFO:  eta: 0:20:57  iter: 1119  total_loss: 32.83  loss_ce: 0.061  loss_mask: 0.3187  loss_dice: 2.543  loss_ce_0: 0.7712  loss_mask_0: 0.3858  loss_dice_0: 3.622  loss_ce_1: 0.2845  loss_mask_1: 0.3778  loss_dice_1: 3.092  loss_ce_2: 0.1111  loss_mask_2: 0.3407  loss_dice_2: 2.85  loss_ce_3: 0.07559  loss_mask_3: 0.3338  loss_dice_3: 2.716  loss_ce_4: 0.06517  loss_mask_4: 0.3249  loss_dice_4: 2.681  loss_ce_5: 0.05961  loss_mask_5: 0.32  loss_dice_5: 2.598  loss_ce_6: 0.06647  loss_mask_6: 0.3283  loss_dice_6: 2.561  loss_ce_7: 0.06086  loss_mask_7: 0.3124  loss_dice_7: 2.53  loss_ce_8: 0.06671  loss_mask_8: 0.3045  loss_dice_8: 2.552  loss_mgm_entropy: 0.005059    time: 0.4368  last_time: 0.4368  data_time: 0.0035  last_data_time: 0.0036   lr: 1e-05  max_mem: 15545M
[08/30 23:33:02] d2.utils.events INFO:  eta: 0:20:49  iter: 1139  total_loss: 32.07  loss_ce: 0.07579  loss_mask: 0.3608  loss_dice: 2.463  loss_ce_0: 0.7761  loss_mask_0: 0.3978  loss_dice_0: 3.609  loss_ce_1: 0.2833  loss_mask_1: 0.3646  loss_dice_1: 3.018  loss_ce_2: 0.1043  loss_mask_2: 0.3374  loss_dice_2: 2.778  loss_ce_3: 0.08442  loss_mask_3: 0.3275  loss_dice_3: 2.62  loss_ce_4: 0.06798  loss_mask_4: 0.345  loss_dice_4: 2.57  loss_ce_5: 0.06415  loss_mask_5: 0.3377  loss_dice_5: 2.494  loss_ce_6: 0.06578  loss_mask_6: 0.3467  loss_dice_6: 2.484  loss_ce_7: 0.06614  loss_mask_7: 0.3345  loss_dice_7: 2.466  loss_ce_8: 0.07566  loss_mask_8: 0.3341  loss_dice_8: 2.454  loss_mgm_entropy: 0.004979    time: 0.4367  last_time: 0.4374  data_time: 0.0034  last_data_time: 0.0040   lr: 1e-05  max_mem: 15545M
[08/30 23:33:11] d2.utils.events INFO:  eta: 0:20:40  iter: 1159  total_loss: 31.74  loss_ce: 0.07857  loss_mask: 0.3534  loss_dice: 2.429  loss_ce_0: 0.7957  loss_mask_0: 0.4012  loss_dice_0: 3.519  loss_ce_1: 0.2907  loss_mask_1: 0.3398  loss_dice_1: 2.945  loss_ce_2: 0.1238  loss_mask_2: 0.3342  loss_dice_2: 2.638  loss_ce_3: 0.09064  loss_mask_3: 0.3365  loss_dice_3: 2.48  loss_ce_4: 0.08167  loss_mask_4: 0.3288  loss_dice_4: 2.477  loss_ce_5: 0.07311  loss_mask_5: 0.3272  loss_dice_5: 2.465  loss_ce_6: 0.07466  loss_mask_6: 0.3165  loss_dice_6: 2.442  loss_ce_7: 0.07487  loss_mask_7: 0.3302  loss_dice_7: 2.429  loss_ce_8: 0.0785  loss_mask_8: 0.3323  loss_dice_8: 2.403  loss_mgm_entropy: 0.004927    time: 0.4367  last_time: 0.4365  data_time: 0.0036  last_data_time: 0.0038   lr: 1e-05  max_mem: 15545M
[08/30 23:33:20] d2.utils.events INFO:  eta: 0:20:31  iter: 1179  total_loss: 31.06  loss_ce: 0.08178  loss_mask: 0.3251  loss_dice: 2.379  loss_ce_0: 0.789  loss_mask_0: 0.3648  loss_dice_0: 3.447  loss_ce_1: 0.3008  loss_mask_1: 0.3309  loss_dice_1: 2.878  loss_ce_2: 0.1193  loss_mask_2: 0.3269  loss_dice_2: 2.703  loss_ce_3: 0.09314  loss_mask_3: 0.3143  loss_dice_3: 2.479  loss_ce_4: 0.08209  loss_mask_4: 0.3496  loss_dice_4: 2.457  loss_ce_5: 0.07839  loss_mask_5: 0.3204  loss_dice_5: 2.436  loss_ce_6: 0.0804  loss_mask_6: 0.324  loss_dice_6: 2.395  loss_ce_7: 0.07713  loss_mask_7: 0.3288  loss_dice_7: 2.344  loss_ce_8: 0.07758  loss_mask_8: 0.307  loss_dice_8: 2.416  loss_mgm_entropy: 0.005037    time: 0.4367  last_time: 0.4364  data_time: 0.0035  last_data_time: 0.0035   lr: 1e-05  max_mem: 15545M
[08/30 23:33:28] d2.utils.events INFO:  eta: 0:20:22  iter: 1199  total_loss: 30.45  loss_ce: 0.08435  loss_mask: 0.362  loss_dice: 2.356  loss_ce_0: 0.7927  loss_mask_0: 0.3677  loss_dice_0: 3.43  loss_ce_1: 0.2854  loss_mask_1: 0.3315  loss_dice_1: 2.845  loss_ce_2: 0.111  loss_mask_2: 0.3436  loss_dice_2: 2.54  loss_ce_3: 0.08171  loss_mask_3: 0.3413  loss_dice_3: 2.435  loss_ce_4: 0.07191  loss_mask_4: 0.3331  loss_dice_4: 2.385  loss_ce_5: 0.06973  loss_mask_5: 0.3407  loss_dice_5: 2.343  loss_ce_6: 0.07907  loss_mask_6: 0.3348  loss_dice_6: 2.338  loss_ce_7: 0.07247  loss_mask_7: 0.3473  loss_dice_7: 2.307  loss_ce_8: 0.07554  loss_mask_8: 0.345  loss_dice_8: 2.336  loss_mgm_entropy: 0.005041    time: 0.4367  last_time: 0.4400  data_time: 0.0037  last_data_time: 0.0037   lr: 1e-05  max_mem: 15545M
[08/30 23:33:37] d2.utils.events INFO:  eta: 0:20:14  iter: 1219  total_loss: 29.83  loss_ce: 0.08614  loss_mask: 0.3174  loss_dice: 2.318  loss_ce_0: 0.785  loss_mask_0: 0.3528  loss_dice_0: 3.397  loss_ce_1: 0.2654  loss_mask_1: 0.3263  loss_dice_1: 2.764  loss_ce_2: 0.1054  loss_mask_2: 0.2923  loss_dice_2: 2.527  loss_ce_3: 0.08554  loss_mask_3: 0.282  loss_dice_3: 2.39  loss_ce_4: 0.06937  loss_mask_4: 0.3025  loss_dice_4: 2.361  loss_ce_5: 0.06207  loss_mask_5: 0.3078  loss_dice_5: 2.324  loss_ce_6: 0.06176  loss_mask_6: 0.2961  loss_dice_6: 2.274  loss_ce_7: 0.06474  loss_mask_7: 0.3072  loss_dice_7: 2.329  loss_ce_8: 0.0767  loss_mask_8: 0.3032  loss_dice_8: 2.335  loss_mgm_entropy: 0.004983    time: 0.4367  last_time: 0.4361  data_time: 0.0034  last_data_time: 0.0037   lr: 1e-05  max_mem: 15545M
[08/30 23:33:46] d2.utils.events INFO:  eta: 0:20:05  iter: 1239  total_loss: 28.28  loss_ce: 0.08481  loss_mask: 0.2763  loss_dice: 2.214  loss_ce_0: 0.7847  loss_mask_0: 0.2925  loss_dice_0: 3.371  loss_ce_1: 0.2682  loss_mask_1: 0.274  loss_dice_1: 2.728  loss_ce_2: 0.1034  loss_mask_2: 0.2616  loss_dice_2: 2.424  loss_ce_3: 0.07543  loss_mask_3: 0.2667  loss_dice_3: 2.299  loss_ce_4: 0.06775  loss_mask_4: 0.2641  loss_dice_4: 2.25  loss_ce_5: 0.06738  loss_mask_5: 0.251  loss_dice_5: 2.26  loss_ce_6: 0.07265  loss_mask_6: 0.2545  loss_dice_6: 2.157  loss_ce_7: 0.07526  loss_mask_7: 0.2563  loss_dice_7: 2.166  loss_ce_8: 0.07771  loss_mask_8: 0.274  loss_dice_8: 2.197  loss_mgm_entropy: 0.004969    time: 0.4367  last_time: 0.4366  data_time: 0.0035  last_data_time: 0.0033   lr: 1e-05  max_mem: 15545M
[08/30 23:33:55] d2.utils.events INFO:  eta: 0:19:56  iter: 1259  total_loss: 28.9  loss_ce: 0.1127  loss_mask: 0.3091  loss_dice: 2.217  loss_ce_0: 0.7915  loss_mask_0: 0.3864  loss_dice_0: 3.316  loss_ce_1: 0.2706  loss_mask_1: 0.3508  loss_dice_1: 2.708  loss_ce_2: 0.1109  loss_mask_2: 0.3223  loss_dice_2: 2.426  loss_ce_3: 0.08758  loss_mask_3: 0.3281  loss_dice_3: 2.296  loss_ce_4: 0.07828  loss_mask_4: 0.3092  loss_dice_4: 2.285  loss_ce_5: 0.07597  loss_mask_5: 0.3004  loss_dice_5: 2.241  loss_ce_6: 0.08008  loss_mask_6: 0.3078  loss_dice_6: 2.238  loss_ce_7: 0.07837  loss_mask_7: 0.3224  loss_dice_7: 2.2  loss_ce_8: 0.09992  loss_mask_8: 0.3139  loss_dice_8: 2.215  loss_mgm_entropy: 0.005056    time: 0.4368  last_time: 0.4991  data_time: 0.0035  last_data_time: 0.0036   lr: 1e-05  max_mem: 15545M
[08/30 23:34:03] d2.utils.events INFO:  eta: 0:19:47  iter: 1279  total_loss: 28.63  loss_ce: 0.1197  loss_mask: 0.3143  loss_dice: 2.171  loss_ce_0: 0.7922  loss_mask_0: 0.3376  loss_dice_0: 3.269  loss_ce_1: 0.2633  loss_mask_1: 0.2944  loss_dice_1: 2.619  loss_ce_2: 0.1145  loss_mask_2: 0.2989  loss_dice_2: 2.368  loss_ce_3: 0.0946  loss_mask_3: 0.3029  loss_dice_3: 2.263  loss_ce_4: 0.09008  loss_mask_4: 0.3079  loss_dice_4: 2.211  loss_ce_5: 0.0799  loss_mask_5: 0.3188  loss_dice_5: 2.194  loss_ce_6: 0.08671  loss_mask_6: 0.3119  loss_dice_6: 2.177  loss_ce_7: 0.1058  loss_mask_7: 0.316  loss_dice_7: 2.155  loss_ce_8: 0.1132  loss_mask_8: 0.3269  loss_dice_8: 2.153  loss_mgm_entropy: 0.004971    time: 0.4368  last_time: 0.4371  data_time: 0.0034  last_data_time: 0.0033   lr: 1e-05  max_mem: 15545M
[08/30 23:34:12] d2.utils.events INFO:  eta: 0:19:38  iter: 1299  total_loss: 27.18  loss_ce: 0.09657  loss_mask: 0.2837  loss_dice: 2.051  loss_ce_0: 0.8133  loss_mask_0: 0.3139  loss_dice_0: 3.2  loss_ce_1: 0.2678  loss_mask_1: 0.2643  loss_dice_1: 2.548  loss_ce_2: 0.1089  loss_mask_2: 0.2532  loss_dice_2: 2.226  loss_ce_3: 0.09143  loss_mask_3: 0.2453  loss_dice_3: 2.159  loss_ce_4: 0.08514  loss_mask_4: 0.2471  loss_dice_4: 2.084  loss_ce_5: 0.07592  loss_mask_5: 0.2633  loss_dice_5: 2.102  loss_ce_6: 0.07868  loss_mask_6: 0.2562  loss_dice_6: 2.085  loss_ce_7: 0.09414  loss_mask_7: 0.259  loss_dice_7: 2.058  loss_ce_8: 0.09449  loss_mask_8: 0.2609  loss_dice_8: 2.059  loss_mgm_entropy: 0.005066    time: 0.4367  last_time: 0.4354  data_time: 0.0035  last_data_time: 0.0035   lr: 1e-05  max_mem: 15545M
[08/30 23:34:21] d2.utils.events INFO:  eta: 0:19:30  iter: 1319  total_loss: 27.39  loss_ce: 0.1057  loss_mask: 0.2942  loss_dice: 2.092  loss_ce_0: 0.7975  loss_mask_0: 0.3409  loss_dice_0: 3.181  loss_ce_1: 0.2548  loss_mask_1: 0.2944  loss_dice_1: 2.532  loss_ce_2: 0.1062  loss_mask_2: 0.2833  loss_dice_2: 2.301  loss_ce_3: 0.08696  loss_mask_3: 0.2771  loss_dice_3: 2.162  loss_ce_4: 0.08601  loss_mask_4: 0.2722  loss_dice_4: 2.127  loss_ce_5: 0.07924  loss_mask_5: 0.2777  loss_dice_5: 2.114  loss_ce_6: 0.08783  loss_mask_6: 0.2663  loss_dice_6: 2.077  loss_ce_7: 0.09325  loss_mask_7: 0.2661  loss_dice_7: 2.049  loss_ce_8: 0.1027  loss_mask_8: 0.2811  loss_dice_8: 2.104  loss_mgm_entropy: 0.005007    time: 0.4367  last_time: 0.4357  data_time: 0.0035  last_data_time: 0.0035   lr: 1e-05  max_mem: 15545M
[08/30 23:34:30] d2.utils.events INFO:  eta: 0:19:21  iter: 1339  total_loss: 25.74  loss_ce: 0.1075  loss_mask: 0.2821  loss_dice: 1.937  loss_ce_0: 0.7984  loss_mask_0: 0.306  loss_dice_0: 3.097  loss_ce_1: 0.2496  loss_mask_1: 0.2548  loss_dice_1: 2.431  loss_ce_2: 0.1511  loss_mask_2: 0.2486  loss_dice_2: 2.155  loss_ce_3: 0.09913  loss_mask_3: 0.2436  loss_dice_3: 2.023  loss_ce_4: 0.1015  loss_mask_4: 0.2608  loss_dice_4: 2.002  loss_ce_5: 0.09252  loss_mask_5: 0.258  loss_dice_5: 1.952  loss_ce_6: 0.0899  loss_mask_6: 0.2596  loss_dice_6: 1.949  loss_ce_7: 0.09937  loss_mask_7: 0.2592  loss_dice_7: 1.913  loss_ce_8: 0.1081  loss_mask_8: 0.279  loss_dice_8: 1.899  loss_mgm_entropy: 0.00495    time: 0.4367  last_time: 0.4348  data_time: 0.0035  last_data_time: 0.0037   lr: 1e-05  max_mem: 15545M
[08/30 23:34:38] d2.utils.events INFO:  eta: 0:19:12  iter: 1359  total_loss: 24.28  loss_ce: 0.1144  loss_mask: 0.2241  loss_dice: 1.822  loss_ce_0: 0.7871  loss_mask_0: 0.2808  loss_dice_0: 3.061  loss_ce_1: 0.2445  loss_mask_1: 0.2233  loss_dice_1: 2.347  loss_ce_2: 0.1463  loss_mask_2: 0.1973  loss_dice_2: 1.988  loss_ce_3: 0.1027  loss_mask_3: 0.2156  loss_dice_3: 1.878  loss_ce_4: 0.09745  loss_mask_4: 0.2131  loss_dice_4: 1.842  loss_ce_5: 0.09286  loss_mask_5: 0.2214  loss_dice_5: 1.838  loss_ce_6: 0.09396  loss_mask_6: 0.2216  loss_dice_6: 1.853  loss_ce_7: 0.09838  loss_mask_7: 0.2163  loss_dice_7: 1.828  loss_ce_8: 0.1086  loss_mask_8: 0.2163  loss_dice_8: 1.831  loss_mgm_entropy: 0.004919    time: 0.4367  last_time: 0.4369  data_time: 0.0034  last_data_time: 0.0038   lr: 1e-05  max_mem: 15545M
[08/30 23:34:47] d2.utils.events INFO:  eta: 0:19:03  iter: 1379  total_loss: 24.6  loss_ce: 0.11  loss_mask: 0.2609  loss_dice: 1.812  loss_ce_0: 0.8123  loss_mask_0: 0.321  loss_dice_0: 3.011  loss_ce_1: 0.2477  loss_mask_1: 0.2552  loss_dice_1: 2.308  loss_ce_2: 0.1476  loss_mask_2: 0.2458  loss_dice_2: 1.986  loss_ce_3: 0.1234  loss_mask_3: 0.2316  loss_dice_3: 1.888  loss_ce_4: 0.1002  loss_mask_4: 0.2393  loss_dice_4: 1.841  loss_ce_5: 0.1079  loss_mask_5: 0.2298  loss_dice_5: 1.823  loss_ce_6: 0.1103  loss_mask_6: 0.234  loss_dice_6: 1.747  loss_ce_7: 0.1107  loss_mask_7: 0.2196  loss_dice_7: 1.757  loss_ce_8: 0.1173  loss_mask_8: 0.2398  loss_dice_8: 1.789  loss_mgm_entropy: 0.005017    time: 0.4367  last_time: 0.4366  data_time: 0.0036  last_data_time: 0.0037   lr: 1e-05  max_mem: 15545M
[08/30 23:34:56] d2.utils.events INFO:  eta: 0:18:55  iter: 1399  total_loss: 24.85  loss_ce: 0.125  loss_mask: 0.2672  loss_dice: 1.837  loss_ce_0: 0.8083  loss_mask_0: 0.3065  loss_dice_0: 2.969  loss_ce_1: 0.253  loss_mask_1: 0.2486  loss_dice_1: 2.304  loss_ce_2: 0.1505  loss_mask_2: 0.2543  loss_dice_2: 2.025  loss_ce_3: 0.1309  loss_mask_3: 0.2362  loss_dice_3: 1.929  loss_ce_4: 0.1187  loss_mask_4: 0.2363  loss_dice_4: 1.912  loss_ce_5: 0.1193  loss_mask_5: 0.2362  loss_dice_5: 1.888  loss_ce_6: 0.1196  loss_mask_6: 0.2374  loss_dice_6: 1.876  loss_ce_7: 0.1205  loss_mask_7: 0.2394  loss_dice_7: 1.831  loss_ce_8: 0.1218  loss_mask_8: 0.2466  loss_dice_8: 1.837  loss_mgm_entropy: 0.004971    time: 0.4367  last_time: 0.4355  data_time: 0.0035  last_data_time: 0.0031   lr: 1e-05  max_mem: 15545M
[08/30 23:35:04] d2.utils.events INFO:  eta: 0:18:46  iter: 1419  total_loss: 25.68  loss_ce: 0.1157  loss_mask: 0.2707  loss_dice: 1.883  loss_ce_0: 0.7988  loss_mask_0: 0.3195  loss_dice_0: 2.978  loss_ce_1: 0.2433  loss_mask_1: 0.2809  loss_dice_1: 2.306  loss_ce_2: 0.1443  loss_mask_2: 0.2585  loss_dice_2: 2.122  loss_ce_3: 0.1263  loss_mask_3: 0.2565  loss_dice_3: 2.059  loss_ce_4: 0.1121  loss_mask_4: 0.2623  loss_dice_4: 1.971  loss_ce_5: 0.1104  loss_mask_5: 0.2655  loss_dice_5: 1.947  loss_ce_6: 0.1144  loss_mask_6: 0.2755  loss_dice_6: 1.948  loss_ce_7: 0.114  loss_mask_7: 0.2679  loss_dice_7: 1.91  loss_ce_8: 0.1176  loss_mask_8: 0.2755  loss_dice_8: 1.891  loss_mgm_entropy: 0.00491    time: 0.4367  last_time: 0.4362  data_time: 0.0036  last_data_time: 0.0033   lr: 1e-05  max_mem: 15545M
[08/30 23:35:13] d2.utils.events INFO:  eta: 0:18:37  iter: 1439  total_loss: 23.44  loss_ce: 0.1106  loss_mask: 0.2201  loss_dice: 1.747  loss_ce_0: 0.791  loss_mask_0: 0.2767  loss_dice_0: 2.927  loss_ce_1: 0.2371  loss_mask_1: 0.2267  loss_dice_1: 2.209  loss_ce_2: 0.1365  loss_mask_2: 0.1966  loss_dice_2: 1.9  loss_ce_3: 0.1033  loss_mask_3: 0.2003  loss_dice_3: 1.822  loss_ce_4: 0.09973  loss_mask_4: 0.2088  loss_dice_4: 1.77  loss_ce_5: 0.09277  loss_mask_5: 0.2063  loss_dice_5: 1.78  loss_ce_6: 0.09543  loss_mask_6: 0.2101  loss_dice_6: 1.727  loss_ce_7: 0.09973  loss_mask_7: 0.2077  loss_dice_7: 1.751  loss_ce_8: 0.1069  loss_mask_8: 0.2088  loss_dice_8: 1.747  loss_mgm_entropy: 0.004876    time: 0.4367  last_time: 0.4363  data_time: 0.0034  last_data_time: 0.0035   lr: 1e-05  max_mem: 15545M
[08/30 23:35:22] d2.utils.events INFO:  eta: 0:18:28  iter: 1459  total_loss: 23.11  loss_ce: 0.1212  loss_mask: 0.2206  loss_dice: 1.718  loss_ce_0: 0.7857  loss_mask_0: 0.2826  loss_dice_0: 2.882  loss_ce_1: 0.2367  loss_mask_1: 0.2376  loss_dice_1: 2.13  loss_ce_2: 0.1487  loss_mask_2: 0.2219  loss_dice_2: 1.857  loss_ce_3: 0.1317  loss_mask_3: 0.2175  loss_dice_3: 1.766  loss_ce_4: 0.1131  loss_mask_4: 0.2216  loss_dice_4: 1.755  loss_ce_5: 0.1088  loss_mask_5: 0.2171  loss_dice_5: 1.684  loss_ce_6: 0.1143  loss_mask_6: 0.2163  loss_dice_6: 1.7  loss_ce_7: 0.1169  loss_mask_7: 0.2183  loss_dice_7: 1.69  loss_ce_8: 0.1148  loss_mask_8: 0.2257  loss_dice_8: 1.711  loss_mgm_entropy: 0.004891    time: 0.4367  last_time: 0.4352  data_time: 0.0034  last_data_time: 0.0030   lr: 1e-05  max_mem: 15545M
[08/30 23:35:31] d2.utils.events INFO:  eta: 0:18:19  iter: 1479  total_loss: 23.6  loss_ce: 0.113  loss_mask: 0.2602  loss_dice: 1.827  loss_ce_0: 0.7971  loss_mask_0: 0.2962  loss_dice_0: 2.849  loss_ce_1: 0.2444  loss_mask_1: 0.2488  loss_dice_1: 2.145  loss_ce_2: 0.1408  loss_mask_2: 0.2328  loss_dice_2: 1.948  loss_ce_3: 0.1228  loss_mask_3: 0.234  loss_dice_3: 1.869  loss_ce_4: 0.1145  loss_mask_4: 0.2387  loss_dice_4: 1.797  loss_ce_5: 0.1112  loss_mask_5: 0.2403  loss_dice_5: 1.733  loss_ce_6: 0.1136  loss_mask_6: 0.2322  loss_dice_6: 1.764  loss_ce_7: 0.1102  loss_mask_7: 0.2341  loss_dice_7: 1.768  loss_ce_8: 0.1051  loss_mask_8: 0.246  loss_dice_8: 1.784  loss_mgm_entropy: 0.004979    time: 0.4367  last_time: 0.4363  data_time: 0.0034  last_data_time: 0.0033   lr: 1e-05  max_mem: 15545M
[08/30 23:35:39] d2.utils.events INFO:  eta: 0:18:11  iter: 1499  total_loss: 22.4  loss_ce: 0.1096  loss_mask: 0.2062  loss_dice: 1.607  loss_ce_0: 0.7757  loss_mask_0: 0.2652  loss_dice_0: 2.834  loss_ce_1: 0.2259  loss_mask_1: 0.2264  loss_dice_1: 2.097  loss_ce_2: 0.1433  loss_mask_2: 0.1947  loss_dice_2: 1.809  loss_ce_3: 0.1225  loss_mask_3: 0.2126  loss_dice_3: 1.724  loss_ce_4: 0.1135  loss_mask_4: 0.206  loss_dice_4: 1.73  loss_ce_5: 0.09832  loss_mask_5: 0.201  loss_dice_5: 1.656  loss_ce_6: 0.1034  loss_mask_6: 0.2003  loss_dice_6: 1.653  loss_ce_7: 0.1102  loss_mask_7: 0.2092  loss_dice_7: 1.604  loss_ce_8: 0.106  loss_mask_8: 0.2066  loss_dice_8: 1.606  loss_mgm_entropy: 0.004934    time: 0.4367  last_time: 0.4351  data_time: 0.0035  last_data_time: 0.0037   lr: 1e-05  max_mem: 15545M
[08/30 23:35:48] d2.utils.events INFO:  eta: 0:18:02  iter: 1519  total_loss: 21.21  loss_ce: 0.1151  loss_mask: 0.2018  loss_dice: 1.505  loss_ce_0: 0.7825  loss_mask_0: 0.26  loss_dice_0: 2.783  loss_ce_1: 0.2123  loss_mask_1: 0.2304  loss_dice_1: 2.038  loss_ce_2: 0.137  loss_mask_2: 0.2064  loss_dice_2: 1.718  loss_ce_3: 0.1205  loss_mask_3: 0.2001  loss_dice_3: 1.615  loss_ce_4: 0.09984  loss_mask_4: 0.2029  loss_dice_4: 1.579  loss_ce_5: 0.09343  loss_mask_5: 0.2031  loss_dice_5: 1.548  loss_ce_6: 0.09816  loss_mask_6: 0.1974  loss_dice_6: 1.548  loss_ce_7: 0.1001  loss_mask_7: 0.1877  loss_dice_7: 1.518  loss_ce_8: 0.1039  loss_mask_8: 0.1962  loss_dice_8: 1.545  loss_mgm_entropy: 0.004918    time: 0.4367  last_time: 0.4363  data_time: 0.0036  last_data_time: 0.0036   lr: 1e-05  max_mem: 15545M
[08/30 23:35:57] d2.utils.events INFO:  eta: 0:17:53  iter: 1539  total_loss: 23.27  loss_ce: 0.1168  loss_mask: 0.2518  loss_dice: 1.672  loss_ce_0: 0.7844  loss_mask_0: 0.324  loss_dice_0: 2.809  loss_ce_1: 0.237  loss_mask_1: 0.262  loss_dice_1: 2.132  loss_ce_2: 0.1462  loss_mask_2: 0.2478  loss_dice_2: 1.896  loss_ce_3: 0.1296  loss_mask_3: 0.2446  loss_dice_3: 1.794  loss_ce_4: 0.1147  loss_mask_4: 0.2588  loss_dice_4: 1.744  loss_ce_5: 0.1149  loss_mask_5: 0.2413  loss_dice_5: 1.73  loss_ce_6: 0.1176  loss_mask_6: 0.243  loss_dice_6: 1.702  loss_ce_7: 0.1125  loss_mask_7: 0.244  loss_dice_7: 1.687  loss_ce_8: 0.1156  loss_mask_8: 0.2444  loss_dice_8: 1.677  loss_mgm_entropy: 0.004913    time: 0.4367  last_time: 0.4365  data_time: 0.0035  last_data_time: 0.0040   lr: 1e-05  max_mem: 15545M
[08/30 23:36:06] d2.utils.events INFO:  eta: 0:17:44  iter: 1559  total_loss: 21.66  loss_ce: 0.12  loss_mask: 0.1819  loss_dice: 1.556  loss_ce_0: 0.7861  loss_mask_0: 0.2597  loss_dice_0: 2.701  loss_ce_1: 0.2198  loss_mask_1: 0.2146  loss_dice_1: 1.961  loss_ce_2: 0.1574  loss_mask_2: 0.1841  loss_dice_2: 1.731  loss_ce_3: 0.1276  loss_mask_3: 0.1709  loss_dice_3: 1.647  loss_ce_4: 0.1136  loss_mask_4: 0.1833  loss_dice_4: 1.632  loss_ce_5: 0.1143  loss_mask_5: 0.1828  loss_dice_5: 1.649  loss_ce_6: 0.1155  loss_mask_6: 0.1805  loss_dice_6: 1.597  loss_ce_7: 0.1161  loss_mask_7: 0.1783  loss_dice_7: 1.577  loss_ce_8: 0.1176  loss_mask_8: 0.1785  loss_dice_8: 1.574  loss_mgm_entropy: 0.004837    time: 0.4367  last_time: 0.4355  data_time: 0.0035  last_data_time: 0.0036   lr: 1e-05  max_mem: 15545M
[08/30 23:36:14] d2.utils.events INFO:  eta: 0:17:35  iter: 1579  total_loss: 20.55  loss_ce: 0.1166  loss_mask: 0.1564  loss_dice: 1.434  loss_ce_0: 0.7879  loss_mask_0: 0.221  loss_dice_0: 2.66  loss_ce_1: 0.2093  loss_mask_1: 0.1877  loss_dice_1: 1.949  loss_ce_2: 0.1444  loss_mask_2: 0.165  loss_dice_2: 1.658  loss_ce_3: 0.1289  loss_mask_3: 0.1687  loss_dice_3: 1.572  loss_ce_4: 0.1024  loss_mask_4: 0.1627  loss_dice_4: 1.538  loss_ce_5: 0.09756  loss_mask_5: 0.1638  loss_dice_5: 1.512  loss_ce_6: 0.1085  loss_mask_6: 0.1625  loss_dice_6: 1.492  loss_ce_7: 0.1095  loss_mask_7: 0.1604  loss_dice_7: 1.442  loss_ce_8: 0.1145  loss_mask_8: 0.1668  loss_dice_8: 1.439  loss_mgm_entropy: 0.004768    time: 0.4367  last_time: 0.4365  data_time: 0.0035  last_data_time: 0.0036   lr: 1e-05  max_mem: 15545M
[08/30 23:36:23] d2.utils.events INFO:  eta: 0:17:27  iter: 1599  total_loss: 20.3  loss_ce: 0.1255  loss_mask: 0.1826  loss_dice: 1.442  loss_ce_0: 0.7748  loss_mask_0: 0.2385  loss_dice_0: 2.62  loss_ce_1: 0.2244  loss_mask_1: 0.1865  loss_dice_1: 1.923  loss_ce_2: 0.1485  loss_mask_2: 0.172  loss_dice_2: 1.63  loss_ce_3: 0.1318  loss_mask_3: 0.1951  loss_dice_3: 1.541  loss_ce_4: 0.1034  loss_mask_4: 0.1827  loss_dice_4: 1.51  loss_ce_5: 0.1073  loss_mask_5: 0.1812  loss_dice_5: 1.471  loss_ce_6: 0.1099  loss_mask_6: 0.1884  loss_dice_6: 1.454  loss_ce_7: 0.1149  loss_mask_7: 0.1754  loss_dice_7: 1.446  loss_ce_8: 0.1186  loss_mask_8: 0.1805  loss_dice_8: 1.432  loss_mgm_entropy: 0.004782    time: 0.4367  last_time: 0.4348  data_time: 0.0034  last_data_time: 0.0039   lr: 1e-05  max_mem: 15545M
[08/30 23:36:32] d2.utils.events INFO:  eta: 0:17:18  iter: 1619  total_loss: 21.67  loss_ce: 0.1104  loss_mask: 0.2535  loss_dice: 1.634  loss_ce_0: 0.785  loss_mask_0: 0.2755  loss_dice_0: 2.644  loss_ce_1: 0.2178  loss_mask_1: 0.252  loss_dice_1: 1.958  loss_ce_2: 0.1413  loss_mask_2: 0.2377  loss_dice_2: 1.724  loss_ce_3: 0.1212  loss_mask_3: 0.2347  loss_dice_3: 1.667  loss_ce_4: 0.1038  loss_mask_4: 0.2542  loss_dice_4: 1.643  loss_ce_5: 0.09821  loss_mask_5: 0.2565  loss_dice_5: 1.65  loss_ce_6: 0.1035  loss_mask_6: 0.2658  loss_dice_6: 1.677  loss_ce_7: 0.1091  loss_mask_7: 0.2621  loss_dice_7: 1.587  loss_ce_8: 0.1113  loss_mask_8: 0.2522  loss_dice_8: 1.652  loss_mgm_entropy: 0.004808    time: 0.4367  last_time: 0.4362  data_time: 0.0037  last_data_time: 0.0035   lr: 1e-05  max_mem: 15545M
[08/30 23:36:41] d2.utils.events INFO:  eta: 0:17:09  iter: 1639  total_loss: 20.62  loss_ce: 0.1236  loss_mask: 0.2082  loss_dice: 1.453  loss_ce_0: 0.7772  loss_mask_0: 0.2516  loss_dice_0: 2.607  loss_ce_1: 0.2092  loss_mask_1: 0.2163  loss_dice_1: 1.863  loss_ce_2: 0.1418  loss_mask_2: 0.2057  loss_dice_2: 1.605  loss_ce_3: 0.125  loss_mask_3: 0.1965  loss_dice_3: 1.544  loss_ce_4: 0.1102  loss_mask_4: 0.1958  loss_dice_4: 1.465  loss_ce_5: 0.09826  loss_mask_5: 0.2106  loss_dice_5: 1.492  loss_ce_6: 0.109  loss_mask_6: 0.2003  loss_dice_6: 1.485  loss_ce_7: 0.111  loss_mask_7: 0.2055  loss_dice_7: 1.434  loss_ce_8: 0.1118  loss_mask_8: 0.2106  loss_dice_8: 1.458  loss_mgm_entropy: 0.004861    time: 0.4366  last_time: 0.4365  data_time: 0.0037  last_data_time: 0.0035   lr: 1e-05  max_mem: 15545M
[08/30 23:36:49] d2.utils.events INFO:  eta: 0:17:00  iter: 1659  total_loss: 18.81  loss_ce: 0.1198  loss_mask: 0.1557  loss_dice: 1.312  loss_ce_0: 0.7762  loss_mask_0: 0.2436  loss_dice_0: 2.546  loss_ce_1: 0.213  loss_mask_1: 0.1871  loss_dice_1: 1.781  loss_ce_2: 0.1439  loss_mask_2: 0.1652  loss_dice_2: 1.505  loss_ce_3: 0.1338  loss_mask_3: 0.1591  loss_dice_3: 1.373  loss_ce_4: 0.1274  loss_mask_4: 0.1572  loss_dice_4: 1.358  loss_ce_5: 0.1032  loss_mask_5: 0.1563  loss_dice_5: 1.365  loss_ce_6: 0.1169  loss_mask_6: 0.1546  loss_dice_6: 1.354  loss_ce_7: 0.1154  loss_mask_7: 0.1613  loss_dice_7: 1.338  loss_ce_8: 0.1103  loss_mask_8: 0.16  loss_dice_8: 1.309  loss_mgm_entropy: 0.004809    time: 0.4366  last_time: 0.4380  data_time: 0.0034  last_data_time: 0.0035   lr: 1e-05  max_mem: 15545M
[08/30 23:36:58] d2.utils.events INFO:  eta: 0:16:52  iter: 1679  total_loss: 18.81  loss_ce: 0.1315  loss_mask: 0.1758  loss_dice: 1.291  loss_ce_0: 0.7741  loss_mask_0: 0.2446  loss_dice_0: 2.498  loss_ce_1: 0.2095  loss_mask_1: 0.2164  loss_dice_1: 1.763  loss_ce_2: 0.1457  loss_mask_2: 0.1874  loss_dice_2: 1.501  loss_ce_3: 0.1313  loss_mask_3: 0.1868  loss_dice_3: 1.381  loss_ce_4: 0.1257  loss_mask_4: 0.1763  loss_dice_4: 1.326  loss_ce_5: 0.1124  loss_mask_5: 0.178  loss_dice_5: 1.331  loss_ce_6: 0.1158  loss_mask_6: 0.1795  loss_dice_6: 1.316  loss_ce_7: 0.1188  loss_mask_7: 0.1748  loss_dice_7: 1.281  loss_ce_8: 0.1268  loss_mask_8: 0.1671  loss_dice_8: 1.268  loss_mgm_entropy: 0.004799    time: 0.4366  last_time: 0.4352  data_time: 0.0035  last_data_time: 0.0037   lr: 1e-05  max_mem: 15545M
[08/30 23:37:07] d2.utils.events INFO:  eta: 0:16:43  iter: 1699  total_loss: 17.97  loss_ce: 0.136  loss_mask: 0.1433  loss_dice: 1.211  loss_ce_0: 0.7711  loss_mask_0: 0.2116  loss_dice_0: 2.43  loss_ce_1: 0.2032  loss_mask_1: 0.1614  loss_dice_1: 1.712  loss_ce_2: 0.1466  loss_mask_2: 0.1503  loss_dice_2: 1.455  loss_ce_3: 0.1299  loss_mask_3: 0.1341  loss_dice_3: 1.349  loss_ce_4: 0.1243  loss_mask_4: 0.1408  loss_dice_4: 1.295  loss_ce_5: 0.1222  loss_mask_5: 0.1417  loss_dice_5: 1.276  loss_ce_6: 0.1223  loss_mask_6: 0.1356  loss_dice_6: 1.261  loss_ce_7: 0.1268  loss_mask_7: 0.1387  loss_dice_7: 1.238  loss_ce_8: 0.1297  loss_mask_8: 0.1403  loss_dice_8: 1.229  loss_mgm_entropy: 0.004759    time: 0.4366  last_time: 0.4372  data_time: 0.0035  last_data_time: 0.0033   lr: 1e-05  max_mem: 15545M
[08/30 23:37:16] d2.utils.events INFO:  eta: 0:16:34  iter: 1719  total_loss: 18.34  loss_ce: 0.1401  loss_mask: 0.1551  loss_dice: 1.212  loss_ce_0: 0.769  loss_mask_0: 0.2492  loss_dice_0: 2.496  loss_ce_1: 0.2034  loss_mask_1: 0.2083  loss_dice_1: 1.751  loss_ce_2: 0.1532  loss_mask_2: 0.1803  loss_dice_2: 1.502  loss_ce_3: 0.1435  loss_mask_3: 0.1651  loss_dice_3: 1.342  loss_ce_4: 0.1312  loss_mask_4: 0.166  loss_dice_4: 1.313  loss_ce_5: 0.1248  loss_mask_5: 0.165  loss_dice_5: 1.295  loss_ce_6: 0.1267  loss_mask_6: 0.1644  loss_dice_6: 1.238  loss_ce_7: 0.1278  loss_mask_7: 0.1526  loss_dice_7: 1.225  loss_ce_8: 0.144  loss_mask_8: 0.1473  loss_dice_8: 1.216  loss_mgm_entropy: 0.004778    time: 0.4366  last_time: 0.4368  data_time: 0.0033  last_data_time: 0.0032   lr: 1e-05  max_mem: 15545M
[08/30 23:37:24] d2.utils.events INFO:  eta: 0:16:25  iter: 1739  total_loss: 17.44  loss_ce: 0.135  loss_mask: 0.1484  loss_dice: 1.173  loss_ce_0: 0.7651  loss_mask_0: 0.2209  loss_dice_0: 2.396  loss_ce_1: 0.1932  loss_mask_1: 0.1719  loss_dice_1: 1.657  loss_ce_2: 0.143  loss_mask_2: 0.1634  loss_dice_2: 1.4  loss_ce_3: 0.1329  loss_mask_3: 0.1517  loss_dice_3: 1.325  loss_ce_4: 0.1303  loss_mask_4: 0.1487  loss_dice_4: 1.256  loss_ce_5: 0.1257  loss_mask_5: 0.1442  loss_dice_5: 1.203  loss_ce_6: 0.1263  loss_mask_6: 0.1461  loss_dice_6: 1.223  loss_ce_7: 0.1253  loss_mask_7: 0.1471  loss_dice_7: 1.185  loss_ce_8: 0.1228  loss_mask_8: 0.1471  loss_dice_8: 1.176  loss_mgm_entropy: 0.004767    time: 0.4366  last_time: 0.4346  data_time: 0.0036  last_data_time: 0.0034   lr: 1e-05  max_mem: 15545M
[08/30 23:37:33] d2.utils.events INFO:  eta: 0:16:17  iter: 1759  total_loss: 18.26  loss_ce: 0.1489  loss_mask: 0.174  loss_dice: 1.22  loss_ce_0: 0.7645  loss_mask_0: 0.2562  loss_dice_0: 2.446  loss_ce_1: 0.2116  loss_mask_1: 0.2139  loss_dice_1: 1.669  loss_ce_2: 0.1602  loss_mask_2: 0.1902  loss_dice_2: 1.433  loss_ce_3: 0.146  loss_mask_3: 0.1832  loss_dice_3: 1.315  loss_ce_4: 0.1424  loss_mask_4: 0.1769  loss_dice_4: 1.244  loss_ce_5: 0.1313  loss_mask_5: 0.1779  loss_dice_5: 1.272  loss_ce_6: 0.1358  loss_mask_6: 0.1708  loss_dice_6: 1.24  loss_ce_7: 0.1384  loss_mask_7: 0.1768  loss_dice_7: 1.226  loss_ce_8: 0.1522  loss_mask_8: 0.1751  loss_dice_8: 1.219  loss_mgm_entropy: 0.004814    time: 0.4366  last_time: 0.4364  data_time: 0.0034  last_data_time: 0.0037   lr: 1e-05  max_mem: 15545M
[08/30 23:37:42] d2.utils.events INFO:  eta: 0:16:08  iter: 1779  total_loss: 18.21  loss_ce: 0.142  loss_mask: 0.1744  loss_dice: 1.279  loss_ce_0: 0.7541  loss_mask_0: 0.2277  loss_dice_0: 2.389  loss_ce_1: 0.1883  loss_mask_1: 0.1925  loss_dice_1: 1.734  loss_ce_2: 0.1426  loss_mask_2: 0.183  loss_dice_2: 1.428  loss_ce_3: 0.132  loss_mask_3: 0.1718  loss_dice_3: 1.363  loss_ce_4: 0.1258  loss_mask_4: 0.1749  loss_dice_4: 1.293  loss_ce_5: 0.1202  loss_mask_5: 0.1707  loss_dice_5: 1.277  loss_ce_6: 0.1285  loss_mask_6: 0.1671  loss_dice_6: 1.281  loss_ce_7: 0.1288  loss_mask_7: 0.1703  loss_dice_7: 1.275  loss_ce_8: 0.1295  loss_mask_8: 0.1709  loss_dice_8: 1.305  loss_mgm_entropy: 0.004853    time: 0.4366  last_time: 0.4370  data_time: 0.0036  last_data_time: 0.0030   lr: 1e-05  max_mem: 15545M
[08/30 23:37:50] d2.utils.events INFO:  eta: 0:15:59  iter: 1799  total_loss: 18.16  loss_ce: 0.146  loss_mask: 0.1693  loss_dice: 1.242  loss_ce_0: 0.7658  loss_mask_0: 0.2319  loss_dice_0: 2.314  loss_ce_1: 0.2013  loss_mask_1: 0.1703  loss_dice_1: 1.61  loss_ce_2: 0.1468  loss_mask_2: 0.1656  loss_dice_2: 1.419  loss_ce_3: 0.1399  loss_mask_3: 0.16  loss_dice_3: 1.346  loss_ce_4: 0.1383  loss_mask_4: 0.1519  loss_dice_4: 1.294  loss_ce_5: 0.1331  loss_mask_5: 0.1527  loss_dice_5: 1.265  loss_ce_6: 0.1398  loss_mask_6: 0.1524  loss_dice_6: 1.289  loss_ce_7: 0.1423  loss_mask_7: 0.1671  loss_dice_7: 1.265  loss_ce_8: 0.139  loss_mask_8: 0.1684  loss_dice_8: 1.256  loss_mgm_entropy: 0.004896    time: 0.4366  last_time: 0.4360  data_time: 0.0035  last_data_time: 0.0041   lr: 1e-05  max_mem: 15545M
[08/30 23:37:59] d2.utils.events INFO:  eta: 0:15:50  iter: 1819  total_loss: 16.67  loss_ce: 0.1389  loss_mask: 0.1325  loss_dice: 1.158  loss_ce_0: 0.7606  loss_mask_0: 0.1944  loss_dice_0: 2.259  loss_ce_1: 0.1923  loss_mask_1: 0.151  loss_dice_1: 1.585  loss_ce_2: 0.1457  loss_mask_2: 0.1416  loss_dice_2: 1.323  loss_ce_3: 0.134  loss_mask_3: 0.1367  loss_dice_3: 1.204  loss_ce_4: 0.1263  loss_mask_4: 0.1351  loss_dice_4: 1.207  loss_ce_5: 0.1261  loss_mask_5: 0.132  loss_dice_5: 1.235  loss_ce_6: 0.1291  loss_mask_6: 0.1396  loss_dice_6: 1.179  loss_ce_7: 0.1284  loss_mask_7: 0.1338  loss_dice_7: 1.158  loss_ce_8: 0.1332  loss_mask_8: 0.1354  loss_dice_8: 1.144  loss_mgm_entropy: 0.004741    time: 0.4366  last_time: 0.4355  data_time: 0.0036  last_data_time: 0.0039   lr: 1e-05  max_mem: 15545M
[08/30 23:38:08] d2.utils.events INFO:  eta: 0:15:42  iter: 1839  total_loss: 15.81  loss_ce: 0.1336  loss_mask: 0.1332  loss_dice: 1.076  loss_ce_0: 0.7558  loss_mask_0: 0.1987  loss_dice_0: 2.259  loss_ce_1: 0.184  loss_mask_1: 0.1546  loss_dice_1: 1.503  loss_ce_2: 0.1375  loss_mask_2: 0.1361  loss_dice_2: 1.298  loss_ce_3: 0.1273  loss_mask_3: 0.1199  loss_dice_3: 1.158  loss_ce_4: 0.1244  loss_mask_4: 0.1276  loss_dice_4: 1.126  loss_ce_5: 0.1188  loss_mask_5: 0.1233  loss_dice_5: 1.076  loss_ce_6: 0.1273  loss_mask_6: 0.123  loss_dice_6: 1.071  loss_ce_7: 0.1235  loss_mask_7: 0.1192  loss_dice_7: 1.053  loss_ce_8: 0.1399  loss_mask_8: 0.1292  loss_dice_8: 1.094  loss_mgm_entropy: 0.004764    time: 0.4366  last_time: 0.4354  data_time: 0.0035  last_data_time: 0.0037   lr: 1e-05  max_mem: 15545M
[08/30 23:38:17] d2.utils.events INFO:  eta: 0:15:33  iter: 1859  total_loss: 17.1  loss_ce: 0.1405  loss_mask: 0.1401  loss_dice: 1.12  loss_ce_0: 0.7496  loss_mask_0: 0.2126  loss_dice_0: 2.249  loss_ce_1: 0.1902  loss_mask_1: 0.1714  loss_dice_1: 1.624  loss_ce_2: 0.1443  loss_mask_2: 0.1573  loss_dice_2: 1.349  loss_ce_3: 0.1374  loss_mask_3: 0.1413  loss_dice_3: 1.292  loss_ce_4: 0.134  loss_mask_4: 0.1468  loss_dice_4: 1.212  loss_ce_5: 0.1269  loss_mask_5: 0.1455  loss_dice_5: 1.207  loss_ce_6: 0.1388  loss_mask_6: 0.1487  loss_dice_6: 1.193  loss_ce_7: 0.1416  loss_mask_7: 0.1446  loss_dice_7: 1.184  loss_ce_8: 0.1408  loss_mask_8: 0.1473  loss_dice_8: 1.147  loss_mgm_entropy: 0.0048    time: 0.4366  last_time: 0.4374  data_time: 0.0035  last_data_time: 0.0034   lr: 1e-05  max_mem: 15545M
[08/30 23:38:25] d2.utils.events INFO:  eta: 0:15:24  iter: 1879  total_loss: 15.86  loss_ce: 0.1473  loss_mask: 0.1276  loss_dice: 1.046  loss_ce_0: 0.7444  loss_mask_0: 0.2062  loss_dice_0: 2.249  loss_ce_1: 0.1984  loss_mask_1: 0.1585  loss_dice_1: 1.473  loss_ce_2: 0.141  loss_mask_2: 0.1388  loss_dice_2: 1.229  loss_ce_3: 0.1324  loss_mask_3: 0.1356  loss_dice_3: 1.123  loss_ce_4: 0.1318  loss_mask_4: 0.1317  loss_dice_4: 1.09  loss_ce_5: 0.1277  loss_mask_5: 0.129  loss_dice_5: 1.073  loss_ce_6: 0.1326  loss_mask_6: 0.1256  loss_dice_6: 1.066  loss_ce_7: 0.1375  loss_mask_7: 0.1309  loss_dice_7: 1.043  loss_ce_8: 0.145  loss_mask_8: 0.1276  loss_dice_8: 1.043  loss_mgm_entropy: 0.004746    time: 0.4366  last_time: 0.4358  data_time: 0.0034  last_data_time: 0.0038   lr: 1e-05  max_mem: 15545M
[08/30 23:38:34] d2.utils.events INFO:  eta: 0:15:16  iter: 1899  total_loss: 17.09  loss_ce: 0.135  loss_mask: 0.1746  loss_dice: 1.191  loss_ce_0: 0.7443  loss_mask_0: 0.2082  loss_dice_0: 2.237  loss_ce_1: 0.1886  loss_mask_1: 0.1589  loss_dice_1: 1.547  loss_ce_2: 0.1381  loss_mask_2: 0.1563  loss_dice_2: 1.296  loss_ce_3: 0.1328  loss_mask_3: 0.1503  loss_dice_3: 1.205  loss_ce_4: 0.1255  loss_mask_4: 0.1473  loss_dice_4: 1.18  loss_ce_5: 0.1111  loss_mask_5: 0.1527  loss_dice_5: 1.192  loss_ce_6: 0.1275  loss_mask_6: 0.1565  loss_dice_6: 1.175  loss_ce_7: 0.1285  loss_mask_7: 0.1633  loss_dice_7: 1.174  loss_ce_8: 0.1311  loss_mask_8: 0.1672  loss_dice_8: 1.151  loss_mgm_entropy: 0.004837    time: 0.4366  last_time: 0.4369  data_time: 0.0035  last_data_time: 0.0031   lr: 1e-05  max_mem: 15545M
[08/30 23:38:43] d2.utils.events INFO:  eta: 0:15:07  iter: 1919  total_loss: 17.35  loss_ce: 0.1621  loss_mask: 0.1595  loss_dice: 1.12  loss_ce_0: 0.7587  loss_mask_0: 0.2171  loss_dice_0: 2.253  loss_ce_1: 0.1943  loss_mask_1: 0.1916  loss_dice_1: 1.573  loss_ce_2: 0.1467  loss_mask_2: 0.1751  loss_dice_2: 1.4  loss_ce_3: 0.147  loss_mask_3: 0.1738  loss_dice_3: 1.274  loss_ce_4: 0.1405  loss_mask_4: 0.159  loss_dice_4: 1.221  loss_ce_5: 0.1283  loss_mask_5: 0.157  loss_dice_5: 1.245  loss_ce_6: 0.1473  loss_mask_6: 0.1538  loss_dice_6: 1.165  loss_ce_7: 0.1444  loss_mask_7: 0.1546  loss_dice_7: 1.168  loss_ce_8: 0.1641  loss_mask_8: 0.1713  loss_dice_8: 1.196  loss_mgm_entropy: 0.004731    time: 0.4366  last_time: 0.4353  data_time: 0.0035  last_data_time: 0.0035   lr: 1e-05  max_mem: 15545M
[08/30 23:38:52] d2.utils.events INFO:  eta: 0:14:58  iter: 1939  total_loss: 15.88  loss_ce: 0.161  loss_mask: 0.1324  loss_dice: 1.076  loss_ce_0: 0.7616  loss_mask_0: 0.1958  loss_dice_0: 2.103  loss_ce_1: 0.1903  loss_mask_1: 0.1444  loss_dice_1: 1.465  loss_ce_2: 0.1484  loss_mask_2: 0.1302  loss_dice_2: 1.204  loss_ce_3: 0.138  loss_mask_3: 0.1264  loss_dice_3: 1.132  loss_ce_4: 0.1403  loss_mask_4: 0.1299  loss_dice_4: 1.089  loss_ce_5: 0.1318  loss_mask_5: 0.1358  loss_dice_5: 1.084  loss_ce_6: 0.1309  loss_mask_6: 0.1311  loss_dice_6: 1.082  loss_ce_7: 0.1426  loss_mask_7: 0.128  loss_dice_7: 1.052  loss_ce_8: 0.1505  loss_mask_8: 0.1308  loss_dice_8: 1.044  loss_mgm_entropy: 0.004744    time: 0.4366  last_time: 0.4364  data_time: 0.0035  last_data_time: 0.0038   lr: 1e-05  max_mem: 15545M
[08/30 23:39:00] d2.utils.events INFO:  eta: 0:14:49  iter: 1959  total_loss: 15.12  loss_ce: 0.1468  loss_mask: 0.1403  loss_dice: 1.024  loss_ce_0: 0.7322  loss_mask_0: 0.1935  loss_dice_0: 2.223  loss_ce_1: 0.1825  loss_mask_1: 0.1453  loss_dice_1: 1.443  loss_ce_2: 0.1497  loss_mask_2: 0.1343  loss_dice_2: 1.2  loss_ce_3: 0.1355  loss_mask_3: 0.1266  loss_dice_3: 1.083  loss_ce_4: 0.1268  loss_mask_4: 0.1235  loss_dice_4: 1.031  loss_ce_5: 0.125  loss_mask_5: 0.1312  loss_dice_5: 1.036  loss_ce_6: 0.1318  loss_mask_6: 0.1281  loss_dice_6: 1.01  loss_ce_7: 0.1417  loss_mask_7: 0.1254  loss_dice_7: 1.025  loss_ce_8: 0.1421  loss_mask_8: 0.1339  loss_dice_8: 1.037  loss_mgm_entropy: 0.004783    time: 0.4366  last_time: 0.4382  data_time: 0.0033  last_data_time: 0.0030   lr: 1e-05  max_mem: 15545M
[08/30 23:39:09] d2.utils.events INFO:  eta: 0:14:41  iter: 1979  total_loss: 14.46  loss_ce: 0.138  loss_mask: 0.09585  loss_dice: 0.9284  loss_ce_0: 0.7349  loss_mask_0: 0.16  loss_dice_0: 2.11  loss_ce_1: 0.182  loss_mask_1: 0.134  loss_dice_1: 1.365  loss_ce_2: 0.1364  loss_mask_2: 0.1197  loss_dice_2: 1.132  loss_ce_3: 0.1297  loss_mask_3: 0.1028  loss_dice_3: 1.019  loss_ce_4: 0.1362  loss_mask_4: 0.09775  loss_dice_4: 0.9786  loss_ce_5: 0.1243  loss_mask_5: 0.09933  loss_dice_5: 0.9747  loss_ce_6: 0.1235  loss_mask_6: 0.09666  loss_dice_6: 0.9566  loss_ce_7: 0.1321  loss_mask_7: 0.09087  loss_dice_7: 0.9631  loss_ce_8: 0.1399  loss_mask_8: 0.09712  loss_dice_8: 0.9325  loss_mgm_entropy: 0.00466    time: 0.4366  last_time: 0.4359  data_time: 0.0034  last_data_time: 0.0033   lr: 1e-05  max_mem: 15545M
[08/30 23:39:18] d2.utils.events INFO:  eta: 0:14:32  iter: 1999  total_loss: 16.84  loss_ce: 0.1628  loss_mask: 0.1521  loss_dice: 1.084  loss_ce_0: 0.7322  loss_mask_0: 0.2018  loss_dice_0: 2.127  loss_ce_1: 0.1903  loss_mask_1: 0.1723  loss_dice_1: 1.525  loss_ce_2: 0.1546  loss_mask_2: 0.1654  loss_dice_2: 1.296  loss_ce_3: 0.1508  loss_mask_3: 0.1537  loss_dice_3: 1.226  loss_ce_4: 0.1447  loss_mask_4: 0.1557  loss_dice_4: 1.164  loss_ce_5: 0.1474  loss_mask_5: 0.1504  loss_dice_5: 1.152  loss_ce_6: 0.1532  loss_mask_6: 0.1373  loss_dice_6: 1.094  loss_ce_7: 0.1651  loss_mask_7: 0.1418  loss_dice_7: 1.096  loss_ce_8: 0.1609  loss_mask_8: 0.1518  loss_dice_8: 1.089  loss_mgm_entropy: 0.004663    time: 0.4366  last_time: 0.4365  data_time: 0.0035  last_data_time: 0.0033   lr: 1e-05  max_mem: 15545M
[08/30 23:39:27] d2.utils.events INFO:  eta: 0:14:23  iter: 2019  total_loss: 16.01  loss_ce: 0.1487  loss_mask: 0.1277  loss_dice: 1.005  loss_ce_0: 0.748  loss_mask_0: 0.196  loss_dice_0: 2.129  loss_ce_1: 0.1808  loss_mask_1: 0.1668  loss_dice_1: 1.504  loss_ce_2: 0.1478  loss_mask_2: 0.1479  loss_dice_2: 1.269  loss_ce_3: 0.1309  loss_mask_3: 0.1275  loss_dice_3: 1.172  loss_ce_4: 0.1368  loss_mask_4: 0.1239  loss_dice_4: 1.086  loss_ce_5: 0.1376  loss_mask_5: 0.1245  loss_dice_5: 1.063  loss_ce_6: 0.1383  loss_mask_6: 0.1264  loss_dice_6: 1.048  loss_ce_7: 0.142  loss_mask_7: 0.1239  loss_dice_7: 1.025  loss_ce_8: 0.1505  loss_mask_8: 0.1208  loss_dice_8: 1.001  loss_mgm_entropy: 0.004673    time: 0.4366  last_time: 0.4384  data_time: 0.0035  last_data_time: 0.0033   lr: 1e-06  max_mem: 15545M
[08/30 23:39:35] d2.utils.events INFO:  eta: 0:14:14  iter: 2039  total_loss: 13.83  loss_ce: 0.1426  loss_mask: 0.1103  loss_dice: 0.8556  loss_ce_0: 0.725  loss_mask_0: 0.2181  loss_dice_0: 2.085  loss_ce_1: 0.1793  loss_mask_1: 0.1522  loss_dice_1: 1.34  loss_ce_2: 0.1368  loss_mask_2: 0.1302  loss_dice_2: 1.054  loss_ce_3: 0.1314  loss_mask_3: 0.1173  loss_dice_3: 0.9779  loss_ce_4: 0.1281  loss_mask_4: 0.1125  loss_dice_4: 0.92  loss_ce_5: 0.1264  loss_mask_5: 0.1173  loss_dice_5: 0.8904  loss_ce_6: 0.1298  loss_mask_6: 0.114  loss_dice_6: 0.8899  loss_ce_7: 0.1364  loss_mask_7: 0.1107  loss_dice_7: 0.8685  loss_ce_8: 0.1402  loss_mask_8: 0.1054  loss_dice_8: 0.8747  loss_mgm_entropy: 0.004746    time: 0.4366  last_time: 0.4354  data_time: 0.0034  last_data_time: 0.0036   lr: 1e-06  max_mem: 15545M
[08/30 23:39:44] d2.utils.events INFO:  eta: 0:14:06  iter: 2059  total_loss: 15.99  loss_ce: 0.147  loss_mask: 0.1248  loss_dice: 0.9834  loss_ce_0: 0.7462  loss_mask_0: 0.2185  loss_dice_0: 2.177  loss_ce_1: 0.188  loss_mask_1: 0.1687  loss_dice_1: 1.532  loss_ce_2: 0.1489  loss_mask_2: 0.1445  loss_dice_2: 1.28  loss_ce_3: 0.1394  loss_mask_3: 0.1377  loss_dice_3: 1.185  loss_ce_4: 0.145  loss_mask_4: 0.1288  loss_dice_4: 1.06  loss_ce_5: 0.1437  loss_mask_5: 0.1231  loss_dice_5: 1.031  loss_ce_6: 0.1452  loss_mask_6: 0.1195  loss_dice_6: 1.021  loss_ce_7: 0.1373  loss_mask_7: 0.124  loss_dice_7: 1.016  loss_ce_8: 0.1434  loss_mask_8: 0.1173  loss_dice_8: 0.9704  loss_mgm_entropy: 0.004771    time: 0.4366  last_time: 0.4364  data_time: 0.0035  last_data_time: 0.0029   lr: 1e-06  max_mem: 15545M
[08/30 23:39:53] d2.utils.events INFO:  eta: 0:13:57  iter: 2079  total_loss: 14.86  loss_ce: 0.1409  loss_mask: 0.1234  loss_dice: 0.9321  loss_ce_0: 0.7322  loss_mask_0: 0.1973  loss_dice_0: 2.083  loss_ce_1: 0.1796  loss_mask_1: 0.1535  loss_dice_1: 1.378  loss_ce_2: 0.1455  loss_mask_2: 0.1342  loss_dice_2: 1.128  loss_ce_3: 0.1396  loss_mask_3: 0.1244  loss_dice_3: 1.05  loss_ce_4: 0.135  loss_mask_4: 0.121  loss_dice_4: 0.9957  loss_ce_5: 0.1311  loss_mask_5: 0.1206  loss_dice_5: 0.9758  loss_ce_6: 0.1323  loss_mask_6: 0.1251  loss_dice_6: 0.971  loss_ce_7: 0.1359  loss_mask_7: 0.1205  loss_dice_7: 0.9359  loss_ce_8: 0.1397  loss_mask_8: 0.1147  loss_dice_8: 0.9284  loss_mgm_entropy: 0.00473    time: 0.4366  last_time: 0.4377  data_time: 0.0033  last_data_time: 0.0035   lr: 1e-06  max_mem: 15545M
[08/30 23:40:02] d2.utils.events INFO:  eta: 0:13:48  iter: 2099  total_loss: 13.37  loss_ce: 0.141  loss_mask: 0.0968  loss_dice: 0.8367  loss_ce_0: 0.7536  loss_mask_0: 0.1687  loss_dice_0: 1.961  loss_ce_1: 0.1817  loss_mask_1: 0.1406  loss_dice_1: 1.295  loss_ce_2: 0.133  loss_mask_2: 0.1295  loss_dice_2: 1.032  loss_ce_3: 0.131  loss_mask_3: 0.1102  loss_dice_3: 0.9575  loss_ce_4: 0.1276  loss_mask_4: 0.1063  loss_dice_4: 0.8983  loss_ce_5: 0.1276  loss_mask_5: 0.103  loss_dice_5: 0.8872  loss_ce_6: 0.13  loss_mask_6: 0.09862  loss_dice_6: 0.8618  loss_ce_7: 0.1354  loss_mask_7: 0.09825  loss_dice_7: 0.8812  loss_ce_8: 0.1395  loss_mask_8: 0.09528  loss_dice_8: 0.856  loss_mgm_entropy: 0.004717    time: 0.4366  last_time: 0.4369  data_time: 0.0036  last_data_time: 0.0038   lr: 1e-06  max_mem: 15545M
[08/30 23:40:10] d2.utils.events INFO:  eta: 0:13:40  iter: 2119  total_loss: 13.64  loss_ce: 0.1452  loss_mask: 0.1008  loss_dice: 0.8635  loss_ce_0: 0.7481  loss_mask_0: 0.1947  loss_dice_0: 2.074  loss_ce_1: 0.182  loss_mask_1: 0.1322  loss_dice_1: 1.3  loss_ce_2: 0.1339  loss_mask_2: 0.1122  loss_dice_2: 1.047  loss_ce_3: 0.1316  loss_mask_3: 0.1069  loss_dice_3: 0.9616  loss_ce_4: 0.1286  loss_mask_4: 0.106  loss_dice_4: 0.8998  loss_ce_5: 0.1283  loss_mask_5: 0.1018  loss_dice_5: 0.881  loss_ce_6: 0.1337  loss_mask_6: 0.1024  loss_dice_6: 0.8905  loss_ce_7: 0.14  loss_mask_7: 0.09717  loss_dice_7: 0.891  loss_ce_8: 0.1425  loss_mask_8: 0.09696  loss_dice_8: 0.8724  loss_mgm_entropy: 0.004732    time: 0.4366  last_time: 0.4359  data_time: 0.0034  last_data_time: 0.0035   lr: 1e-06  max_mem: 15545M
[08/30 23:40:19] d2.utils.events INFO:  eta: 0:13:31  iter: 2139  total_loss: 13.41  loss_ce: 0.1396  loss_mask: 0.09505  loss_dice: 0.8397  loss_ce_0: 0.7398  loss_mask_0: 0.2016  loss_dice_0: 2.045  loss_ce_1: 0.1831  loss_mask_1: 0.1381  loss_dice_1: 1.325  loss_ce_2: 0.1409  loss_mask_2: 0.1192  loss_dice_2: 1.056  loss_ce_3: 0.133  loss_mask_3: 0.1089  loss_dice_3: 0.9504  loss_ce_4: 0.1296  loss_mask_4: 0.1037  loss_dice_4: 0.8938  loss_ce_5: 0.1283  loss_mask_5: 0.0975  loss_dice_5: 0.8891  loss_ce_6: 0.1314  loss_mask_6: 0.0955  loss_dice_6: 0.8768  loss_ce_7: 0.1346  loss_mask_7: 0.09944  loss_dice_7: 0.8623  loss_ce_8: 0.1412  loss_mask_8: 0.09314  loss_dice_8: 0.8627  loss_mgm_entropy: 0.004707    time: 0.4366  last_time: 0.4370  data_time: 0.0036  last_data_time: 0.0037   lr: 1e-06  max_mem: 15545M
[08/30 23:40:28] d2.utils.events INFO:  eta: 0:13:22  iter: 2159  total_loss: 14.73  loss_ce: 0.1542  loss_mask: 0.1134  loss_dice: 0.8765  loss_ce_0: 0.7383  loss_mask_0: 0.2047  loss_dice_0: 2.071  loss_ce_1: 0.1845  loss_mask_1: 0.1493  loss_dice_1: 1.358  loss_ce_2: 0.149  loss_mask_2: 0.1294  loss_dice_2: 1.149  loss_ce_3: 0.1394  loss_mask_3: 0.1211  loss_dice_3: 1.043  loss_ce_4: 0.1467  loss_mask_4: 0.1172  loss_dice_4: 0.9813  loss_ce_5: 0.1443  loss_mask_5: 0.116  loss_dice_5: 0.962  loss_ce_6: 0.1503  loss_mask_6: 0.1144  loss_dice_6: 0.9255  loss_ce_7: 0.1503  loss_mask_7: 0.116  loss_dice_7: 0.9268  loss_ce_8: 0.1509  loss_mask_8: 0.111  loss_dice_8: 0.8797  loss_mgm_entropy: 0.004716    time: 0.4366  last_time: 0.4371  data_time: 0.0033  last_data_time: 0.0038   lr: 1e-06  max_mem: 15545M
[08/30 23:40:37] d2.utils.events INFO:  eta: 0:13:13  iter: 2179  total_loss: 14.08  loss_ce: 0.1399  loss_mask: 0.1028  loss_dice: 0.8484  loss_ce_0: 0.7361  loss_mask_0: 0.2053  loss_dice_0: 2.071  loss_ce_1: 0.1779  loss_mask_1: 0.1368  loss_dice_1: 1.332  loss_ce_2: 0.1337  loss_mask_2: 0.129  loss_dice_2: 1.072  loss_ce_3: 0.1278  loss_mask_3: 0.1212  loss_dice_3: 0.9879  loss_ce_4: 0.1262  loss_mask_4: 0.1123  loss_dice_4: 0.967  loss_ce_5: 0.1251  loss_mask_5: 0.1029  loss_dice_5: 0.9006  loss_ce_6: 0.1276  loss_mask_6: 0.1015  loss_dice_6: 0.9157  loss_ce_7: 0.1349  loss_mask_7: 0.1062  loss_dice_7: 0.8792  loss_ce_8: 0.1367  loss_mask_8: 0.1042  loss_dice_8: 0.8853  loss_mgm_entropy: 0.004686    time: 0.4366  last_time: 0.4371  data_time: 0.0036  last_data_time: 0.0038   lr: 1e-06  max_mem: 15545M
[08/30 23:40:45] d2.utils.events INFO:  eta: 0:13:05  iter: 2199  total_loss: 13.34  loss_ce: 0.1405  loss_mask: 0.08559  loss_dice: 0.8204  loss_ce_0: 0.7397  loss_mask_0: 0.1682  loss_dice_0: 2.001  loss_ce_1: 0.1787  loss_mask_1: 0.1117  loss_dice_1: 1.273  loss_ce_2: 0.1374  loss_mask_2: 0.1064  loss_dice_2: 1.016  loss_ce_3: 0.1297  loss_mask_3: 0.1011  loss_dice_3: 0.9079  loss_ce_4: 0.1289  loss_mask_4: 0.09706  loss_dice_4: 0.8855  loss_ce_5: 0.1252  loss_mask_5: 0.08841  loss_dice_5: 0.8424  loss_ce_6: 0.1313  loss_mask_6: 0.08458  loss_dice_6: 0.8565  loss_ce_7: 0.1337  loss_mask_7: 0.08923  loss_dice_7: 0.8393  loss_ce_8: 0.1417  loss_mask_8: 0.08852  loss_dice_8: 0.8463  loss_mgm_entropy: 0.004652    time: 0.4366  last_time: 0.4369  data_time: 0.0032  last_data_time: 0.0036   lr: 1e-06  max_mem: 15545M
[08/30 23:40:54] d2.utils.events INFO:  eta: 0:12:56  iter: 2219  total_loss: 15.47  loss_ce: 0.1504  loss_mask: 0.1278  loss_dice: 0.9769  loss_ce_0: 0.7387  loss_mask_0: 0.2136  loss_dice_0: 2.108  loss_ce_1: 0.1849  loss_mask_1: 0.1613  loss_dice_1: 1.476  loss_ce_2: 0.1399  loss_mask_2: 0.1365  loss_dice_2: 1.286  loss_ce_3: 0.1456  loss_mask_3: 0.1256  loss_dice_3: 1.158  loss_ce_4: 0.1264  loss_mask_4: 0.1249  loss_dice_4: 1.086  loss_ce_5: 0.134  loss_mask_5: 0.1266  loss_dice_5: 1.039  loss_ce_6: 0.1477  loss_mask_6: 0.1239  loss_dice_6: 1.003  loss_ce_7: 0.1436  loss_mask_7: 0.1261  loss_dice_7: 1.014  loss_ce_8: 0.1514  loss_mask_8: 0.1273  loss_dice_8: 0.9836  loss_mgm_entropy: 0.004664    time: 0.4366  last_time: 0.4361  data_time: 0.0037  last_data_time: 0.0036   lr: 1e-06  max_mem: 15545M
[08/30 23:41:03] d2.utils.events INFO:  eta: 0:12:47  iter: 2239  total_loss: 14.98  loss_ce: 0.144  loss_mask: 0.1064  loss_dice: 0.9021  loss_ce_0: 0.7397  loss_mask_0: 0.2169  loss_dice_0: 2.108  loss_ce_1: 0.1765  loss_mask_1: 0.155  loss_dice_1: 1.463  loss_ce_2: 0.1395  loss_mask_2: 0.1371  loss_dice_2: 1.166  loss_ce_3: 0.1377  loss_mask_3: 0.1231  loss_dice_3: 1.066  loss_ce_4: 0.129  loss_mask_4: 0.1184  loss_dice_4: 1.046  loss_ce_5: 0.1328  loss_mask_5: 0.1119  loss_dice_5: 0.9769  loss_ce_6: 0.1357  loss_mask_6: 0.114  loss_dice_6: 0.9615  loss_ce_7: 0.133  loss_mask_7: 0.1068  loss_dice_7: 0.9115  loss_ce_8: 0.1405  loss_mask_8: 0.1044  loss_dice_8: 0.9085  loss_mgm_entropy: 0.004675    time: 0.4366  last_time: 0.4358  data_time: 0.0034  last_data_time: 0.0037   lr: 1e-06  max_mem: 15545M
[08/30 23:41:11] d2.utils.events INFO:  eta: 0:12:39  iter: 2259  total_loss: 13.55  loss_ce: 0.1381  loss_mask: 0.09142  loss_dice: 0.8047  loss_ce_0: 0.7396  loss_mask_0: 0.1839  loss_dice_0: 2.034  loss_ce_1: 0.1747  loss_mask_1: 0.1335  loss_dice_1: 1.328  loss_ce_2: 0.1336  loss_mask_2: 0.1096  loss_dice_2: 1.05  loss_ce_3: 0.1259  loss_mask_3: 0.1013  loss_dice_3: 0.9647  loss_ce_4: 0.1237  loss_mask_4: 0.08753  loss_dice_4: 0.8846  loss_ce_5: 0.1239  loss_mask_5: 0.09459  loss_dice_5: 0.8502  loss_ce_6: 0.1293  loss_mask_6: 0.09336  loss_dice_6: 0.8579  loss_ce_7: 0.1324  loss_mask_7: 0.09378  loss_dice_7: 0.8439  loss_ce_8: 0.1349  loss_mask_8: 0.0945  loss_dice_8: 0.8389  loss_mgm_entropy: 0.004682    time: 0.4366  last_time: 0.4352  data_time: 0.0033  last_data_time: 0.0032   lr: 1e-06  max_mem: 15545M
[08/30 23:41:20] d2.utils.events INFO:  eta: 0:12:30  iter: 2279  total_loss: 13.34  loss_ce: 0.1438  loss_mask: 0.1008  loss_dice: 0.8048  loss_ce_0: 0.7306  loss_mask_0: 0.193  loss_dice_0: 1.94  loss_ce_1: 0.1845  loss_mask_1: 0.1369  loss_dice_1: 1.301  loss_ce_2: 0.1439  loss_mask_2: 0.1133  loss_dice_2: 1.038  loss_ce_3: 0.135  loss_mask_3: 0.1075  loss_dice_3: 0.9413  loss_ce_4: 0.1296  loss_mask_4: 0.1101  loss_dice_4: 0.8638  loss_ce_5: 0.1327  loss_mask_5: 0.1059  loss_dice_5: 0.831  loss_ce_6: 0.1328  loss_mask_6: 0.1001  loss_dice_6: 0.8373  loss_ce_7: 0.1389  loss_mask_7: 0.1028  loss_dice_7: 0.8275  loss_ce_8: 0.143  loss_mask_8: 0.1043  loss_dice_8: 0.823  loss_mgm_entropy: 0.004707    time: 0.4366  last_time: 0.4349  data_time: 0.0035  last_data_time: 0.0035   lr: 1e-06  max_mem: 15545M
[08/30 23:41:29] d2.utils.events INFO:  eta: 0:12:21  iter: 2299  total_loss: 13.44  loss_ce: 0.1391  loss_mask: 0.1065  loss_dice: 0.8944  loss_ce_0: 0.7402  loss_mask_0: 0.1778  loss_dice_0: 2.029  loss_ce_1: 0.1784  loss_mask_1: 0.1398  loss_dice_1: 1.255  loss_ce_2: 0.1373  loss_mask_2: 0.1226  loss_dice_2: 1.035  loss_ce_3: 0.1307  loss_mask_3: 0.1098  loss_dice_3: 0.9519  loss_ce_4: 0.1282  loss_mask_4: 0.1068  loss_dice_4: 0.8932  loss_ce_5: 0.1251  loss_mask_5: 0.1025  loss_dice_5: 0.8647  loss_ce_6: 0.1275  loss_mask_6: 0.1024  loss_dice_6: 0.8747  loss_ce_7: 0.1333  loss_mask_7: 0.1038  loss_dice_7: 0.8954  loss_ce_8: 0.1383  loss_mask_8: 0.1004  loss_dice_8: 0.8884  loss_mgm_entropy: 0.004658    time: 0.4366  last_time: 0.4369  data_time: 0.0034  last_data_time: 0.0039   lr: 1e-06  max_mem: 15545M
[08/30 23:41:38] d2.utils.events INFO:  eta: 0:12:12  iter: 2319  total_loss: 14.43  loss_ce: 0.1401  loss_mask: 0.1037  loss_dice: 0.867  loss_ce_0: 0.7456  loss_mask_0: 0.1748  loss_dice_0: 2.046  loss_ce_1: 0.1714  loss_mask_1: 0.1223  loss_dice_1: 1.369  loss_ce_2: 0.1288  loss_mask_2: 0.1131  loss_dice_2: 1.138  loss_ce_3: 0.1214  loss_mask_3: 0.1105  loss_dice_3: 1.015  loss_ce_4: 0.1232  loss_mask_4: 0.1062  loss_dice_4: 0.9824  loss_ce_5: 0.1209  loss_mask_5: 0.1092  loss_dice_5: 0.9486  loss_ce_6: 0.1232  loss_mask_6: 0.104  loss_dice_6: 0.9327  loss_ce_7: 0.1324  loss_mask_7: 0.09894  loss_dice_7: 0.8826  loss_ce_8: 0.1368  loss_mask_8: 0.1045  loss_dice_8: 0.8741  loss_mgm_entropy: 0.004606    time: 0.4366  last_time: 0.4357  data_time: 0.0035  last_data_time: 0.0039   lr: 1e-06  max_mem: 15545M
[08/30 23:41:46] d2.utils.events INFO:  eta: 0:12:04  iter: 2339  total_loss: 13.08  loss_ce: 0.135  loss_mask: 0.09517  loss_dice: 0.8036  loss_ce_0: 0.7452  loss_mask_0: 0.1706  loss_dice_0: 2.045  loss_ce_1: 0.1734  loss_mask_1: 0.1264  loss_dice_1: 1.277  loss_ce_2: 0.1344  loss_mask_2: 0.1071  loss_dice_2: 1.021  loss_ce_3: 0.1255  loss_mask_3: 0.1004  loss_dice_3: 0.9506  loss_ce_4: 0.1224  loss_mask_4: 0.09847  loss_dice_4: 0.8709  loss_ce_5: 0.1239  loss_mask_5: 0.09593  loss_dice_5: 0.8651  loss_ce_6: 0.126  loss_mask_6: 0.09409  loss_dice_6: 0.8536  loss_ce_7: 0.1276  loss_mask_7: 0.0925  loss_dice_7: 0.8366  loss_ce_8: 0.1313  loss_mask_8: 0.09313  loss_dice_8: 0.8083  loss_mgm_entropy: 0.004542    time: 0.4366  last_time: 0.4353  data_time: 0.0035  last_data_time: 0.0033   lr: 1e-06  max_mem: 15545M
[08/30 23:41:55] d2.utils.events INFO:  eta: 0:11:55  iter: 2359  total_loss: 14.78  loss_ce: 0.1401  loss_mask: 0.1118  loss_dice: 0.9352  loss_ce_0: 0.7272  loss_mask_0: 0.2066  loss_dice_0: 2.012  loss_ce_1: 0.1793  loss_mask_1: 0.1499  loss_dice_1: 1.359  loss_ce_2: 0.1361  loss_mask_2: 0.1284  loss_dice_2: 1.175  loss_ce_3: 0.1297  loss_mask_3: 0.1282  loss_dice_3: 1.071  loss_ce_4: 0.1285  loss_mask_4: 0.1187  loss_dice_4: 1.016  loss_ce_5: 0.1259  loss_mask_5: 0.1229  loss_dice_5: 0.9936  loss_ce_6: 0.1266  loss_mask_6: 0.1179  loss_dice_6: 0.9715  loss_ce_7: 0.1384  loss_mask_7: 0.116  loss_dice_7: 0.9418  loss_ce_8: 0.1406  loss_mask_8: 0.1086  loss_dice_8: 0.934  loss_mgm_entropy: 0.004668    time: 0.4366  last_time: 0.4348  data_time: 0.0034  last_data_time: 0.0032   lr: 1e-06  max_mem: 15545M
[08/30 23:42:04] d2.utils.events INFO:  eta: 0:11:46  iter: 2379  total_loss: 14.03  loss_ce: 0.1529  loss_mask: 0.1041  loss_dice: 0.8707  loss_ce_0: 0.7233  loss_mask_0: 0.1888  loss_dice_0: 2.078  loss_ce_1: 0.1857  loss_mask_1: 0.1412  loss_dice_1: 1.304  loss_ce_2: 0.1446  loss_mask_2: 0.1294  loss_dice_2: 1.054  loss_ce_3: 0.1394  loss_mask_3: 0.1192  loss_dice_3: 0.9636  loss_ce_4: 0.1353  loss_mask_4: 0.1118  loss_dice_4: 0.8975  loss_ce_5: 0.1393  loss_mask_5: 0.1102  loss_dice_5: 0.9044  loss_ce_6: 0.1434  loss_mask_6: 0.1066  loss_dice_6: 0.8902  loss_ce_7: 0.1481  loss_mask_7: 0.1079  loss_dice_7: 0.8779  loss_ce_8: 0.1501  loss_mask_8: 0.1078  loss_dice_8: 0.8778  loss_mgm_entropy: 0.004566    time: 0.4366  last_time: 0.4366  data_time: 0.0034  last_data_time: 0.0033   lr: 1e-06  max_mem: 15545M
[08/30 23:42:13] d2.utils.events INFO:  eta: 0:11:38  iter: 2399  total_loss: 13.57  loss_ce: 0.1358  loss_mask: 0.103  loss_dice: 0.8527  loss_ce_0: 0.745  loss_mask_0: 0.2035  loss_dice_0: 2.054  loss_ce_1: 0.1769  loss_mask_1: 0.1532  loss_dice_1: 1.298  loss_ce_2: 0.1319  loss_mask_2: 0.119  loss_dice_2: 1.028  loss_ce_3: 0.1225  loss_mask_3: 0.1142  loss_dice_3: 0.945  loss_ce_4: 0.1219  loss_mask_4: 0.108  loss_dice_4: 0.9139  loss_ce_5: 0.1202  loss_mask_5: 0.103  loss_dice_5: 0.8963  loss_ce_6: 0.1258  loss_mask_6: 0.09841  loss_dice_6: 0.8802  loss_ce_7: 0.1267  loss_mask_7: 0.1018  loss_dice_7: 0.8702  loss_ce_8: 0.1312  loss_mask_8: 0.1023  loss_dice_8: 0.8742  loss_mgm_entropy: 0.004615    time: 0.4366  last_time: 0.4372  data_time: 0.0033  last_data_time: 0.0037   lr: 1e-06  max_mem: 15545M
[08/30 23:42:21] d2.utils.events INFO:  eta: 0:11:29  iter: 2419  total_loss: 13.54  loss_ce: 0.1484  loss_mask: 0.09847  loss_dice: 0.8448  loss_ce_0: 0.7426  loss_mask_0: 0.1549  loss_dice_0: 2.012  loss_ce_1: 0.1764  loss_mask_1: 0.1284  loss_dice_1: 1.306  loss_ce_2: 0.1365  loss_mask_2: 0.1206  loss_dice_2: 1.065  loss_ce_3: 0.1358  loss_mask_3: 0.1009  loss_dice_3: 0.9406  loss_ce_4: 0.1334  loss_mask_4: 0.09733  loss_dice_4: 0.8933  loss_ce_5: 0.1277  loss_mask_5: 0.09177  loss_dice_5: 0.8999  loss_ce_6: 0.131  loss_mask_6: 0.0953  loss_dice_6: 0.8666  loss_ce_7: 0.1376  loss_mask_7: 0.09764  loss_dice_7: 0.8567  loss_ce_8: 0.1439  loss_mask_8: 0.0938  loss_dice_8: 0.8328  loss_mgm_entropy: 0.004501    time: 0.4366  last_time: 0.4360  data_time: 0.0034  last_data_time: 0.0034   lr: 1e-06  max_mem: 15545M
[08/30 23:42:30] d2.utils.events INFO:  eta: 0:11:20  iter: 2439  total_loss: 13.59  loss_ce: 0.1354  loss_mask: 0.09673  loss_dice: 0.8085  loss_ce_0: 0.7292  loss_mask_0: 0.1899  loss_dice_0: 1.988  loss_ce_1: 0.1755  loss_mask_1: 0.142  loss_dice_1: 1.347  loss_ce_2: 0.1355  loss_mask_2: 0.1207  loss_dice_2: 1.034  loss_ce_3: 0.1308  loss_mask_3: 0.1089  loss_dice_3: 0.9485  loss_ce_4: 0.1276  loss_mask_4: 0.1091  loss_dice_4: 0.8842  loss_ce_5: 0.1285  loss_mask_5: 0.09945  loss_dice_5: 0.8718  loss_ce_6: 0.1271  loss_mask_6: 0.1006  loss_dice_6: 0.8651  loss_ce_7: 0.1319  loss_mask_7: 0.1012  loss_dice_7: 0.8625  loss_ce_8: 0.138  loss_mask_8: 0.09885  loss_dice_8: 0.8344  loss_mgm_entropy: 0.004622    time: 0.4366  last_time: 0.4391  data_time: 0.0034  last_data_time: 0.0033   lr: 1e-06  max_mem: 15545M
[08/30 23:42:39] d2.utils.events INFO:  eta: 0:11:11  iter: 2459  total_loss: 13.01  loss_ce: 0.1387  loss_mask: 0.08363  loss_dice: 0.8108  loss_ce_0: 0.7249  loss_mask_0: 0.1841  loss_dice_0: 1.995  loss_ce_1: 0.1747  loss_mask_1: 0.1274  loss_dice_1: 1.31  loss_ce_2: 0.1383  loss_mask_2: 0.1153  loss_dice_2: 1.017  loss_ce_3: 0.1309  loss_mask_3: 0.09843  loss_dice_3: 0.9585  loss_ce_4: 0.131  loss_mask_4: 0.1014  loss_dice_4: 0.8653  loss_ce_5: 0.1315  loss_mask_5: 0.08791  loss_dice_5: 0.8505  loss_ce_6: 0.1296  loss_mask_6: 0.08795  loss_dice_6: 0.8332  loss_ce_7: 0.1332  loss_mask_7: 0.08716  loss_dice_7: 0.8165  loss_ce_8: 0.1399  loss_mask_8: 0.08333  loss_dice_8: 0.8288  loss_mgm_entropy: 0.004557    time: 0.4366  last_time: 0.4359  data_time: 0.0036  last_data_time: 0.0033   lr: 1e-06  max_mem: 15545M
[08/30 23:42:48] d2.utils.events INFO:  eta: 0:11:03  iter: 2479  total_loss: 14.4  loss_ce: 0.1486  loss_mask: 0.1152  loss_dice: 0.8734  loss_ce_0: 0.7358  loss_mask_0: 0.2141  loss_dice_0: 2.028  loss_ce_1: 0.1781  loss_mask_1: 0.1597  loss_dice_1: 1.4  loss_ce_2: 0.1536  loss_mask_2: 0.1484  loss_dice_2: 1.183  loss_ce_3: 0.1466  loss_mask_3: 0.1304  loss_dice_3: 1.066  loss_ce_4: 0.1473  loss_mask_4: 0.1207  loss_dice_4: 0.9549  loss_ce_5: 0.1445  loss_mask_5: 0.1234  loss_dice_5: 0.9293  loss_ce_6: 0.1422  loss_mask_6: 0.1183  loss_dice_6: 0.9163  loss_ce_7: 0.1404  loss_mask_7: 0.114  loss_dice_7: 0.9104  loss_ce_8: 0.1472  loss_mask_8: 0.1127  loss_dice_8: 0.8724  loss_mgm_entropy: 0.004539    time: 0.4366  last_time: 0.4359  data_time: 0.0034  last_data_time: 0.0033   lr: 1e-06  max_mem: 15545M
[08/30 23:42:56] d2.utils.events INFO:  eta: 0:10:54  iter: 2499  total_loss: 13.67  loss_ce: 0.1443  loss_mask: 0.1177  loss_dice: 0.833  loss_ce_0: 0.7347  loss_mask_0: 0.2042  loss_dice_0: 2.054  loss_ce_1: 0.1814  loss_mask_1: 0.1523  loss_dice_1: 1.299  loss_ce_2: 0.1443  loss_mask_2: 0.1245  loss_dice_2: 1.065  loss_ce_3: 0.1399  loss_mask_3: 0.1232  loss_dice_3: 0.9981  loss_ce_4: 0.1301  loss_mask_4: 0.1139  loss_dice_4: 0.9147  loss_ce_5: 0.1312  loss_mask_5: 0.1184  loss_dice_5: 0.8826  loss_ce_6: 0.1387  loss_mask_6: 0.1171  loss_dice_6: 0.8499  loss_ce_7: 0.1339  loss_mask_7: 0.113  loss_dice_7: 0.8459  loss_ce_8: 0.1394  loss_mask_8: 0.1146  loss_dice_8: 0.8379  loss_mgm_entropy: 0.004571    time: 0.4366  last_time: 0.4371  data_time: 0.0036  last_data_time: 0.0033   lr: 1e-06  max_mem: 15545M
[08/30 23:43:05] d2.utils.events INFO:  eta: 0:10:45  iter: 2519  total_loss: 13.36  loss_ce: 0.1403  loss_mask: 0.08743  loss_dice: 0.8352  loss_ce_0: 0.7415  loss_mask_0: 0.1766  loss_dice_0: 1.98  loss_ce_1: 0.1847  loss_mask_1: 0.1335  loss_dice_1: 1.274  loss_ce_2: 0.1413  loss_mask_2: 0.1117  loss_dice_2: 1.024  loss_ce_3: 0.1379  loss_mask_3: 0.1023  loss_dice_3: 0.9326  loss_ce_4: 0.1311  loss_mask_4: 0.09088  loss_dice_4: 0.8747  loss_ce_5: 0.1317  loss_mask_5: 0.08381  loss_dice_5: 0.852  loss_ce_6: 0.1354  loss_mask_6: 0.08618  loss_dice_6: 0.8757  loss_ce_7: 0.1402  loss_mask_7: 0.08469  loss_dice_7: 0.8611  loss_ce_8: 0.1431  loss_mask_8: 0.08473  loss_dice_8: 0.8569  loss_mgm_entropy: 0.00458    time: 0.4366  last_time: 0.4369  data_time: 0.0035  last_data_time: 0.0038   lr: 1e-06  max_mem: 15545M
[08/30 23:43:14] d2.utils.events INFO:  eta: 0:10:36  iter: 2539  total_loss: 13.41  loss_ce: 0.1453  loss_mask: 0.09566  loss_dice: 0.8232  loss_ce_0: 0.7369  loss_mask_0: 0.1961  loss_dice_0: 2.024  loss_ce_1: 0.1834  loss_mask_1: 0.144  loss_dice_1: 1.284  loss_ce_2: 0.1542  loss_mask_2: 0.1233  loss_dice_2: 1.072  loss_ce_3: 0.1457  loss_mask_3: 0.114  loss_dice_3: 0.9183  loss_ce_4: 0.1455  loss_mask_4: 0.1041  loss_dice_4: 0.868  loss_ce_5: 0.1348  loss_mask_5: 0.09749  loss_dice_5: 0.8631  loss_ce_6: 0.1455  loss_mask_6: 0.09546  loss_dice_6: 0.8461  loss_ce_7: 0.1386  loss_mask_7: 0.09635  loss_dice_7: 0.8198  loss_ce_8: 0.1437  loss_mask_8: 0.09574  loss_dice_8: 0.811  loss_mgm_entropy: 0.004571    time: 0.4366  last_time: 0.4354  data_time: 0.0035  last_data_time: 0.0037   lr: 1e-06  max_mem: 15545M
[08/30 23:43:23] d2.utils.events INFO:  eta: 0:10:28  iter: 2559  total_loss: 13.93  loss_ce: 0.1445  loss_mask: 0.1124  loss_dice: 0.9021  loss_ce_0: 0.7437  loss_mask_0: 0.2099  loss_dice_0: 2.038  loss_ce_1: 0.1777  loss_mask_1: 0.1446  loss_dice_1: 1.298  loss_ce_2: 0.1375  loss_mask_2: 0.1253  loss_dice_2: 1.036  loss_ce_3: 0.1327  loss_mask_3: 0.1136  loss_dice_3: 0.9517  loss_ce_4: 0.1307  loss_mask_4: 0.1096  loss_dice_4: 0.9061  loss_ce_5: 0.1315  loss_mask_5: 0.1099  loss_dice_5: 0.8936  loss_ce_6: 0.1344  loss_mask_6: 0.114  loss_dice_6: 0.8904  loss_ce_7: 0.1372  loss_mask_7: 0.1181  loss_dice_7: 0.8845  loss_ce_8: 0.1424  loss_mask_8: 0.1033  loss_dice_8: 0.9027  loss_mgm_entropy: 0.004553    time: 0.4366  last_time: 0.4437  data_time: 0.0034  last_data_time: 0.0036   lr: 1e-06  max_mem: 15545M
[08/30 23:43:31] d2.utils.events INFO:  eta: 0:10:19  iter: 2579  total_loss: 12.98  loss_ce: 0.1338  loss_mask: 0.1077  loss_dice: 0.8097  loss_ce_0: 0.7303  loss_mask_0: 0.197  loss_dice_0: 1.967  loss_ce_1: 0.1735  loss_mask_1: 0.1365  loss_dice_1: 1.246  loss_ce_2: 0.1267  loss_mask_2: 0.1098  loss_dice_2: 1.003  loss_ce_3: 0.125  loss_mask_3: 0.1089  loss_dice_3: 0.8885  loss_ce_4: 0.1229  loss_mask_4: 0.1023  loss_dice_4: 0.8439  loss_ce_5: 0.1163  loss_mask_5: 0.1033  loss_dice_5: 0.8222  loss_ce_6: 0.1173  loss_mask_6: 0.09694  loss_dice_6: 0.826  loss_ce_7: 0.126  loss_mask_7: 0.1044  loss_dice_7: 0.8298  loss_ce_8: 0.1328  loss_mask_8: 0.09847  loss_dice_8: 0.8098  loss_mgm_entropy: 0.004575    time: 0.4366  last_time: 0.4366  data_time: 0.0035  last_data_time: 0.0032   lr: 1e-06  max_mem: 15545M
[08/30 23:43:40] d2.utils.events INFO:  eta: 0:10:10  iter: 2599  total_loss: 13.73  loss_ce: 0.1453  loss_mask: 0.1102  loss_dice: 0.8579  loss_ce_0: 0.7176  loss_mask_0: 0.2082  loss_dice_0: 2.08  loss_ce_1: 0.1759  loss_mask_1: 0.1516  loss_dice_1: 1.32  loss_ce_2: 0.1378  loss_mask_2: 0.1235  loss_dice_2: 1.066  loss_ce_3: 0.1338  loss_mask_3: 0.1096  loss_dice_3: 0.9561  loss_ce_4: 0.1243  loss_mask_4: 0.1091  loss_dice_4: 0.9115  loss_ce_5: 0.1256  loss_mask_5: 0.104  loss_dice_5: 0.8896  loss_ce_6: 0.1278  loss_mask_6: 0.1042  loss_dice_6: 0.8755  loss_ce_7: 0.1318  loss_mask_7: 0.108  loss_dice_7: 0.8827  loss_ce_8: 0.1394  loss_mask_8: 0.1064  loss_dice_8: 0.8619  loss_mgm_entropy: 0.004569    time: 0.4366  last_time: 0.4364  data_time: 0.0035  last_data_time: 0.0034   lr: 1e-06  max_mem: 15545M
[08/30 23:43:49] d2.utils.events INFO:  eta: 0:10:02  iter: 2619  total_loss: 12.75  loss_ce: 0.1346  loss_mask: 0.08516  loss_dice: 0.8015  loss_ce_0: 0.7408  loss_mask_0: 0.1674  loss_dice_0: 1.936  loss_ce_1: 0.1709  loss_mask_1: 0.1278  loss_dice_1: 1.249  loss_ce_2: 0.1331  loss_mask_2: 0.1044  loss_dice_2: 1.01  loss_ce_3: 0.1277  loss_mask_3: 0.09067  loss_dice_3: 0.8892  loss_ce_4: 0.1261  loss_mask_4: 0.08735  loss_dice_4: 0.8468  loss_ce_5: 0.1234  loss_mask_5: 0.08629  loss_dice_5: 0.8044  loss_ce_6: 0.1256  loss_mask_6: 0.08486  loss_dice_6: 0.8201  loss_ce_7: 0.1287  loss_mask_7: 0.08569  loss_dice_7: 0.8256  loss_ce_8: 0.1311  loss_mask_8: 0.08361  loss_dice_8: 0.8095  loss_mgm_entropy: 0.004527    time: 0.4366  last_time: 0.4351  data_time: 0.0035  last_data_time: 0.0032   lr: 1e-06  max_mem: 15545M
[08/30 23:43:58] d2.utils.events INFO:  eta: 0:09:53  iter: 2639  total_loss: 14.35  loss_ce: 0.1402  loss_mask: 0.1052  loss_dice: 0.8723  loss_ce_0: 0.7319  loss_mask_0: 0.2109  loss_dice_0: 2.063  loss_ce_1: 0.1748  loss_mask_1: 0.1446  loss_dice_1: 1.38  loss_ce_2: 0.1395  loss_mask_2: 0.1334  loss_dice_2: 1.073  loss_ce_3: 0.1348  loss_mask_3: 0.1236  loss_dice_3: 1.036  loss_ce_4: 0.1244  loss_mask_4: 0.1137  loss_dice_4: 0.9679  loss_ce_5: 0.1316  loss_mask_5: 0.1079  loss_dice_5: 0.9273  loss_ce_6: 0.1324  loss_mask_6: 0.1092  loss_dice_6: 0.9175  loss_ce_7: 0.1346  loss_mask_7: 0.1081  loss_dice_7: 0.9261  loss_ce_8: 0.1364  loss_mask_8: 0.1032  loss_dice_8: 0.875  loss_mgm_entropy: 0.004571    time: 0.4366  last_time: 0.4364  data_time: 0.0035  last_data_time: 0.0037   lr: 1e-06  max_mem: 15545M
[08/30 23:44:06] d2.utils.events INFO:  eta: 0:09:44  iter: 2659  total_loss: 14.15  loss_ce: 0.1467  loss_mask: 0.1068  loss_dice: 0.8673  loss_ce_0: 0.7262  loss_mask_0: 0.2043  loss_dice_0: 2.03  loss_ce_1: 0.1742  loss_mask_1: 0.1596  loss_dice_1: 1.297  loss_ce_2: 0.1359  loss_mask_2: 0.135  loss_dice_2: 1.07  loss_ce_3: 0.1332  loss_mask_3: 0.1192  loss_dice_3: 0.9644  loss_ce_4: 0.1417  loss_mask_4: 0.113  loss_dice_4: 0.9126  loss_ce_5: 0.1429  loss_mask_5: 0.1106  loss_dice_5: 0.9101  loss_ce_6: 0.1456  loss_mask_6: 0.1062  loss_dice_6: 0.8989  loss_ce_7: 0.1418  loss_mask_7: 0.1021  loss_dice_7: 0.8848  loss_ce_8: 0.1467  loss_mask_8: 0.1029  loss_dice_8: 0.8818  loss_mgm_entropy: 0.004558    time: 0.4366  last_time: 0.4371  data_time: 0.0036  last_data_time: 0.0037   lr: 1e-06  max_mem: 15545M
[08/30 23:44:15] d2.utils.events INFO:  eta: 0:09:35  iter: 2679  total_loss: 13.44  loss_ce: 0.1399  loss_mask: 0.09763  loss_dice: 0.8055  loss_ce_0: 0.7455  loss_mask_0: 0.1944  loss_dice_0: 1.984  loss_ce_1: 0.1831  loss_mask_1: 0.1441  loss_dice_1: 1.268  loss_ce_2: 0.1446  loss_mask_2: 0.1168  loss_dice_2: 1.006  loss_ce_3: 0.1371  loss_mask_3: 0.1126  loss_dice_3: 0.8934  loss_ce_4: 0.1351  loss_mask_4: 0.1043  loss_dice_4: 0.8786  loss_ce_5: 0.1339  loss_mask_5: 0.1063  loss_dice_5: 0.8356  loss_ce_6: 0.1352  loss_mask_6: 0.1024  loss_dice_6: 0.8323  loss_ce_7: 0.1404  loss_mask_7: 0.1016  loss_dice_7: 0.8108  loss_ce_8: 0.1401  loss_mask_8: 0.09598  loss_dice_8: 0.8022  loss_mgm_entropy: 0.004549    time: 0.4366  last_time: 0.4391  data_time: 0.0034  last_data_time: 0.0031   lr: 1e-06  max_mem: 15545M
[08/30 23:44:24] d2.utils.events INFO:  eta: 0:09:27  iter: 2699  total_loss: 12.97  loss_ce: 0.137  loss_mask: 0.09223  loss_dice: 0.7914  loss_ce_0: 0.7356  loss_mask_0: 0.1494  loss_dice_0: 2.021  loss_ce_1: 0.1757  loss_mask_1: 0.1202  loss_dice_1: 1.29  loss_ce_2: 0.1409  loss_mask_2: 0.1015  loss_dice_2: 1.018  loss_ce_3: 0.1332  loss_mask_3: 0.09384  loss_dice_3: 0.9168  loss_ce_4: 0.1262  loss_mask_4: 0.09305  loss_dice_4: 0.8573  loss_ce_5: 0.1246  loss_mask_5: 0.08479  loss_dice_5: 0.8202  loss_ce_6: 0.1286  loss_mask_6: 0.08555  loss_dice_6: 0.846  loss_ce_7: 0.1318  loss_mask_7: 0.08837  loss_dice_7: 0.8181  loss_ce_8: 0.1387  loss_mask_8: 0.08818  loss_dice_8: 0.7887  loss_mgm_entropy: 0.00447    time: 0.4366  last_time: 0.4351  data_time: 0.0037  last_data_time: 0.0031   lr: 1e-06  max_mem: 15545M
[08/30 23:44:32] d2.utils.events INFO:  eta: 0:09:18  iter: 2719  total_loss: 12.62  loss_ce: 0.1423  loss_mask: 0.09135  loss_dice: 0.7832  loss_ce_0: 0.7332  loss_mask_0: 0.185  loss_dice_0: 1.931  loss_ce_1: 0.1768  loss_mask_1: 0.1272  loss_dice_1: 1.213  loss_ce_2: 0.134  loss_mask_2: 0.1074  loss_dice_2: 0.9552  loss_ce_3: 0.1262  loss_mask_3: 0.09497  loss_dice_3: 0.8799  loss_ce_4: 0.132  loss_mask_4: 0.09307  loss_dice_4: 0.8177  loss_ce_5: 0.1352  loss_mask_5: 0.08826  loss_dice_5: 0.8111  loss_ce_6: 0.1309  loss_mask_6: 0.08449  loss_dice_6: 0.8057  loss_ce_7: 0.1359  loss_mask_7: 0.09094  loss_dice_7: 0.7841  loss_ce_8: 0.1402  loss_mask_8: 0.09067  loss_dice_8: 0.7877  loss_mgm_entropy: 0.004573    time: 0.4366  last_time: 0.4362  data_time: 0.0035  last_data_time: 0.0033   lr: 1e-06  max_mem: 15545M
[08/30 23:44:41] d2.utils.events INFO:  eta: 0:09:09  iter: 2739  total_loss: 13.76  loss_ce: 0.1453  loss_mask: 0.09536  loss_dice: 0.851  loss_ce_0: 0.7303  loss_mask_0: 0.1671  loss_dice_0: 1.932  loss_ce_1: 0.176  loss_mask_1: 0.1273  loss_dice_1: 1.342  loss_ce_2: 0.1484  loss_mask_2: 0.1204  loss_dice_2: 1.088  loss_ce_3: 0.1433  loss_mask_3: 0.1081  loss_dice_3: 0.9868  loss_ce_4: 0.138  loss_mask_4: 0.1013  loss_dice_4: 0.9126  loss_ce_5: 0.1417  loss_mask_5: 0.09814  loss_dice_5: 0.8861  loss_ce_6: 0.1377  loss_mask_6: 0.0928  loss_dice_6: 0.8597  loss_ce_7: 0.1414  loss_mask_7: 0.09338  loss_dice_7: 0.8657  loss_ce_8: 0.1452  loss_mask_8: 0.09514  loss_dice_8: 0.8726  loss_mgm_entropy: 0.00449    time: 0.4366  last_time: 0.4364  data_time: 0.0036  last_data_time: 0.0036   lr: 1e-06  max_mem: 15545M
[08/30 23:44:50] d2.utils.events INFO:  eta: 0:09:00  iter: 2759  total_loss: 12.61  loss_ce: 0.142  loss_mask: 0.08374  loss_dice: 0.7904  loss_ce_0: 0.7516  loss_mask_0: 0.1757  loss_dice_0: 1.954  loss_ce_1: 0.1822  loss_mask_1: 0.1311  loss_dice_1: 1.243  loss_ce_2: 0.1486  loss_mask_2: 0.1125  loss_dice_2: 0.9689  loss_ce_3: 0.1373  loss_mask_3: 0.1008  loss_dice_3: 0.8854  loss_ce_4: 0.1318  loss_mask_4: 0.09508  loss_dice_4: 0.8428  loss_ce_5: 0.1327  loss_mask_5: 0.08443  loss_dice_5: 0.8188  loss_ce_6: 0.1373  loss_mask_6: 0.08216  loss_dice_6: 0.8153  loss_ce_7: 0.1363  loss_mask_7: 0.08458  loss_dice_7: 0.807  loss_ce_8: 0.1396  loss_mask_8: 0.0832  loss_dice_8: 0.809  loss_mgm_entropy: 0.004524    time: 0.4366  last_time: 0.4373  data_time: 0.0035  last_data_time: 0.0033   lr: 1e-06  max_mem: 15545M
[08/30 23:44:59] d2.utils.events INFO:  eta: 0:08:52  iter: 2779  total_loss: 13.09  loss_ce: 0.1469  loss_mask: 0.08869  loss_dice: 0.8001  loss_ce_0: 0.7373  loss_mask_0: 0.1718  loss_dice_0: 1.94  loss_ce_1: 0.1739  loss_mask_1: 0.1258  loss_dice_1: 1.233  loss_ce_2: 0.1436  loss_mask_2: 0.1108  loss_dice_2: 0.9888  loss_ce_3: 0.1411  loss_mask_3: 0.1075  loss_dice_3: 0.9127  loss_ce_4: 0.1438  loss_mask_4: 0.1011  loss_dice_4: 0.8611  loss_ce_5: 0.1445  loss_mask_5: 0.09937  loss_dice_5: 0.8248  loss_ce_6: 0.1415  loss_mask_6: 0.09327  loss_dice_6: 0.8048  loss_ce_7: 0.1432  loss_mask_7: 0.09199  loss_dice_7: 0.7914  loss_ce_8: 0.1413  loss_mask_8: 0.09349  loss_dice_8: 0.8067  loss_mgm_entropy: 0.00454    time: 0.4366  last_time: 0.4365  data_time: 0.0035  last_data_time: 0.0032   lr: 1e-06  max_mem: 15545M
[08/30 23:45:07] d2.utils.events INFO:  eta: 0:08:43  iter: 2799  total_loss: 13.26  loss_ce: 0.1459  loss_mask: 0.09425  loss_dice: 0.8131  loss_ce_0: 0.7353  loss_mask_0: 0.1932  loss_dice_0: 1.931  loss_ce_1: 0.1721  loss_mask_1: 0.141  loss_dice_1: 1.26  loss_ce_2: 0.1372  loss_mask_2: 0.1284  loss_dice_2: 1.016  loss_ce_3: 0.133  loss_mask_3: 0.1153  loss_dice_3: 0.9116  loss_ce_4: 0.1313  loss_mask_4: 0.1061  loss_dice_4: 0.8788  loss_ce_5: 0.1283  loss_mask_5: 0.09797  loss_dice_5: 0.8368  loss_ce_6: 0.1342  loss_mask_6: 0.09795  loss_dice_6: 0.8419  loss_ce_7: 0.1356  loss_mask_7: 0.09488  loss_dice_7: 0.8289  loss_ce_8: 0.1393  loss_mask_8: 0.08881  loss_dice_8: 0.8102  loss_mgm_entropy: 0.004528    time: 0.4366  last_time: 0.4347  data_time: 0.0035  last_data_time: 0.0034   lr: 1e-06  max_mem: 15545M
[08/30 23:45:16] d2.utils.events INFO:  eta: 0:08:34  iter: 2819  total_loss: 12.74  loss_ce: 0.1326  loss_mask: 0.08911  loss_dice: 0.8001  loss_ce_0: 0.7375  loss_mask_0: 0.1984  loss_dice_0: 1.967  loss_ce_1: 0.1766  loss_mask_1: 0.1328  loss_dice_1: 1.235  loss_ce_2: 0.1336  loss_mask_2: 0.1051  loss_dice_2: 0.9818  loss_ce_3: 0.1217  loss_mask_3: 0.09519  loss_dice_3: 0.8832  loss_ce_4: 0.1237  loss_mask_4: 0.0988  loss_dice_4: 0.8332  loss_ce_5: 0.1266  loss_mask_5: 0.09237  loss_dice_5: 0.8278  loss_ce_6: 0.123  loss_mask_6: 0.09524  loss_dice_6: 0.8101  loss_ce_7: 0.1252  loss_mask_7: 0.09425  loss_dice_7: 0.8136  loss_ce_8: 0.1269  loss_mask_8: 0.08986  loss_dice_8: 0.8122  loss_mgm_entropy: 0.004494    time: 0.4366  last_time: 0.4365  data_time: 0.0034  last_data_time: 0.0033   lr: 1e-06  max_mem: 15545M
[08/30 23:45:25] d2.utils.events INFO:  eta: 0:08:26  iter: 2839  total_loss: 12.75  loss_ce: 0.1424  loss_mask: 0.08487  loss_dice: 0.7974  loss_ce_0: 0.7426  loss_mask_0: 0.1877  loss_dice_0: 1.992  loss_ce_1: 0.1733  loss_mask_1: 0.1375  loss_dice_1: 1.282  loss_ce_2: 0.1358  loss_mask_2: 0.1188  loss_dice_2: 1.029  loss_ce_3: 0.1324  loss_mask_3: 0.1048  loss_dice_3: 0.8935  loss_ce_4: 0.1371  loss_mask_4: 0.09872  loss_dice_4: 0.8323  loss_ce_5: 0.1365  loss_mask_5: 0.09827  loss_dice_5: 0.8288  loss_ce_6: 0.1362  loss_mask_6: 0.0893  loss_dice_6: 0.8224  loss_ce_7: 0.135  loss_mask_7: 0.08763  loss_dice_7: 0.808  loss_ce_8: 0.1393  loss_mask_8: 0.08859  loss_dice_8: 0.783  loss_mgm_entropy: 0.004515    time: 0.4366  last_time: 0.4370  data_time: 0.0034  last_data_time: 0.0040   lr: 1e-06  max_mem: 15545M
[08/30 23:45:34] d2.utils.events INFO:  eta: 0:08:17  iter: 2859  total_loss: 14.47  loss_ce: 0.1456  loss_mask: 0.1249  loss_dice: 0.8903  loss_ce_0: 0.7271  loss_mask_0: 0.2099  loss_dice_0: 2.066  loss_ce_1: 0.1804  loss_mask_1: 0.1723  loss_dice_1: 1.403  loss_ce_2: 0.144  loss_mask_2: 0.139  loss_dice_2: 1.156  loss_ce_3: 0.1389  loss_mask_3: 0.1264  loss_dice_3: 1.014  loss_ce_4: 0.1449  loss_mask_4: 0.1314  loss_dice_4: 0.9649  loss_ce_5: 0.1396  loss_mask_5: 0.1264  loss_dice_5: 0.9547  loss_ce_6: 0.1405  loss_mask_6: 0.1213  loss_dice_6: 0.9138  loss_ce_7: 0.1392  loss_mask_7: 0.1266  loss_dice_7: 0.8963  loss_ce_8: 0.1442  loss_mask_8: 0.1269  loss_dice_8: 0.8834  loss_mgm_entropy: 0.004493    time: 0.4366  last_time: 0.4352  data_time: 0.0034  last_data_time: 0.0034   lr: 1e-06  max_mem: 15545M
[08/30 23:45:42] d2.utils.events INFO:  eta: 0:08:08  iter: 2879  total_loss: 13.46  loss_ce: 0.1349  loss_mask: 0.1002  loss_dice: 0.8563  loss_ce_0: 0.7433  loss_mask_0: 0.183  loss_dice_0: 1.972  loss_ce_1: 0.1697  loss_mask_1: 0.1418  loss_dice_1: 1.28  loss_ce_2: 0.1482  loss_mask_2: 0.1235  loss_dice_2: 1.028  loss_ce_3: 0.1293  loss_mask_3: 0.1157  loss_dice_3: 0.9202  loss_ce_4: 0.1236  loss_mask_4: 0.1154  loss_dice_4: 0.8827  loss_ce_5: 0.1246  loss_mask_5: 0.1169  loss_dice_5: 0.8751  loss_ce_6: 0.1266  loss_mask_6: 0.1097  loss_dice_6: 0.8667  loss_ce_7: 0.1307  loss_mask_7: 0.1072  loss_dice_7: 0.868  loss_ce_8: 0.1315  loss_mask_8: 0.1039  loss_dice_8: 0.8573  loss_mgm_entropy: 0.0045    time: 0.4366  last_time: 0.4352  data_time: 0.0035  last_data_time: 0.0033   lr: 1e-06  max_mem: 15545M
[08/30 23:45:51] d2.utils.events INFO:  eta: 0:07:59  iter: 2899  total_loss: 13.7  loss_ce: 0.1368  loss_mask: 0.1089  loss_dice: 0.8199  loss_ce_0: 0.7422  loss_mask_0: 0.1919  loss_dice_0: 1.937  loss_ce_1: 0.1864  loss_mask_1: 0.1525  loss_dice_1: 1.309  loss_ce_2: 0.1364  loss_mask_2: 0.1256  loss_dice_2: 1.067  loss_ce_3: 0.1309  loss_mask_3: 0.1155  loss_dice_3: 0.9607  loss_ce_4: 0.1305  loss_mask_4: 0.1065  loss_dice_4: 0.9213  loss_ce_5: 0.131  loss_mask_5: 0.1069  loss_dice_5: 0.8761  loss_ce_6: 0.1359  loss_mask_6: 0.1097  loss_dice_6: 0.8561  loss_ce_7: 0.1356  loss_mask_7: 0.1123  loss_dice_7: 0.837  loss_ce_8: 0.1388  loss_mask_8: 0.1083  loss_dice_8: 0.8383  loss_mgm_entropy: 0.004546    time: 0.4365  last_time: 0.4361  data_time: 0.0034  last_data_time: 0.0038   lr: 1e-06  max_mem: 15545M
[08/30 23:46:00] d2.utils.events INFO:  eta: 0:07:51  iter: 2919  total_loss: 13.13  loss_ce: 0.1448  loss_mask: 0.08897  loss_dice: 0.8056  loss_ce_0: 0.7327  loss_mask_0: 0.1786  loss_dice_0: 1.992  loss_ce_1: 0.1774  loss_mask_1: 0.1384  loss_dice_1: 1.231  loss_ce_2: 0.1395  loss_mask_2: 0.1231  loss_dice_2: 1.021  loss_ce_3: 0.1327  loss_mask_3: 0.1058  loss_dice_3: 0.901  loss_ce_4: 0.1277  loss_mask_4: 0.1023  loss_dice_4: 0.8724  loss_ce_5: 0.1352  loss_mask_5: 0.09729  loss_dice_5: 0.8607  loss_ce_6: 0.1419  loss_mask_6: 0.09106  loss_dice_6: 0.8459  loss_ce_7: 0.1376  loss_mask_7: 0.09592  loss_dice_7: 0.8291  loss_ce_8: 0.1434  loss_mask_8: 0.08706  loss_dice_8: 0.8073  loss_mgm_entropy: 0.004499    time: 0.4365  last_time: 0.4362  data_time: 0.0036  last_data_time: 0.0031   lr: 1e-06  max_mem: 15545M
[08/30 23:46:09] d2.utils.events INFO:  eta: 0:07:42  iter: 2939  total_loss: 14.14  loss_ce: 0.1365  loss_mask: 0.1017  loss_dice: 0.8859  loss_ce_0: 0.7374  loss_mask_0: 0.1832  loss_dice_0: 2.051  loss_ce_1: 0.1746  loss_mask_1: 0.143  loss_dice_1: 1.363  loss_ce_2: 0.1369  loss_mask_2: 0.1125  loss_dice_2: 1.183  loss_ce_3: 0.132  loss_mask_3: 0.1106  loss_dice_3: 1.038  loss_ce_4: 0.1372  loss_mask_4: 0.1015  loss_dice_4: 0.9575  loss_ce_5: 0.1308  loss_mask_5: 0.1037  loss_dice_5: 0.9399  loss_ce_6: 0.1349  loss_mask_6: 0.1003  loss_dice_6: 0.9357  loss_ce_7: 0.133  loss_mask_7: 0.1036  loss_dice_7: 0.9104  loss_ce_8: 0.1337  loss_mask_8: 0.1028  loss_dice_8: 0.9085  loss_mgm_entropy: 0.004511    time: 0.4365  last_time: 0.4368  data_time: 0.0036  last_data_time: 0.0037   lr: 1e-06  max_mem: 15545M
[08/30 23:46:17] d2.utils.events INFO:  eta: 0:07:33  iter: 2959  total_loss: 13.28  loss_ce: 0.1332  loss_mask: 0.09653  loss_dice: 0.8148  loss_ce_0: 0.7393  loss_mask_0: 0.1833  loss_dice_0: 2.037  loss_ce_1: 0.169  loss_mask_1: 0.1338  loss_dice_1: 1.282  loss_ce_2: 0.1316  loss_mask_2: 0.1256  loss_dice_2: 1.026  loss_ce_3: 0.1246  loss_mask_3: 0.1134  loss_dice_3: 0.9101  loss_ce_4: 0.1239  loss_mask_4: 0.1044  loss_dice_4: 0.8972  loss_ce_5: 0.1229  loss_mask_5: 0.1038  loss_dice_5: 0.8197  loss_ce_6: 0.127  loss_mask_6: 0.1015  loss_dice_6: 0.8452  loss_ce_7: 0.1305  loss_mask_7: 0.09844  loss_dice_7: 0.8235  loss_ce_8: 0.1278  loss_mask_8: 0.09827  loss_dice_8: 0.8172  loss_mgm_entropy: 0.004499    time: 0.4365  last_time: 0.4361  data_time: 0.0035  last_data_time: 0.0036   lr: 1e-06  max_mem: 15545M
[08/30 23:46:26] d2.utils.events INFO:  eta: 0:07:24  iter: 2979  total_loss: 13.12  loss_ce: 0.1363  loss_mask: 0.09489  loss_dice: 0.7796  loss_ce_0: 0.7375  loss_mask_0: 0.2088  loss_dice_0: 1.985  loss_ce_1: 0.1732  loss_mask_1: 0.1359  loss_dice_1: 1.271  loss_ce_2: 0.1308  loss_mask_2: 0.1209  loss_dice_2: 1.01  loss_ce_3: 0.1271  loss_mask_3: 0.1122  loss_dice_3: 0.9002  loss_ce_4: 0.1242  loss_mask_4: 0.1053  loss_dice_4: 0.8493  loss_ce_5: 0.1243  loss_mask_5: 0.1067  loss_dice_5: 0.82  loss_ce_6: 0.1258  loss_mask_6: 0.1036  loss_dice_6: 0.8354  loss_ce_7: 0.1308  loss_mask_7: 0.1016  loss_dice_7: 0.7947  loss_ce_8: 0.1322  loss_mask_8: 0.09742  loss_dice_8: 0.7867  loss_mgm_entropy: 0.004527    time: 0.4365  last_time: 0.4360  data_time: 0.0036  last_data_time: 0.0036   lr: 1e-06  max_mem: 15545M
[08/30 23:46:35] d2.utils.events INFO:  eta: 0:07:16  iter: 2999  total_loss: 12.47  loss_ce: 0.1369  loss_mask: 0.08152  loss_dice: 0.767  loss_ce_0: 0.7347  loss_mask_0: 0.1557  loss_dice_0: 1.955  loss_ce_1: 0.1733  loss_mask_1: 0.1233  loss_dice_1: 1.244  loss_ce_2: 0.1357  loss_mask_2: 0.1081  loss_dice_2: 0.9723  loss_ce_3: 0.1336  loss_mask_3: 0.09767  loss_dice_3: 0.8835  loss_ce_4: 0.1295  loss_mask_4: 0.09014  loss_dice_4: 0.832  loss_ce_5: 0.1268  loss_mask_5: 0.08199  loss_dice_5: 0.7924  loss_ce_6: 0.1285  loss_mask_6: 0.08305  loss_dice_6: 0.7815  loss_ce_7: 0.1313  loss_mask_7: 0.08917  loss_dice_7: 0.7636  loss_ce_8: 0.1337  loss_mask_8: 0.0797  loss_dice_8: 0.767  loss_mgm_entropy: 0.004427    time: 0.4365  last_time: 0.4365  data_time: 0.0036  last_data_time: 0.0036   lr: 1e-06  max_mem: 15545M
[08/30 23:46:43] d2.utils.events INFO:  eta: 0:07:07  iter: 3019  total_loss: 13.89  loss_ce: 0.1412  loss_mask: 0.09847  loss_dice: 0.8603  loss_ce_0: 0.7285  loss_mask_0: 0.2012  loss_dice_0: 2.061  loss_ce_1: 0.1816  loss_mask_1: 0.1595  loss_dice_1: 1.381  loss_ce_2: 0.1486  loss_mask_2: 0.1274  loss_dice_2: 1.081  loss_ce_3: 0.1351  loss_mask_3: 0.116  loss_dice_3: 0.9681  loss_ce_4: 0.1367  loss_mask_4: 0.1118  loss_dice_4: 0.9016  loss_ce_5: 0.1377  loss_mask_5: 0.1026  loss_dice_5: 0.8875  loss_ce_6: 0.1329  loss_mask_6: 0.09784  loss_dice_6: 0.8718  loss_ce_7: 0.1406  loss_mask_7: 0.09744  loss_dice_7: 0.8623  loss_ce_8: 0.1326  loss_mask_8: 0.09321  loss_dice_8: 0.8489  loss_mgm_entropy: 0.004495    time: 0.4365  last_time: 0.4366  data_time: 0.0036  last_data_time: 0.0036   lr: 1e-07  max_mem: 15545M
[08/30 23:46:52] d2.utils.events INFO:  eta: 0:06:58  iter: 3039  total_loss: 13.76  loss_ce: 0.1311  loss_mask: 0.09862  loss_dice: 0.8123  loss_ce_0: 0.7257  loss_mask_0: 0.1689  loss_dice_0: 2.052  loss_ce_1: 0.1763  loss_mask_1: 0.1396  loss_dice_1: 1.323  loss_ce_2: 0.1338  loss_mask_2: 0.1138  loss_dice_2: 1.124  loss_ce_3: 0.1203  loss_mask_3: 0.1086  loss_dice_3: 0.9865  loss_ce_4: 0.1209  loss_mask_4: 0.1018  loss_dice_4: 0.9026  loss_ce_5: 0.1191  loss_mask_5: 0.09889  loss_dice_5: 0.8879  loss_ce_6: 0.1236  loss_mask_6: 0.09467  loss_dice_6: 0.8458  loss_ce_7: 0.1184  loss_mask_7: 0.09536  loss_dice_7: 0.8357  loss_ce_8: 0.1274  loss_mask_8: 0.09292  loss_dice_8: 0.8114  loss_mgm_entropy: 0.004471    time: 0.4365  last_time: 0.4363  data_time: 0.0038  last_data_time: 0.0034   lr: 1e-07  max_mem: 15545M
[08/30 23:47:01] d2.utils.events INFO:  eta: 0:06:50  iter: 3059  total_loss: 13.69  loss_ce: 0.1399  loss_mask: 0.09698  loss_dice: 0.8023  loss_ce_0: 0.7218  loss_mask_0: 0.1856  loss_dice_0: 1.913  loss_ce_1: 0.1788  loss_mask_1: 0.1415  loss_dice_1: 1.284  loss_ce_2: 0.1392  loss_mask_2: 0.1237  loss_dice_2: 1.02  loss_ce_3: 0.1366  loss_mask_3: 0.1045  loss_dice_3: 0.918  loss_ce_4: 0.1297  loss_mask_4: 0.101  loss_dice_4: 0.8773  loss_ce_5: 0.1306  loss_mask_5: 0.0948  loss_dice_5: 0.8513  loss_ce_6: 0.1317  loss_mask_6: 0.0913  loss_dice_6: 0.8541  loss_ce_7: 0.1372  loss_mask_7: 0.09568  loss_dice_7: 0.813  loss_ce_8: 0.1356  loss_mask_8: 0.08803  loss_dice_8: 0.7984  loss_mgm_entropy: 0.00447    time: 0.4365  last_time: 0.4347  data_time: 0.0036  last_data_time: 0.0040   lr: 1e-07  max_mem: 15545M
[08/30 23:47:10] d2.utils.events INFO:  eta: 0:06:41  iter: 3079  total_loss: 12.71  loss_ce: 0.1334  loss_mask: 0.0821  loss_dice: 0.7709  loss_ce_0: 0.7379  loss_mask_0: 0.176  loss_dice_0: 1.977  loss_ce_1: 0.1697  loss_mask_1: 0.1288  loss_dice_1: 1.255  loss_ce_2: 0.1312  loss_mask_2: 0.1027  loss_dice_2: 0.9769  loss_ce_3: 0.1262  loss_mask_3: 0.09414  loss_dice_3: 0.8995  loss_ce_4: 0.1227  loss_mask_4: 0.08942  loss_dice_4: 0.8294  loss_ce_5: 0.1238  loss_mask_5: 0.08732  loss_dice_5: 0.7843  loss_ce_6: 0.1265  loss_mask_6: 0.08601  loss_dice_6: 0.7871  loss_ce_7: 0.1296  loss_mask_7: 0.0847  loss_dice_7: 0.7852  loss_ce_8: 0.1318  loss_mask_8: 0.08126  loss_dice_8: 0.7771  loss_mgm_entropy: 0.004454    time: 0.4365  last_time: 0.4356  data_time: 0.0036  last_data_time: 0.0038   lr: 1e-07  max_mem: 15545M
[08/30 23:47:18] d2.utils.events INFO:  eta: 0:06:32  iter: 3099  total_loss: 13.85  loss_ce: 0.139  loss_mask: 0.0983  loss_dice: 0.818  loss_ce_0: 0.7157  loss_mask_0: 0.1847  loss_dice_0: 2.008  loss_ce_1: 0.171  loss_mask_1: 0.1323  loss_dice_1: 1.289  loss_ce_2: 0.132  loss_mask_2: 0.1196  loss_dice_2: 1.055  loss_ce_3: 0.1306  loss_mask_3: 0.1114  loss_dice_3: 0.9627  loss_ce_4: 0.1284  loss_mask_4: 0.1076  loss_dice_4: 0.8972  loss_ce_5: 0.1296  loss_mask_5: 0.1025  loss_dice_5: 0.8791  loss_ce_6: 0.1303  loss_mask_6: 0.1017  loss_dice_6: 0.8477  loss_ce_7: 0.1294  loss_mask_7: 0.09822  loss_dice_7: 0.8191  loss_ce_8: 0.1343  loss_mask_8: 0.09604  loss_dice_8: 0.8104  loss_mgm_entropy: 0.004524    time: 0.4365  last_time: 0.4367  data_time: 0.0035  last_data_time: 0.0034   lr: 1e-07  max_mem: 15545M
[08/30 23:47:27] d2.utils.events INFO:  eta: 0:06:23  iter: 3119  total_loss: 13.4  loss_ce: 0.1457  loss_mask: 0.1022  loss_dice: 0.819  loss_ce_0: 0.7398  loss_mask_0: 0.1859  loss_dice_0: 1.997  loss_ce_1: 0.176  loss_mask_1: 0.1386  loss_dice_1: 1.308  loss_ce_2: 0.1356  loss_mask_2: 0.1186  loss_dice_2: 1.024  loss_ce_3: 0.141  loss_mask_3: 0.1134  loss_dice_3: 0.927  loss_ce_4: 0.1405  loss_mask_4: 0.1098  loss_dice_4: 0.8741  loss_ce_5: 0.1423  loss_mask_5: 0.11  loss_dice_5: 0.8182  loss_ce_6: 0.1403  loss_mask_6: 0.1019  loss_dice_6: 0.8221  loss_ce_7: 0.1381  loss_mask_7: 0.107  loss_dice_7: 0.8124  loss_ce_8: 0.1403  loss_mask_8: 0.1065  loss_dice_8: 0.8087  loss_mgm_entropy: 0.004521    time: 0.4365  last_time: 0.4356  data_time: 0.0035  last_data_time: 0.0034   lr: 1e-07  max_mem: 15545M
[08/30 23:47:36] d2.utils.events INFO:  eta: 0:06:15  iter: 3139  total_loss: 12.49  loss_ce: 0.1427  loss_mask: 0.08287  loss_dice: 0.7673  loss_ce_0: 0.7333  loss_mask_0: 0.1613  loss_dice_0: 1.986  loss_ce_1: 0.1772  loss_mask_1: 0.1143  loss_dice_1: 1.2  loss_ce_2: 0.1401  loss_mask_2: 0.09878  loss_dice_2: 0.9233  loss_ce_3: 0.1403  loss_mask_3: 0.09124  loss_dice_3: 0.8542  loss_ce_4: 0.1371  loss_mask_4: 0.0901  loss_dice_4: 0.8156  loss_ce_5: 0.1399  loss_mask_5: 0.08667  loss_dice_5: 0.799  loss_ce_6: 0.1403  loss_mask_6: 0.08587  loss_dice_6: 0.7874  loss_ce_7: 0.1417  loss_mask_7: 0.08183  loss_dice_7: 0.7728  loss_ce_8: 0.1441  loss_mask_8: 0.08205  loss_dice_8: 0.781  loss_mgm_entropy: 0.004456    time: 0.4365  last_time: 0.4366  data_time: 0.0036  last_data_time: 0.0036   lr: 1e-07  max_mem: 15545M
[08/30 23:47:45] d2.utils.events INFO:  eta: 0:06:06  iter: 3159  total_loss: 12.35  loss_ce: 0.1366  loss_mask: 0.082  loss_dice: 0.7695  loss_ce_0: 0.7365  loss_mask_0: 0.1827  loss_dice_0: 1.886  loss_ce_1: 0.1722  loss_mask_1: 0.1237  loss_dice_1: 1.178  loss_ce_2: 0.1353  loss_mask_2: 0.0977  loss_dice_2: 0.9181  loss_ce_3: 0.1282  loss_mask_3: 0.09329  loss_dice_3: 0.8554  loss_ce_4: 0.1294  loss_mask_4: 0.0924  loss_dice_4: 0.8071  loss_ce_5: 0.1284  loss_mask_5: 0.08915  loss_dice_5: 0.7697  loss_ce_6: 0.1306  loss_mask_6: 0.08889  loss_dice_6: 0.7951  loss_ce_7: 0.1312  loss_mask_7: 0.08877  loss_dice_7: 0.787  loss_ce_8: 0.1371  loss_mask_8: 0.08347  loss_dice_8: 0.7705  loss_mgm_entropy: 0.004489    time: 0.4365  last_time: 0.4358  data_time: 0.0037  last_data_time: 0.0038   lr: 1e-07  max_mem: 15545M
[08/30 23:47:53] d2.utils.events INFO:  eta: 0:05:57  iter: 3179  total_loss: 12.85  loss_ce: 0.1407  loss_mask: 0.08199  loss_dice: 0.7754  loss_ce_0: 0.7383  loss_mask_0: 0.1657  loss_dice_0: 1.933  loss_ce_1: 0.1728  loss_mask_1: 0.1181  loss_dice_1: 1.252  loss_ce_2: 0.1469  loss_mask_2: 0.107  loss_dice_2: 0.989  loss_ce_3: 0.1388  loss_mask_3: 0.09529  loss_dice_3: 0.8891  loss_ce_4: 0.138  loss_mask_4: 0.09412  loss_dice_4: 0.8429  loss_ce_5: 0.1363  loss_mask_5: 0.09214  loss_dice_5: 0.8109  loss_ce_6: 0.1369  loss_mask_6: 0.0896  loss_dice_6: 0.803  loss_ce_7: 0.1398  loss_mask_7: 0.08835  loss_dice_7: 0.7978  loss_ce_8: 0.1419  loss_mask_8: 0.08194  loss_dice_8: 0.7846  loss_mgm_entropy: 0.004477    time: 0.4365  last_time: 0.4364  data_time: 0.0035  last_data_time: 0.0043   lr: 1e-07  max_mem: 15545M
[08/30 23:48:02] d2.utils.events INFO:  eta: 0:05:49  iter: 3199  total_loss: 13.25  loss_ce: 0.1393  loss_mask: 0.1063  loss_dice: 0.803  loss_ce_0: 0.733  loss_mask_0: 0.1883  loss_dice_0: 2.024  loss_ce_1: 0.1752  loss_mask_1: 0.1505  loss_dice_1: 1.23  loss_ce_2: 0.1351  loss_mask_2: 0.1258  loss_dice_2: 0.9855  loss_ce_3: 0.129  loss_mask_3: 0.1099  loss_dice_3: 0.9095  loss_ce_4: 0.1327  loss_mask_4: 0.1119  loss_dice_4: 0.8533  loss_ce_5: 0.134  loss_mask_5: 0.1107  loss_dice_5: 0.8315  loss_ce_6: 0.1339  loss_mask_6: 0.1083  loss_dice_6: 0.8445  loss_ce_7: 0.1365  loss_mask_7: 0.09958  loss_dice_7: 0.8195  loss_ce_8: 0.1359  loss_mask_8: 0.1041  loss_dice_8: 0.8337  loss_mgm_entropy: 0.004511    time: 0.4365  last_time: 0.4366  data_time: 0.0036  last_data_time: 0.0033   lr: 1e-07  max_mem: 15545M
[08/30 23:48:11] d2.utils.events INFO:  eta: 0:05:40  iter: 3219  total_loss: 12.37  loss_ce: 0.1299  loss_mask: 0.08734  loss_dice: 0.7464  loss_ce_0: 0.7219  loss_mask_0: 0.1857  loss_dice_0: 1.891  loss_ce_1: 0.1682  loss_mask_1: 0.1246  loss_dice_1: 1.193  loss_ce_2: 0.1327  loss_mask_2: 0.1089  loss_dice_2: 0.9515  loss_ce_3: 0.1214  loss_mask_3: 0.0967  loss_dice_3: 0.8465  loss_ce_4: 0.126  loss_mask_4: 0.09088  loss_dice_4: 0.8045  loss_ce_5: 0.1194  loss_mask_5: 0.09232  loss_dice_5: 0.7953  loss_ce_6: 0.1189  loss_mask_6: 0.08619  loss_dice_6: 0.7792  loss_ce_7: 0.1278  loss_mask_7: 0.08697  loss_dice_7: 0.7696  loss_ce_8: 0.1248  loss_mask_8: 0.0828  loss_dice_8: 0.7509  loss_mgm_entropy: 0.0045    time: 0.4365  last_time: 0.4365  data_time: 0.0033  last_data_time: 0.0029   lr: 1e-07  max_mem: 15545M
[08/30 23:48:20] d2.utils.events INFO:  eta: 0:05:31  iter: 3239  total_loss: 13.19  loss_ce: 0.1375  loss_mask: 0.0948  loss_dice: 0.8415  loss_ce_0: 0.7342  loss_mask_0: 0.1877  loss_dice_0: 1.991  loss_ce_1: 0.172  loss_mask_1: 0.16  loss_dice_1: 1.345  loss_ce_2: 0.1352  loss_mask_2: 0.1338  loss_dice_2: 1.122  loss_ce_3: 0.1287  loss_mask_3: 0.1164  loss_dice_3: 0.9941  loss_ce_4: 0.124  loss_mask_4: 0.1096  loss_dice_4: 0.904  loss_ce_5: 0.1241  loss_mask_5: 0.1061  loss_dice_5: 0.87  loss_ce_6: 0.1246  loss_mask_6: 0.1008  loss_dice_6: 0.8557  loss_ce_7: 0.132  loss_mask_7: 0.1012  loss_dice_7: 0.8417  loss_ce_8: 0.1336  loss_mask_8: 0.09584  loss_dice_8: 0.8304  loss_mgm_entropy: 0.004516    time: 0.4365  last_time: 0.4361  data_time: 0.0035  last_data_time: 0.0039   lr: 1e-07  max_mem: 15545M
[08/30 23:48:28] d2.utils.events INFO:  eta: 0:05:22  iter: 3259  total_loss: 12.66  loss_ce: 0.1424  loss_mask: 0.09011  loss_dice: 0.7611  loss_ce_0: 0.7286  loss_mask_0: 0.1858  loss_dice_0: 1.949  loss_ce_1: 0.1749  loss_mask_1: 0.1174  loss_dice_1: 1.24  loss_ce_2: 0.1435  loss_mask_2: 0.09502  loss_dice_2: 0.9387  loss_ce_3: 0.1413  loss_mask_3: 0.08872  loss_dice_3: 0.8476  loss_ce_4: 0.1408  loss_mask_4: 0.0887  loss_dice_4: 0.8165  loss_ce_5: 0.1358  loss_mask_5: 0.08531  loss_dice_5: 0.8127  loss_ce_6: 0.1319  loss_mask_6: 0.08427  loss_dice_6: 0.7892  loss_ce_7: 0.1348  loss_mask_7: 0.09315  loss_dice_7: 0.7943  loss_ce_8: 0.1351  loss_mask_8: 0.0883  loss_dice_8: 0.7674  loss_mgm_entropy: 0.004511    time: 0.4365  last_time: 0.4371  data_time: 0.0034  last_data_time: 0.0032   lr: 1e-07  max_mem: 15545M
[08/30 23:48:37] d2.utils.events INFO:  eta: 0:05:14  iter: 3279  total_loss: 12.85  loss_ce: 0.1369  loss_mask: 0.08861  loss_dice: 0.7875  loss_ce_0: 0.7396  loss_mask_0: 0.1824  loss_dice_0: 1.911  loss_ce_1: 0.1688  loss_mask_1: 0.1219  loss_dice_1: 1.211  loss_ce_2: 0.1386  loss_mask_2: 0.1016  loss_dice_2: 0.9476  loss_ce_3: 0.1327  loss_mask_3: 0.09716  loss_dice_3: 0.8708  loss_ce_4: 0.1337  loss_mask_4: 0.09928  loss_dice_4: 0.8084  loss_ce_5: 0.1345  loss_mask_5: 0.1006  loss_dice_5: 0.7869  loss_ce_6: 0.1303  loss_mask_6: 0.09273  loss_dice_6: 0.8029  loss_ce_7: 0.1334  loss_mask_7: 0.08779  loss_dice_7: 0.791  loss_ce_8: 0.1353  loss_mask_8: 0.08602  loss_dice_8: 0.7828  loss_mgm_entropy: 0.004549    time: 0.4366  last_time: 0.4373  data_time: 0.0036  last_data_time: 0.0040   lr: 1e-07  max_mem: 15545M
[08/30 23:48:46] d2.utils.events INFO:  eta: 0:05:05  iter: 3299  total_loss: 12.94  loss_ce: 0.1443  loss_mask: 0.09474  loss_dice: 0.7834  loss_ce_0: 0.7272  loss_mask_0: 0.1936  loss_dice_0: 1.952  loss_ce_1: 0.1767  loss_mask_1: 0.1346  loss_dice_1: 1.232  loss_ce_2: 0.1404  loss_mask_2: 0.1102  loss_dice_2: 0.9798  loss_ce_3: 0.1379  loss_mask_3: 0.108  loss_dice_3: 0.8914  loss_ce_4: 0.1363  loss_mask_4: 0.09909  loss_dice_4: 0.8442  loss_ce_5: 0.141  loss_mask_5: 0.1005  loss_dice_5: 0.8266  loss_ce_6: 0.1397  loss_mask_6: 0.101  loss_dice_6: 0.8088  loss_ce_7: 0.1354  loss_mask_7: 0.09923  loss_dice_7: 0.8065  loss_ce_8: 0.1442  loss_mask_8: 0.09496  loss_dice_8: 0.7803  loss_mgm_entropy: 0.004514    time: 0.4366  last_time: 0.4354  data_time: 0.0036  last_data_time: 0.0039   lr: 1e-07  max_mem: 15545M
[08/30 23:48:55] d2.utils.events INFO:  eta: 0:04:56  iter: 3319  total_loss: 13.13  loss_ce: 0.1414  loss_mask: 0.0926  loss_dice: 0.8251  loss_ce_0: 0.7375  loss_mask_0: 0.1674  loss_dice_0: 1.952  loss_ce_1: 0.1751  loss_mask_1: 0.1295  loss_dice_1: 1.25  loss_ce_2: 0.1428  loss_mask_2: 0.1031  loss_dice_2: 1.031  loss_ce_3: 0.1279  loss_mask_3: 0.0877  loss_dice_3: 0.9361  loss_ce_4: 0.1256  loss_mask_4: 0.08785  loss_dice_4: 0.8734  loss_ce_5: 0.131  loss_mask_5: 0.09012  loss_dice_5: 0.8372  loss_ce_6: 0.1349  loss_mask_6: 0.08775  loss_dice_6: 0.8372  loss_ce_7: 0.137  loss_mask_7: 0.09001  loss_dice_7: 0.812  loss_ce_8: 0.1412  loss_mask_8: 0.09223  loss_dice_8: 0.8352  loss_mgm_entropy: 0.004488    time: 0.4366  last_time: 0.4367  data_time: 0.0035  last_data_time: 0.0038   lr: 1e-07  max_mem: 15545M
[08/30 23:49:03] d2.utils.events INFO:  eta: 0:04:47  iter: 3339  total_loss: 12.39  loss_ce: 0.1398  loss_mask: 0.09409  loss_dice: 0.7794  loss_ce_0: 0.7362  loss_mask_0: 0.1839  loss_dice_0: 1.886  loss_ce_1: 0.1797  loss_mask_1: 0.1286  loss_dice_1: 1.166  loss_ce_2: 0.1386  loss_mask_2: 0.1114  loss_dice_2: 0.9461  loss_ce_3: 0.1337  loss_mask_3: 0.09587  loss_dice_3: 0.865  loss_ce_4: 0.1284  loss_mask_4: 0.09086  loss_dice_4: 0.8285  loss_ce_5: 0.13  loss_mask_5: 0.0949  loss_dice_5: 0.8062  loss_ce_6: 0.1303  loss_mask_6: 0.09105  loss_dice_6: 0.8086  loss_ce_7: 0.1324  loss_mask_7: 0.09662  loss_dice_7: 0.8017  loss_ce_8: 0.1346  loss_mask_8: 0.08853  loss_dice_8: 0.7863  loss_mgm_entropy: 0.00448    time: 0.4366  last_time: 0.4364  data_time: 0.0035  last_data_time: 0.0033   lr: 1e-07  max_mem: 15545M
[08/30 23:49:12] d2.utils.events INFO:  eta: 0:04:39  iter: 3359  total_loss: 13.49  loss_ce: 0.1328  loss_mask: 0.08231  loss_dice: 0.7938  loss_ce_0: 0.7351  loss_mask_0: 0.1829  loss_dice_0: 2.013  loss_ce_1: 0.1728  loss_mask_1: 0.1434  loss_dice_1: 1.268  loss_ce_2: 0.136  loss_mask_2: 0.1138  loss_dice_2: 1.063  loss_ce_3: 0.132  loss_mask_3: 0.1009  loss_dice_3: 0.9793  loss_ce_4: 0.1292  loss_mask_4: 0.0978  loss_dice_4: 0.9024  loss_ce_5: 0.1256  loss_mask_5: 0.09922  loss_dice_5: 0.9039  loss_ce_6: 0.1224  loss_mask_6: 0.09019  loss_dice_6: 0.8718  loss_ce_7: 0.129  loss_mask_7: 0.09611  loss_dice_7: 0.8278  loss_ce_8: 0.132  loss_mask_8: 0.09053  loss_dice_8: 0.8129  loss_mgm_entropy: 0.004517    time: 0.4366  last_time: 0.4347  data_time: 0.0035  last_data_time: 0.0036   lr: 1e-07  max_mem: 15545M
[08/30 23:49:21] d2.utils.events INFO:  eta: 0:04:30  iter: 3379  total_loss: 13.19  loss_ce: 0.1405  loss_mask: 0.1005  loss_dice: 0.7698  loss_ce_0: 0.7213  loss_mask_0: 0.2016  loss_dice_0: 1.96  loss_ce_1: 0.1732  loss_mask_1: 0.1467  loss_dice_1: 1.233  loss_ce_2: 0.137  loss_mask_2: 0.1145  loss_dice_2: 0.9857  loss_ce_3: 0.133  loss_mask_3: 0.1062  loss_dice_3: 0.8919  loss_ce_4: 0.1347  loss_mask_4: 0.102  loss_dice_4: 0.8654  loss_ce_5: 0.1358  loss_mask_5: 0.1038  loss_dice_5: 0.8273  loss_ce_6: 0.1362  loss_mask_6: 0.09626  loss_dice_6: 0.8163  loss_ce_7: 0.1331  loss_mask_7: 0.09842  loss_dice_7: 0.8132  loss_ce_8: 0.1385  loss_mask_8: 0.09408  loss_dice_8: 0.7962  loss_mgm_entropy: 0.004548    time: 0.4366  last_time: 0.4349  data_time: 0.0034  last_data_time: 0.0034   lr: 1e-07  max_mem: 15545M
[08/30 23:49:30] d2.utils.events INFO:  eta: 0:04:21  iter: 3399  total_loss: 12.53  loss_ce: 0.1433  loss_mask: 0.09486  loss_dice: 0.7615  loss_ce_0: 0.7321  loss_mask_0: 0.1988  loss_dice_0: 1.931  loss_ce_1: 0.1733  loss_mask_1: 0.1313  loss_dice_1: 1.231  loss_ce_2: 0.1365  loss_mask_2: 0.1094  loss_dice_2: 0.9706  loss_ce_3: 0.1318  loss_mask_3: 0.1008  loss_dice_3: 0.8624  loss_ce_4: 0.1331  loss_mask_4: 0.1037  loss_dice_4: 0.8151  loss_ce_5: 0.1415  loss_mask_5: 0.1011  loss_dice_5: 0.8117  loss_ce_6: 0.1421  loss_mask_6: 0.09368  loss_dice_6: 0.8015  loss_ce_7: 0.1405  loss_mask_7: 0.0931  loss_dice_7: 0.7864  loss_ce_8: 0.1434  loss_mask_8: 0.09239  loss_dice_8: 0.7658  loss_mgm_entropy: 0.00451    time: 0.4365  last_time: 0.4354  data_time: 0.0034  last_data_time: 0.0038   lr: 1e-07  max_mem: 15545M
[08/30 23:49:38] d2.utils.events INFO:  eta: 0:04:13  iter: 3419  total_loss: 12.45  loss_ce: 0.1361  loss_mask: 0.07383  loss_dice: 0.7707  loss_ce_0: 0.7391  loss_mask_0: 0.1607  loss_dice_0: 1.894  loss_ce_1: 0.1691  loss_mask_1: 0.1083  loss_dice_1: 1.19  loss_ce_2: 0.1365  loss_mask_2: 0.08861  loss_dice_2: 0.9614  loss_ce_3: 0.13  loss_mask_3: 0.08166  loss_dice_3: 0.8608  loss_ce_4: 0.1304  loss_mask_4: 0.07759  loss_dice_4: 0.8243  loss_ce_5: 0.1279  loss_mask_5: 0.07498  loss_dice_5: 0.7993  loss_ce_6: 0.1288  loss_mask_6: 0.078  loss_dice_6: 0.8045  loss_ce_7: 0.1332  loss_mask_7: 0.07639  loss_dice_7: 0.7676  loss_ce_8: 0.1345  loss_mask_8: 0.0747  loss_dice_8: 0.7561  loss_mgm_entropy: 0.004442    time: 0.4365  last_time: 0.4351  data_time: 0.0034  last_data_time: 0.0035   lr: 1e-07  max_mem: 15545M
[08/30 23:49:47] d2.utils.events INFO:  eta: 0:04:04  iter: 3439  total_loss: 12.69  loss_ce: 0.1365  loss_mask: 0.08185  loss_dice: 0.7907  loss_ce_0: 0.7263  loss_mask_0: 0.1781  loss_dice_0: 1.984  loss_ce_1: 0.174  loss_mask_1: 0.1136  loss_dice_1: 1.212  loss_ce_2: 0.1315  loss_mask_2: 0.09611  loss_dice_2: 0.9679  loss_ce_3: 0.1262  loss_mask_3: 0.0869  loss_dice_3: 0.8587  loss_ce_4: 0.1241  loss_mask_4: 0.08711  loss_dice_4: 0.8212  loss_ce_5: 0.1318  loss_mask_5: 0.08273  loss_dice_5: 0.8104  loss_ce_6: 0.1261  loss_mask_6: 0.08529  loss_dice_6: 0.8079  loss_ce_7: 0.1309  loss_mask_7: 0.0815  loss_dice_7: 0.8039  loss_ce_8: 0.1352  loss_mask_8: 0.08102  loss_dice_8: 0.7912  loss_mgm_entropy: 0.004488    time: 0.4365  last_time: 0.4360  data_time: 0.0033  last_data_time: 0.0038   lr: 1e-07  max_mem: 15545M
[08/30 23:49:56] d2.utils.events INFO:  eta: 0:03:55  iter: 3459  total_loss: 12.61  loss_ce: 0.1386  loss_mask: 0.08236  loss_dice: 0.7652  loss_ce_0: 0.7383  loss_mask_0: 0.1829  loss_dice_0: 1.921  loss_ce_1: 0.1713  loss_mask_1: 0.1241  loss_dice_1: 1.188  loss_ce_2: 0.1396  loss_mask_2: 0.1088  loss_dice_2: 0.9586  loss_ce_3: 0.1316  loss_mask_3: 0.104  loss_dice_3: 0.8517  loss_ce_4: 0.125  loss_mask_4: 0.09896  loss_dice_4: 0.8192  loss_ce_5: 0.1265  loss_mask_5: 0.09703  loss_dice_5: 0.809  loss_ce_6: 0.1266  loss_mask_6: 0.09007  loss_dice_6: 0.7897  loss_ce_7: 0.1297  loss_mask_7: 0.09012  loss_dice_7: 0.7923  loss_ce_8: 0.1361  loss_mask_8: 0.08993  loss_dice_8: 0.7838  loss_mgm_entropy: 0.004524    time: 0.4365  last_time: 0.4368  data_time: 0.0036  last_data_time: 0.0035   lr: 1e-07  max_mem: 15545M
[08/30 23:50:04] d2.utils.events INFO:  eta: 0:03:46  iter: 3479  total_loss: 12.67  loss_ce: 0.1419  loss_mask: 0.08782  loss_dice: 0.786  loss_ce_0: 0.7321  loss_mask_0: 0.1856  loss_dice_0: 1.946  loss_ce_1: 0.1772  loss_mask_1: 0.1292  loss_dice_1: 1.2  loss_ce_2: 0.1407  loss_mask_2: 0.1104  loss_dice_2: 0.9756  loss_ce_3: 0.1341  loss_mask_3: 0.09348  loss_dice_3: 0.8951  loss_ce_4: 0.1304  loss_mask_4: 0.09133  loss_dice_4: 0.825  loss_ce_5: 0.1397  loss_mask_5: 0.08753  loss_dice_5: 0.8016  loss_ce_6: 0.1397  loss_mask_6: 0.08884  loss_dice_6: 0.8194  loss_ce_7: 0.1367  loss_mask_7: 0.08468  loss_dice_7: 0.7989  loss_ce_8: 0.141  loss_mask_8: 0.0859  loss_dice_8: 0.7792  loss_mgm_entropy: 0.00451    time: 0.4365  last_time: 0.4365  data_time: 0.0035  last_data_time: 0.0039   lr: 1e-07  max_mem: 15545M
[08/30 23:50:13] d2.utils.events INFO:  eta: 0:03:38  iter: 3499  total_loss: 13.13  loss_ce: 0.1384  loss_mask: 0.09931  loss_dice: 0.7736  loss_ce_0: 0.7361  loss_mask_0: 0.2128  loss_dice_0: 2.044  loss_ce_1: 0.1698  loss_mask_1: 0.1539  loss_dice_1: 1.301  loss_ce_2: 0.1326  loss_mask_2: 0.1323  loss_dice_2: 1.009  loss_ce_3: 0.1278  loss_mask_3: 0.1144  loss_dice_3: 0.8928  loss_ce_4: 0.1312  loss_mask_4: 0.1088  loss_dice_4: 0.8366  loss_ce_5: 0.1325  loss_mask_5: 0.09835  loss_dice_5: 0.792  loss_ce_6: 0.1301  loss_mask_6: 0.09971  loss_dice_6: 0.7849  loss_ce_7: 0.1317  loss_mask_7: 0.09527  loss_dice_7: 0.7693  loss_ce_8: 0.1364  loss_mask_8: 0.09679  loss_dice_8: 0.7677  loss_mgm_entropy: 0.00451    time: 0.4365  last_time: 0.4359  data_time: 0.0035  last_data_time: 0.0042   lr: 1e-07  max_mem: 15545M
[08/30 23:50:22] d2.utils.events INFO:  eta: 0:03:29  iter: 3519  total_loss: 12.77  loss_ce: 0.1452  loss_mask: 0.08106  loss_dice: 0.7652  loss_ce_0: 0.7357  loss_mask_0: 0.1882  loss_dice_0: 1.944  loss_ce_1: 0.174  loss_mask_1: 0.1336  loss_dice_1: 1.217  loss_ce_2: 0.1405  loss_mask_2: 0.1135  loss_dice_2: 0.9803  loss_ce_3: 0.1327  loss_mask_3: 0.1005  loss_dice_3: 0.8949  loss_ce_4: 0.132  loss_mask_4: 0.09357  loss_dice_4: 0.8516  loss_ce_5: 0.1321  loss_mask_5: 0.09054  loss_dice_5: 0.8246  loss_ce_6: 0.1353  loss_mask_6: 0.08652  loss_dice_6: 0.8159  loss_ce_7: 0.1394  loss_mask_7: 0.08905  loss_dice_7: 0.7934  loss_ce_8: 0.1412  loss_mask_8: 0.08462  loss_dice_8: 0.7754  loss_mgm_entropy: 0.004464    time: 0.4365  last_time: 0.4360  data_time: 0.0036  last_data_time: 0.0034   lr: 1e-07  max_mem: 15545M
[08/30 23:50:31] d2.utils.events INFO:  eta: 0:03:20  iter: 3539  total_loss: 14.22  loss_ce: 0.1391  loss_mask: 0.1222  loss_dice: 0.8962  loss_ce_0: 0.7335  loss_mask_0: 0.2091  loss_dice_0: 2.069  loss_ce_1: 0.1752  loss_mask_1: 0.1644  loss_dice_1: 1.401  loss_ce_2: 0.1346  loss_mask_2: 0.1296  loss_dice_2: 1.155  loss_ce_3: 0.1307  loss_mask_3: 0.1236  loss_dice_3: 1.03  loss_ce_4: 0.1273  loss_mask_4: 0.1207  loss_dice_4: 0.9606  loss_ce_5: 0.1258  loss_mask_5: 0.1269  loss_dice_5: 0.9324  loss_ce_6: 0.1275  loss_mask_6: 0.1239  loss_dice_6: 0.935  loss_ce_7: 0.1283  loss_mask_7: 0.1263  loss_dice_7: 0.8961  loss_ce_8: 0.1314  loss_mask_8: 0.1215  loss_dice_8: 0.9087  loss_mgm_entropy: 0.004509    time: 0.4365  last_time: 0.4359  data_time: 0.0034  last_data_time: 0.0041   lr: 1e-07  max_mem: 15545M
[08/30 23:50:39] d2.utils.events INFO:  eta: 0:03:11  iter: 3559  total_loss: 13.02  loss_ce: 0.1407  loss_mask: 0.08728  loss_dice: 0.7787  loss_ce_0: 0.7358  loss_mask_0: 0.1656  loss_dice_0: 1.928  loss_ce_1: 0.1788  loss_mask_1: 0.134  loss_dice_1: 1.223  loss_ce_2: 0.1405  loss_mask_2: 0.1147  loss_dice_2: 0.9891  loss_ce_3: 0.1321  loss_mask_3: 0.09782  loss_dice_3: 0.8895  loss_ce_4: 0.1322  loss_mask_4: 0.09803  loss_dice_4: 0.8547  loss_ce_5: 0.128  loss_mask_5: 0.0956  loss_dice_5: 0.8204  loss_ce_6: 0.1307  loss_mask_6: 0.09074  loss_dice_6: 0.7993  loss_ce_7: 0.1336  loss_mask_7: 0.09061  loss_dice_7: 0.7924  loss_ce_8: 0.1414  loss_mask_8: 0.09134  loss_dice_8: 0.7802  loss_mgm_entropy: 0.004467    time: 0.4365  last_time: 0.4363  data_time: 0.0035  last_data_time: 0.0034   lr: 1e-07  max_mem: 15545M
[08/30 23:50:48] d2.utils.events INFO:  eta: 0:03:03  iter: 3579  total_loss: 13.39  loss_ce: 0.1411  loss_mask: 0.1058  loss_dice: 0.7921  loss_ce_0: 0.7409  loss_mask_0: 0.186  loss_dice_0: 1.96  loss_ce_1: 0.1767  loss_mask_1: 0.1458  loss_dice_1: 1.296  loss_ce_2: 0.1538  loss_mask_2: 0.1202  loss_dice_2: 0.9911  loss_ce_3: 0.1405  loss_mask_3: 0.112  loss_dice_3: 0.8997  loss_ce_4: 0.1375  loss_mask_4: 0.1041  loss_dice_4: 0.8535  loss_ce_5: 0.136  loss_mask_5: 0.1118  loss_dice_5: 0.8324  loss_ce_6: 0.1371  loss_mask_6: 0.1034  loss_dice_6: 0.8021  loss_ce_7: 0.1404  loss_mask_7: 0.1037  loss_dice_7: 0.7911  loss_ce_8: 0.1419  loss_mask_8: 0.1025  loss_dice_8: 0.7922  loss_mgm_entropy: 0.00448    time: 0.4365  last_time: 0.4355  data_time: 0.0036  last_data_time: 0.0041   lr: 1e-07  max_mem: 15545M
[08/30 23:50:57] d2.utils.events INFO:  eta: 0:02:54  iter: 3599  total_loss: 13.05  loss_ce: 0.1423  loss_mask: 0.09099  loss_dice: 0.8131  loss_ce_0: 0.7265  loss_mask_0: 0.177  loss_dice_0: 2.017  loss_ce_1: 0.1739  loss_mask_1: 0.1486  loss_dice_1: 1.228  loss_ce_2: 0.1343  loss_mask_2: 0.1124  loss_dice_2: 0.9594  loss_ce_3: 0.131  loss_mask_3: 0.09917  loss_dice_3: 0.8872  loss_ce_4: 0.1286  loss_mask_4: 0.09764  loss_dice_4: 0.8789  loss_ce_5: 0.1392  loss_mask_5: 0.09483  loss_dice_5: 0.8438  loss_ce_6: 0.1344  loss_mask_6: 0.09242  loss_dice_6: 0.8439  loss_ce_7: 0.1374  loss_mask_7: 0.0938  loss_dice_7: 0.8368  loss_ce_8: 0.1387  loss_mask_8: 0.09071  loss_dice_8: 0.8278  loss_mgm_entropy: 0.004488    time: 0.4365  last_time: 0.4357  data_time: 0.0035  last_data_time: 0.0043   lr: 1e-07  max_mem: 15545M
[08/30 23:51:06] d2.utils.events INFO:  eta: 0:02:45  iter: 3619  total_loss: 13.03  loss_ce: 0.1271  loss_mask: 0.08019  loss_dice: 0.7863  loss_ce_0: 0.7375  loss_mask_0: 0.1799  loss_dice_0: 1.946  loss_ce_1: 0.1693  loss_mask_1: 0.1297  loss_dice_1: 1.235  loss_ce_2: 0.132  loss_mask_2: 0.1146  loss_dice_2: 0.9733  loss_ce_3: 0.1245  loss_mask_3: 0.09924  loss_dice_3: 0.8793  loss_ce_4: 0.1209  loss_mask_4: 0.09295  loss_dice_4: 0.836  loss_ce_5: 0.1194  loss_mask_5: 0.0858  loss_dice_5: 0.8311  loss_ce_6: 0.1203  loss_mask_6: 0.07891  loss_dice_6: 0.8465  loss_ce_7: 0.1217  loss_mask_7: 0.07744  loss_dice_7: 0.816  loss_ce_8: 0.1216  loss_mask_8: 0.07864  loss_dice_8: 0.8059  loss_mgm_entropy: 0.004472    time: 0.4365  last_time: 0.4362  data_time: 0.0036  last_data_time: 0.0032   lr: 1e-07  max_mem: 15545M
[08/30 23:51:14] d2.utils.events INFO:  eta: 0:02:37  iter: 3639  total_loss: 12.5  loss_ce: 0.1387  loss_mask: 0.0881  loss_dice: 0.7435  loss_ce_0: 0.7325  loss_mask_0: 0.1782  loss_dice_0: 1.907  loss_ce_1: 0.1735  loss_mask_1: 0.1246  loss_dice_1: 1.269  loss_ce_2: 0.1524  loss_mask_2: 0.1062  loss_dice_2: 0.963  loss_ce_3: 0.1384  loss_mask_3: 0.09509  loss_dice_3: 0.8664  loss_ce_4: 0.1257  loss_mask_4: 0.09646  loss_dice_4: 0.8006  loss_ce_5: 0.1376  loss_mask_5: 0.09554  loss_dice_5: 0.7735  loss_ce_6: 0.1276  loss_mask_6: 0.09608  loss_dice_6: 0.7654  loss_ce_7: 0.138  loss_mask_7: 0.09315  loss_dice_7: 0.7467  loss_ce_8: 0.1419  loss_mask_8: 0.08986  loss_dice_8: 0.7488  loss_mgm_entropy: 0.004502    time: 0.4365  last_time: 0.4357  data_time: 0.0034  last_data_time: 0.0030   lr: 1e-07  max_mem: 15545M
[08/30 23:51:23] d2.utils.events INFO:  eta: 0:02:28  iter: 3659  total_loss: 13.91  loss_ce: 0.1422  loss_mask: 0.09269  loss_dice: 0.7961  loss_ce_0: 0.7272  loss_mask_0: 0.1994  loss_dice_0: 2.012  loss_ce_1: 0.175  loss_mask_1: 0.1293  loss_dice_1: 1.32  loss_ce_2: 0.1348  loss_mask_2: 0.115  loss_dice_2: 1.098  loss_ce_3: 0.1294  loss_mask_3: 0.1046  loss_dice_3: 0.9979  loss_ce_4: 0.1409  loss_mask_4: 0.1018  loss_dice_4: 0.912  loss_ce_5: 0.138  loss_mask_5: 0.1006  loss_dice_5: 0.8943  loss_ce_6: 0.1285  loss_mask_6: 0.09777  loss_dice_6: 0.9023  loss_ce_7: 0.1332  loss_mask_7: 0.09521  loss_dice_7: 0.8731  loss_ce_8: 0.1396  loss_mask_8: 0.09189  loss_dice_8: 0.8193  loss_mgm_entropy: 0.004494    time: 0.4365  last_time: 0.4357  data_time: 0.0035  last_data_time: 0.0033   lr: 1e-07  max_mem: 15545M
[08/30 23:51:32] d2.utils.events INFO:  eta: 0:02:19  iter: 3679  total_loss: 14.01  loss_ce: 0.1457  loss_mask: 0.08094  loss_dice: 0.838  loss_ce_0: 0.7423  loss_mask_0: 0.1654  loss_dice_0: 1.943  loss_ce_1: 0.1779  loss_mask_1: 0.1325  loss_dice_1: 1.279  loss_ce_2: 0.1499  loss_mask_2: 0.1132  loss_dice_2: 1.021  loss_ce_3: 0.1416  loss_mask_3: 0.1028  loss_dice_3: 0.9583  loss_ce_4: 0.1398  loss_mask_4: 0.09956  loss_dice_4: 0.9343  loss_ce_5: 0.1445  loss_mask_5: 0.09731  loss_dice_5: 0.8794  loss_ce_6: 0.1394  loss_mask_6: 0.09225  loss_dice_6: 0.8746  loss_ce_7: 0.1427  loss_mask_7: 0.08892  loss_dice_7: 0.8688  loss_ce_8: 0.1451  loss_mask_8: 0.08429  loss_dice_8: 0.8398  loss_mgm_entropy: 0.004509    time: 0.4365  last_time: 0.4356  data_time: 0.0036  last_data_time: 0.0034   lr: 1e-07  max_mem: 15545M
[08/30 23:51:41] d2.utils.events INFO:  eta: 0:02:10  iter: 3699  total_loss: 12.78  loss_ce: 0.1369  loss_mask: 0.08943  loss_dice: 0.7839  loss_ce_0: 0.7256  loss_mask_0: 0.1777  loss_dice_0: 1.968  loss_ce_1: 0.1697  loss_mask_1: 0.1315  loss_dice_1: 1.231  loss_ce_2: 0.1357  loss_mask_2: 0.1094  loss_dice_2: 0.9703  loss_ce_3: 0.1306  loss_mask_3: 0.0952  loss_dice_3: 0.8725  loss_ce_4: 0.1291  loss_mask_4: 0.09275  loss_dice_4: 0.8317  loss_ce_5: 0.1284  loss_mask_5: 0.08862  loss_dice_5: 0.8031  loss_ce_6: 0.1315  loss_mask_6: 0.08859  loss_dice_6: 0.7969  loss_ce_7: 0.1314  loss_mask_7: 0.09159  loss_dice_7: 0.7791  loss_ce_8: 0.1324  loss_mask_8: 0.09208  loss_dice_8: 0.781  loss_mgm_entropy: 0.004504    time: 0.4365  last_time: 0.4362  data_time: 0.0033  last_data_time: 0.0031   lr: 1e-07  max_mem: 15545M
[08/30 23:51:49] d2.utils.events INFO:  eta: 0:02:02  iter: 3719  total_loss: 12.52  loss_ce: 0.1437  loss_mask: 0.09094  loss_dice: 0.7542  loss_ce_0: 0.7404  loss_mask_0: 0.1757  loss_dice_0: 1.895  loss_ce_1: 0.1719  loss_mask_1: 0.1256  loss_dice_1: 1.205  loss_ce_2: 0.1322  loss_mask_2: 0.112  loss_dice_2: 0.982  loss_ce_3: 0.1317  loss_mask_3: 0.1043  loss_dice_3: 0.8664  loss_ce_4: 0.128  loss_mask_4: 0.09859  loss_dice_4: 0.8136  loss_ce_5: 0.126  loss_mask_5: 0.09612  loss_dice_5: 0.7765  loss_ce_6: 0.1276  loss_mask_6: 0.09379  loss_dice_6: 0.7777  loss_ce_7: 0.1315  loss_mask_7: 0.0953  loss_dice_7: 0.7649  loss_ce_8: 0.1339  loss_mask_8: 0.0895  loss_dice_8: 0.7615  loss_mgm_entropy: 0.004547    time: 0.4365  last_time: 0.4354  data_time: 0.0035  last_data_time: 0.0036   lr: 1e-07  max_mem: 15545M
[08/30 23:51:58] d2.utils.events INFO:  eta: 0:01:53  iter: 3739  total_loss: 12.67  loss_ce: 0.1338  loss_mask: 0.09546  loss_dice: 0.774  loss_ce_0: 0.7353  loss_mask_0: 0.1873  loss_dice_0: 1.939  loss_ce_1: 0.1734  loss_mask_1: 0.1455  loss_dice_1: 1.212  loss_ce_2: 0.1346  loss_mask_2: 0.1105  loss_dice_2: 0.9641  loss_ce_3: 0.1315  loss_mask_3: 0.09836  loss_dice_3: 0.8817  loss_ce_4: 0.1271  loss_mask_4: 0.09044  loss_dice_4: 0.839  loss_ce_5: 0.124  loss_mask_5: 0.08817  loss_dice_5: 0.8095  loss_ce_6: 0.1309  loss_mask_6: 0.08675  loss_dice_6: 0.8176  loss_ce_7: 0.1292  loss_mask_7: 0.09202  loss_dice_7: 0.8161  loss_ce_8: 0.135  loss_mask_8: 0.08957  loss_dice_8: 0.7958  loss_mgm_entropy: 0.004502    time: 0.4365  last_time: 0.4378  data_time: 0.0036  last_data_time: 0.0041   lr: 1e-07  max_mem: 15545M
[08/30 23:52:07] d2.utils.events INFO:  eta: 0:01:44  iter: 3759  total_loss: 12.77  loss_ce: 0.1413  loss_mask: 0.08314  loss_dice: 0.7813  loss_ce_0: 0.7333  loss_mask_0: 0.1673  loss_dice_0: 1.95  loss_ce_1: 0.1765  loss_mask_1: 0.1375  loss_dice_1: 1.194  loss_ce_2: 0.1345  loss_mask_2: 0.1078  loss_dice_2: 0.9431  loss_ce_3: 0.1274  loss_mask_3: 0.094  loss_dice_3: 0.8567  loss_ce_4: 0.1272  loss_mask_4: 0.09337  loss_dice_4: 0.815  loss_ce_5: 0.1284  loss_mask_5: 0.08618  loss_dice_5: 0.8025  loss_ce_6: 0.13  loss_mask_6: 0.08104  loss_dice_6: 0.7992  loss_ce_7: 0.137  loss_mask_7: 0.08506  loss_dice_7: 0.7805  loss_ce_8: 0.139  loss_mask_8: 0.08197  loss_dice_8: 0.7811  loss_mgm_entropy: 0.004485    time: 0.4365  last_time: 0.4354  data_time: 0.0036  last_data_time: 0.0038   lr: 1e-07  max_mem: 15545M
[08/30 23:52:16] d2.utils.events INFO:  eta: 0:01:35  iter: 3779  total_loss: 13.51  loss_ce: 0.1402  loss_mask: 0.1063  loss_dice: 0.8058  loss_ce_0: 0.7296  loss_mask_0: 0.2031  loss_dice_0: 1.977  loss_ce_1: 0.1752  loss_mask_1: 0.1638  loss_dice_1: 1.299  loss_ce_2: 0.1403  loss_mask_2: 0.1382  loss_dice_2: 1.037  loss_ce_3: 0.1333  loss_mask_3: 0.1217  loss_dice_3: 0.9545  loss_ce_4: 0.1257  loss_mask_4: 0.115  loss_dice_4: 0.8809  loss_ce_5: 0.1279  loss_mask_5: 0.1141  loss_dice_5: 0.8665  loss_ce_6: 0.1325  loss_mask_6: 0.1047  loss_dice_6: 0.8524  loss_ce_7: 0.1327  loss_mask_7: 0.1143  loss_dice_7: 0.8456  loss_ce_8: 0.138  loss_mask_8: 0.1052  loss_dice_8: 0.821  loss_mgm_entropy: 0.004516    time: 0.4365  last_time: 0.4368  data_time: 0.0035  last_data_time: 0.0035   lr: 1e-07  max_mem: 15545M
[08/30 23:52:24] d2.utils.events INFO:  eta: 0:01:27  iter: 3799  total_loss: 13.19  loss_ce: 0.1353  loss_mask: 0.1008  loss_dice: 0.7579  loss_ce_0: 0.7319  loss_mask_0: 0.193  loss_dice_0: 1.97  loss_ce_1: 0.1723  loss_mask_1: 0.1522  loss_dice_1: 1.239  loss_ce_2: 0.1367  loss_mask_2: 0.1274  loss_dice_2: 0.9987  loss_ce_3: 0.1362  loss_mask_3: 0.1161  loss_dice_3: 0.9074  loss_ce_4: 0.1262  loss_mask_4: 0.1132  loss_dice_4: 0.8737  loss_ce_5: 0.1263  loss_mask_5: 0.1074  loss_dice_5: 0.8236  loss_ce_6: 0.1285  loss_mask_6: 0.1087  loss_dice_6: 0.8138  loss_ce_7: 0.1297  loss_mask_7: 0.1074  loss_dice_7: 0.7892  loss_ce_8: 0.1331  loss_mask_8: 0.09674  loss_dice_8: 0.7649  loss_mgm_entropy: 0.004523    time: 0.4365  last_time: 0.4373  data_time: 0.0033  last_data_time: 0.0032   lr: 1e-07  max_mem: 15545M
[08/30 23:52:33] d2.utils.events INFO:  eta: 0:01:18  iter: 3819  total_loss: 13.12  loss_ce: 0.1463  loss_mask: 0.09549  loss_dice: 0.7777  loss_ce_0: 0.7321  loss_mask_0: 0.1874  loss_dice_0: 2.049  loss_ce_1: 0.1781  loss_mask_1: 0.1377  loss_dice_1: 1.296  loss_ce_2: 0.1285  loss_mask_2: 0.1138  loss_dice_2: 1.003  loss_ce_3: 0.1359  loss_mask_3: 0.1102  loss_dice_3: 0.9311  loss_ce_4: 0.1412  loss_mask_4: 0.1023  loss_dice_4: 0.8417  loss_ce_5: 0.1403  loss_mask_5: 0.1034  loss_dice_5: 0.8413  loss_ce_6: 0.136  loss_mask_6: 0.1002  loss_dice_6: 0.8066  loss_ce_7: 0.1416  loss_mask_7: 0.101  loss_dice_7: 0.8109  loss_ce_8: 0.1454  loss_mask_8: 0.09752  loss_dice_8: 0.7953  loss_mgm_entropy: 0.004512    time: 0.4365  last_time: 0.4366  data_time: 0.0035  last_data_time: 0.0038   lr: 1e-07  max_mem: 15545M
[08/30 23:52:42] d2.utils.events INFO:  eta: 0:01:09  iter: 3839  total_loss: 14  loss_ce: 0.1378  loss_mask: 0.09234  loss_dice: 0.8337  loss_ce_0: 0.7223  loss_mask_0: 0.1968  loss_dice_0: 1.922  loss_ce_1: 0.1695  loss_mask_1: 0.153  loss_dice_1: 1.389  loss_ce_2: 0.1365  loss_mask_2: 0.1315  loss_dice_2: 1.127  loss_ce_3: 0.1315  loss_mask_3: 0.121  loss_dice_3: 1.006  loss_ce_4: 0.127  loss_mask_4: 0.1073  loss_dice_4: 0.9342  loss_ce_5: 0.1261  loss_mask_5: 0.09355  loss_dice_5: 0.9012  loss_ce_6: 0.1299  loss_mask_6: 0.09487  loss_dice_6: 0.8638  loss_ce_7: 0.1306  loss_mask_7: 0.09585  loss_dice_7: 0.8704  loss_ce_8: 0.1377  loss_mask_8: 0.09644  loss_dice_8: 0.8507  loss_mgm_entropy: 0.004478    time: 0.4365  last_time: 0.4371  data_time: 0.0035  last_data_time: 0.0035   lr: 1e-07  max_mem: 15545M
[08/30 23:52:51] d2.utils.events INFO:  eta: 0:01:01  iter: 3859  total_loss: 12.47  loss_ce: 0.1379  loss_mask: 0.08004  loss_dice: 0.7986  loss_ce_0: 0.7361  loss_mask_0: 0.1651  loss_dice_0: 1.926  loss_ce_1: 0.1697  loss_mask_1: 0.122  loss_dice_1: 1.244  loss_ce_2: 0.1319  loss_mask_2: 0.1026  loss_dice_2: 0.971  loss_ce_3: 0.1237  loss_mask_3: 0.09459  loss_dice_3: 0.8588  loss_ce_4: 0.123  loss_mask_4: 0.08801  loss_dice_4: 0.846  loss_ce_5: 0.1319  loss_mask_5: 0.08989  loss_dice_5: 0.8151  loss_ce_6: 0.1276  loss_mask_6: 0.08658  loss_dice_6: 0.8175  loss_ce_7: 0.1285  loss_mask_7: 0.08749  loss_dice_7: 0.8206  loss_ce_8: 0.1363  loss_mask_8: 0.08375  loss_dice_8: 0.8017  loss_mgm_entropy: 0.004417    time: 0.4365  last_time: 0.4378  data_time: 0.0036  last_data_time: 0.0040   lr: 1e-07  max_mem: 15545M
[08/30 23:52:59] d2.utils.events INFO:  eta: 0:00:52  iter: 3879  total_loss: 13.62  loss_ce: 0.1444  loss_mask: 0.09159  loss_dice: 0.8281  loss_ce_0: 0.7275  loss_mask_0: 0.18  loss_dice_0: 1.92  loss_ce_1: 0.1766  loss_mask_1: 0.1357  loss_dice_1: 1.3  loss_ce_2: 0.1395  loss_mask_2: 0.1086  loss_dice_2: 1.063  loss_ce_3: 0.1352  loss_mask_3: 0.09487  loss_dice_3: 0.9818  loss_ce_4: 0.1428  loss_mask_4: 0.09466  loss_dice_4: 0.9296  loss_ce_5: 0.1413  loss_mask_5: 0.09485  loss_dice_5: 0.883  loss_ce_6: 0.1429  loss_mask_6: 0.0908  loss_dice_6: 0.8837  loss_ce_7: 0.1417  loss_mask_7: 0.09034  loss_dice_7: 0.8493  loss_ce_8: 0.1425  loss_mask_8: 0.09248  loss_dice_8: 0.862  loss_mgm_entropy: 0.0045    time: 0.4365  last_time: 0.4357  data_time: 0.0036  last_data_time: 0.0034   lr: 1e-07  max_mem: 15545M
[08/30 23:53:08] d2.utils.events INFO:  eta: 0:00:43  iter: 3899  total_loss: 12.36  loss_ce: 0.1439  loss_mask: 0.0796  loss_dice: 0.7664  loss_ce_0: 0.7322  loss_mask_0: 0.1595  loss_dice_0: 1.89  loss_ce_1: 0.1689  loss_mask_1: 0.1142  loss_dice_1: 1.195  loss_ce_2: 0.1348  loss_mask_2: 0.09836  loss_dice_2: 0.9351  loss_ce_3: 0.1411  loss_mask_3: 0.09627  loss_dice_3: 0.8499  loss_ce_4: 0.1396  loss_mask_4: 0.08934  loss_dice_4: 0.8214  loss_ce_5: 0.1339  loss_mask_5: 0.08653  loss_dice_5: 0.7859  loss_ce_6: 0.1316  loss_mask_6: 0.08025  loss_dice_6: 0.7944  loss_ce_7: 0.1342  loss_mask_7: 0.08475  loss_dice_7: 0.7803  loss_ce_8: 0.1424  loss_mask_8: 0.07906  loss_dice_8: 0.7603  loss_mgm_entropy: 0.004489    time: 0.4365  last_time: 0.4357  data_time: 0.0036  last_data_time: 0.0039   lr: 1e-07  max_mem: 15545M
[08/30 23:53:17] d2.utils.events INFO:  eta: 0:00:34  iter: 3919  total_loss: 11.99  loss_ce: 0.1447  loss_mask: 0.07157  loss_dice: 0.7864  loss_ce_0: 0.7315  loss_mask_0: 0.1409  loss_dice_0: 1.867  loss_ce_1: 0.1796  loss_mask_1: 0.1073  loss_dice_1: 1.205  loss_ce_2: 0.1382  loss_mask_2: 0.08888  loss_dice_2: 0.9471  loss_ce_3: 0.1333  loss_mask_3: 0.0789  loss_dice_3: 0.8514  loss_ce_4: 0.1294  loss_mask_4: 0.07701  loss_dice_4: 0.8017  loss_ce_5: 0.1354  loss_mask_5: 0.07497  loss_dice_5: 0.7703  loss_ce_6: 0.1451  loss_mask_6: 0.07261  loss_dice_6: 0.772  loss_ce_7: 0.1441  loss_mask_7: 0.07279  loss_dice_7: 0.7856  loss_ce_8: 0.138  loss_mask_8: 0.07086  loss_dice_8: 0.777  loss_mgm_entropy: 0.004463    time: 0.4365  last_time: 0.4364  data_time: 0.0035  last_data_time: 0.0033   lr: 1e-07  max_mem: 15545M
[08/30 23:53:25] d2.utils.events INFO:  eta: 0:00:26  iter: 3939  total_loss: 12.56  loss_ce: 0.1416  loss_mask: 0.09135  loss_dice: 0.7782  loss_ce_0: 0.7385  loss_mask_0: 0.1744  loss_dice_0: 1.855  loss_ce_1: 0.1683  loss_mask_1: 0.1191  loss_dice_1: 1.203  loss_ce_2: 0.1341  loss_mask_2: 0.09847  loss_dice_2: 0.9363  loss_ce_3: 0.1321  loss_mask_3: 0.08662  loss_dice_3: 0.8498  loss_ce_4: 0.1273  loss_mask_4: 0.09097  loss_dice_4: 0.8244  loss_ce_5: 0.1354  loss_mask_5: 0.08718  loss_dice_5: 0.7986  loss_ce_6: 0.127  loss_mask_6: 0.09252  loss_dice_6: 0.8104  loss_ce_7: 0.134  loss_mask_7: 0.09134  loss_dice_7: 0.7849  loss_ce_8: 0.1376  loss_mask_8: 0.08703  loss_dice_8: 0.7948  loss_mgm_entropy: 0.004506    time: 0.4365  last_time: 0.4366  data_time: 0.0036  last_data_time: 0.0034   lr: 1e-07  max_mem: 15545M
[08/30 23:53:34] d2.utils.events INFO:  eta: 0:00:17  iter: 3959  total_loss: 13.89  loss_ce: 0.1435  loss_mask: 0.09625  loss_dice: 0.8211  loss_ce_0: 0.7317  loss_mask_0: 0.1764  loss_dice_0: 1.98  loss_ce_1: 0.1768  loss_mask_1: 0.1461  loss_dice_1: 1.349  loss_ce_2: 0.1528  loss_mask_2: 0.1216  loss_dice_2: 1.108  loss_ce_3: 0.144  loss_mask_3: 0.11  loss_dice_3: 1.014  loss_ce_4: 0.1346  loss_mask_4: 0.1039  loss_dice_4: 0.9096  loss_ce_5: 0.1429  loss_mask_5: 0.1026  loss_dice_5: 0.8907  loss_ce_6: 0.1428  loss_mask_6: 0.09527  loss_dice_6: 0.8784  loss_ce_7: 0.1429  loss_mask_7: 0.09445  loss_dice_7: 0.8614  loss_ce_8: 0.1426  loss_mask_8: 0.09308  loss_dice_8: 0.8412  loss_mgm_entropy: 0.004475    time: 0.4365  last_time: 0.4363  data_time: 0.0034  last_data_time: 0.0037   lr: 1e-07  max_mem: 15545M
[08/30 23:53:43] d2.utils.events INFO:  eta: 0:00:08  iter: 3979  total_loss: 12.96  loss_ce: 0.1389  loss_mask: 0.08924  loss_dice: 0.8344  loss_ce_0: 0.7301  loss_mask_0: 0.188  loss_dice_0: 1.994  loss_ce_1: 0.1699  loss_mask_1: 0.1396  loss_dice_1: 1.277  loss_ce_2: 0.145  loss_mask_2: 0.1199  loss_dice_2: 1.006  loss_ce_3: 0.1379  loss_mask_3: 0.1099  loss_dice_3: 0.9023  loss_ce_4: 0.1404  loss_mask_4: 0.1024  loss_dice_4: 0.8587  loss_ce_5: 0.1386  loss_mask_5: 0.1001  loss_dice_5: 0.8405  loss_ce_6: 0.1369  loss_mask_6: 0.0945  loss_dice_6: 0.8478  loss_ce_7: 0.1398  loss_mask_7: 0.09521  loss_dice_7: 0.8723  loss_ce_8: 0.1427  loss_mask_8: 0.09248  loss_dice_8: 0.8534  loss_mgm_entropy: 0.004511    time: 0.4365  last_time: 0.4370  data_time: 0.0037  last_data_time: 0.0038   lr: 1e-07  max_mem: 15545M
[08/30 23:53:52] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/model_final.pth
[08/30 23:53:52] d2.utils.events INFO:  eta: 0:00:00  iter: 3999  total_loss: 12.9  loss_ce: 0.1453  loss_mask: 0.1017  loss_dice: 0.7889  loss_ce_0: 0.7373  loss_mask_0: 0.2029  loss_dice_0: 1.983  loss_ce_1: 0.1757  loss_mask_1: 0.153  loss_dice_1: 1.239  loss_ce_2: 0.1442  loss_mask_2: 0.1194  loss_dice_2: 0.9866  loss_ce_3: 0.1377  loss_mask_3: 0.1092  loss_dice_3: 0.8921  loss_ce_4: 0.1381  loss_mask_4: 0.1052  loss_dice_4: 0.8648  loss_ce_5: 0.1288  loss_mask_5: 0.106  loss_dice_5: 0.8228  loss_ce_6: 0.1304  loss_mask_6: 0.1019  loss_dice_6: 0.8298  loss_ce_7: 0.1336  loss_mask_7: 0.0978  loss_dice_7: 0.8144  loss_ce_8: 0.1441  loss_mask_8: 0.09703  loss_dice_8: 0.8134  loss_mgm_entropy: 0.004499    time: 0.4365  last_time: 0.4366  data_time: 0.0035  last_data_time: 0.0033   lr: 1e-07  max_mem: 15545M
[08/30 23:53:52] d2.engine.hooks INFO: Overall training speed: 3998 iterations in 0:29:05 (0.4365 s / it)
[08/30 23:53:52] d2.engine.hooks INFO: Total training time: 0:29:07 (0:00:02 on hooks)
[08/30 23:53:52] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [Mapper] Noise-mask dir not found, will skip masks: /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/depth/depth_noise_mask
[08/30 23:53:52] mask2former.data.dataset_mappers.coco_instance_rgbd_dataset_mapper INFO: [COCOInstanceRGBDDatasetMapper] Augs: [] | RGB: RGB | DATASET_ROOT=/home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input
[08/30 23:53:52] d2.data.datasets.coco INFO: Loaded 6 images in COCO format from /home/fuyx/zhn/mask2former/MGM_Mask2Former/mgm_test_input/annotations/instances_val.json
[08/30 23:53:52] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[08/30 23:53:52] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[08/30 23:53:52] d2.data.common INFO: Serialized dataset takes 0.16 MiB
[08/30 23:53:52] d2.evaluation.evaluator INFO: Start inference on 6 batches
[08/30 23:53:55] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.392498 (0.392498 s / iter per device, on 1 devices)
[08/30 23:53:55] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.162148 s / iter per device, on 1 devices)
[08/30 23:53:55] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[08/30 23:53:55] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[08/30 23:53:55] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[08/30 23:53:55] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[08/30 23:53:55] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.00 seconds.
[08/30 23:53:55] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[08/30 23:53:55] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[08/30 23:53:55] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  |  nan  | 0.000 | 0.000 |
[08/30 23:53:55] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/30 23:53:55] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[08/30 23:53:55] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[08/30 23:53:55] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[08/30 23:53:55] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.00 seconds.
[08/30 23:53:55] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 65.116 | 91.349 | 69.761 |  nan  | 58.776 | 72.217 |
[08/30 23:53:55] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/30 23:53:55] d2.engine.defaults INFO: Evaluation results for coco_instance_rgbd_val in csv format:
[08/30 23:53:55] d2.evaluation.testing INFO: copypaste: Task: bbox
[08/30 23:53:55] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/30 23:53:55] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,nan,0.0000,0.0000
[08/30 23:53:55] d2.evaluation.testing INFO: copypaste: Task: segm
[08/30 23:53:55] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/30 23:53:55] d2.evaluation.testing INFO: copypaste: 65.1157,91.3488,69.7608,nan,58.7758,72.2168
