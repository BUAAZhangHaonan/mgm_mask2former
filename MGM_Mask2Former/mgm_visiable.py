# -*- coding: utf-8 -*-
"""
æ”¹è¿›ç‰ˆ MGM Mask2Former çƒŸé›¾æµ‹è¯•è„šæœ¬ï¼š
1. æ”¯æŒåŠ è½½é¢„è®­ç»ƒæƒé‡ (--weights)
2. æ”¯æŒæŠ½å– MGM å¤šå°ºåº¦æ·±åº¦ç½®ä¿¡åº¦å›¾å¹¶ä¿å­˜ (--export-conf)
3. è®¡ç®—å™ªå£°åŒºåŸŸ / ç©ºæ´åŒºåŸŸä¸æ­£å¸¸åŒºåŸŸçš„ç½®ä¿¡åº¦ç»Ÿè®¡å¯¹æ¯”
4. å¯åŠ è½½çœŸå® RGB / Depth è¾“å…¥ï¼ˆ--rgb / --depthï¼‰ï¼Œå¦åˆ™ç”Ÿæˆéšæœº batch
5. ä¿ç•™åŸè®­ç»ƒ smoke æµç¨‹ï¼ˆå¯é€šè¿‡ --no-train è·³è¿‡ï¼‰
"""

import argparse
import os
import random
from typing import Dict, List, Tuple, Optional

import torch
import torch.nn as nn
import torch.nn.functional as F

import numpy as np
from PIL import Image

from detectron2.config import get_cfg
from detectron2.data import DatasetCatalog, MetadataCatalog
from detectron2.structures import BitMasks, Instances, ImageList
from detectron2.checkpoint import DetectionCheckpointer

from mask2former.modeling.config.mgm_config import add_mgm_config
from mask2former.modeling.meta_arch.mgm_model import MGMMaskFormer


# --------------------------------------------------------------------------------------
# å‚æ•°ç»Ÿè®¡å‡½æ•°
# --------------------------------------------------------------------------------------
def count_parameters(model: nn.Module, detailed: bool = True) -> Dict:
    total_params = 0
    trainable_params = 0
    frozen_params = 0
    module_stats = {}

    def format_number(num):
        return f"{num:,}"

    def get_size_mb(num_params):
        return num_params * 4 / (1024 * 1024)

    print("=" * 80)
    print("æ¨¡å‹å‚æ•°ç»Ÿè®¡")
    print("=" * 80)

    for name, param in model.named_parameters():
        param_count = param.numel()
        total_params += param_count
        if param.requires_grad:
            trainable_params += param_count
        else:
            frozen_params += param_count

        module_name = name.split(".")[0] if "." in name else "root"
        if module_name not in module_stats:
            module_stats[module_name] = {
                "total": 0,
                "trainable": 0,
                "frozen": 0,
                "params": [],
            }
        module_stats[module_name]["total"] += param_count
        if param.requires_grad:
            module_stats[module_name]["trainable"] += param_count
        else:
            module_stats[module_name]["frozen"] += param_count
        module_stats[module_name]["params"].append(
            {
                "name": name,
                "shape": list(param.shape),
                "params": param_count,
                "trainable": param.requires_grad,
            }
        )

    print(f"æ€»å‚æ•°æ•°é‡: {format_number(total_params)}")
    print(f"å¯è®­ç»ƒå‚æ•°: {format_number(trainable_params)}")
    print(f"å†»ç»“å‚æ•°: {format_number(frozen_params)}")
    print(f"æ¨¡å‹å¤§å°: {get_size_mb(total_params):.2f} MB")
    print(f"å¯è®­ç»ƒå‚æ•°æ¯”ä¾‹: {trainable_params/total_params*100:.2f}%")

    if detailed:
        print("\n" + "=" * 80)
        print("å„æ¨¡å—å‚æ•°ç»Ÿè®¡")
        print("=" * 80)
        sorted_modules = sorted(
            module_stats.items(), key=lambda x: x[1]["total"], reverse=True
        )
        for module_name, stats in sorted_modules:
            print(f"\nğŸ“¦ {module_name}:")
            print(
                f"  æ€»å‚æ•°: {format_number(stats['total'])} ({stats['total']/total_params*100:.2f}%)"
            )
            print(f"  å¯è®­ç»ƒ: {format_number(stats['trainable'])}")
            print(f"  å†»ç»“: {format_number(stats['frozen'])}")
            print(f"  å¤§å°: {get_size_mb(stats['total']):.2f} MB")

            large_params = [p for p in stats["params"] if p["params"] > 1000]
            large_params.sort(key=lambda x: x["params"], reverse=True)
            if large_params:
                print("  ä¸»è¦å‚æ•°å±‚ (>1Kå‚æ•°):")
                for param_info in large_params[:5]:
                    trainable_mark = "âœ“" if param_info["trainable"] else "âœ—"
                    print(
                        f"    {trainable_mark} {param_info['name']}: {param_info['shape']} -> {format_number(param_info['params'])}"
                    )
                if len(large_params) > 5:
                    print(f"    ... è¿˜æœ‰ {len(large_params) - 5} ä¸ªå‚æ•°å±‚")

    print("\n" + "=" * 80)
    print("æ¨¡å‹ç»“æ„æ¦‚è§ˆ")
    print("=" * 80)

    def print_model_structure(model, prefix="", max_depth=2, current_depth=0):
        if current_depth >= max_depth:
            return
        for name, child in model.named_children():
            child_params = sum(p.numel() for p in child.parameters())
            if child_params > 0:
                print(
                    f"{prefix}â”œâ”€ {name}: {child.__class__.__name__} ({child_params:,} params)"
                )
                if current_depth < max_depth - 1:
                    print_model_structure(
                        child, prefix + "â”‚  ", max_depth, current_depth + 1
                    )

    print_model_structure(model)

    return {
        "total_params": total_params,
        "trainable_params": trainable_params,
        "frozen_params": frozen_params,
        "model_size_mb": get_size_mb(total_params),
        "trainable_ratio": trainable_params / total_params,
        "module_stats": module_stats,
    }


# --------------------------------------------------------------------------------------
# æ•°æ®æ³¨å†Œä¸é…ç½®
# --------------------------------------------------------------------------------------
def register_dummy_dataset(name: str, num_thing_classes: int = 3):
    if name in DatasetCatalog.list():
        return
    DatasetCatalog.register(name, lambda: [])
    thing_map = {i: i for i in range(num_thing_classes)}
    MetadataCatalog.get(name).set(
        thing_dataset_id_to_contiguous_id=thing_map,
        thing_classes=[f"cls{i}" for i in range(num_thing_classes)],
    )


def build_cfg(yaml_path: str, device: Optional[str] = None):
    cfg = get_cfg()
    add_mgm_config(cfg)
    cfg.merge_from_file(yaml_path)
    # dummy dataset
    train_name = "__dummy_rgbd_train__"
    test_name = "__dummy_rgbd_test__"
    register_dummy_dataset(
        train_name, num_thing_classes=cfg.MODEL.SEM_SEG_HEAD.NUM_CLASSES
    )
    register_dummy_dataset(
        test_name, num_thing_classes=cfg.MODEL.SEM_SEG_HEAD.NUM_CLASSES
    )
    cfg.DATASETS.TRAIN = (train_name,)
    cfg.DATASETS.TEST = (test_name,)

    cfg.MODEL.MASK_FORMER.TEST.SEMANTIC_ON = False
    cfg.MODEL.MASK_FORMER.TEST.PANOPTIC_ON = False
    cfg.MODEL.MASK_FORMER.TEST.INSTANCE_ON = True

    if device is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"
    cfg.MODEL.DEVICE = device
    return cfg


# --------------------------------------------------------------------------------------
# æ„é€ éšæœº / çœŸå® batch
# --------------------------------------------------------------------------------------
def make_random_instances(h, w, num_classes, max_inst=2):
    n = random.randint(1, max_inst)
    masks = torch.zeros((n, h, w), dtype=torch.bool)
    for i in range(n):
        rh, rw = random.randint(h // 8, h // 3), random.randint(w // 8, w // 3)
        y0 = random.randint(0, max(0, h - rh))
        x0 = random.randint(0, max(0, w - rw))
        masks[i, y0 : y0 + rh, x0 : x0 + rw] = True
    gt = Instances((h, w))
    gt.gt_masks = BitMasks(masks)
    gt.gt_classes = torch.randint(low=0, high=num_classes, size=(n,), dtype=torch.int64)
    return gt


def make_fake_batch(
    B=2,
    H=256,
    W=256,
    with_targets=True,
    with_noise_mask=True,
    device="cpu",
    depth_noise_ratio=0.5,
):
    batch = []
    for _ in range(B):
        img = torch.randint(0, 256, (3, H, W), dtype=torch.uint8, device=device)
        depth = torch.rand(1, H, W, dtype=torch.float32, device=device)
        sample = {"image": img, "depth": depth, "height": H, "width": W}

        if with_noise_mask:
            noise = (torch.rand(1, H, W, device=device) < depth_noise_ratio).float()
            sample["depth_noise_mask"] = noise  # 1 è¡¨ç¤ºå™ªå£°
        if with_targets:
            sample["_need_targets"] = True
        batch.append(sample)
    return batch


def load_rgb_depth(
    rgb_path: str,
    depth_path: str,
    device: str,
    resize: Optional[int] = None,
    keep_aspect: bool = True,
) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    depth:
      - è‹¥ä¸º .npy: è¯»å–åæœŸæœ›ä¸º [H,W] æˆ– [1,H,W]ï¼Œè‡ªåŠ¨å½’ä¸€åŒ–åˆ°[0,1]ï¼ˆè‹¥çœ‹èµ·æ¥åƒ>1ï¼‰
      - è‹¥ä¸ºå›¾åƒ: è‡ªåŠ¨è½¬ float32/255
    """
    rgb = Image.open(rgb_path).convert("RGB")
    depth_ext = os.path.splitext(depth_path)[1].lower()

    if resize is not None:
        if keep_aspect:
            # æœ€é•¿è¾¹=resize
            w, h = rgb.size
            scale = resize / float(max(w, h))
            new_w, new_h = int(round(w * scale)), int(round(h * scale))
            rgb = rgb.resize((new_w, new_h), Image.BILINEAR)
        else:
            rgb = rgb.resize((resize, resize), Image.BILINEAR)

    rgb_np = np.asarray(rgb).astype("uint8")  # [H,W,3]
    rgb_t = torch.from_numpy(rgb_np).permute(2, 0, 1).to(device)

    if depth_ext == ".npy":
        d_np = np.load(depth_path)
        if d_np.ndim == 2:
            pass
        elif d_np.ndim == 3 and d_np.shape[0] in (1, 3):
            # assume CHW
            if d_np.shape[0] == 1:
                d_np = d_np[0]
            else:
                d_np = d_np.mean(0)
        else:
            raise ValueError("Unsupported depth npy shape.")
        d_min, d_max = float(d_np.min()), float(d_np.max())
        if d_max > 1.2:  # heuristic: normalize
            d_np = (d_np - d_min) / (d_max - d_min + 1e-6)
        depth_t = torch.from_numpy(d_np).unsqueeze(0).float().to(device)
    else:
        depth_img = Image.open(depth_path)
        if resize is not None:
            if keep_aspect:
                w2, h2 = depth_img.size
                # ä¸ rgb åŒæ­¥ç¼©æ”¾ï¼ˆç®€å•å®ç°ï¼šç›´æ¥æŒ‰ rgb å½“å‰å°ºå¯¸ï¼‰
                depth_img = depth_img.resize(rgb.size, Image.NEAREST)
            else:
                depth_img = depth_img.resize((resize, resize), Image.NEAREST)
        d_np = np.asarray(depth_img).astype("float32")
        if d_np.ndim == 3:
            d_np = d_np[..., 0]
        if d_np.max() > 1.2:
            d_np /= 255.0
        depth_t = torch.from_numpy(d_np).unsqueeze(0).to(device)

    return rgb_t, depth_t


def build_batch_from_files(
    rgb_path: str,
    depth_path: str,
    device: str,
    noise_mask: bool = True,
    resize: Optional[int] = None,
) -> List[Dict]:
    rgb_t, depth_t = load_rgb_depth(rgb_path, depth_path, device=device, resize=resize)
    H, W = depth_t.shape[-2:]
    sample = {
        "image": rgb_t.to(torch.uint8),
        "depth": depth_t,
        "height": H,
        "width": W,
    }
    if noise_mask:
        # ç®€å•åŸºäºæ¢¯åº¦æˆ–éšæœºæ¨¡æ‹Ÿå™ªå£°ï¼Œè¿™é‡Œéšæœºç¤ºä¾‹
        noise = (torch.rand(1, H, W, device=device) < 0.3).float()
        sample["depth_noise_mask"] = noise
    return [sample]


# --------------------------------------------------------------------------------------
# ç½®ä¿¡åº¦æå–ä¸å¯è§†åŒ–
# --------------------------------------------------------------------------------------
def extract_mgm_confidence(
    model: MGMMaskFormer, batched_inputs: List[Dict], upsample: bool = True
) -> Tuple[List[Dict[str, torch.Tensor]], List[torch.Tensor], List[torch.Tensor]]:
    """
    æ‰‹åŠ¨å¤åˆ» MGMMaskFormer.forward çš„å‰åŠéƒ¨åˆ†ï¼Œè·å– MGM è¾“å‡ºçš„ multi-scale confidence mapsã€‚
    è¿”å›:
        per_image_conf (list, len=B): æ¯å¼ å›¾çš„ {scale_key: [1,h,w]}
        depth_list (list): åŸå§‹æ·±åº¦ (after padding) çš„è£å‰ªå›åŸå°ºå¯¸
        noise_mask_list (list or empty): è‹¥æœ‰ depth_noise_mask
    """
    model.eval()
    device = model.device

    # -------- æ„é€ ä¸ forward ä¸€è‡´çš„ ImageList --------
    images = [x["image"].to(device) for x in batched_inputs]
    images = [
        (x.float() - model.pixel_mean) / model.pixel_std for x in images
    ]  # å½’ä¸€åŒ–
    images_list = ImageList.from_tensors(images, model.size_divisibility)

    depths = [x["depth"].to(device) for x in batched_inputs]
    depths_list = ImageList.from_tensors(depths, model.size_divisibility)

    assert (
        images_list.tensor.shape[-2:] == depths_list.tensor.shape[-2:]
    ), "RGB ä¸ Depth å¡«å……åå°ºå¯¸ä¸ä¸€è‡´"

    depth_raw = depths_list.tensor  # [B,1,H,W]

    depth_noise_mask = None
    if "depth_noise_mask" in batched_inputs[0]:
        dm = [x["depth_noise_mask"].to(device).float() for x in batched_inputs]
        depth_noise_mask = ImageList.from_tensors(
            dm, model.size_divisibility
        ).tensor  # [B,1,H,W]

    # padding mask æ„é€ ï¼ˆä¸ forward ä¸€è‡´ï¼‰
    B, _, H_pad, W_pad = images_list.tensor.shape
    padding_mask = torch.zeros((B, H_pad, W_pad), dtype=torch.bool, device=device)
    for i, (h, w) in enumerate(images_list.image_sizes):
        padding_mask[i, h:, :] = True
        padding_mask[i, :, w:] = True

    # -------- ç‰¹å¾ä¸ MGM --------
    with torch.no_grad():
        rgb_features = model.rgb_backbone(images_list.tensor)
        depth_features = model.depth_backbone(depths_list.tensor)
        fused_features, confidence_maps, _ = model.mgm(
            image_features=rgb_features,
            depth_features=depth_features,
            depth_raw=depth_raw,
            rgb_image=images_list.tensor,
            depth_noise_mask=depth_noise_mask,
        )

    # confidence_maps: Dict[str, Tensor]  æ¯ä¸ª: [B,1,h,w] Sigmoid+clamp å
    # éœ€è¦æŒ‰åŸå›¾å°ºå¯¸è£å‰ªï¼ˆå»æ‰ paddingï¼‰
    per_image_conf: List[Dict[str, torch.Tensor]] = []
    depth_list: List[torch.Tensor] = []
    noise_mask_list: List[torch.Tensor] = []

    for i, (h, w) in enumerate(images_list.image_sizes):
        img_conf = {}
        for scale, m in confidence_maps.items():
            c = m[i : i + 1, :, :h, :w].detach()  # [1,1,h,w]
            if upsample:
                c = F.interpolate(c, size=(h, w), mode="bilinear", align_corners=False)
            img_conf[scale] = c.squeeze(0)  # -> [1,h,w]
        per_image_conf.append(img_conf)

        depth_c = depth_raw[i : i + 1, :, :h, :w]
        depth_list.append(depth_c)

        if depth_noise_mask is not None:
            nm = depth_noise_mask[i : i + 1, :, :h, :w]
            noise_mask_list.append(nm)

    return per_image_conf, depth_list, noise_mask_list


def apply_colormap(x: torch.Tensor, cmap: str = "turbo") -> np.ndarray:
    """
    x: [H,W] in [0,1]
    è¿”å›å½©è‰² uint8
    è‹¥æ—  matplotlibï¼Œåˆ™ä½¿ç”¨ç®€æ˜“åˆ†æ®µ colormap
    """
    x_np = x.clamp(0, 1).cpu().numpy()
    try:
        import matplotlib.cm as cm

        if hasattr(cm, cmap):
            cm_func = getattr(cm, cmap)
        else:
            cm_func = cm.get_cmap("viridis")
        colored = cm_func(x_np)[:, :, :3]  # RGBA -> RGB
        colored = (colored * 255).astype("uint8")
        return colored
    except Exception:
        # fallback: simple jet-like
        r = np.clip(1.5 - np.abs(2 * x_np - 1.0), 0, 1)
        g = np.clip(1.5 - np.abs(2 * x_np - 0.5), 0, 1)
        b = np.clip(1.5 - np.abs(2 * x_np - 0.0), 0, 1)
        rgb = np.stack([r, g, b], axis=-1)
        return (rgb * 255).astype("uint8")


def save_confidence_maps(
    per_image_conf: List[Dict[str, torch.Tensor]],
    depths: List[torch.Tensor],
    noise_masks: List[torch.Tensor],
    out_dir: str,
    prefix: str = "sample",
):
    os.makedirs(out_dir, exist_ok=True)
    for idx, conf_dict in enumerate(per_image_conf):
        depth = depths[idx][0, 0]  # [H,W]
        depth_img = (depth.clamp(0, 1).cpu().numpy() * 255).astype("uint8")
        Image.fromarray(depth_img).save(
            os.path.join(out_dir, f"{prefix}{idx}_depth.png")
        )

        if noise_masks:
            nm = noise_masks[idx][0, 0]
            nm_img = (nm.clamp(0, 1).cpu().numpy() * 255).astype("uint8")
            Image.fromarray(nm_img).save(
                os.path.join(out_dir, f"{prefix}{idx}_noise_mask.png")
            )

        # èšåˆå¹³å‡ç½®ä¿¡åº¦
        agg_list = []
        for scale, m in conf_dict.items():
            # m: [1,H,W]
            c_map = m[0]
            agg_list.append(c_map)
            colored = apply_colormap(c_map)
            Image.fromarray(colored).save(
                os.path.join(out_dir, f"{prefix}{idx}_conf_{scale}.png")
            )
        if agg_list:
            mean_conf = torch.stack(agg_list).mean(0)
            Image.fromarray(apply_colormap(mean_conf)).save(
                os.path.join(out_dir, f"{prefix}{idx}_conf_mean.png")
            )


def confidence_statistics(
    per_image_conf: List[Dict[str, torch.Tensor]],
    depths: List[torch.Tensor],
    noise_masks: List[torch.Tensor],
    z_min: float = 0.0,
    z_max: float = 1.0,
):
    """
    è¾“å‡ºæ¯å¼ å›¾ï¼š
      - æ‰€æœ‰å°ºåº¦å¹³å‡ç½®ä¿¡åº¦
      - å™ªå£°åŒºåŸŸ vs éå™ªå£°åŒºåŸŸ å¹³å‡ç½®ä¿¡åº¦
      - ç©ºæ´åŒºåŸŸ (depth<=z_min or depth>=z_max) vs æœ‰æ•ˆåŒºåŸŸ å¹³å‡ç½®ä¿¡åº¦
    """
    print("\n" + "=" * 80)
    print("MGM ç½®ä¿¡åº¦ç»Ÿè®¡")
    print("=" * 80)
    for i, conf_dict in enumerate(per_image_conf):
        # èšåˆ
        agg = torch.stack([m[0] for m in conf_dict.values()])  # [S,H,W]
        mean_conf = agg.mean(0)  # [H,W]

        depth = depths[i][0, 0]
        hole_mask = ((depth <= z_min) | (depth >= z_max)).float()
        valid_mask = 1.0 - hole_mask

        if noise_masks:
            noise_mask = noise_masks[i][0, 0]
        else:
            noise_mask = torch.zeros_like(depth)

        def masked_mean(t, m):
            denom = m.sum()
            if denom < 1:
                return float("nan")
            return float((t * m).sum() / denom)

        overall = float(mean_conf.mean())
        conf_noise = masked_mean(mean_conf, (noise_mask > 0.5).float())
        conf_clean = masked_mean(mean_conf, (noise_mask <= 0.5).float())
        conf_hole = masked_mean(mean_conf, (hole_mask > 0.5).float())
        conf_valid = masked_mean(mean_conf, (valid_mask > 0.5).float())

        print(f"[Image {i}] overall={overall:.4f}")
        if noise_masks:
            print(
                f"  å™ªå£°åŒºåŸŸå‡å€¼: {conf_noise:.4f}  | éå™ªå£°åŒºåŸŸå‡å€¼: {conf_clean:.4f}  (å·®å€¼ clean-noise={conf_clean - conf_noise:.4f})"
            )
        print(
            f"  ç©ºæ´åŒºåŸŸå‡å€¼: {conf_hole:.4f} | æœ‰æ•ˆåŒºåŸŸå‡å€¼: {conf_valid:.4f}  (å·®å€¼ valid-hole={conf_valid - conf_hole:.4f})"
        )


# --------------------------------------------------------------------------------------
# è®­ç»ƒç›®æ ‡é™„åŠ 
# --------------------------------------------------------------------------------------
def attach_targets(batch, num_classes):
    for s in batch:
        if s.pop("_need_targets", False):
            H, W = s["height"], s["width"]
            s["instances"] = make_random_instances(H, W, num_classes)
    return batch


# --------------------------------------------------------------------------------------
# ä¸»æµç¨‹
# --------------------------------------------------------------------------------------
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--cfg", default="MGM_Mask2Former/configs/mgm_swin_convnext_tiny.yaml", help="Path to config yaml")
    parser.add_argument("--weights", default="MGM_Mask2Former/pretrained-checkpoint/0907_20K_DEPTH_NOISE.pth", help="é¢„è®­ç»ƒæƒé‡(.pth)")
    parser.add_argument("--device", default="cuda", help="cuda æˆ– cpu")
    parser.add_argument("--size", type=int, default=1024, help="åˆæˆæ•°æ®å°ºå¯¸ (æ­£æ–¹å½¢)")
    parser.add_argument("--batch", type=int, default=2)
    parser.add_argument("--detailed-stats", action="store_true")
    parser.add_argument("--no-train", action="store_true", help="è·³è¿‡è®­ç»ƒé“¾è·¯æµ‹è¯•")
    parser.add_argument("--export-conf", action="store_true", help="å¯¼å‡ºå¤šå°ºåº¦ç½®ä¿¡åº¦å›¾")
    parser.add_argument("--out-dir", default="output/mgm_conf_out", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--rgb", default="MGM_Mask2Former/input/DEPTH_NOISE/RGB/3521_7843763521_100_scene_000000_002186_v1.png", help="çœŸå®RGBè·¯å¾„ï¼Œå¯é€‰")
    parser.add_argument("--depth", default="MGM_Mask2Former/input/DEPTH_NOISE/DEPTH/3521_7843763521_100_scene_000000_002186_v1.npy", help="çœŸå®Depthè·¯å¾„ï¼Œå¯é€‰(npyæˆ–å›¾åƒ)")
    parser.add_argument(
        "--resize-input", type=int, default=None, help="è¯»å–çœŸå®å›¾åƒæ—¶é™åˆ¶æœ€é•¿è¾¹"
    )
    parser.add_argument(
        "--depth-noise-ratio",
        type=float,
        default=0.5,
        help="éšæœºç”Ÿæˆæ—¶å™ªå£°maskæ¯”ä¾‹ä¼°è®¡ (0~1)",
    )
    args = parser.parse_args()

    cfg = build_cfg(args.cfg, device=args.device)

    # æ„å»ºæ¨¡å‹
    model_kwargs = MGMMaskFormer.from_config(cfg)
    model = MGMMaskFormer(**model_kwargs).to(cfg.MODEL.DEVICE)

    # åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆå¦‚æœæä¾›ï¼‰
    if args.weights and os.path.isfile(args.weights):
        print(f"ğŸ”„ åŠ è½½æƒé‡: {args.weights}")
        # Detectron2 å…¼å®¹
        checkpointer = DetectionCheckpointer(model)
        extra = checkpointer.load(args.weights)
        print(
            f"æƒé‡åŠ è½½å®Œæˆ (keys={len(model.state_dict())}), extra={list(extra.keys())}"
        )
    else:
        print("âš  æœªæä¾›æœ‰æ•ˆæƒé‡è·¯å¾„ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–å‚æ•°ã€‚")

    # å‚æ•°ç»Ÿè®¡
    print("\nğŸ” æ­£åœ¨åˆ†ææ¨¡å‹å‚æ•°...")
    param_stats = count_parameters(model, detailed=args.detailed_stats)

    # è®­ç»ƒ smokeï¼ˆå¯é€‰ï¼‰
    if not args.no_train:
        model.train()
        if args.rgb and args.depth:
            batch = build_batch_from_files(
                args.rgb,
                args.depth,
                device=cfg.MODEL.DEVICE,
                noise_mask=True,
                resize=args.resize_input,
            )
            # è‹¥åªå•å›¾ï¼Œä½† batch>1ï¼Œå¤åˆ¶
            if args.batch > 1:
                batch = batch * args.batch
        else:
            batch = make_fake_batch(
                B=args.batch,
                H=args.size,
                W=args.size,
                with_targets=True,
                with_noise_mask=True,
                device=cfg.MODEL.DEVICE,
                depth_noise_ratio=args.depth_noise_ratio,
            )
        batch = attach_targets(batch, cfg.MODEL.SEM_SEG_HEAD.NUM_CLASSES)
        losses = model(batch)
        loss_sum = sum(v for v in losses.values())
        print(
            "[train] losses:",
            {k: float(v.detach().cpu()) for k, v in losses.items()},
        )
        loss_sum.backward()
        print("[train] backward ok, total loss =", float(loss_sum.detach().cpu()))
    else:
        print("â­ è·³è¿‡è®­ç»ƒé“¾è·¯æµ‹è¯• (--no-train)")

    # æ¨ç†å¹¶æŠ½å– MGM ç½®ä¿¡åº¦
    model.eval()
    if args.rgb and args.depth:
        infer_inputs = build_batch_from_files(
            args.rgb,
            args.depth,
            device=cfg.MODEL.DEVICE,
            noise_mask=True,
            resize=args.resize_input,
        )
        if args.batch > 1:
            infer_inputs = infer_inputs * args.batch
    else:
        infer_inputs = make_fake_batch(
            B=args.batch,
            H=args.size,
            W=args.size,
            with_targets=False,
            with_noise_mask=True,
            device=cfg.MODEL.DEVICE,
            depth_noise_ratio=args.depth_noise_ratio,
        )

    with torch.no_grad():
        # æ­£å¸¸ forward (è·å¾—å®ä¾‹/åˆ†å‰²ç­‰)
        outputs = model(infer_inputs)
        print("[eval] num outputs:", len(outputs))
        for i, out in enumerate(outputs):
            print(f"[eval] sample {i} keys:", list(out.keys()))
            if "instances" in out:
                inst = out["instances"]
                print(
                    f"  instances: {len(inst)} masks={getattr(inst,'pred_masks',None) is not None}"
                )

        # æå– MGM confidence maps
        per_image_conf, depths, noise_masks = extract_mgm_confidence(
            model, infer_inputs, upsample=True
        )

    # ç»Ÿè®¡å¯¹æ¯”
    confidence_statistics(per_image_conf, depths, noise_masks, z_min=0.0, z_max=1.0)

    # å¯¼å‡º
    if args.export_conf:
        save_confidence_maps(
            per_image_conf, depths, noise_masks, out_dir=args.out_dir, prefix="img"
        )
        print(f"âœ… ç½®ä¿¡åº¦å›¾å·²ä¿å­˜åˆ°: {args.out_dir}")

    print("\n" + "=" * 80)
    print("æµ‹è¯•å®Œæˆ - å‚æ•°ç»Ÿè®¡æ‘˜è¦")
    print("=" * 80)
    print(f"âœ… æ¨¡å‹æ€»å‚æ•°: {param_stats['total_params']:,}")
    print(f"âœ… å¯è®­ç»ƒå‚æ•°: {param_stats['trainable_params']:,}")
    print(f"âœ… æ¨¡å‹å¤§å°: {param_stats['model_size_mb']:.2f} MB")
    print("âœ… è®­ç»ƒ/æ¨ç†æµ‹è¯•:", "è·³è¿‡" if args.no_train else "é€šè¿‡")
    print("âœ… MGM å¤šå°ºåº¦ç½®ä¿¡åº¦æå–: å·²å®Œæˆ")
    print("Smoke test + Confidence export passed âœ”")


if __name__ == "__main__":
    main()
