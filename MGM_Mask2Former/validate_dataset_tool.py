#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®é›†éªŒè¯ç»¼åˆå·¥å…·
åŠŸèƒ½ï¼šæ•°æ®é›†æ³¨å†Œ + å®Œæ•´æ€§æ£€æŸ¥ + å¯è§†åŒ–éªŒè¯

è¾“å…¥ï¼šæ•°æ®é›†é…ç½®å‚æ•°
è¾“å‡ºï¼šéªŒè¯æŠ¥å‘Š + å¯è§†åŒ–æ ·æœ¬ + è®­ç»ƒé…ç½®å»ºè®®

ä½¿ç”¨æ–¹æ³•: python validate_dataset_tool.py --dataset-name my_dataset --data-root datasets/my_dataset

è¿™ä¸ªå·¥å…·æ•´åˆäº†åŸæ¥çš„ä¸‰ä¸ªè„šæœ¬åŠŸèƒ½ï¼š
1. æ•°æ®é›†æ³¨å†Œå’ŒéªŒè¯ï¼ˆåŸregister_custom_dataset.pyï¼‰
2. æ•°æ®é›†å®Œæ•´æ€§æ£€æŸ¥å’Œç»Ÿè®¡åˆ†æï¼ˆåŸvisualize_dataset.pyï¼‰  
3. ç”Ÿæˆè®­ç»ƒé…ç½®å»ºè®®ï¼ˆåŸgenerate_config.pyçš„æ ¸å¿ƒåŠŸèƒ½ï¼‰
"""

import os
import sys
import cv2
import json
import argparse
import numpy as np
import random
from pathlib import Path
from typing import Dict, List, Optional

# Detectron2 imports
from detectron2.data import DatasetCatalog, MetadataCatalog
from detectron2.data.datasets.coco import register_coco_instances
from detectron2.utils.visualizer import Visualizer

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from mask2former.data.datasets.register_coco_rgbd_instance import register_coco_rgbd_instances


class DatasetValidator:
    """æ•°æ®é›†éªŒè¯å™¨ - æ•´åˆæ‰€æœ‰éªŒè¯åŠŸèƒ½"""
    
    def __init__(self, dataset_name: str, data_root: str, categories: List[Dict]):
        self.dataset_name = dataset_name
        self.data_root = Path(data_root)
        self.categories = categories
        self.validation_results = {}
        
    def get_metadata(self):
        """è·å–æ•°æ®é›†å…ƒæ•°æ®"""
        thing_ids = [cat["id"] for cat in self.categories]
        thing_dataset_id_to_contiguous_id = {k: i for i, k in enumerate(thing_ids)}
        thing_classes = [cat["name"] for cat in self.categories]
        
        return {
            "thing_dataset_id_to_contiguous_id": thing_dataset_id_to_contiguous_id,
            "thing_classes": thing_classes,
        }
    
    def check_dataset_structure(self) -> bool:
        """æ£€æŸ¥æ•°æ®é›†ç›®å½•ç»“æ„"""
        print("ğŸ” æ£€æŸ¥æ•°æ®é›†ç»“æ„...")
        
        required_structure = {
            "images/train": "è®­ç»ƒå›¾åƒç›®å½•",
            "images/val": "éªŒè¯å›¾åƒç›®å½•", 
            "annotations/instances_train.json": "è®­ç»ƒæ ‡æ³¨æ–‡ä»¶",
            "annotations/instances_val.json": "éªŒè¯æ ‡æ³¨æ–‡ä»¶"
        }
        
        optional_structure = {
            "depth/train": "è®­ç»ƒæ·±åº¦å›¾åƒç›®å½•",
            "depth/val": "éªŒè¯æ·±åº¦å›¾åƒç›®å½•"
        }
        
        structure_ok = True
        has_depth = True
        
        # æ£€æŸ¥å¿…éœ€æ–‡ä»¶
        for path, desc in required_structure.items():
            full_path = self.data_root / path
            if full_path.exists():
                print(f"  âœ… {desc}: {full_path}")
            else:
                print(f"  âŒ {desc}: {full_path} (ç¼ºå¤±)")
                structure_ok = False
        
        # æ£€æŸ¥å¯é€‰æ–‡ä»¶ï¼ˆæ·±åº¦æ•°æ®ï¼‰
        for path, desc in optional_structure.items():
            full_path = self.data_root / path
            if full_path.exists():
                print(f"  âœ… {desc}: {full_path}")
            else:
                print(f"  âš ï¸  {desc}: {full_path} (å¯é€‰ï¼ŒRGB-Dæ¨¡å¼éœ€è¦)")
                has_depth = False
        
        self.validation_results['structure_ok'] = structure_ok
        self.validation_results['has_depth'] = has_depth
        return structure_ok
    
    def validate_annotations(self) -> bool:
        """éªŒè¯æ ‡æ³¨æ–‡ä»¶æ ¼å¼"""
        print("\nğŸ“‹ éªŒè¯æ ‡æ³¨æ–‡ä»¶...")
        
        annotation_files = {
            "train": self.data_root / "annotations/instances_train.json",
            "val": self.data_root / "annotations/instances_val.json"
        }
        
        annotations_ok = True
        dataset_stats = {}
        
        for split, ann_file in annotation_files.items():
            if not ann_file.exists():
                continue
                
            try:
                with open(ann_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # æ£€æŸ¥å¿…éœ€å­—æ®µ
                required_fields = ['images', 'annotations', 'categories']
                missing_fields = [field for field in required_fields if field not in data]
                
                if missing_fields:
                    print(f"  âŒ {split}: ç¼ºå°‘å­—æ®µ {missing_fields}")
                    annotations_ok = False
                    continue
                
                # ç»Ÿè®¡ä¿¡æ¯
                num_images = len(data['images'])
                num_annotations = len(data['annotations'])
                num_categories = len(data['categories'])
                
                print(f"  âœ… {split}: {num_images} å›¾åƒ, {num_annotations} æ ‡æ³¨, {num_categories} ç±»åˆ«")
                
                dataset_stats[split] = {
                    'num_images': num_images,
                    'num_annotations': num_annotations,
                    'num_categories': num_categories,
                    'avg_annotations_per_image': num_annotations / num_images if num_images > 0 else 0
                }
                
                # æ£€æŸ¥å›¾åƒæ–‡ä»¶æ˜¯å¦å­˜åœ¨
                image_dir = self.data_root / f"images/{split}"
                missing_images = 0
                for img_info in data['images'][:10]:  # åªæ£€æŸ¥å‰10ä¸ª
                    img_path = image_dir / img_info['file_name']
                    if not img_path.exists():
                        missing_images += 1
                
                if missing_images > 0:
                    print(f"    âš ï¸  å‘ç° {missing_images}/10 ä¸ªå›¾åƒæ–‡ä»¶ç¼ºå¤±ï¼ˆæŠ½æ ·æ£€æŸ¥ï¼‰")
                
            except Exception as e:
                print(f"  âŒ {split}: æ ‡æ³¨æ–‡ä»¶è§£æé”™è¯¯ - {e}")
                annotations_ok = False
        
        self.validation_results['annotations_ok'] = annotations_ok
        self.validation_results['dataset_stats'] = dataset_stats
        return annotations_ok
    
    def register_datasets(self) -> bool:
        """æ³¨å†Œæ•°æ®é›†"""
        print("\nğŸ“ æ³¨å†Œæ•°æ®é›†...")
        
        metadata = self.get_metadata()
        registration_ok = True
        
        try:
            # æ³¨å†ŒRGBæ•°æ®é›†
            for split in ['train', 'val']:
                dataset_name = f"{self.dataset_name}_{split}"
                ann_file = self.data_root / f"annotations/instances_{split}.json"
                img_dir = self.data_root / f"images/{split}"
                
                if ann_file.exists() and img_dir.exists():
                    register_coco_instances(
                        dataset_name,
                        metadata,
                        str(ann_file),
                        str(img_dir)
                    )
                    print(f"  âœ… å·²æ³¨å†ŒRGBæ•°æ®é›†: {dataset_name}")
            
            # å¦‚æœæœ‰æ·±åº¦æ•°æ®ï¼Œæ³¨å†ŒRGB-Dæ•°æ®é›†
            if self.validation_results.get('has_depth', False):
                for split in ['train', 'val']:
                    dataset_name = f"{self.dataset_name}_rgbd_{split}"
                    ann_file = self.data_root / f"annotations/instances_{split}.json"
                    img_dir = self.data_root / f"images/{split}"
                    depth_dir = self.data_root / f"depth/{split}"
                    
                    if all(p.exists() for p in [ann_file, img_dir, depth_dir]):
                        register_coco_rgbd_instances(
                            dataset_name,
                            metadata,
                            str(ann_file),
                            str(img_dir),
                            str(depth_dir)
                        )
                        print(f"  âœ… å·²æ³¨å†ŒRGB-Dæ•°æ®é›†: {dataset_name}")
            
        except Exception as e:
            print(f"  âŒ æ•°æ®é›†æ³¨å†Œå¤±è´¥: {e}")
            registration_ok = False
        
        self.validation_results['registration_ok'] = registration_ok
        return registration_ok
    
    def analyze_dataset_statistics(self):
        """åˆ†ææ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        print("\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡åˆ†æ...")
        
        for split in ['train', 'val']:
            dataset_name = f"{self.dataset_name}_{split}"
            
            try:
                dataset_dicts = DatasetCatalog.get(dataset_name)
                metadata = MetadataCatalog.get(dataset_name)
                
                print(f"\n{split.upper()}é›†ç»Ÿè®¡:")
                print(f"  - å›¾åƒæ€»æ•°: {len(dataset_dicts)}")
                
                # ç±»åˆ«ç»Ÿè®¡
                category_counts = {}
                image_sizes = []
                annotation_areas = []
                
                for d in dataset_dicts:
                    # å›¾åƒå°ºå¯¸
                    if "height" in d and "width" in d:
                        image_sizes.append((d["width"], d["height"]))
                    
                    # æ ‡æ³¨ç»Ÿè®¡
                    if "annotations" in d:
                        for ann in d["annotations"]:
                            cat_id = ann["category_id"]
                            if cat_id in metadata.thing_dataset_id_to_contiguous_id:
                                contiguous_id = metadata.thing_dataset_id_to_contiguous_id[cat_id]
                                cat_name = metadata.thing_classes[contiguous_id]
                                category_counts[cat_name] = category_counts.get(cat_name, 0) + 1
                            
                            if "area" in ann:
                                annotation_areas.append(ann["area"])
                
                # æ˜¾ç¤ºç±»åˆ«åˆ†å¸ƒ
                total_annotations = sum(category_counts.values())
                print(f"  - æ ‡æ³¨æ€»æ•°: {total_annotations}")
                
                for cat_name, count in sorted(category_counts.items()):
                    percentage = count / total_annotations * 100 if total_annotations > 0 else 0
                    print(f"    {cat_name}: {count} ({percentage:.1f}%)")
                
                # å›¾åƒå°ºå¯¸ç»Ÿè®¡
                if image_sizes:
                    widths = [size[0] for size in image_sizes]
                    heights = [size[1] for size in image_sizes]
                    print(f"  - å›¾åƒå°ºå¯¸èŒƒå›´: {min(widths)}x{min(heights)} ~ {max(widths)}x{max(heights)}")
                
            except Exception as e:
                print(f"  âŒ {split}é›†åˆ†æå¤±è´¥: {e}")
    
    def visualize_samples(self, num_samples: int = 3, save_dir: Optional[str] = None):
        """å¯è§†åŒ–æ•°æ®é›†æ ·æœ¬"""
        print(f"\nğŸ¨ å¯è§†åŒ–æ•°æ®é›†æ ·æœ¬...")
        
        if save_dir:
            os.makedirs(save_dir, exist_ok=True)
        
        for split in ['train', 'val']:
            dataset_name = f"{self.dataset_name}_{split}"
            
            try:
                dataset_dicts = DatasetCatalog.get(dataset_name)
                metadata = MetadataCatalog.get(dataset_name)
                
                if not dataset_dicts:
                    continue
                
                samples = random.sample(dataset_dicts, min(num_samples, len(dataset_dicts)))
                
                for i, d in enumerate(samples):
                    # è¯»å–RGBå›¾åƒ
                    img = cv2.imread(d["file_name"])
                    if img is None:
                        continue
                    
                    # å¯è§†åŒ–æ ‡æ³¨
                    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, scale=1.0)
                    if "annotations" in d:
                        vis = visualizer.draw_dataset_dict(d)
                    else:
                        vis = visualizer.get_output()
                    
                    result_img = vis.get_image()[:, :, ::-1]
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ·±åº¦å›¾åƒ
                    has_depth_sample = False
                    if f"{self.dataset_name}_rgbd_{split}" in DatasetCatalog.list():
                        rgbd_dataset_dicts = DatasetCatalog.get(f"{self.dataset_name}_rgbd_{split}")
                        for rgbd_d in rgbd_dataset_dicts:
                            if rgbd_d["file_name"] == d["file_name"] and "depth_file_name" in rgbd_d:
                                depth_img = cv2.imread(rgbd_d["depth_file_name"], cv2.IMREAD_UNCHANGED)
                                if depth_img is not None:
                                    # æ·±åº¦å›¾å¯è§†åŒ–
                                    depth_normalized = np.zeros_like(depth_img, dtype=np.uint8)
                                    cv2.normalize(depth_img, depth_normalized, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)
                                    depth_colored = cv2.applyColorMap(depth_normalized, cv2.COLORMAP_JET)
                                    
                                    # ç»„åˆRGBå’Œæ·±åº¦å›¾
                                    h, w = img.shape[:2]
                                    combined = np.zeros((h, w*2, 3), dtype=np.uint8)
                                    combined[:, :w] = result_img
                                    combined[:, w:] = depth_colored
                                    result_img = combined
                                    has_depth_sample = True
                                break
                    
                    # ä¿å­˜æˆ–æ˜¾ç¤º
                    title = f"{split}_sample_{i+1}" + ("_rgbd" if has_depth_sample else "_rgb")
                    
                    if save_dir:
                        save_path = os.path.join(save_dir, f"{title}.jpg")
                        cv2.imwrite(save_path, result_img)
                        print(f"  ğŸ’¾ å·²ä¿å­˜: {save_path}")
                    else:
                        cv2.imshow(title, result_img)
                        
                if not save_dir:
                    print("  ğŸ‘ï¸  æŒ‰ä»»æ„é”®æŸ¥çœ‹ä¸‹ä¸€ç»„æ ·æœ¬...")
                    cv2.waitKey(0)
                    
            except Exception as e:
                print(f"  âŒ {split}é›†å¯è§†åŒ–å¤±è´¥: {e}")
        
        if not save_dir:
            cv2.destroyAllWindows()
    
    def generate_training_suggestions(self) -> Dict:
        """ç”Ÿæˆè®­ç»ƒé…ç½®å»ºè®®"""
        print("\nğŸ’¡ ç”Ÿæˆè®­ç»ƒé…ç½®å»ºè®®...")
        
        stats = self.validation_results.get('dataset_stats', {})
        has_depth = self.validation_results.get('has_depth', False)
        
        suggestions = {
            'dataset_info': {
                'name': self.dataset_name,
                'num_classes': len(self.categories),
                'has_depth_data': has_depth,
                'recommended_modes': ['RGB'] + (['RGB-D'] if has_depth else [])
            },
            'training_config': {}
        }
        
        # æ ¹æ®æ•°æ®é›†å¤§å°æ¨èè®­ç»ƒå‚æ•°
        train_stats = stats.get('train', {})
        if train_stats:
            num_images = train_stats['num_images']
            
            # æ¨èbatch size
            if has_depth:
                batch_size = 4 if num_images > 1000 else 2
            else:
                batch_size = 8 if num_images > 1000 else 4
            
            # æ¨èè®­ç»ƒè¿­ä»£æ•°
            epochs = 50 if num_images < 5000 else 30
            max_iter = max(1000, (num_images // batch_size) * epochs)
            
            suggestions['training_config'] = {
                'batch_size_rgb': 8 if num_images > 1000 else 4,
                'batch_size_rgbd': 4 if num_images > 1000 else 2,
                'max_iter': max_iter,
                'learning_rate': 0.0001,
                'image_size': 1024 if num_images > 2000 else 512
            }
        
        # æ‰“å°å»ºè®®
        print(f"  ğŸ“‹ æ•°æ®é›†ä¿¡æ¯:")
        print(f"    - æ•°æ®é›†åç§°: {suggestions['dataset_info']['name']}")
        print(f"    - ç±»åˆ«æ•°é‡: {suggestions['dataset_info']['num_classes']}")
        print(f"    - æ”¯æŒæ¨¡å¼: {', '.join(suggestions['dataset_info']['recommended_modes'])}")
        
        if suggestions['training_config']:
            print(f"  âš™ï¸  è®­ç»ƒé…ç½®å»ºè®®:")
            config = suggestions['training_config']
            print(f"    - RGBæ‰¹æ¬¡å¤§å°: {config['batch_size_rgb']}")
            if has_depth:
                print(f"    - RGB-Dæ‰¹æ¬¡å¤§å°: {config['batch_size_rgbd']}")
            print(f"    - æœ€å¤§è¿­ä»£æ•°: {config['max_iter']}")
            print(f"    - å­¦ä¹ ç‡: {config['learning_rate']}")
            print(f"    - å›¾åƒå¤§å°: {config['image_size']}")
        
        return suggestions
    
    def print_usage_instructions(self, suggestions: Dict):
        """æ‰“å°ä½¿ç”¨è¯´æ˜"""
        print(f"\nğŸ“– ä½¿ç”¨è¯´æ˜:")
        print(f"ç°åœ¨ä½ å¯ä»¥åœ¨train_net.pyä¸­æ·»åŠ ä»¥ä¸‹æ³¨å†Œä»£ç ï¼š")
        print(f"")
        print(f"# åœ¨train_net.pyå¼€å¤´æ·»åŠ æ•°æ®é›†æ³¨å†Œ")
        print(f"def register_custom_dataset():")
        print(f"    from detectron2.data.datasets.coco import register_coco_instances")
        print(f"    metadata = {{")
        print(f"        'thing_dataset_id_to_contiguous_id': {self.get_metadata()['thing_dataset_id_to_contiguous_id']},")
        print(f"        'thing_classes': {self.get_metadata()['thing_classes']}")
        print(f"    }}")
        print(f"    ")
        print(f"    # RGBæ•°æ®é›†")
        print(f"    register_coco_instances('{self.dataset_name}_train', metadata, '{self.data_root}/annotations/instances_train.json', '{self.data_root}/images/train')")
        print(f"    register_coco_instances('{self.dataset_name}_val', metadata, '{self.data_root}/annotations/instances_val.json', '{self.data_root}/images/val')")
        
        if suggestions['dataset_info']['has_depth_data']:
            print(f"    ")
            print(f"    # RGB-Dæ•°æ®é›†")
            print(f"    from mask2former.data.datasets.register_coco_rgbd_instance import register_coco_rgbd_instances")
            print(f"    register_coco_rgbd_instances('{self.dataset_name}_rgbd_train', metadata, '{self.data_root}/annotations/instances_train.json', '{self.data_root}/images/train', '{self.data_root}/depth/train')")
            print(f"    register_coco_rgbd_instances('{self.dataset_name}_rgbd_val', metadata, '{self.data_root}/annotations/instances_val.json', '{self.data_root}/images/val', '{self.data_root}/depth/val')")
        
        print(f"")
        print(f"register_custom_dataset()  # åœ¨main()å‡½æ•°ä¹‹å‰è°ƒç”¨")
        print(f"")
        print(f"é…ç½®æ–‡ä»¶ä¸­è®¾ç½®ï¼š")
        print(f"DATASETS:")
        print(f"  TRAIN: ('{self.dataset_name}_train',)")
        print(f"  TEST: ('{self.dataset_name}_val',)")
        print(f"MODEL:")
        print(f"  SEM_SEG_HEAD:")
        print(f"    NUM_CLASSES: {len(self.categories)}")
        
        if suggestions['training_config']:
            config = suggestions['training_config']
            print(f"SOLVER:")
            print(f"  IMS_PER_BATCH: {config['batch_size_rgb']}")
            print(f"  MAX_ITER: {config['max_iter']}")
            print(f"INPUT:")
            print(f"  IMAGE_SIZE: {config['image_size']}")
            print(f"  DATASET_MAPPER_NAME: 'coco_instance_lsj'  # RGBæ¨¡å¼")
    
    def run_validation(self, visualize: bool = True, save_samples: Optional[str] = None) -> bool:
        """è¿è¡Œå®Œæ•´éªŒè¯æµç¨‹"""
        print(f"ğŸš€ å¼€å§‹éªŒè¯æ•°æ®é›†: {self.dataset_name}")
        print(f"ğŸ“ æ•°æ®æ ¹ç›®å½•: {self.data_root}")
        print(f"=" * 60)
        
        # æ­¥éª¤1: æ£€æŸ¥ç›®å½•ç»“æ„
        if not self.check_dataset_structure():
            print("âŒ æ•°æ®é›†ç»“æ„æ£€æŸ¥å¤±è´¥")
            return False
        
        # æ­¥éª¤2: éªŒè¯æ ‡æ³¨æ–‡ä»¶
        if not self.validate_annotations():
            print("âŒ æ ‡æ³¨æ–‡ä»¶éªŒè¯å¤±è´¥")
            return False
        
        # æ­¥éª¤3: æ³¨å†Œæ•°æ®é›†
        if not self.register_datasets():
            print("âŒ æ•°æ®é›†æ³¨å†Œå¤±è´¥")
            return False
        
        # æ­¥éª¤4: ç»Ÿè®¡åˆ†æ
        self.analyze_dataset_statistics()
        
        # æ­¥éª¤5: å¯è§†åŒ–éªŒè¯
        if visualize:
            self.visualize_samples(save_dir=save_samples)
        
        # æ­¥éª¤6: ç”Ÿæˆå»ºè®®
        suggestions = self.generate_training_suggestions()
        
        # æ­¥éª¤7: æ‰“å°ä½¿ç”¨è¯´æ˜
        self.print_usage_instructions(suggestions)
        
        print(f"\nâœ… æ•°æ®é›†éªŒè¯å®Œæˆï¼æ•°æ®é›†å¯ç”¨äºè®­ç»ƒã€‚")
        return True


def main():
    parser = argparse.ArgumentParser(
        description="æ•°æ®é›†éªŒè¯ç»¼åˆå·¥å…·",
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python validate_dataset_tool.py --dataset-name my_dataset --data-root datasets/my_dataset --categories person,vehicle
  python validate_dataset_tool.py --dataset-name custom_data --data-root /path/to/data --config categories.json --save-samples output/samples
        """,
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument("--dataset-name", required=True, help="æ•°æ®é›†åç§°")
    parser.add_argument("--data-root", required=True, help="æ•°æ®é›†æ ¹ç›®å½•è·¯å¾„")
    parser.add_argument("--categories", help="ç±»åˆ«åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”ï¼Œå¦‚: person,vehicle,object")
    parser.add_argument("--config", help="ç±»åˆ«é…ç½®JSONæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--no-visualize", action="store_true", help="è·³è¿‡å¯è§†åŒ–æ­¥éª¤")
    parser.add_argument("--save-samples", help="ä¿å­˜å¯è§†åŒ–æ ·æœ¬çš„ç›®å½•ï¼ˆå¦‚æœä¸æŒ‡å®šåˆ™æ˜¾ç¤ºï¼‰")
    
    args = parser.parse_args()
    
    # è§£æç±»åˆ«ä¿¡æ¯
    categories = []
    if args.config:
        with open(args.config, 'r', encoding='utf-8') as f:
            categories = json.load(f)
    elif args.categories:
        cat_names = args.categories.split(',')
        categories = [
            {"id": i+1, "name": name.strip(), "supercategory": name.strip()}
            for i, name in enumerate(cat_names)
        ]
    else:
        print("âŒ è¯·æä¾›ç±»åˆ«ä¿¡æ¯ï¼ˆ--categories æˆ– --configï¼‰")
        return False
    
    # åˆ›å»ºéªŒè¯å™¨å¹¶è¿è¡Œ
    validator = DatasetValidator(args.dataset_name, args.data_root, categories)
    success = validator.run_validation(
        visualize=not args.no_visualize,
        save_samples=args.save_samples
    )
    
    if success:
        print("âœ… æ•°æ®é›†éªŒè¯æˆåŠŸ")
    else:
        print("âŒ æ•°æ®é›†éªŒè¯å¤±è´¥")


if __name__ == "__main__":
    main()
