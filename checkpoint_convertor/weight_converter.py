import torch
from convnext_depth_backbone import ConvNeXtDepthBackbone


def load_and_convert_weights(checkpoint_path, output_path):
    """
    è½¬æ¢æ–°çš„å®˜æ–¹æƒé‡ (convnext_tiny_22k_224.pth)
    """
    print("Loading official ConvNeXt checkpoint...")
    checkpoint = torch.load(
        checkpoint_path, map_location='cpu', weights_only=False)

    original_state_dict = checkpoint['model']

    print("Converting weights...")
    new_state_dict = {}

    for key, value in original_state_dict.items():
        # ç‰¹æ®Šå¤„ç†ç¬¬ä¸€å±‚å·ç§¯ (3é€šé“â†’1é€šé“)
        if key == 'downsample_layers.0.0.weight' and value.shape[1] == 3:
            # å–RGBä¸‰é€šé“çš„å¹³å‡å€¼
            new_value = value.mean(dim=1, keepdim=True)
            new_state_dict[key] = new_value
            print(f"âœ“ Converted {key}: {value.shape} â†’ {new_value.shape}")

        # è·³è¿‡åˆ†ç±»å¤´å’Œå…¨å±€norm
        elif key.startswith('head.') or key == 'norm.weight' or key == 'norm.bias':
            print(f"âœ— Skipping: {key}")
            continue

        # ä¿ç•™æ‰€æœ‰å…¶ä»–æƒé‡
        else:
            new_state_dict[key] = value

    print(f"\nTotal converted parameters: {len(new_state_dict)}")

    # ä¿å­˜è½¬æ¢åçš„æƒé‡
    torch.save({
        'state_dict': new_state_dict,
        'meta': {
            'converted_from': checkpoint_path,
            'input_channels': 1,
            'architecture': 'ConvNeXt-Tiny-Depth-22K',
            'original_training': 'ImageNet-22K'
        }
    }, output_path)

    print(f"Converted weights saved to: {output_path}")
    return new_state_dict


def test_weight_loading(converted_path:str):
    """æµ‹è¯•æƒé‡åŠ è½½å’Œå‰å‘ä¼ æ’­"""
    print("\n" + "="*50)
    print("Testing weight loading and forward pass...")

    # 1. åˆ›å»ºæ¨¡å‹
    model = ConvNeXtDepthBackbone(in_chans=1)
    print(f"âœ“ Model created")

    # 2. åŠ è½½è½¬æ¢åçš„æƒé‡
    converted_weights = torch.load(
        converted_path, map_location='cpu', weights_only=False)
    missing, unexpected = model.load_state_dict(
        converted_weights['state_dict'], strict=False)

    print(f"âœ“ Weights loaded")
    print(
        f"  Missing keys: {len(missing)} - {missing[:3]}..." if missing else "  No missing keys")
    print(
        f"  Unexpected keys: {len(unexpected)} - {unexpected[:3]}..." if unexpected else "  No unexpected keys")

    # 3. æµ‹è¯•å‰å‘ä¼ æ’­
    model.eval()
    with torch.no_grad():
        # æ¨¡æ‹Ÿæ·±åº¦å›¾è¾“å…¥ (batch_size=2, channels=1, height=224, width=224)
        test_input = torch.randn(2, 1, 224, 224)
        print(f"âœ“ Test input shape: {test_input.shape}")

        # å‰å‘ä¼ æ’­
        outputs = model(test_input)

        print(f"âœ“ Forward pass successful!")
        print("Output features:")
        for name, tensor in outputs.items():
            print(f"  {name}: {tensor.shape}")

        # éªŒè¯è¾“å‡ºshapeæ˜¯å¦ç¬¦åˆæœŸæœ›
        expected_shapes = {
            "res2": (2, 96, 56, 56),   # H/4, W/4
            "res3": (2, 192, 28, 28),  # H/8, W/8
            "res4": (2, 384, 14, 14),  # H/16, W/16
            "res5": (2, 768, 7, 7)     # H/32, W/32
        }

        all_correct = True
        for name, expected_shape in expected_shapes.items():
            actual_shape = outputs[name].shape
            if actual_shape == expected_shape:
                print(f"  âœ“ {name}: {actual_shape} (correct)")
            else:
                print(f"  âœ— {name}: {actual_shape} (expected {expected_shape})")
                all_correct = False

        if all_correct:
            print("ğŸ‰ All output shapes are correct!")
        else:
            print("âŒ Some output shapes are incorrect!")

    return model, outputs


if __name__ == "__main__":
    # è½¬æ¢æƒé‡
    original_path = "test/convnext-checkpoint/convnext-tiny_3rdparty_32xb128-noema_in1k_20220301-795e9634.pth"
    converted_path = "test/convnext-checkpoint/convnext_tiny_depth_22k_converted.pth"

    # æ‰§è¡Œè½¬æ¢
    load_and_convert_weights(original_path, converted_path)

    # æµ‹è¯•åŠ è½½å’Œå‰å‘ä¼ æ’­
    model, outputs = test_weight_loading(converted_path)
