import torch


def load_and_convert_weights(checkpoint_path, output_path):
    """
    è½¬æ¢ConvNeXtå®˜æ–¹æƒé‡ä¸ºdepthè¾“å…¥ç‰ˆæœ¬
    """
    print("Loading official ConvNeXt checkpoint...")
    checkpoint = torch.load(
        checkpoint_path, map_location='cpu', weights_only=True)

    original_state_dict = checkpoint['model']
    print(f"âœ“ Found state_dict with {len(original_state_dict)} parameters")

    print("\n=== Converting weights ===")
    new_state_dict = {}
    skipped_count = 0
    converted_count = 0

    for key, value in original_state_dict.items():
        # ç‰¹æ®Šå¤„ç†ç¬¬ä¸€å±‚å·ç§¯ (3é€šé“â†’1é€šé“)
        if key == 'downsample_layers.0.0.weight' and value.shape[1] == 3:
            new_value = value.mean(dim=1, keepdim=True)
            new_state_dict[key] = new_value
            print(f"âœ“ Converted {key}: {value.shape} â†’ {new_value.shape}")
            converted_count += 1

        # è·³è¿‡åˆ†ç±»å¤´å’Œå…¨å±€norm
        elif key.startswith('head.') or key == 'norm.weight' or key == 'norm.bias':
            print(f"âœ— Skipping {key}: {value.shape}")
            skipped_count += 1
            continue

        # ä¿ç•™æ‰€æœ‰å…¶ä»–æƒé‡
        else:
            new_state_dict[key] = value
            converted_count += 1

    print(f"\nâœ“ Conversion summary:")
    print(f"  - Converted parameters: {converted_count}")
    print(f"  - Skipped parameters: {skipped_count}")
    print(f"  - Total output parameters: {len(new_state_dict)}")

    # ä¿å­˜è½¬æ¢åçš„æƒé‡
    torch.save({
        'state_dict': new_state_dict,
        'meta': {
            'converted_from': checkpoint_path,
            'input_channels': 1,
            'architecture': 'ConvNeXt-Tiny-Depth-22K',
            'original_params': len(original_state_dict),
            'converted_params': len(new_state_dict)
        }
    }, output_path)

    print(f"âœ“ Converted weights saved to: {output_path}")
    return new_state_dict


def test_weight_loading():
    """æµ‹è¯•æƒé‡åŠ è½½å’Œå‰å‘ä¼ æ’­"""
    print("\n" + "="*60)
    print("Testing weight loading and forward pass...")

    from convnext_depth_backbone import ConvNeXtDepthBackbone

    # 1. åˆ›å»ºæ¨¡å‹
    model = ConvNeXtDepthBackbone(in_chans=1)
    print(f"âœ“ Model created")

    # æ‰“å°æ¨¡å‹å‚æ•°æ•°é‡ç”¨äºå¯¹æ¯”
    total_params = sum(p.numel() for p in model.parameters())
    print(f"  Model has {total_params:,} parameters")

    # 2. åŠ è½½è½¬æ¢åçš„æƒé‡
    converted_path = 'test/convnext-checkpoint/convnext_tiny_depth_22k_converted.pth'
    converted_checkpoint = torch.load(
        converted_path, map_location='cpu', weights_only=True)
    converted_state_dict = converted_checkpoint['state_dict']

    missing, unexpected = model.load_state_dict(
        converted_state_dict, strict=False)

    print(f"âœ“ Weights loaded")
    print(f"  Missing keys: {len(missing)}")
    if missing:
        print(f"    Examples: {missing[:3]}...")
    print(f"  Unexpected keys: {len(unexpected)}")
    if unexpected:
        print(f"    Examples: {unexpected[:3]}...")

    # 3. æµ‹è¯•å‰å‘ä¼ æ’­
    model.eval()
    with torch.no_grad():
        test_input = torch.randn(2, 1, 224, 224)
        print(f"\nâœ“ Test input shape: {test_input.shape}")

        try:
            outputs = model(test_input)
            print(f"âœ“ Forward pass successful!")

            print("\nOutput features:")
            for name, tensor in outputs.items():
                print(f"  {name}: {tensor.shape}")

            # éªŒè¯shape
            expected_shapes = {
                "res2": (2, 96, 56, 56),    # stride=4
                "res3": (2, 192, 28, 28),   # stride=8
                "res4": (2, 384, 14, 14),   # stride=16
                "res5": (2, 768, 7, 7)      # stride=32
            }

            print("\nShape verification:")
            all_correct = True
            for name, expected_shape in expected_shapes.items():
                actual_shape = outputs[name].shape
                if actual_shape == expected_shape:
                    print(f"  âœ“ {name}: {actual_shape} (correct)")
                else:
                    print(
                        f"  âœ— {name}: {actual_shape} (expected {expected_shape})")
                    all_correct = False

            # æ£€æŸ¥è¾“å‡ºå€¼æ˜¯å¦åˆç†
            print("\nOutput value checks:")
            for name, tensor in outputs.items():
                mean_val = tensor.mean().item()
                std_val = tensor.std().item()
                min_val = tensor.min().item()
                max_val = tensor.max().item()
                print(
                    f"  {name}: mean={mean_val:.4f}, std={std_val:.4f}, range=[{min_val:.4f}, {max_val:.4f}]")

            if all_correct:
                print("\nğŸ‰ All tests passed! ConvNeXt depth backbone is ready!")
            else:
                print("\nâŒ Some shape mismatches detected!")

        except Exception as e:
            print(f"âŒ Forward pass failed: {e}")
            import traceback
            traceback.print_exc()

    return model, outputs if 'outputs' in locals() else None


if __name__ == "__main__":
    print("="*60)
    print("ConvNeXt Depth Backbone Weight Conversion")
    print("="*60)

    # è®¾ç½®è·¯å¾„
    original_path = "test/convnext-checkpoint/convnext_tiny_22k_224.pth"
    converted_path = "test/convnext-checkpoint/convnext_tiny_depth_22k_converted.pth"

    try:
        # Step 1: è½¬æ¢æƒé‡
        print("STEP 1: Converting weights")
        load_and_convert_weights(original_path, converted_path)

        # Step 2: æµ‹è¯•åŠ è½½å’Œå‰å‘ä¼ æ’­
        print("\nSTEP 2: Testing model")
        model, outputs = test_weight_loading()

        print("\n" + "="*60)
        print("Conversion and testing completed successfully!")
        print("Your ConvNeXt depth backbone is ready for integration.")
        print("="*60)

    except Exception as e:
        print(f"âŒ Error during conversion/testing: {e}")
        import traceback
        traceback.print_exc()
